### 基本的な解法について
- テキストを中心に予測をすることになる。
  - テキストの難しさとは何か？を考え抜くことになる。
- 一方、テキスト以外の情報から何を読み取るか？ モデルに組み込む事は可能か？ についても、後半戦において重要になると思われる。
  - standard_errorを特徴として組み込むか？ NNのモデルを組む場合の、第二の予測対象とするか？
  - url_legal, licenseを何かに活用できないか？
    - 例: グループ特徴として使う方針で、例えばtestのexperptからこれらを予測して、それでグルーピングした特徴を更に作成する、とか？
    - licenseから年代とか地域を取得して、それを予測するモデルを作れないか？

### 飛び道具的なアイディア
- ライセンス情報を予測するモデルを作るのもありか？
  - めんどいので、データで完結する部分を作ってから検討する。
  - 外部データ必須なので、同じこと考えてる人がいれば、Discussionの外部データスレに書かれるはず。

### 基本方針
- まずは手持ちの武器で勝負して、その後新しい手法をnotebook, Discussion, 必要に応じて書籍、外部サイトから学んでいく。
- すなわち…
  - モデルはLightGBMの回帰タスク
  - 特徴量は…
    - 統計量的な特徴
      - 簡単に作れる特徴
        - 文の長さ
        - 単語数
        - 単語の種類数
      - ちょっと工夫がいる？
        - 単語の長さのバリエーション
          - 分布を表せると良い。
            - とりあえず基本統計量を食わせる。
            - 尖度・歪度とか、細かいのは劣後とする。
    - 埋め込み系の特徴
      - TF-IDF & SVD
      - W2V
      - 学習ずみBERT(かえるさんのatma10のDiscussionを後で読む)
      - araisanさんのZennに記載の手法(後で読む)
- LightGBMで出来ることをやり尽くしたら、NNのモデル作成を試してみる。
  - experptを直接BERTとかで学習するかんじ？
  - なんとなく、上級者の皆さんは初手NNでやりそうなので、そのうちいい感じのbaseline-notebookが出回ると思われる。
  - standard_errorを考慮したtargetとかも、NNならやりやすそう

  

