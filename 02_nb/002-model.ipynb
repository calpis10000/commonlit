{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 002_model","metadata":{}},{"cell_type":"code","source":"# basic\nimport os\nimport gc\nimport sys\nimport yaml\nimport warnings\nimport random\nfrom pathlib import Path\nfrom glob import glob\nfrom tqdm import tqdm_notebook as tqdm\nimport hashlib\nimport pickle\nwarnings.filterwarnings('ignore')\n\n# usual\nimport numpy as np\nimport pandas as pd\nfrom datetime import datetime\nfrom datetime import timedelta\nimport re\n\n# preprocess\nfrom fasttext import load_model\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.pipeline import Pipeline\n#import texthero as hero\nimport nltk\nimport collections\nfrom gensim.models import word2vec, KeyedVectors\nimport cv2\n\n# LightGBM\nimport lightgbm as lgb\n#import optuna.integration.lightgbm as lgb  # チューニング用\n\n# visualization\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nimport seaborn as sns\nfrom pandas_profiling import ProfileReport  # profile report を作る用\n\n# preprocessing\nfrom sklearn.preprocessing import LabelEncoder\n\n# plot settings\nplt.rcParams[\"patch.force_edgecolor\"] = False\nplt.rcParams['font.family'] = 'sans_serif'\nsns.set(style=\"whitegrid\",  palette=\"muted\", color_codes=True, rc={'grid.linestyle': '--'})\nred = sns.xkcd_rgb[\"light red\"]\ngreen = sns.xkcd_rgb[\"medium green\"]\nblue = sns.xkcd_rgb[\"denim blue\"]\n\n# plot extentions\n#import japanize_matplotlib\nfrom matplotlib_venn import venn2\n\nfrom tqdm import tqdm\n","metadata":{"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"# 試験ID生成\ntrial_prefix = 'nb002'  # ←手動で指定 \ndttm_now = datetime.now().strftime('%Y%m%d_%H%M%S')\ntrial_id = f'{trial_prefix}_{dttm_now}'\n\nprint(trial_prefix)\nprint(trial_id)","metadata":{"trusted":true},"execution_count":76,"outputs":[{"name":"stdout","text":"nb002\nnb002_20210517_132144\n","output_type":"stream"}]},{"cell_type":"code","source":"# アウトプットの出力先指定\nif 'kaggle_web_client' in sys.modules:  # kaggle環境\n    OUTPUT_DIR = Path(\".\")\nelse:\n    OUTPUT_DIR = Path(f\"../03_outputs/{trial_prefix}\")\n    OUTPUT_DIR.mkdir(exist_ok=True, parents=True)","metadata":{"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"# seed固定\ndef set_seed(seed=2021):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n\nSEED = 2021\nset_seed(SEED)","metadata":{"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"# インプットフォルダ指定\nif 'kaggle_web_client' in sys.modules:  # kaggle環境\n    DATA_DIR = '../input/commonlitreadabilityprize/'\nelse:\n    DATA_DIR = '../00_input/commonlitreadabilityprize/'","metadata":{"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"# read_data\ntrain_base = pd.read_csv(DATA_DIR + 'train.csv')\ntest_base = pd.read_csv(DATA_DIR + 'test.csv')\nsample = pd.read_csv(DATA_DIR + 'sample_submission.csv')","metadata":{"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"markdown","source":"## excerptの加工\n- テキストの長さ\n- 単語数\n- 単語の種類数","metadata":{}},{"cell_type":"code","source":"# ローカルの場合、stopwordsをダウンロード\nimport nltk\nif 'kaggle_web_client' in sys.modules:  # kaggle環境\n    pass\nelse:\n    import nltk\n    nltk.download('stopwords')\n    os.listdir(os.path.expanduser('~/nltk_data/corpora/stopwords/'))","metadata":{"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"# テキスト前処理\n# https://www.kaggle.com/alaasedeeq/commonlit-readability-eda\nimport string\nimport re\n\n#filtering the unwanted symbols, spaces, ....etc\nto_replace_by_space = re.compile('[/(){}\\[\\]|@,;]')\npunctuation = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\nbad_symbols = re.compile('[^0-9a-z #+_]')\nstopwords = set(nltk.corpus.stopwords.words('english'))\n\ndef text_prepare(text):\n    '''\n    text: a string\n    returna modified version of the string\n    '''\n    text = text.lower() # lowercase text\n    text = re.sub(punctuation, '',text)\n    text = re.sub(to_replace_by_space, \" \", text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n    text = re.sub(bad_symbols, \"\", text)         # delete symbols which are in BAD_SYMBOLS_RE from text\n    text = \" \".join([word for word in text.split(\" \") if word not in stopwords]) # delete stopwords from text\n    text = re.sub(' +', ' ', text)\n    return text\n","metadata":{"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"def text_normalization(s:pd.Series):\n    x = s.apply(text_prepare)\n    return x\n\n# Counterオブジェクトを取得\ndef get_counter(text:str):\n    text_list = [wrd for wrd in text.split(\" \") if wrd not in ('', '\\n')]\n    counter = collections.Counter(text_list)\n    return counter","metadata":{"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"# ベースとなる継承元のクラス\nclass BaseBlock(object):\n    def fit(self, input_df, y=None):\n        return self.transform(input_df)\n    def transform(self, input_df):\n        raise NotImplementedError()","metadata":{"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"class TextDescriptionBlock(BaseBlock):\n    \"\"\"テキストに関する統計量を返す block\"\"\"\n    def __init__(self, column: str):\n        \"\"\"\n        args:\n            column: str\n                変換対象のカラム名\n        \"\"\"\n        self.column = column\n\n    # 前処理\n    def preprocess(self, input_df):\n        x = text_normalization(input_df[self.column])\n        return x\n        \n    def fit(self, input_df, y=None, n_components=50):\n        self.text = self.preprocess(input_df)\n        self.counters = self.text.map(get_counter)\n        return self.transform(input_df)\n\n    def transform(self, input_df):\n        _length = input_df[self.column].fillna('').map(lambda x: len(x) if x!='' else np.nan)\n        _wrd_cnt = self.counters.map(lambda x: sum(x.values()))\n        _wrd_nuniq = self.counters.map(lambda x: len(x))\n        _wrd_mean = self.counters.map(lambda x: np.mean(list(x.values())))\n        _wrd_max = self.counters.map(lambda x: np.max(list(x.values())))\n        \n        word_length = self.counters.map(lambda x: np.array([len(i) for i in x.keys()]))\n        word_length_desc = word_length.map(lambda x: pd.Series(x.ravel()).describe())\n        _word_length_desc_df = pd.DataFrame(word_length_desc.tolist()).iloc[:,1:]\n        _word_length_desc_df = _word_length_desc_df.add_prefix('word_length_')\n        \n        out_df = pd.concat([_length, _wrd_cnt, _wrd_nuniq, _wrd_mean, _wrd_max], axis=1)\n        out_df.columns = ['text_length', 'word_count', 'word_nunique', 'word_appearance_mean', 'word_appearance_max']\n        out_df = pd.concat([out_df, _word_length_desc_df], axis=1)\n        return out_df.add_suffix(f'_{self.column}')","metadata":{"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"markdown","source":"# make_feat","metadata":{}},{"cell_type":"code","source":"train_feat = TextDescriptionBlock('excerpt').fit(train_base)\ntrain_target = train_base['target'].copy()","metadata":{"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"train_feat.head()","metadata":{"trusted":true},"execution_count":87,"outputs":[{"execution_count":87,"output_type":"execute_result","data":{"text/plain":"   text_length_excerpt  word_count_excerpt  word_nunique_excerpt  \\\n0                  992                  89                    76   \n1                  937                  85                    75   \n2                  908                  83                    74   \n3                  909                  91                    82   \n4                  723                  70                    23   \n\n   word_appearance_mean_excerpt  word_appearance_max_excerpt  \\\n0                      1.171053                            4   \n1                      1.133333                            4   \n2                      1.121622                            4   \n3                      1.109756                            2   \n4                      3.043478                           12   \n\n   word_length_mean_excerpt  word_length_std_excerpt  word_length_min_excerpt  \\\n0                  6.381579                 2.039393                      3.0   \n1                  5.786667                 2.225730                      2.0   \n2                  5.716216                 2.205350                      2.0   \n3                  5.548780                 1.873483                      3.0   \n4                  4.956522                 1.918291                      3.0   \n\n   word_length_25%_excerpt  word_length_50%_excerpt  word_length_75%_excerpt  \\\n0                      5.0                      6.0                      8.0   \n1                      4.0                      5.0                      7.0   \n2                      4.0                      5.0                      7.0   \n3                      4.0                      5.0                      7.0   \n4                      4.0                      5.0                      5.0   \n\n   word_length_max_excerpt  \n0                     12.0  \n1                     12.0  \n2                     13.0  \n3                     12.0  \n4                     11.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_length_excerpt</th>\n      <th>word_count_excerpt</th>\n      <th>word_nunique_excerpt</th>\n      <th>word_appearance_mean_excerpt</th>\n      <th>word_appearance_max_excerpt</th>\n      <th>word_length_mean_excerpt</th>\n      <th>word_length_std_excerpt</th>\n      <th>word_length_min_excerpt</th>\n      <th>word_length_25%_excerpt</th>\n      <th>word_length_50%_excerpt</th>\n      <th>word_length_75%_excerpt</th>\n      <th>word_length_max_excerpt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>992</td>\n      <td>89</td>\n      <td>76</td>\n      <td>1.171053</td>\n      <td>4</td>\n      <td>6.381579</td>\n      <td>2.039393</td>\n      <td>3.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>8.0</td>\n      <td>12.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>937</td>\n      <td>85</td>\n      <td>75</td>\n      <td>1.133333</td>\n      <td>4</td>\n      <td>5.786667</td>\n      <td>2.225730</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>7.0</td>\n      <td>12.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>908</td>\n      <td>83</td>\n      <td>74</td>\n      <td>1.121622</td>\n      <td>4</td>\n      <td>5.716216</td>\n      <td>2.205350</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>7.0</td>\n      <td>13.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>909</td>\n      <td>91</td>\n      <td>82</td>\n      <td>1.109756</td>\n      <td>2</td>\n      <td>5.548780</td>\n      <td>1.873483</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>7.0</td>\n      <td>12.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>723</td>\n      <td>70</td>\n      <td>23</td>\n      <td>3.043478</td>\n      <td>12</td>\n      <td>4.956522</td>\n      <td>1.918291</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>11.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test_feat = TextDescriptionBlock('excerpt').fit(test_base)","metadata":{"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"print(train_feat.shape)\nprint(test_feat.shape)","metadata":{"trusted":true},"execution_count":89,"outputs":[{"name":"stdout","text":"(2834, 12)\n(7, 12)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# train & predict\n- 各特徴が効いてそうかだけ確認する。","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import KFold\n\ndef kfold_cv(X, y, n_splits=5, random_state=0):\n    folds = KFold(n_splits=n_splits, random_state=0, shuffle=True)\n    return list(folds.split(X, y))","metadata":{"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"target = 'target'\ncv = kfold_cv(train_feat, train_target)","metadata":{"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"params = {\n    'objective': 'regression',\n    'metrics': 'rmse',\n    'seed': SEED\n}","metadata":{"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, mean_squared_log_error","metadata":{"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"# testの前処理は一時的に除外\noof_preds = np.zeros(len(train_feat))\ntest_preds = np.zeros(len(test_feat))\n\nimportances = pd.DataFrame()\nscores = []\nmodels = []\n\nfor i, (train_index, valid_index) in enumerate(cv):\n    print(f'\\nFold {i + 1}')\n    trn_x, trn_y = train_feat.iloc[train_index], train_target.iloc[train_index]\n    val_x, val_y = train_feat.iloc[valid_index], train_target.iloc[valid_index]\n    \n    #dtrain = lgb.Dataset(trn_x, trn_y, categorical_feature = ['LE_' + val_ for val_ in le_categories])\n    #dvalid = lgb.Dataset(val_x, val_y, categorical_feature = ['LE_' + val_ for val_ in le_categories])\n\n    dtrain = lgb.Dataset(trn_x, trn_y)\n    dvalid = lgb.Dataset(val_x, val_y)\n\n    model = lgb.train(\n        params,\n        train_set=dtrain,\n        num_boost_round=100000,\n        valid_sets=[dtrain, dvalid],\n        valid_names=['training', 'valid'],\n        early_stopping_rounds=20,\n        verbose_eval=50\n    )\n    \n    val_preds = model.predict(val_x)\n    oof_preds[valid_index] = val_preds\n    test_preds += model.predict(test_feat) / 5\n    \n    val_score = model.best_score['valid']['rmse']\n    scores.append(val_score)\n    models.append(model)\n    \n    imp_df = pd.DataFrame({\n        'feature': model.feature_name(),\n        'gain': model.feature_importance(importance_type='gain'),\n        'fold': i+1\n    })\n    \n    importances = pd.concat([importances, imp_df], axis=0)\n    \nmean_score = np.mean(scores)\nstd_score  = np.std(scores)\nall_score  = np.sqrt(mean_squared_error(train_target, oof_preds))\nmetrics_name = 'RMSE'\nprint(f'Mean {metrics_name}: {mean_score}, std: {std_score}, All {metrics_name}: {all_score}')","metadata":{"scrolled":true,"trusted":true},"execution_count":94,"outputs":[{"name":"stdout","text":"\nFold 1\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000140 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1228\n[LightGBM] [Info] Number of data points in the train set: 2267, number of used features: 12\n[LightGBM] [Info] Start training from score -0.961023\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[27]\ttraining's rmse: 0.683295\tvalid's rmse: 0.811589\n\nFold 2\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000317 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 1229\n[LightGBM] [Info] Number of data points in the train set: 2267, number of used features: 12\n[LightGBM] [Info] Start training from score -0.946950\nTraining until validation scores don't improve for 20 rounds\n[50]\ttraining's rmse: 0.605436\tvalid's rmse: 0.850921\nEarly stopping, best iteration is:\n[30]\ttraining's rmse: 0.665631\tvalid's rmse: 0.84227\n\nFold 3\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000297 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 1232\n[LightGBM] [Info] Number of data points in the train set: 2267, number of used features: 12\n[LightGBM] [Info] Start training from score -0.970257\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[25]\ttraining's rmse: 0.689819\tvalid's rmse: 0.837518\n\nFold 4\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000339 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 1232\n[LightGBM] [Info] Number of data points in the train set: 2267, number of used features: 12\n[LightGBM] [Info] Start training from score -0.954341\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[25]\ttraining's rmse: 0.689876\tvalid's rmse: 0.823142\n\nFold 5\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000121 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1229\n[LightGBM] [Info] Number of data points in the train set: 2268, number of used features: 12\n[LightGBM] [Info] Start training from score -0.964019\nTraining until validation scores don't improve for 20 rounds\n[50]\ttraining's rmse: 0.613544\tvalid's rmse: 0.80826\nEarly stopping, best iteration is:\n[37]\ttraining's rmse: 0.648844\tvalid's rmse: 0.802976\nMean RMSE: 0.8234990687875889, std: 0.014913374307169755, All RMSE: 0.8236412951732285\n","output_type":"stream"}]},{"cell_type":"code","source":"sample['target'] = test_preds\n\nif 'kaggle_web_client' in sys.modules:  # kaggle環境\n    sample.to_csv('submission.csv',index=False)\nelse:\n    sample.to_csv(OUTPUT_DIR/'submission.csv',index=False)","metadata":{"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"print(sample.shape)\nsample.head()","metadata":{"trusted":true},"execution_count":96,"outputs":[{"name":"stdout","text":"(7, 2)\n","output_type":"stream"},{"execution_count":96,"output_type":"execute_result","data":{"text/plain":"          id    target\n0  c0f722661 -0.704132\n1  f0953f0a5 -0.181339\n2  0df072751 -1.002296\n3  04caf4e0c -1.425845\n4  0e63f8bea -1.701927","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>c0f722661</td>\n      <td>-0.704132</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>f0953f0a5</td>\n      <td>-0.181339</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0df072751</td>\n      <td>-1.002296</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>04caf4e0c</td>\n      <td>-1.425845</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0e63f8bea</td>\n      <td>-1.701927</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# importance(kaggle環境では描画しない)\nif 'kaggle_web_client' in sys.modules:  # kaggle環境\n    pass\nelse:\n    plt.figure(figsize=(8, 10))\n    sns.barplot(x='gain', y='feature', data=importances.sort_values('gain', ascending=False));\n    plt.savefig(os.path.join(OUTPUT_DIR, 'feature_importance.png'))","metadata":{"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"# importance_boxen(kaggle環境では描画しない)\n# 参考: https://www.guruguru.science/competitions/13/discussions/d8f2d66a-aeee-4789-8b3d-d5935c26b1b7/\n\nif 'kaggle_web_client' in sys.modules:  # kaggle環境\n    pass\nelse:\n    order = importances.groupby('feature')\\\n        .sum()[['gain']]\\\n        .sort_values('gain', ascending=False).index[:50]\n\n    fig, ax = plt.subplots(figsize=(max(6, len(order) * .4), 7))\n    sns.boxenplot(data=importances, x='feature', y='gain', order=order, ax=ax, palette='viridis')\n    ax.tick_params(axis='x', rotation=90)\n    ax.grid()\n    fig.tight_layout()\n    fig.savefig(os.path.join(OUTPUT_DIR, 'feature_importance_boxen.png'))","metadata":{"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"# SHAP(kaggle環境では描画しない)\n# 参考その1: https://github.com/slundberg/shap/issues/337\n# 参考その2: https://github.com/slundberg/shap/issues/630\nimport shap\n\nif 'kaggle_web_client' in sys.modules:  # kaggle環境\n    pass\nelse:\n    shap_values = []\n    for model_ in models:\n        explainer = shap.TreeExplainer(model_)\n        shap_values.append(explainer.shap_values(train_feat))\n\n    shap_mean = np.mean(shap_values, axis=0)","metadata":{"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"# SHAP_summary_plot\n# 参考_画像の出力について: https://github.com/slundberg/shap/issues/153\nif 'kaggle_web_client' in sys.modules:  # kaggle環境\n    pass\nelse:\n    shap.summary_plot(shap_mean, train_feat, show=False)\n    plt.subplots_adjust(left=0.4, right=1.0)  # 保存画像のラベルが欠けるのを防ぐ\n    plt.savefig(os.path.join(OUTPUT_DIR, 'shap_summary_plot.png'))","metadata":{"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"# SHAP_dependence_plot\nif 'kaggle_web_client' in sys.modules:  # kaggle環境\n    pass\nelse:\n    for col_ in train_feat.columns:\n        shap.dependence_plot(col_, shap_mean, train_feat)","metadata":{"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"# 分布(train_vs_oof)\nif 'kaggle_web_client' in sys.modules:  # kaggle環境\n    pass\nelse:\n    fig, ax = plt.subplots(figsize=(8, 8))\n    sns.distplot(train_target, label='Train', ax=ax, color='C1')\n    sns.distplot(oof_preds, label='Out Of Fold', ax=ax, color='C2')\n    ax.legend()\n    ax.grid()\n    plt.savefig(os.path.join(OUTPUT_DIR, 'train_vs_oof.png'))","metadata":{"trusted":true},"execution_count":102,"outputs":[]}]}