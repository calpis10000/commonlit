{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"046-train-02.ipynb","provenance":[{"file_id":"1G_W9irFTrEmDeHR0S6_u0bjpk8nxipXW","timestamp":1626689695352},{"file_id":"1bhhkorT--y8XXaVLM8hibVgC-tLqZ16P","timestamp":1626358153868},{"file_id":"1WtT2hX6O9Qbt_hb9sF50nM2QmDXFi-XA","timestamp":1626338366006},{"file_id":"1k_p5wftcUeo711Xho1-T5an2Xkneau-J","timestamp":1626323813472},{"file_id":"1Vz2GB2BNTWuefEFkCSh3TBPEIel7KG1t","timestamp":1626317426487},{"file_id":"1djoMWojeaIPopG5tS1jNMohn8ineblRh","timestamp":1626306831897},{"file_id":"1-6tlDO8158Pi6TpptIF884oFaEiT4Uxb","timestamp":1626276420047},{"file_id":"1js8eA3mDNS8mwSpCiHuzPeARFlUPAVrg","timestamp":1626272452526},{"file_id":"1yhcPgulwJtjJKUK9IuRKmNMhJ-4YXGol","timestamp":1626267205517},{"file_id":"1mnnSv0Pofn1QxArywV81VYqnZPB8uUWN","timestamp":1626180468522},{"file_id":"1RRdjt_UAeHmr5QQBAMyC82Fq1s31OWdK","timestamp":1625833136005},{"file_id":"1JPgg44HFemzwk8VSCXih3PejL0idy-C4","timestamp":1625825483466},{"file_id":"1Ye6wqVX71xAAAhmjXkw9IpRvTqeUyJDA","timestamp":1625812137500}],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":86},"id":"Z6yRwt-PXtbP","executionInfo":{"status":"ok","timestamp":1626691065738,"user_tz":-540,"elapsed":336,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"0f8a2656-7d24-451e-9ecf-78ac66b77a96"},"source":["\"\"\"\n","if 'google.colab' in sys.modules:  # colab環境特有の処理_初回のみ\n","  # Google Driveのマウント\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","\n","  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules' \\\n","   -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/requirements.txt' \\\n","   --ignore-installed\n","\n","  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules' \\\n","   transformers -U\n","  !pip install gensim==4.0.1 --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\n","  !pip install pytorch_memlab --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\n","\"\"\""],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\nif 'google.colab' in sys.modules:  # colab環境特有の処理_初回のみ\\n  # Google Driveのマウント\\n  from google.colab import drive\\n  drive.mount('/content/drive')\\n\\n  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'    -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/requirements.txt'    --ignore-installed\\n\\n  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'    transformers -U\\n  !pip install gensim==4.0.1 --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\\n  !pip install pytorch_memlab --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\\n\""]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ucCbvGD1XvG7","executionInfo":{"status":"ok","timestamp":1626691071124,"user_tz":-540,"elapsed":5160,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"76c0429e-1af2-489a-e975-426e6adea458"},"source":["import sys\n","if 'google.colab' in sys.modules:  # colab特有の処理_2回目以降\n","  # Google Driveのマウント\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","\n","  # データセットをDriveから取得\n","  !mkdir -p 'input'\n","  !cp -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/00_input/commonlitreadabilityprize/' '/content/input'\n","  !cp -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/97_pre_trained/clrp_pretrained_03' '/content/clrp-roberta-large'\n","  # ライブラリのパス指定\n","  sys.path.append('/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules')\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RV9-VwbpZLZ9","executionInfo":{"status":"ok","timestamp":1626691071125,"user_tz":-540,"elapsed":19,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["from pathlib import Path\n","\n","# input\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    DATA_DIR = Path('../input/commonlitreadabilityprize/')\n","\n","elif 'google.colab' in sys.modules: # Colab環境\n","    DATA_DIR = Path('/content/input/commonlitreadabilityprize')\n","\n","else:\n","    DATA_DIR = Path('../00_input/commonlitreadabilityprize/')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"x5difyXe00UV","executionInfo":{"status":"ok","timestamp":1626691071125,"user_tz":-540,"elapsed":17,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["from pathlib import Path\n","\n","# tokenizer\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    TOKENIZER_DIR = '../input/roberta-transformers-pytorch/roberta-large'\n","elif 'google.colab' in sys.modules: # Colab環境\n","    TOKENIZER_DIR = 'roberta-large' # 仮で、毎回DLする想定のモデル名を指定。あとで変更予定。\n","else:\n","    TOKENIZER_DIR = 'roberta-large'"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"tKjsUxnOeDYl","executionInfo":{"status":"ok","timestamp":1626691071126,"user_tz":-540,"elapsed":18,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["from pathlib import Path\n","\n","# pre-trained model\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    PRE_TRAINED_MODEL_DIR = '../input/roberta-transformers-pytorch/roberta-large'\n","elif 'google.colab' in sys.modules: # Colab環境\n","    PRE_TRAINED_MODEL_DIR = '/content/clrp-roberta-large' # 仮で、毎回DLする想定のモデル名を指定。あとで変更予定。\n","else:\n","    PRE_TRAINED_MODEL_DIR = 'roberta-large'"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZLaT2V0ReoAZ","executionInfo":{"status":"ok","timestamp":1626691071126,"user_tz":-540,"elapsed":17,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["UPLOAD_DIR = Path('/content/model')\n","EX_NO = '046-train-02'  # 実験番号などを入れる、folderのpathにする\n","USERID = 'calpis10000'"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"hOGjAb4pAJ0F","executionInfo":{"status":"ok","timestamp":1626691071126,"user_tz":-540,"elapsed":16,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["import subprocess\n","import shlex\n","\n","def gpuinfo():\n","    \"\"\"\n","    Returns size of total GPU RAM and used GPU RAM.\n","\n","    Parameters\n","    ----------\n","    None\n","\n","    Returns\n","    -------\n","    info : dict\n","        Total GPU RAM in integer for key 'total_MiB'.\n","        Used GPU RAM in integer for key 'used_MiB'.\n","    \"\"\"\n","\n","    command = 'nvidia-smi -q -d MEMORY | sed -n \"/FB Memory Usage/,/Free/p\" | sed -e \"1d\" -e \"4d\" -e \"s/ MiB//g\" | cut -d \":\" -f 2 | cut -c2-'\n","    commands = [shlex.split(part) for part in command.split(' | ')]\n","    for i, cmd in enumerate(commands):\n","        if i==0:\n","            res = subprocess.Popen(cmd, stdout=subprocess.PIPE)\n","        else:\n","            res = subprocess.Popen(cmd, stdin=res.stdout, stdout=subprocess.PIPE)\n","    total, used = map(int, res.communicate()[0].decode('utf-8').strip().split('\\n'))\n","    info = {'total_MiB':total, 'used_MiB':used}\n","    return info\n"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g3-6m5MKXecB"},"source":["# Overview\n","This nb is based on copy from https://www.kaggle.com/andretugan/lightweight-roberta-solution-in-pytorch .\n","\n","Acknowledgments(from base nb): \n","some ideas were taken from kernels by [Torch](https://www.kaggle.com/rhtsingh) and [Maunish](https://www.kaggle.com/maunish)."]},{"cell_type":"code","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-04T06:26:32.834365Z","iopub.execute_input":"2021-07-04T06:26:32.834903Z","iopub.status.idle":"2021-07-04T06:26:40.143740Z","shell.execute_reply.started":"2021-07-04T06:26:32.834785Z","shell.execute_reply":"2021-07-04T06:26:40.142864Z"},"trusted":true,"id":"HRsRZ06WXecD","executionInfo":{"status":"ok","timestamp":1626691074470,"user_tz":-540,"elapsed":3360,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["import os\n","import math\n","import random\n","import time\n","\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","\n","from transformers import AdamW # optimizer\n","from transformers import AutoTokenizer\n","from transformers import AutoModel\n","from transformers import AutoConfig\n","from transformers import get_cosine_schedule_with_warmup # scheduler\n","from pytorch_memlab import profile\n","import pytorch_memlab\n","from pytorch_memlab import MemReporter\n","\n","from sklearn.model_selection import KFold, StratifiedKFold\n","\n","import gc\n","gc.enable()"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.145217Z","iopub.execute_input":"2021-07-04T06:26:40.145539Z","iopub.status.idle":"2021-07-04T06:26:40.201326Z","shell.execute_reply.started":"2021-07-04T06:26:40.145504Z","shell.execute_reply":"2021-07-04T06:26:40.200136Z"},"trusted":true,"id":"omBfwshTXecE","executionInfo":{"status":"ok","timestamp":1626691074476,"user_tz":-540,"elapsed":21,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["NUM_FOLDS = 5 # K Fold\n","NUM_EPOCHS = 5 # Epochs\n","BATCH_SIZE = 12 # Batch Size\n","MAX_LEN = 248 # ベクトル長\n","EVAL_SCHEDULE = [(0.55, 64), (0.50, 32), (0.49, 16), (0.48, 8), (0.47, 4), (0.46, 2), (-1., 1)] # schedulerの何らかの設定？\n","ROBERTA_PATH = PRE_TRAINED_MODEL_DIR # roberta pre-trainedモデル(モデルとして指定)\n","TOKENIZER_PATH = TOKENIZER_DIR # roberta pre-trainedモデル(Tokenizerとして指定)\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\" # cudaがなければcpuを使えばいいじゃない"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.203398Z","iopub.execute_input":"2021-07-04T06:26:40.204055Z","iopub.status.idle":"2021-07-04T06:26:40.211572Z","shell.execute_reply.started":"2021-07-04T06:26:40.204015Z","shell.execute_reply":"2021-07-04T06:26:40.210762Z"},"trusted":true,"id":"4qcuXqwtXecF","executionInfo":{"status":"ok","timestamp":1626691074477,"user_tz":-540,"elapsed":21,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["def set_random_seed(random_seed):\n","    random.seed(random_seed)\n","    np.random.seed(random_seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(random_seed)\n","\n","    torch.manual_seed(random_seed)\n","    torch.cuda.manual_seed(random_seed)\n","    torch.cuda.manual_seed_all(random_seed)\n","\n","    torch.backends.cudnn.deterministic = True# cudnnによる最適化で結果が変わらないためのおまじない "],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.214188Z","iopub.execute_input":"2021-07-04T06:26:40.214809Z","iopub.status.idle":"2021-07-04T06:26:40.309744Z","shell.execute_reply.started":"2021-07-04T06:26:40.214769Z","shell.execute_reply":"2021-07-04T06:26:40.308926Z"},"trusted":true,"id":"70PyLsJTXecF","executionInfo":{"status":"ok","timestamp":1626691074478,"user_tz":-540,"elapsed":21,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# train, testを読む\n","train_df = pd.read_csv(DATA_DIR/\"train.csv\")\n","\n","# Remove incomplete entries if any.\n","train_df.drop(train_df[(train_df.target == 0) & (train_df.standard_error == 0)].index,\n","              inplace=True)\n","train_df.reset_index(drop=True, inplace=True)\n","\n","test_df = pd.read_csv(DATA_DIR/\"test.csv\")\n","submission_df = pd.read_csv(DATA_DIR/\"sample_submission.csv\")"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"9ZYOB59L8qtA","executionInfo":{"status":"ok","timestamp":1626691074478,"user_tz":-540,"elapsed":20,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"29aea4d7-4a45-410d-fed1-fcf3265dfb48"},"source":["train_df.head()\n"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>url_legal</th>\n","      <th>license</th>\n","      <th>excerpt</th>\n","      <th>target</th>\n","      <th>standard_error</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>c12129c31</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>When the young people returned to the ballroom...</td>\n","      <td>-0.340259</td>\n","      <td>0.464009</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>85aa80a4c</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>All through dinner time, Mrs. Fayre was somewh...</td>\n","      <td>-0.315372</td>\n","      <td>0.480805</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>b69ac6792</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>As Roger had predicted, the snow departed as q...</td>\n","      <td>-0.580118</td>\n","      <td>0.476676</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>dd1000b26</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>And outside before the palace a great garden w...</td>\n","      <td>-1.054013</td>\n","      <td>0.450007</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>37c1b32fb</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Once upon a time there were Three Bears who li...</td>\n","      <td>0.247197</td>\n","      <td>0.510845</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          id url_legal  ...    target standard_error\n","0  c12129c31       NaN  ... -0.340259       0.464009\n","1  85aa80a4c       NaN  ... -0.315372       0.480805\n","2  b69ac6792       NaN  ... -0.580118       0.476676\n","3  dd1000b26       NaN  ... -1.054013       0.450007\n","4  37c1b32fb       NaN  ...  0.247197       0.510845\n","\n","[5 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.311021Z","iopub.execute_input":"2021-07-04T06:26:40.311347Z","iopub.status.idle":"2021-07-04T06:26:40.624393Z","shell.execute_reply.started":"2021-07-04T06:26:40.311314Z","shell.execute_reply":"2021-07-04T06:26:40.623347Z"},"trusted":true,"id":"xf0662k4XecF","executionInfo":{"status":"ok","timestamp":1626691076964,"user_tz":-540,"elapsed":2505,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# tokenizerを指定\n","tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N6aaghNkXecG"},"source":["# Dataset"]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.628883Z","iopub.execute_input":"2021-07-04T06:26:40.629347Z","iopub.status.idle":"2021-07-04T06:26:40.644338Z","shell.execute_reply.started":"2021-07-04T06:26:40.629309Z","shell.execute_reply":"2021-07-04T06:26:40.643336Z"},"trusted":true,"id":"zkopT0U1XecG","executionInfo":{"status":"ok","timestamp":1626691076969,"user_tz":-540,"elapsed":14,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# Dataset用のClass。おそらく、trainとtestでインスタンスを生成し、DataFrameと同じように扱えるような思想。\n","class LitDataset(Dataset):\n","    def __init__(self, df, inference_only=False):\n","        super().__init__()\n","\n","        self.df = df        \n","        self.inference_only = inference_only # Testデータ用フラグ\n","        self.text = df.excerpt.tolist() # 分析対象カラムをlistにする。(分かち書きではなく、Seriesをlistへ変換するような処理)\n","        #self.text = [text.replace(\"\\n\", \" \") for text in self.text] # 単語単位で分かち書きする場合\n","        \n","        if not self.inference_only:\n","            self.target = torch.tensor(df.target.values, dtype=torch.float32) # trainのみ、targetをtensorに変換\n","            self.standard_error = torch.tensor(df.standard_error.values, dtype=torch.float32) \n","\n","        self.encoded = tokenizer.batch_encode_plus( # textをtokenize\n","            self.text,\n","            padding = 'max_length',            \n","            max_length = MAX_LEN,\n","            truncation = True, # 最大長を超える文字は切り捨て\n","            return_attention_mask=True\n","        )        \n"," \n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    \n","    def __getitem__(self, index): # 変換結果を返す\n","        input_ids = torch.tensor(self.encoded['input_ids'][index])\n","        attention_mask = torch.tensor(self.encoded['attention_mask'][index])\n","        \n","        if self.inference_only:\n","            return (input_ids, attention_mask)            \n","        else:\n","            target = self.target[index]\n","            standard_error = self.standard_error[index]\n","            return (input_ids, attention_mask, target, standard_error)"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KKtdy32wXecG"},"source":["# Model\n","The model is inspired by the one from [Maunish](https://www.kaggle.com/maunish/clrp-roberta-svm)."]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.649629Z","iopub.execute_input":"2021-07-04T06:26:40.650066Z","iopub.status.idle":"2021-07-04T06:26:40.666374Z","shell.execute_reply.started":"2021-07-04T06:26:40.650002Z","shell.execute_reply":"2021-07-04T06:26:40.665211Z"},"trusted":true,"id":"BpkxjXEUXecH","executionInfo":{"status":"ok","timestamp":1626691076970,"user_tz":-540,"elapsed":14,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["class LitModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        config = AutoConfig.from_pretrained(ROBERTA_PATH) # pretrainedからconfigを読み込み\n","        config.update({\"output_hidden_states\":True, # config更新: embedding層を抽出\n","                       \"hidden_dropout_prob\": 0.0, # config更新: dropoutしない\n","                       \"layer_norm_eps\": 1e-7}) # config更新: layer normalizationのepsilon                      \n","        \n","        self.roberta = AutoModel.from_pretrained(ROBERTA_PATH, config=config) # cpuで処理する\n","            \n","        self.attention = nn.Sequential(# attentionレイヤー            \n","            nn.Linear(config.hidden_size, 512),      \n","            nn.Tanh(),                       \n","            nn.Linear(512, 1),\n","            nn.Softmax(dim=1)\n","        )\n","\n","        self.regressor = nn.Sequential( # 出力レイヤー                    \n","            nn.Linear(config.hidden_size, 2)                        \n","        )\n","\n","    def forward(self, input_ids, attention_mask):\n","        roberta_output = self.roberta(input_ids=input_ids, # robertaに入力データを流し、出力としてrobertaモデル(layerの複合体)を得る\n","                                      attention_mask=attention_mask)     \n","\n","        last_hidden_state = roberta_output.hidden_states[-1] # robertaモデルの最後のlayerを得る\n","        weights = self.attention(last_hidden_state) # robertaの最後のlayerをattentionへ入力し、出力として重みを得る                \n","        context_vector = torch.sum(weights * last_hidden_state, dim=1) # 重み×最後の層を足し合わせて文書ベクトルとする。\n","        return self.regressor(context_vector) # 文書ベクトルを線形層に入力し、targetを出力する\n","\n","        # https://www.kaggle.com/rhtsingh/utilizing-transformer-representations-efficiently\n","        #last_hidden_state = roberta_output[0]\n","        #input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        #sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        #sum_mask = input_mask_expanded.sum(1)\n","        #sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        #mean_embeddings = sum_embeddings / sum_mask\n","\n","        \n","        # Now we reduce the context vector to the prediction score.\n","        #return self.regressor(mean_embeddings) # 文書ベクトルを線形層に入力し、targetを出力する"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.672515Z","iopub.execute_input":"2021-07-04T06:26:40.672944Z","iopub.status.idle":"2021-07-04T06:26:40.684593Z","shell.execute_reply.started":"2021-07-04T06:26:40.672908Z","shell.execute_reply":"2021-07-04T06:26:40.683569Z"},"trusted":true,"id":"bB4jvQTxXecH","executionInfo":{"status":"ok","timestamp":1626691076970,"user_tz":-540,"elapsed":13,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 評価指標(MSE)の計算。最終的に、ルートしてRMSEにすると思われる。\n","def eval_mse(model, data_loader):\n","    \"\"\"Evaluates the mean squared error of the |model| on |data_loader|\"\"\"\n","    model.eval() # evalモードを選択。Batch Normとかdropoutをしなくなる           \n","    mse_mean_sum = 0\n","    mse_std_sum = 0\n","\n","    with torch.no_grad(): # 勾配の計算をしないBlock\n","        for batch_num, (input_ids, attention_mask, target, standard_error) in enumerate(data_loader): # data_loaderからinput, attentin_mask, targetをbatchごとに取り出す\n","            input_ids = input_ids.to(DEVICE)   \n","            attention_mask = attention_mask.to(DEVICE)   \n","            target = target.to(DEVICE)      \n","            standard_error = standard_error.to(DEVICE) \n","            \n","            output = model(input_ids, attention_mask) # 取得した値をモデルへ入力し、出力として予測値を得る。\n","\n","            mse_mean_sum += nn.MSELoss(reduction=\"sum\")(output[:,0].flatten(), target).item() # 誤差の合計を得る(Batchごとに計算した誤差を足し上げる)\n","            mse_std_sum += nn.MSELoss(reduction=\"sum\")(output[:,1].flatten(), target).item() # 誤差の合計を得る(Batchごとに計算した誤差を足し上げる)\n","\n","    del input_ids\n","    del attention_mask\n","    del target\n","\n","    mse_mean_result = mse_mean_sum / len(data_loader.dataset)\n","    mse_std_result = mse_std_sum / len(data_loader.dataset)\n","  \n","    return mse_mean_result, mse_std_result # 誤差の合計をdataset長で除し、mseを取得＆返す"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.690155Z","iopub.execute_input":"2021-07-04T06:26:40.692530Z","iopub.status.idle":"2021-07-04T06:26:40.703425Z","shell.execute_reply.started":"2021-07-04T06:26:40.692488Z","shell.execute_reply":"2021-07-04T06:26:40.702366Z"},"trusted":true,"id":"47bDno_LXecI","executionInfo":{"status":"ok","timestamp":1626691076971,"user_tz":-540,"elapsed":14,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 推論結果を返す\n","def predict(model, data_loader):\n","    \"\"\"Returns an np.array with predictions of the |model| on |data_loader|\"\"\"\n","    model.eval() # evalモード(dropout, batch_normしない)\n","\n","    result = np.zeros(len(data_loader.dataset)) # 結果をdataset長のzero配列として用意\n","    index = 0\n","    \n","    with torch.no_grad(): # 勾配の計算をしないblock(inputすると、現状の重みによる推論結果を返す)\n","        for batch_num, (input_ids, attention_mask) in enumerate(data_loader): # data_loaderからbatchごとにinputを得る\n","            input_ids = input_ids.to(DEVICE)\n","            attention_mask = attention_mask.to(DEVICE)\n","                        \n","            output = model(input_ids, attention_mask) # modelにinputを入力し、予測結果を得る。\n","\n","            result[index : index + output[:,0].shape[0]] = output[:,0].flatten().to(\"cpu\") # result[index ~ predの長さ]へ、予測結果を格納\n","            index += pred.shape[0] # indexを更新\n","\n","    return result # 全batchで推論が終わったら、結果を返す"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.708605Z","iopub.execute_input":"2021-07-04T06:26:40.709024Z","iopub.status.idle":"2021-07-04T06:26:40.730675Z","shell.execute_reply.started":"2021-07-04T06:26:40.708983Z","shell.execute_reply":"2021-07-04T06:26:40.729705Z"},"trusted":true,"id":"oInneuAmXecI","executionInfo":{"status":"ok","timestamp":1626691076971,"user_tz":-540,"elapsed":13,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 学習\n","def train(model, # モデル\n","          model_path, # モデルのアウトプット先\n","          train_loader, # train-setのdata_loader\n","          val_loader, # valid-setのdata_loader\n","          optimizer, # optimizer\n","          scheduler=None, # scheduler, デフォルトはNone\n","          num_epochs=NUM_EPOCHS # epoch数、notebook冒頭で指定した値\n","         ):    \n","    \n","    best_val_rmse = None\n","    best_epoch = 0\n","    step = 0\n","    last_eval_step = 0\n","    eval_period = EVAL_SCHEDULE[0][1] # eval期間(って何？) 冒頭で決めたEVAL_SCHEDULEの最初のtupleの[1]を取得\n","\n","    start = time.time() # 時間計測用\n","\n","    for epoch in range(num_epochs): # 指定したEpoch数だけ繰り返し\n","        val_rmse = None         \n","\n","        for batch_num, (input_ids, attention_mask, target, standard_error) in enumerate(train_loader): # train_loaderからinput, targetを取得\n","            input_ids = input_ids.to(DEVICE) # inputをDEVICEへ突っ込む\n","            attention_mask = attention_mask.to(DEVICE)       \n","            target = target.to(DEVICE)\n","            standard_error = standard_error.to(DEVICE)  \n","\n","            optimizer.zero_grad() # 勾配を初期化            \n","            model.train() # 学習モード開始\n","\n","            # https://www.kaggle.com/c/commonlitreadabilityprize/discussion/239421\n","            output = model(input_ids, attention_mask) # input,attention_maskを入力し、予測結果を得る\n","            p = torch.distributions.Normal(output[:,0], torch.sqrt(output[:,1]**2))\n","            q = torch.distributions.Normal(target, standard_error)\n","            kl_vector = torch.distributions.kl_divergence(p, q)\n","            loss = kl_vector.mean()\n","\n","            loss.backward() # 誤差逆伝播法により勾配を得る\n","            optimizer.step() # 重みを更新する\n","\n","            if scheduler:\n","                scheduler.step() # schedulerが与えられた場合は、schedulerの学習率更新\n","            \n","            if step >= last_eval_step + eval_period: # batchを回すごとにstepを増やしていって、「前回evalしたstep + eval_period(16)」を超えたら実行。\n","                # Evaluate the model on val_loader.\n","                elapsed_seconds = time.time() - start # 経過時間\n","                num_steps = step - last_eval_step # 経過ステップ数\n","                print(f\"\\n{num_steps} steps took {elapsed_seconds:0.3} seconds\")\n","                last_eval_step = step # 前回stepの更新\n","                \n","                # valid-setによるrmse計算\n","                train_mean_mse = nn.MSELoss(reduction=\"mean\")(output[:,0].flatten(), target) \n","                train_std_mse = nn.MSELoss(reduction=\"mean\")(torch.sqrt(output[:,1]**2).flatten(), standard_error) \n","\n","                train_mean_rmse = math.sqrt(train_mean_mse)\n","                train_std_rmse = math.sqrt(train_std_mse)\n","\n","                val_mean_mse, val_std_mse = eval_mse(model, val_loader)\n","                val_mean_rmse = math.sqrt(val_mean_mse)                            \n","                val_std_rmse = math.sqrt(val_std_mse)                            \n","\n","                print(f\"Epoch: {epoch} batch_num: {batch_num}\")\n","                print(f\"train_rmse_target: {train_mean_rmse:0.4}\",\n","                      f\"train_rmse_stderror: {train_std_rmse:0.4}\",\n","                      f\"train_kl_div: {loss:0.4}\",\n","                      )\n","                print(f\"val_rmse_target: {val_mean_rmse:0.4}\",\n","                      f\"val_rmse_stderror: {val_std_rmse:0.4}\"\n","                      )\n","\n","                for rmse, period in EVAL_SCHEDULE: # eval_periodをvalid-rmseで切り替える処理\n","                    if val_mean_rmse >= rmse: # valid rmseをEVAL_SCHEDULEと比較し、0項 > valid rmseとなるまで回す : EVAL_SCHEDULE = [(0.50, 16), (0.49, 8), (0.48, 4), (0.47, 2), (-1., 1)]\n","                        eval_period = period # eval_periodを更新\n","                        break                               \n","\n","                if not best_val_rmse or val_mean_rmse < best_val_rmse: # 初回(best_val_rmse==None), またはbest_val_rmseを更新したらモデルを保存する\n","                    best_val_rmse = val_mean_rmse\n","                    best_epoch = epoch\n","                    torch.save(model.state_dict(), model_path) # 最高の自分を保存\n","                    print(f\"New best_val_rmse: {best_val_rmse:0.4}\")\n","                else:       \n","                    print(f\"Still best_val_rmse: {best_val_rmse:0.4}\", # 更新されない場合は、元のスコアを表示\n","                          f\"(from epoch {best_epoch})\")      \n","                                                  \n","                start = time.time()\n","            \n","            # batchごとにメモリ解放\n","            del input_ids\n","            del attention_mask\n","            del target\n","            torch.cuda.empty_cache()                                            \n","            step += 1\n","    \n","    return best_val_rmse"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.735798Z","iopub.execute_input":"2021-07-04T06:26:40.738398Z","iopub.status.idle":"2021-07-04T06:26:40.750876Z","shell.execute_reply.started":"2021-07-04T06:26:40.738356Z","shell.execute_reply":"2021-07-04T06:26:40.749635Z"},"trusted":true,"id":"rMY0fjXwXecJ","executionInfo":{"status":"ok","timestamp":1626691076972,"user_tz":-540,"elapsed":14,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# optimizerの作成\n","def create_optimizer(model):\n","    named_parameters = list(model.named_parameters()) # モデルパラメータの取得\n","    \n","    roberta_parameters = list(model.roberta.named_parameters())[:-2] # パラメータをroberta用、attention用、regressor用に格納。(直接引っ張ってくる形式に変更)\n","    attention_parameters = list(model.attention.named_parameters())\n","    regressor_parameters = list(model.regressor.named_parameters())\n","        \n","    attention_group = [params for (name, params) in attention_parameters] # attention用パラメータをリストとして取得\n","    regressor_group = [params for (name, params) in regressor_parameters] # reg用パラメータをリストとして取得\n","\n","    parameters = []\n","    parameters.append({\"params\": attention_group}) # パラメータをリストに辞書として格納していく\n","    parameters.append({\"params\": regressor_group})\n","\n","    for layer_num, (name, params) in enumerate(roberta_parameters): # レイヤーごとにname, paramsを取得していろんな処理\n","        weight_decay = 0.0 if \"bias\" in name else 0.01\n","\n","        lr = 2e-5\n","\n","        if layer_num >= 69:        \n","            lr = 5e-5\n","\n","        if layer_num >= 133:\n","            lr = 1e-4\n","\n","        parameters.append({\"params\": params,\n","                           \"weight_decay\": weight_decay,\n","                           \"lr\": lr})\n","\n","    return AdamW(parameters) # 最終的に、AdamWにパラメータを入力する。\n"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"EbaJojz0Zjif","executionInfo":{"status":"ok","timestamp":1626691076972,"user_tz":-540,"elapsed":13,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# https://www.kaggle.com/abhishek/step-1-create-folds\n","def create_folds(data, num_splits, SEED, return_df=False):\n","    # we create a new column called kfold and fill it with -1\n","    data[\"kfold\"] = -1\n","    \n","    # the next step is to randomize the rows of the data\n","    data = data.sample(frac=1).reset_index(drop=True)\n","\n","    # calculate number of bins by Sturge's rule\n","    # I take the floor of the value, you can also\n","    # just round it\n","    num_bins = int(np.floor(1 + np.log2(len(data))))\n","    \n","    # bin targets\n","    data.loc[:, \"bins_tg\"] = pd.cut(\n","        data[\"target\"], bins=num_bins, labels=False\n","    ).map(lambda x: str(x))\n","\n","    # bin standard_error\n","    data.loc[:, \"bins_std\"] = pd.cut(\n","        data[\"standard_error\"], bins=num_bins, labels=False\n","    )\n","\n","    # bins\n","    data.loc[:, \"bins\"] = data['bins_tg'].map(lambda x: str(x)) + data['bins_std'].map(lambda x: str(x))\n","\n","    # initiate the kfold class from model_selection module\n","    kf = StratifiedKFold(n_splits=5, random_state=SEED, shuffle=True)\n","\n","    # note that, instead of targets, we use bins!\n","    if return_df:\n","      for f, (t_, v_) in enumerate(kf.split(X=data, y=data.bins.values)):\n","        data.loc[v_, 'kfold'] = f\n","      return data\n","    else:\n","      return kf.split(X=data, y=data.bins.values)"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"id":"vAmhaYaylMk5","executionInfo":{"status":"ok","timestamp":1626691076973,"user_tz":-540,"elapsed":14,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"8fe7d8af-a4dc-400d-e52f-05d5f5dd0c22"},"source":["# 検証用\n","SEED = 1000\n","st_kfold_bins_df = create_folds(train_df, num_splits=5, SEED=SEED, return_df=True)\n","st_kfold_bins_df['bins_tg'] = st_kfold_bins_df['bins_tg'].map(lambda x: float(x))\n","st_kfold_bins_df['bins_std'] = st_kfold_bins_df['bins_std'].map(lambda x: float(x))\n","st_kfold_bins_df.groupby('kfold').agg({'bins_tg': ['min', 'max', 'mean'],\n","                                    'bins_std': ['min', 'max', 'mean']})"],"execution_count":21,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  % (min_groups, self.n_splits)), UserWarning)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","\n","    .dataframe thead tr:last-of-type th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th></th>\n","      <th colspan=\"3\" halign=\"left\">bins_tg</th>\n","      <th colspan=\"3\" halign=\"left\">bins_std</th>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <th>min</th>\n","      <th>max</th>\n","      <th>mean</th>\n","      <th>min</th>\n","      <th>max</th>\n","      <th>mean</th>\n","    </tr>\n","    <tr>\n","      <th>kfold</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>5.619048</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>2.954145</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>5.562610</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>2.924162</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>5.507937</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>2.915344</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>5.496466</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>2.925795</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>5.563604</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>2.925795</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      bins_tg                 bins_std                \n","          min   max      mean      min   max      mean\n","kfold                                                 \n","0         0.0  11.0  5.619048      0.0  11.0  2.954145\n","1         0.0  11.0  5.562610      0.0  11.0  2.924162\n","2         0.0  11.0  5.507937      0.0  11.0  2.915344\n","3         0.0  11.0  5.496466      0.0  11.0  2.925795\n","4         0.0  11.0  5.563604      0.0  11.0  2.925795"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"TyjgRCu3mmqG","executionInfo":{"status":"ok","timestamp":1626691076973,"user_tz":-540,"elapsed":12,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"4PLKHwvKtNBn","executionInfo":{"status":"ok","timestamp":1626691076974,"user_tz":-540,"elapsed":11,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["def train_and_save_model(train_indices, val_indices, model_path):\n","    train_dataset = LitDataset(train_df.loc[train_indices]) # train, validのDataset\n","    val_dataset = LitDataset(train_df.loc[val_indices])\n","        \n","    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n","                              drop_last=True, shuffle=True, num_workers=2) # train, validのDataLoader\n","    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n","                            drop_last=False, shuffle=False, num_workers=2)    \n","\n","    model = LitModel().to(DEVICE) # modelをDEVICEへぶち込む\n","    optimizer = create_optimizer(model) # optimizerをモデルから作成\n","    scheduler = get_cosine_schedule_with_warmup( # schedulerを作成\n","        optimizer,\n","        num_training_steps=NUM_EPOCHS * len(train_loader),\n","        num_warmup_steps=50)    \n","    rmse = train(model, model_path, train_loader, val_loader, optimizer, scheduler=scheduler)\n","\n","    del train_dataset\n","    del val_dataset\n","    del train_loader\n","    del val_loader\n","    del model\n","    del optimizer\n","    del scheduler\n","    gc.collect() \n","    torch.cuda.empty_cache()\n","    return rmse"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.755813Z","iopub.execute_input":"2021-07-04T06:26:40.758373Z","iopub.status.idle":"2021-07-04T06:27:12.493221Z","shell.execute_reply.started":"2021-07-04T06:26:40.758265Z","shell.execute_reply":"2021-07-04T06:27:12.490139Z"},"trusted":true,"id":"k2LGJD3XXecK","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1626696647468,"user_tz":-540,"elapsed":5570505,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"ea9ecf40-29ca-44b4-d3ca-a7076d56a318"},"source":["# 実行処理。 KFold & 学習\n","SEED = 1000\n","list_val_rmse = []\n","\n","#kfold = KFold(n_splits=NUM_FOLDS, random_state=SEED, shuffle=True)\n","kfold = create_folds(train_df, 5, SEED=SEED, return_df=False) # binsで切る場合\n","\n","for fold, (train_indices, val_indices) in enumerate(kfold):    \n","    print(f\"\\nFold {fold + 1}/{NUM_FOLDS}\")\n","    print(gpuinfo())\n","    model_path = f\"model_{fold + 1}.pth\" # model_fold数_.pth\n","    set_random_seed(SEED + fold) # SEEDはfold別に変わるようにする\n","    list_val_rmse.append(train_and_save_model(train_indices, val_indices, model_path))\n","\n","    print(\"\\nPerformance estimates:\")\n","    print(list_val_rmse)\n","    print(\"Mean:\", np.array(list_val_rmse).mean())\n","    print(gpuinfo())"],"execution_count":23,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  % (min_groups, self.n_splits)), UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Fold 1/5\n","{'total_MiB': 16280, 'used_MiB': 2}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 82.0 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.6713 train_rmse_stderror: 0.1 train_kl_div: 0.9437\n","val_rmse_target: 0.6175 val_rmse_stderror: 1.793\n","New best_val_rmse: 0.6175\n","\n","64 steps took 81.0 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.2756 train_rmse_stderror: 0.03002 train_kl_div: 0.1644\n","val_rmse_target: 0.6061 val_rmse_stderror: 1.735\n","New best_val_rmse: 0.6061\n","\n","64 steps took 81.2 seconds\n","Epoch: 1 batch_num: 4\n","train_rmse_target: 0.4681 train_rmse_stderror: 0.03616 train_kl_div: 0.4672\n","val_rmse_target: 0.5712 val_rmse_stderror: 1.744\n","New best_val_rmse: 0.5712\n","\n","64 steps took 81.0 seconds\n","Epoch: 1 batch_num: 68\n","train_rmse_target: 0.7136 train_rmse_stderror: 0.0161 train_kl_div: 1.113\n","val_rmse_target: 0.5751 val_rmse_stderror: 1.732\n","Still best_val_rmse: 0.5712 (from epoch 1)\n","\n","64 steps took 81.0 seconds\n","Epoch: 1 batch_num: 132\n","train_rmse_target: 0.5703 train_rmse_stderror: 0.02984 train_kl_div: 0.6922\n","val_rmse_target: 0.5209 val_rmse_stderror: 1.739\n","New best_val_rmse: 0.5209\n","\n","32 steps took 40.5 seconds\n","Epoch: 1 batch_num: 164\n","train_rmse_target: 0.6948 train_rmse_stderror: 0.04831 train_kl_div: 0.7801\n","val_rmse_target: 0.5346 val_rmse_stderror: 1.741\n","Still best_val_rmse: 0.5209 (from epoch 1)\n","\n","32 steps took 40.6 seconds\n","Epoch: 2 batch_num: 8\n","train_rmse_target: 0.2764 train_rmse_stderror: 0.02131 train_kl_div: 0.1614\n","val_rmse_target: 0.5242 val_rmse_stderror: 1.732\n","Still best_val_rmse: 0.5209 (from epoch 1)\n","\n","32 steps took 40.5 seconds\n","Epoch: 2 batch_num: 40\n","train_rmse_target: 0.3396 train_rmse_stderror: 0.02741 train_kl_div: 0.2019\n","val_rmse_target: 0.4975 val_rmse_stderror: 1.732\n","New best_val_rmse: 0.4975\n","\n","16 steps took 20.3 seconds\n","Epoch: 2 batch_num: 56\n","train_rmse_target: 0.3724 train_rmse_stderror: 0.02649 train_kl_div: 0.2827\n","val_rmse_target: 0.5025 val_rmse_stderror: 1.736\n","Still best_val_rmse: 0.4975 (from epoch 2)\n","\n","32 steps took 40.5 seconds\n","Epoch: 2 batch_num: 88\n","train_rmse_target: 0.2868 train_rmse_stderror: 0.03183 train_kl_div: 0.1692\n","val_rmse_target: 0.502 val_rmse_stderror: 1.729\n","Still best_val_rmse: 0.4975 (from epoch 2)\n","\n","32 steps took 40.5 seconds\n","Epoch: 2 batch_num: 120\n","train_rmse_target: 0.2492 train_rmse_stderror: 0.02037 train_kl_div: 0.1368\n","val_rmse_target: 0.5 val_rmse_stderror: 1.729\n","Still best_val_rmse: 0.4975 (from epoch 2)\n","\n","32 steps took 40.5 seconds\n","Epoch: 2 batch_num: 152\n","train_rmse_target: 0.2051 train_rmse_stderror: 0.02165 train_kl_div: 0.08042\n","val_rmse_target: 0.5006 val_rmse_stderror: 1.734\n","Still best_val_rmse: 0.4975 (from epoch 2)\n","\n","32 steps took 40.5 seconds\n","Epoch: 2 batch_num: 184\n","train_rmse_target: 0.4033 train_rmse_stderror: 0.04173 train_kl_div: 0.3564\n","val_rmse_target: 0.486 val_rmse_stderror: 1.726\n","New best_val_rmse: 0.486\n","\n","8 steps took 10.3 seconds\n","Epoch: 3 batch_num: 4\n","train_rmse_target: 0.1271 train_rmse_stderror: 0.02076 train_kl_div: 0.03431\n","val_rmse_target: 0.4813 val_rmse_stderror: 1.734\n","New best_val_rmse: 0.4813\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 12\n","train_rmse_target: 0.1382 train_rmse_stderror: 0.02391 train_kl_div: 0.03766\n","val_rmse_target: 0.4899 val_rmse_stderror: 1.724\n","Still best_val_rmse: 0.4813 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 20\n","train_rmse_target: 0.2457 train_rmse_stderror: 0.03017 train_kl_div: 0.1187\n","val_rmse_target: 0.481 val_rmse_stderror: 1.73\n","New best_val_rmse: 0.481\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 28\n","train_rmse_target: 0.2625 train_rmse_stderror: 0.02895 train_kl_div: 0.1253\n","val_rmse_target: 0.4835 val_rmse_stderror: 1.727\n","Still best_val_rmse: 0.481 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 36\n","train_rmse_target: 0.144 train_rmse_stderror: 0.01329 train_kl_div: 0.04321\n","val_rmse_target: 0.4804 val_rmse_stderror: 1.725\n","New best_val_rmse: 0.4804\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 44\n","train_rmse_target: 0.1613 train_rmse_stderror: 0.0329 train_kl_div: 0.04187\n","val_rmse_target: 0.4924 val_rmse_stderror: 1.74\n","Still best_val_rmse: 0.4804 (from epoch 3)\n","\n","16 steps took 20.2 seconds\n","Epoch: 3 batch_num: 60\n","train_rmse_target: 0.1867 train_rmse_stderror: 0.03027 train_kl_div: 0.0669\n","val_rmse_target: 0.4757 val_rmse_stderror: 1.738\n","New best_val_rmse: 0.4757\n","\n","4 steps took 5.06 seconds\n","Epoch: 3 batch_num: 64\n","train_rmse_target: 0.1862 train_rmse_stderror: 0.01985 train_kl_div: 0.07265\n","val_rmse_target: 0.4791 val_rmse_stderror: 1.725\n","Still best_val_rmse: 0.4757 (from epoch 3)\n","\n","4 steps took 5.05 seconds\n","Epoch: 3 batch_num: 68\n","train_rmse_target: 0.1733 train_rmse_stderror: 0.04907 train_kl_div: 0.05957\n","val_rmse_target: 0.4779 val_rmse_stderror: 1.718\n","Still best_val_rmse: 0.4757 (from epoch 3)\n","\n","4 steps took 5.05 seconds\n","Epoch: 3 batch_num: 72\n","train_rmse_target: 0.2248 train_rmse_stderror: 0.02824 train_kl_div: 0.1092\n","val_rmse_target: 0.4872 val_rmse_stderror: 1.734\n","Still best_val_rmse: 0.4757 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 80\n","train_rmse_target: 0.2786 train_rmse_stderror: 0.01653 train_kl_div: 0.1356\n","val_rmse_target: 0.4798 val_rmse_stderror: 1.722\n","Still best_val_rmse: 0.4757 (from epoch 3)\n","\n","4 steps took 5.05 seconds\n","Epoch: 3 batch_num: 84\n","train_rmse_target: 0.1778 train_rmse_stderror: 0.0225 train_kl_div: 0.06336\n","val_rmse_target: 0.4735 val_rmse_stderror: 1.718\n","New best_val_rmse: 0.4735\n","\n","4 steps took 5.07 seconds\n","Epoch: 3 batch_num: 88\n","train_rmse_target: 0.1647 train_rmse_stderror: 0.01568 train_kl_div: 0.05933\n","val_rmse_target: 0.4728 val_rmse_stderror: 1.729\n","New best_val_rmse: 0.4728\n","\n","4 steps took 5.06 seconds\n","Epoch: 3 batch_num: 92\n","train_rmse_target: 0.07964 train_rmse_stderror: 0.01682 train_kl_div: 0.01415\n","val_rmse_target: 0.4783 val_rmse_stderror: 1.726\n","Still best_val_rmse: 0.4728 (from epoch 3)\n","\n","4 steps took 5.05 seconds\n","Epoch: 3 batch_num: 96\n","train_rmse_target: 0.1198 train_rmse_stderror: 0.01278 train_kl_div: 0.02825\n","val_rmse_target: 0.4813 val_rmse_stderror: 1.725\n","Still best_val_rmse: 0.4728 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 104\n","train_rmse_target: 0.15 train_rmse_stderror: 0.01412 train_kl_div: 0.04222\n","val_rmse_target: 0.4831 val_rmse_stderror: 1.729\n","Still best_val_rmse: 0.4728 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 112\n","train_rmse_target: 0.1858 train_rmse_stderror: 0.0489 train_kl_div: 0.05497\n","val_rmse_target: 0.4735 val_rmse_stderror: 1.733\n","Still best_val_rmse: 0.4728 (from epoch 3)\n","\n","4 steps took 5.05 seconds\n","Epoch: 3 batch_num: 116\n","train_rmse_target: 0.1331 train_rmse_stderror: 0.01791 train_kl_div: 0.03755\n","val_rmse_target: 0.475 val_rmse_stderror: 1.732\n","Still best_val_rmse: 0.4728 (from epoch 3)\n","\n","4 steps took 5.04 seconds\n","Epoch: 3 batch_num: 120\n","train_rmse_target: 0.1424 train_rmse_stderror: 0.01951 train_kl_div: 0.04436\n","val_rmse_target: 0.4735 val_rmse_stderror: 1.73\n","Still best_val_rmse: 0.4728 (from epoch 3)\n","\n","4 steps took 5.05 seconds\n","Epoch: 3 batch_num: 124\n","train_rmse_target: 0.1486 train_rmse_stderror: 0.02481 train_kl_div: 0.04842\n","val_rmse_target: 0.4743 val_rmse_stderror: 1.727\n","Still best_val_rmse: 0.4728 (from epoch 3)\n","\n","4 steps took 5.05 seconds\n","Epoch: 3 batch_num: 128\n","train_rmse_target: 0.1657 train_rmse_stderror: 0.0201 train_kl_div: 0.06187\n","val_rmse_target: 0.4722 val_rmse_stderror: 1.728\n","New best_val_rmse: 0.4722\n","\n","4 steps took 5.07 seconds\n","Epoch: 3 batch_num: 132\n","train_rmse_target: 0.167 train_rmse_stderror: 0.009806 train_kl_div: 0.06098\n","val_rmse_target: 0.4728 val_rmse_stderror: 1.727\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.06 seconds\n","Epoch: 3 batch_num: 136\n","train_rmse_target: 0.1572 train_rmse_stderror: 0.02571 train_kl_div: 0.04873\n","val_rmse_target: 0.4755 val_rmse_stderror: 1.724\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.05 seconds\n","Epoch: 3 batch_num: 140\n","train_rmse_target: 0.1627 train_rmse_stderror: 0.01489 train_kl_div: 0.05621\n","val_rmse_target: 0.4744 val_rmse_stderror: 1.727\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.05 seconds\n","Epoch: 3 batch_num: 144\n","train_rmse_target: 0.1467 train_rmse_stderror: 0.02158 train_kl_div: 0.04914\n","val_rmse_target: 0.4844 val_rmse_stderror: 1.73\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 152\n","train_rmse_target: 0.1933 train_rmse_stderror: 0.0312 train_kl_div: 0.07342\n","val_rmse_target: 0.4782 val_rmse_stderror: 1.729\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.05 seconds\n","Epoch: 3 batch_num: 156\n","train_rmse_target: 0.1075 train_rmse_stderror: 0.02649 train_kl_div: 0.02884\n","val_rmse_target: 0.4765 val_rmse_stderror: 1.729\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.05 seconds\n","Epoch: 3 batch_num: 160\n","train_rmse_target: 0.1842 train_rmse_stderror: 0.02592 train_kl_div: 0.06951\n","val_rmse_target: 0.4745 val_rmse_stderror: 1.726\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.05 seconds\n","Epoch: 3 batch_num: 164\n","train_rmse_target: 0.1254 train_rmse_stderror: 0.01866 train_kl_div: 0.0368\n","val_rmse_target: 0.4753 val_rmse_stderror: 1.721\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.05 seconds\n","Epoch: 3 batch_num: 168\n","train_rmse_target: 0.1674 train_rmse_stderror: 0.02997 train_kl_div: 0.05545\n","val_rmse_target: 0.4781 val_rmse_stderror: 1.722\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.06 seconds\n","Epoch: 3 batch_num: 172\n","train_rmse_target: 0.1554 train_rmse_stderror: 0.03568 train_kl_div: 0.04418\n","val_rmse_target: 0.4772 val_rmse_stderror: 1.733\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.04 seconds\n","Epoch: 3 batch_num: 176\n","train_rmse_target: 0.2424 train_rmse_stderror: 0.02084 train_kl_div: 0.123\n","val_rmse_target: 0.4762 val_rmse_stderror: 1.736\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.05 seconds\n","Epoch: 3 batch_num: 180\n","train_rmse_target: 0.1623 train_rmse_stderror: 0.02376 train_kl_div: 0.0556\n","val_rmse_target: 0.473 val_rmse_stderror: 1.732\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.06 seconds\n","Epoch: 3 batch_num: 184\n","train_rmse_target: 0.08757 train_rmse_stderror: 0.02461 train_kl_div: 0.01731\n","val_rmse_target: 0.4722 val_rmse_stderror: 1.728\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.22 seconds\n","Epoch: 4 batch_num: 0\n","train_rmse_target: 0.0992 train_rmse_stderror: 0.01871 train_kl_div: 0.02357\n","val_rmse_target: 0.473 val_rmse_stderror: 1.724\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.05 seconds\n","Epoch: 4 batch_num: 4\n","train_rmse_target: 0.0657 train_rmse_stderror: 0.01504 train_kl_div: 0.01042\n","val_rmse_target: 0.4735 val_rmse_stderror: 1.724\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.06 seconds\n","Epoch: 4 batch_num: 8\n","train_rmse_target: 0.1036 train_rmse_stderror: 0.02092 train_kl_div: 0.02634\n","val_rmse_target: 0.4747 val_rmse_stderror: 1.727\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.05 seconds\n","Epoch: 4 batch_num: 12\n","train_rmse_target: 0.05457 train_rmse_stderror: 0.02028 train_kl_div: 0.008353\n","val_rmse_target: 0.4761 val_rmse_stderror: 1.727\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.05 seconds\n","Epoch: 4 batch_num: 16\n","train_rmse_target: 0.08717 train_rmse_stderror: 0.01758 train_kl_div: 0.01788\n","val_rmse_target: 0.4781 val_rmse_stderror: 1.724\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.06 seconds\n","Epoch: 4 batch_num: 20\n","train_rmse_target: 0.0821 train_rmse_stderror: 0.02089 train_kl_div: 0.0163\n","val_rmse_target: 0.4786 val_rmse_stderror: 1.725\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.05 seconds\n","Epoch: 4 batch_num: 24\n","train_rmse_target: 0.1102 train_rmse_stderror: 0.02192 train_kl_div: 0.02722\n","val_rmse_target: 0.4777 val_rmse_stderror: 1.727\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.05 seconds\n","Epoch: 4 batch_num: 28\n","train_rmse_target: 0.1177 train_rmse_stderror: 0.01424 train_kl_div: 0.02849\n","val_rmse_target: 0.4762 val_rmse_stderror: 1.729\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.05 seconds\n","Epoch: 4 batch_num: 32\n","train_rmse_target: 0.07357 train_rmse_stderror: 0.03144 train_kl_div: 0.01462\n","val_rmse_target: 0.4756 val_rmse_stderror: 1.729\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.05 seconds\n","Epoch: 4 batch_num: 36\n","train_rmse_target: 0.07712 train_rmse_stderror: 0.02045 train_kl_div: 0.01411\n","val_rmse_target: 0.4751 val_rmse_stderror: 1.729\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.05 seconds\n","Epoch: 4 batch_num: 40\n","train_rmse_target: 0.1337 train_rmse_stderror: 0.01643 train_kl_div: 0.03764\n","val_rmse_target: 0.4751 val_rmse_stderror: 1.729\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.06 seconds\n","Epoch: 4 batch_num: 44\n","train_rmse_target: 0.06817 train_rmse_stderror: 0.01883 train_kl_div: 0.01235\n","val_rmse_target: 0.4747 val_rmse_stderror: 1.73\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.04 seconds\n","Epoch: 4 batch_num: 48\n","train_rmse_target: 0.1405 train_rmse_stderror: 0.03209 train_kl_div: 0.042\n","val_rmse_target: 0.4747 val_rmse_stderror: 1.729\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.05 seconds\n","Epoch: 4 batch_num: 52\n","train_rmse_target: 0.07349 train_rmse_stderror: 0.02127 train_kl_div: 0.01192\n","val_rmse_target: 0.475 val_rmse_stderror: 1.728\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.06 seconds\n","Epoch: 4 batch_num: 56\n","train_rmse_target: 0.1394 train_rmse_stderror: 0.0363 train_kl_div: 0.03221\n","val_rmse_target: 0.4746 val_rmse_stderror: 1.73\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.05 seconds\n","Epoch: 4 batch_num: 60\n","train_rmse_target: 0.1038 train_rmse_stderror: 0.02083 train_kl_div: 0.02107\n","val_rmse_target: 0.4743 val_rmse_stderror: 1.73\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.05 seconds\n","Epoch: 4 batch_num: 64\n","train_rmse_target: 0.0757 train_rmse_stderror: 0.0177 train_kl_div: 0.01201\n","val_rmse_target: 0.4744 val_rmse_stderror: 1.732\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.05 seconds\n","Epoch: 4 batch_num: 68\n","train_rmse_target: 0.05302 train_rmse_stderror: 0.0201 train_kl_div: 0.0076\n","val_rmse_target: 0.4747 val_rmse_stderror: 1.732\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.05 seconds\n","Epoch: 4 batch_num: 72\n","train_rmse_target: 0.06676 train_rmse_stderror: 0.02006 train_kl_div: 0.011\n","val_rmse_target: 0.4753 val_rmse_stderror: 1.73\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.05 seconds\n","Epoch: 4 batch_num: 76\n","train_rmse_target: 0.07025 train_rmse_stderror: 0.01924 train_kl_div: 0.01202\n","val_rmse_target: 0.4755 val_rmse_stderror: 1.729\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.06 seconds\n","Epoch: 4 batch_num: 80\n","train_rmse_target: 0.07695 train_rmse_stderror: 0.02481 train_kl_div: 0.01344\n","val_rmse_target: 0.4756 val_rmse_stderror: 1.727\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.06 seconds\n","Epoch: 4 batch_num: 84\n","train_rmse_target: 0.09454 train_rmse_stderror: 0.02623 train_kl_div: 0.02166\n","val_rmse_target: 0.4755 val_rmse_stderror: 1.725\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.04 seconds\n","Epoch: 4 batch_num: 88\n","train_rmse_target: 0.1007 train_rmse_stderror: 0.02568 train_kl_div: 0.02198\n","val_rmse_target: 0.4748 val_rmse_stderror: 1.726\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.06 seconds\n","Epoch: 4 batch_num: 92\n","train_rmse_target: 0.07449 train_rmse_stderror: 0.01811 train_kl_div: 0.0132\n","val_rmse_target: 0.4741 val_rmse_stderror: 1.728\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.05 seconds\n","Epoch: 4 batch_num: 96\n","train_rmse_target: 0.09257 train_rmse_stderror: 0.0236 train_kl_div: 0.02031\n","val_rmse_target: 0.4739 val_rmse_stderror: 1.73\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.06 seconds\n","Epoch: 4 batch_num: 100\n","train_rmse_target: 0.07774 train_rmse_stderror: 0.01719 train_kl_div: 0.01491\n","val_rmse_target: 0.4738 val_rmse_stderror: 1.73\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.05 seconds\n","Epoch: 4 batch_num: 104\n","train_rmse_target: 0.1321 train_rmse_stderror: 0.01893 train_kl_div: 0.03694\n","val_rmse_target: 0.4741 val_rmse_stderror: 1.73\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.05 seconds\n","Epoch: 4 batch_num: 108\n","train_rmse_target: 0.09227 train_rmse_stderror: 0.02039 train_kl_div: 0.02031\n","val_rmse_target: 0.4747 val_rmse_stderror: 1.729\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.06 seconds\n","Epoch: 4 batch_num: 112\n","train_rmse_target: 0.1008 train_rmse_stderror: 0.02276 train_kl_div: 0.02239\n","val_rmse_target: 0.4753 val_rmse_stderror: 1.728\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.06 seconds\n","Epoch: 4 batch_num: 116\n","train_rmse_target: 0.09005 train_rmse_stderror: 0.01959 train_kl_div: 0.01758\n","val_rmse_target: 0.4753 val_rmse_stderror: 1.727\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.05 seconds\n","Epoch: 4 batch_num: 120\n","train_rmse_target: 0.1013 train_rmse_stderror: 0.01853 train_kl_div: 0.0208\n","val_rmse_target: 0.4751 val_rmse_stderror: 1.727\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.05 seconds\n","Epoch: 4 batch_num: 124\n","train_rmse_target: 0.1374 train_rmse_stderror: 0.02022 train_kl_div: 0.03849\n","val_rmse_target: 0.4749 val_rmse_stderror: 1.727\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.05 seconds\n","Epoch: 4 batch_num: 128\n","train_rmse_target: 0.1113 train_rmse_stderror: 0.02721 train_kl_div: 0.02489\n","val_rmse_target: 0.4747 val_rmse_stderror: 1.727\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.05 seconds\n","Epoch: 4 batch_num: 132\n","train_rmse_target: 0.0798 train_rmse_stderror: 0.02417 train_kl_div: 0.0152\n","val_rmse_target: 0.4746 val_rmse_stderror: 1.727\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.04 seconds\n","Epoch: 4 batch_num: 136\n","train_rmse_target: 0.09404 train_rmse_stderror: 0.01844 train_kl_div: 0.0203\n","val_rmse_target: 0.4745 val_rmse_stderror: 1.727\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.06 seconds\n","Epoch: 4 batch_num: 140\n","train_rmse_target: 0.0962 train_rmse_stderror: 0.01705 train_kl_div: 0.0179\n","val_rmse_target: 0.4745 val_rmse_stderror: 1.727\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.05 seconds\n","Epoch: 4 batch_num: 144\n","train_rmse_target: 0.07218 train_rmse_stderror: 0.02296 train_kl_div: 0.01228\n","val_rmse_target: 0.4745 val_rmse_stderror: 1.727\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.05 seconds\n","Epoch: 4 batch_num: 148\n","train_rmse_target: 0.07416 train_rmse_stderror: 0.03159 train_kl_div: 0.01396\n","val_rmse_target: 0.4745 val_rmse_stderror: 1.727\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.06 seconds\n","Epoch: 4 batch_num: 152\n","train_rmse_target: 0.09134 train_rmse_stderror: 0.01499 train_kl_div: 0.01854\n","val_rmse_target: 0.4745 val_rmse_stderror: 1.727\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.05 seconds\n","Epoch: 4 batch_num: 156\n","train_rmse_target: 0.06993 train_rmse_stderror: 0.02782 train_kl_div: 0.01137\n","val_rmse_target: 0.4745 val_rmse_stderror: 1.727\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.06 seconds\n","Epoch: 4 batch_num: 160\n","train_rmse_target: 0.1169 train_rmse_stderror: 0.02129 train_kl_div: 0.02385\n","val_rmse_target: 0.4745 val_rmse_stderror: 1.727\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.05 seconds\n","Epoch: 4 batch_num: 164\n","train_rmse_target: 0.1215 train_rmse_stderror: 0.01823 train_kl_div: 0.03193\n","val_rmse_target: 0.4745 val_rmse_stderror: 1.727\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.04 seconds\n","Epoch: 4 batch_num: 168\n","train_rmse_target: 0.1175 train_rmse_stderror: 0.02316 train_kl_div: 0.03024\n","val_rmse_target: 0.4745 val_rmse_stderror: 1.727\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.05 seconds\n","Epoch: 4 batch_num: 172\n","train_rmse_target: 0.0844 train_rmse_stderror: 0.0275 train_kl_div: 0.0155\n","val_rmse_target: 0.4745 val_rmse_stderror: 1.727\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.05 seconds\n","Epoch: 4 batch_num: 176\n","train_rmse_target: 0.1218 train_rmse_stderror: 0.02737 train_kl_div: 0.03337\n","val_rmse_target: 0.4745 val_rmse_stderror: 1.727\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.05 seconds\n","Epoch: 4 batch_num: 180\n","train_rmse_target: 0.1939 train_rmse_stderror: 0.02993 train_kl_div: 0.06529\n","val_rmse_target: 0.4745 val_rmse_stderror: 1.727\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","4 steps took 5.05 seconds\n","Epoch: 4 batch_num: 184\n","train_rmse_target: 0.08103 train_rmse_stderror: 0.02215 train_kl_div: 0.01492\n","val_rmse_target: 0.4745 val_rmse_stderror: 1.727\n","Still best_val_rmse: 0.4722 (from epoch 3)\n","\n","Performance estimates:\n","[0.47217571478538095]\n","Mean: 0.47217571478538095\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 2/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 82.0 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.7066 train_rmse_stderror: 0.03926 train_kl_div: 1.043\n","val_rmse_target: 0.8903 val_rmse_stderror: 1.225\n","New best_val_rmse: 0.8903\n","\n","64 steps took 81.0 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.7641 train_rmse_stderror: 0.03717 train_kl_div: 1.248\n","val_rmse_target: 0.6777 val_rmse_stderror: 1.156\n","New best_val_rmse: 0.6777\n","\n","64 steps took 81.2 seconds\n","Epoch: 1 batch_num: 4\n","train_rmse_target: 1.032 train_rmse_stderror: 0.06537 train_kl_div: 2.082\n","val_rmse_target: 0.9727 val_rmse_stderror: 1.133\n","Still best_val_rmse: 0.6777 (from epoch 0)\n","\n","64 steps took 81.0 seconds\n","Epoch: 1 batch_num: 68\n","train_rmse_target: 0.4481 train_rmse_stderror: 0.0323 train_kl_div: 0.4559\n","val_rmse_target: 0.6966 val_rmse_stderror: 1.176\n","Still best_val_rmse: 0.6777 (from epoch 0)\n","\n","64 steps took 81.0 seconds\n","Epoch: 1 batch_num: 132\n","train_rmse_target: 0.4601 train_rmse_stderror: 0.04344 train_kl_div: 0.4112\n","val_rmse_target: 0.6754 val_rmse_stderror: 1.18\n","New best_val_rmse: 0.6754\n","\n","64 steps took 81.2 seconds\n","Epoch: 2 batch_num: 8\n","train_rmse_target: 0.506 train_rmse_stderror: 0.02839 train_kl_div: 0.4878\n","val_rmse_target: 0.583 val_rmse_stderror: 1.174\n","New best_val_rmse: 0.583\n","\n","64 steps took 81.0 seconds\n","Epoch: 2 batch_num: 72\n","train_rmse_target: 0.3662 train_rmse_stderror: 0.03654 train_kl_div: 0.2372\n","val_rmse_target: 0.5422 val_rmse_stderror: 1.187\n","New best_val_rmse: 0.5422\n","\n","32 steps took 40.5 seconds\n","Epoch: 2 batch_num: 104\n","train_rmse_target: 0.4762 train_rmse_stderror: 0.02376 train_kl_div: 0.511\n","val_rmse_target: 0.5724 val_rmse_stderror: 1.196\n","Still best_val_rmse: 0.5422 (from epoch 2)\n","\n","64 steps took 81.0 seconds\n","Epoch: 2 batch_num: 168\n","train_rmse_target: 0.3115 train_rmse_stderror: 0.01854 train_kl_div: 0.1802\n","val_rmse_target: 0.5253 val_rmse_stderror: 1.177\n","New best_val_rmse: 0.5253\n","\n","32 steps took 40.7 seconds\n","Epoch: 3 batch_num: 12\n","train_rmse_target: 0.3473 train_rmse_stderror: 0.03262 train_kl_div: 0.2426\n","val_rmse_target: 0.522 val_rmse_stderror: 1.19\n","New best_val_rmse: 0.522\n","\n","32 steps took 40.5 seconds\n","Epoch: 3 batch_num: 44\n","train_rmse_target: 0.5643 train_rmse_stderror: 0.04722 train_kl_div: 0.5405\n","val_rmse_target: 0.5196 val_rmse_stderror: 1.186\n","New best_val_rmse: 0.5196\n","\n","32 steps took 40.5 seconds\n","Epoch: 3 batch_num: 76\n","train_rmse_target: 0.2095 train_rmse_stderror: 0.01876 train_kl_div: 0.08897\n","val_rmse_target: 0.517 val_rmse_stderror: 1.181\n","New best_val_rmse: 0.517\n","\n","32 steps took 40.5 seconds\n","Epoch: 3 batch_num: 108\n","train_rmse_target: 0.4465 train_rmse_stderror: 0.03246 train_kl_div: 0.3957\n","val_rmse_target: 0.5189 val_rmse_stderror: 1.174\n","Still best_val_rmse: 0.517 (from epoch 3)\n","\n","32 steps took 40.5 seconds\n","Epoch: 3 batch_num: 140\n","train_rmse_target: 0.4491 train_rmse_stderror: 0.03377 train_kl_div: 0.4306\n","val_rmse_target: 0.5259 val_rmse_stderror: 1.178\n","Still best_val_rmse: 0.517 (from epoch 3)\n","\n","32 steps took 40.5 seconds\n","Epoch: 3 batch_num: 172\n","train_rmse_target: 0.4208 train_rmse_stderror: 0.03287 train_kl_div: 0.312\n","val_rmse_target: 0.5462 val_rmse_stderror: 1.192\n","Still best_val_rmse: 0.517 (from epoch 3)\n","\n","32 steps took 40.7 seconds\n","Epoch: 4 batch_num: 16\n","train_rmse_target: 0.2412 train_rmse_stderror: 0.02695 train_kl_div: 0.09605\n","val_rmse_target: 0.517 val_rmse_stderror: 1.186\n","New best_val_rmse: 0.517\n","\n","32 steps took 40.6 seconds\n","Epoch: 4 batch_num: 48\n","train_rmse_target: 0.3931 train_rmse_stderror: 0.05199 train_kl_div: 0.2387\n","val_rmse_target: 0.5184 val_rmse_stderror: 1.181\n","Still best_val_rmse: 0.517 (from epoch 4)\n","\n","32 steps took 40.5 seconds\n","Epoch: 4 batch_num: 80\n","train_rmse_target: 0.2667 train_rmse_stderror: 0.03417 train_kl_div: 0.1417\n","val_rmse_target: 0.5179 val_rmse_stderror: 1.18\n","Still best_val_rmse: 0.517 (from epoch 4)\n","\n","32 steps took 40.5 seconds\n","Epoch: 4 batch_num: 112\n","train_rmse_target: 0.31 train_rmse_stderror: 0.02683 train_kl_div: 0.1686\n","val_rmse_target: 0.5147 val_rmse_stderror: 1.183\n","New best_val_rmse: 0.5147\n","\n","32 steps took 40.5 seconds\n","Epoch: 4 batch_num: 144\n","train_rmse_target: 0.2731 train_rmse_stderror: 0.02986 train_kl_div: 0.1549\n","val_rmse_target: 0.5159 val_rmse_stderror: 1.182\n","Still best_val_rmse: 0.5147 (from epoch 4)\n","\n","32 steps took 40.5 seconds\n","Epoch: 4 batch_num: 176\n","train_rmse_target: 0.3578 train_rmse_stderror: 0.02084 train_kl_div: 0.2807\n","val_rmse_target: 0.515 val_rmse_stderror: 1.182\n","Still best_val_rmse: 0.5147 (from epoch 4)\n","\n","Performance estimates:\n","[0.47217571478538095, 0.5146852177472541]\n","Mean: 0.4934304662663175\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 3/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 82.0 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.7458 train_rmse_stderror: 0.08184 train_kl_div: 1.201\n","val_rmse_target: 0.6763 val_rmse_stderror: 1.831\n","New best_val_rmse: 0.6763\n","\n","64 steps took 81.0 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.7549 train_rmse_stderror: 0.03893 train_kl_div: 1.166\n","val_rmse_target: 0.7502 val_rmse_stderror: 1.757\n","Still best_val_rmse: 0.6763 (from epoch 0)\n","\n","64 steps took 81.3 seconds\n","Epoch: 1 batch_num: 4\n","train_rmse_target: 1.272 train_rmse_stderror: 0.02759 train_kl_div: 2.963\n","val_rmse_target: 1.053 val_rmse_stderror: 1.792\n","Still best_val_rmse: 0.6763 (from epoch 0)\n","\n","64 steps took 81.0 seconds\n","Epoch: 1 batch_num: 68\n","train_rmse_target: 1.317 train_rmse_stderror: 0.05328 train_kl_div: 2.783\n","val_rmse_target: 1.051 val_rmse_stderror: 1.776\n","Still best_val_rmse: 0.6763 (from epoch 0)\n","\n","64 steps took 81.0 seconds\n","Epoch: 1 batch_num: 132\n","train_rmse_target: 0.8269 train_rmse_stderror: 0.0445 train_kl_div: 1.325\n","val_rmse_target: 1.05 val_rmse_stderror: 1.779\n","Still best_val_rmse: 0.6763 (from epoch 0)\n","\n","64 steps took 81.3 seconds\n","Epoch: 2 batch_num: 8\n","train_rmse_target: 1.327 train_rmse_stderror: 0.05847 train_kl_div: 2.912\n","val_rmse_target: 1.051 val_rmse_stderror: 1.779\n","Still best_val_rmse: 0.6763 (from epoch 0)\n","\n","64 steps took 81.0 seconds\n","Epoch: 2 batch_num: 72\n","train_rmse_target: 0.9538 train_rmse_stderror: 0.02697 train_kl_div: 1.824\n","val_rmse_target: 1.05 val_rmse_stderror: 1.762\n","Still best_val_rmse: 0.6763 (from epoch 0)\n","\n","64 steps took 81.0 seconds\n","Epoch: 2 batch_num: 136\n","train_rmse_target: 1.086 train_rmse_stderror: 0.02848 train_kl_div: 2.23\n","val_rmse_target: 1.055 val_rmse_stderror: 1.785\n","Still best_val_rmse: 0.6763 (from epoch 0)\n","\n","64 steps took 81.2 seconds\n","Epoch: 3 batch_num: 12\n","train_rmse_target: 0.9434 train_rmse_stderror: 0.02518 train_kl_div: 1.706\n","val_rmse_target: 1.063 val_rmse_stderror: 1.778\n","Still best_val_rmse: 0.6763 (from epoch 0)\n","\n","64 steps took 81.0 seconds\n","Epoch: 3 batch_num: 76\n","train_rmse_target: 0.9182 train_rmse_stderror: 0.02912 train_kl_div: 1.627\n","val_rmse_target: 1.056 val_rmse_stderror: 1.783\n","Still best_val_rmse: 0.6763 (from epoch 0)\n","\n","64 steps took 81.0 seconds\n","Epoch: 3 batch_num: 140\n","train_rmse_target: 1.166 train_rmse_stderror: 0.03866 train_kl_div: 2.444\n","val_rmse_target: 1.05 val_rmse_stderror: 1.779\n","Still best_val_rmse: 0.6763 (from epoch 0)\n","\n","64 steps took 81.2 seconds\n","Epoch: 4 batch_num: 16\n","train_rmse_target: 1.166 train_rmse_stderror: 0.04951 train_kl_div: 2.258\n","val_rmse_target: 1.05 val_rmse_stderror: 1.784\n","Still best_val_rmse: 0.6763 (from epoch 0)\n","\n","64 steps took 81.0 seconds\n","Epoch: 4 batch_num: 80\n","train_rmse_target: 1.15 train_rmse_stderror: 0.02241 train_kl_div: 2.589\n","val_rmse_target: 1.051 val_rmse_stderror: 1.779\n","Still best_val_rmse: 0.6763 (from epoch 0)\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-bf8661c26b41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"model_{fold + 1}.pth\"\u001b[0m \u001b[0;31m# model_fold数_.pth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mset_random_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSEED\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# SEEDはfold別に変わるようにする\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mlist_val_rmse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_and_save_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nPerformance estimates:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-22-0ab8e515d049>\u001b[0m in \u001b[0;36mtrain_and_save_model\u001b[0;34m(train_indices, val_indices, model_path)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mnum_training_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         num_warmup_steps=50)    \n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-18-4f3f56080850>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, model_path, train_loader, val_loader, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 誤差逆伝播法により勾配を得る\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 重みを更新する\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules/transformers/optimization.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    344\u001b[0m                 \u001b[0;31m# In-place operations to update the averages at the same time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eps\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"m4v-cGx-Mv7S","executionInfo":{"status":"aborted","timestamp":1626696647226,"user_tz":-540,"elapsed":23,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["print(list_val_rmse)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q2CdCMuIKDMP","executionInfo":{"status":"aborted","timestamp":1626696647228,"user_tz":-540,"elapsed":24,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#rep = MemReporter(model)\n","#rep.report()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eLl1yDOOKIe7","executionInfo":{"status":"aborted","timestamp":1626696647229,"user_tz":-540,"elapsed":25,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#rep = MemReporter(model.roberta)\n","#rep.report()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7qkqnknA_m9D","executionInfo":{"status":"aborted","timestamp":1626696647230,"user_tz":-540,"elapsed":25,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#gpuinfo()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PwrqSMdYA6Pu","executionInfo":{"status":"aborted","timestamp":1626696647230,"user_tz":-540,"elapsed":24,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#del model\n","#del optimizer \n","#del train_loader\n","#del val_loader\n","#del scheduler \n","#del list_val_rmse\n","#del train_indices\n","#del val_indices\n","#del tokenizer\n","#torch.cuda.empty_cache()\n","#gpuinfo()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wXcHyUSJXecL"},"source":["# Inference"]},{"cell_type":"code","metadata":{"id":"YIV6UllSIGoa","executionInfo":{"status":"aborted","timestamp":1626696647231,"user_tz":-540,"elapsed":24,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["!cp -r /content/model_1.pth /content/model/model_1.pth\n","!cp -r /content/model_2.pth /content/model/model_2.pth\n","!cp -r /content/model_3.pth /content/model/model_3.pth\n","!cp -r /content/model_4.pth /content/model/model_4.pth\n","!cp -r /content/model_5.pth /content/model/model_5.pth"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"14ddOZH4IMam","executionInfo":{"status":"aborted","timestamp":1626696647231,"user_tz":-540,"elapsed":24,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["def dataset_upload():\n","    import json\n","    from kaggle.api.kaggle_api_extended import KaggleApi\n","\n","    id = f'{USERID}/{EX_NO}'\n","\n","    dataset_metadata = {}\n","    dataset_metadata['id'] = id\n","    dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n","    dataset_metadata['title'] = f'{EX_NO}'\n","\n","    with open(UPLOAD_DIR / 'dataset-metadata.json', 'w') as f:\n","        json.dump(dataset_metadata, f, indent=4)\n","\n","    api = KaggleApi()\n","    api.authenticate()\n","\n","    # データセットがない場合\n","    if f'{USERID}/{EX_NO}' not in [str(d) for d in api.dataset_list(user=USERID, search=f'\"{EX_NO}\"')]:\n","        api.dataset_create_new(folder=UPLOAD_DIR,\n","                               convert_to_csv=False,\n","                               dir_mode='skip')\n","    # データセットがある場合\n","    else:\n","        api.dataset_create_version(folder=UPLOAD_DIR,\n","                                   version_notes='update',\n","                                   convert_to_csv=False,\n","                                   delete_old_versions=True,\n","                                   dir_mode='skip')\n","dataset_upload()\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"huJwVMSAPuDO","executionInfo":{"status":"aborted","timestamp":1626696647232,"user_tz":-540,"elapsed":24,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0zzuBPobmLFu","executionInfo":{"status":"aborted","timestamp":1626696647232,"user_tz":-540,"elapsed":24,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wpc8ro9hmNci","executionInfo":{"status":"aborted","timestamp":1626696647232,"user_tz":-540,"elapsed":24,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ceDI72NumT5-","executionInfo":{"status":"aborted","timestamp":1626696647233,"user_tz":-540,"elapsed":25,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PvRi_JQgwcKI","executionInfo":{"status":"aborted","timestamp":1626696647233,"user_tz":-540,"elapsed":25,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":null,"outputs":[]}]}