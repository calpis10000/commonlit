{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":86},"executionInfo":{"elapsed":338,"status":"ok","timestamp":1626475542602,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"},"user_tz":-540},"id":"Z6yRwt-PXtbP","outputId":"ac100425-d819-4136-fb7b-f085508b7ab7"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\nif 'google.colab' in sys.modules:  # colab環境特有の処理_初回のみ\\n  # Google Driveのマウント\\n  from google.colab import drive\\n  drive.mount('/content/drive')\\n\\n  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'    -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/requirements.txt'    --ignore-installed\\n\\n  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'    transformers -U\\n  !pip install gensim==4.0.1 --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\\n  !pip install pytorch_memlab --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\\n\""]},"execution_count":1,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["\"\"\"\n","if 'google.colab' in sys.modules:  # colab環境特有の処理_初回のみ\n","  # Google Driveのマウント\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","\n","  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules' \\\n","   -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/requirements.txt' \\\n","   --ignore-installed\n","\n","  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules' \\\n","   transformers -U\n","  !pip install gensim==4.0.1 --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\n","  !pip install pytorch_memlab --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\n","\"\"\""]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":451,"status":"ok","timestamp":1626475543297,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"},"user_tz":-540},"id":"ucCbvGD1XvG7","outputId":"b1f16082-4240-4a4f-ca33-9e80f2d1b22f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import sys\n","if 'google.colab' in sys.modules:  # colab特有の処理_2回目以降\n","  # Google Driveのマウント\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","\n","  # データセットをDriveから取得\n","  !mkdir -p 'input'\n","  !cp -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/00_input' '/content/input'\n","\n","  # ライブラリのパス指定\n","  sys.path.append('/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules')\n"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":235,"status":"ok","timestamp":1626475543529,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"},"user_tz":-540},"id":"RV9-VwbpZLZ9"},"outputs":[],"source":["from pathlib import Path\n","\n","# input\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    DATA_DIR = Path('../input/commonlitreadabilityprize/')\n","\n","elif 'google.colab' in sys.modules: # Colab環境\n","    !mkdir 'input' -p\n","    !cp '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/00_input/commonlitreadabilityprize/' './input' -r\n","    DATA_DIR = Path('/content/input/commonlitreadabilityprize')\n","\n","else:\n","    DATA_DIR = Path('../00_input/commonlitreadabilityprize/')"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1626475543531,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"},"user_tz":-540},"id":"8tMampUSaDo5"},"outputs":[],"source":["from pathlib import Path\n","\n","# pre-trained model\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    PRE_TRAINED_MODEL_DIR = '../input/roberta-transformers-pytorch/roberta-large'\n","elif 'google.colab' in sys.modules: # Colab環境\n","    PRE_TRAINED_MODEL_DIR = 'roberta-large' # 仮で、毎回DLする想定のモデル名を指定。あとで変更予定。\n","else:\n","    PRE_TRAINED_MODEL_DIR = 'roberta-large'"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1626475543532,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"},"user_tz":-540},"id":"tKjsUxnOeDYl"},"outputs":[],"source":["from pathlib import Path\n","\n","# pre-trained model\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    PRE_TRAINED_MODEL_DIR = '../input/roberta-transformers-pytorch/roberta-large'\n","elif 'google.colab' in sys.modules: # Colab環境\n","    PRE_TRAINED_MODEL_DIR = 'roberta-large' # 仮で、毎回DLする想定のモデル名を指定。あとで変更予定。\n","else:\n","    PRE_TRAINED_MODEL_DIR = 'roberta-large'"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1626475543533,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"},"user_tz":-540},"id":"ZLaT2V0ReoAZ"},"outputs":[],"source":["UPLOAD_DIR = Path('/content/model')\n","EX_NO = '044-train-04'  # 実験番号などを入れる、folderのpathにする\n","USERID = 'calpis10000'"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1626475543533,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"},"user_tz":-540},"id":"hOGjAb4pAJ0F"},"outputs":[],"source":["import subprocess\n","import shlex\n","\n","def gpuinfo():\n","    \"\"\"\n","    Returns size of total GPU RAM and used GPU RAM.\n","\n","    Parameters\n","    ----------\n","    None\n","\n","    Returns\n","    -------\n","    info : dict\n","        Total GPU RAM in integer for key 'total_MiB'.\n","        Used GPU RAM in integer for key 'used_MiB'.\n","    \"\"\"\n","\n","    command = 'nvidia-smi -q -d MEMORY | sed -n \"/FB Memory Usage/,/Free/p\" | sed -e \"1d\" -e \"4d\" -e \"s/ MiB//g\" | cut -d \":\" -f 2 | cut -c2-'\n","    commands = [shlex.split(part) for part in command.split(' | ')]\n","    for i, cmd in enumerate(commands):\n","        if i==0:\n","            res = subprocess.Popen(cmd, stdout=subprocess.PIPE)\n","        else:\n","            res = subprocess.Popen(cmd, stdin=res.stdout, stdout=subprocess.PIPE)\n","    total, used = map(int, res.communicate()[0].decode('utf-8').strip().split('\\n'))\n","    info = {'total_MiB':total, 'used_MiB':used}\n","    return info\n"]},{"cell_type":"markdown","metadata":{"id":"g3-6m5MKXecB"},"source":["# Overview\n","This nb is based on copy from https://www.kaggle.com/andretugan/lightweight-roberta-solution-in-pytorch .\n","\n","Acknowledgments(from base nb): \n","some ideas were taken from kernels by [Torch](https://www.kaggle.com/rhtsingh) and [Maunish](https://www.kaggle.com/maunish)."]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":120055,"status":"ok","timestamp":1626475663580,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"},"user_tz":-540},"id":"HRsRZ06WXecD"},"outputs":[],"source":["import os\n","import math\n","import random\n","import time\n","\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","\n","from transformers import AdamW # optimizer\n","from transformers import AutoTokenizer\n","from transformers import AutoModel\n","from transformers import AutoConfig\n","from transformers import get_cosine_schedule_with_warmup # scheduler\n","from pytorch_memlab import profile\n","import pytorch_memlab\n","from pytorch_memlab import MemReporter\n","\n","from sklearn.model_selection import KFold, StratifiedKFold\n","\n","import gc\n","gc.enable()"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":24,"status":"ok","timestamp":1626475663587,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"},"user_tz":-540},"id":"omBfwshTXecE"},"outputs":[],"source":["NUM_FOLDS = 5 # K Fold\n","NUM_EPOCHS = 5 # Epochs\n","BATCH_SIZE = 12 # Batch Size\n","MAX_LEN = 248 # ベクトル長\n","EVAL_SCHEDULE = [(0.55, 64), (0.50, 32), (0.49, 16), (0.48, 8), (0.47, 4), (0.46, 2), (-1., 1)] # schedulerの何らかの設定？\n","ROBERTA_PATH = PRE_TRAINED_MODEL_DIR # roberta pre-trainedモデル(モデルとして指定)\n","TOKENIZER_PATH = PRE_TRAINED_MODEL_DIR # roberta pre-trainedモデル(Tokenizerとして指定)\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\" # cudaがなければcpuを使えばいいじゃない"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1626475663589,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"},"user_tz":-540},"id":"4qcuXqwtXecF"},"outputs":[],"source":["def set_random_seed(random_seed):\n","    random.seed(random_seed)\n","    np.random.seed(random_seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(random_seed)\n","\n","    torch.manual_seed(random_seed)\n","    torch.cuda.manual_seed(random_seed)\n","    torch.cuda.manual_seed_all(random_seed)\n","\n","    torch.backends.cudnn.deterministic = True# cudnnによる最適化で結果が変わらないためのおまじない "]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1626475663593,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"},"user_tz":-540},"id":"70PyLsJTXecF"},"outputs":[],"source":["# train, testを読む\n","train_df = pd.read_csv(DATA_DIR/\"train.csv\")\n","\n","# Remove incomplete entries if any.\n","train_df.drop(train_df[(train_df.target == 0) \u0026 (train_df.standard_error == 0)].index,\n","              inplace=True)\n","train_df.reset_index(drop=True, inplace=True)\n","\n","test_df = pd.read_csv(DATA_DIR/\"test.csv\")\n","submission_df = pd.read_csv(DATA_DIR/\"sample_submission.csv\")"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1626475663594,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"},"user_tz":-540},"id":"9ZYOB59L8qtA","outputId":"a557a88e-a997-4170-dad6-3f22a7bf4f34"},"outputs":[{"data":{"text/html":["\u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eid\u003c/th\u003e\n","      \u003cth\u003eurl_legal\u003c/th\u003e\n","      \u003cth\u003elicense\u003c/th\u003e\n","      \u003cth\u003eexcerpt\u003c/th\u003e\n","      \u003cth\u003etarget\u003c/th\u003e\n","      \u003cth\u003estandard_error\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003ec12129c31\u003c/td\u003e\n","      \u003ctd\u003eNaN\u003c/td\u003e\n","      \u003ctd\u003eNaN\u003c/td\u003e\n","      \u003ctd\u003eWhen the young people returned to the ballroom...\u003c/td\u003e\n","      \u003ctd\u003e-0.340259\u003c/td\u003e\n","      \u003ctd\u003e0.464009\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e85aa80a4c\u003c/td\u003e\n","      \u003ctd\u003eNaN\u003c/td\u003e\n","      \u003ctd\u003eNaN\u003c/td\u003e\n","      \u003ctd\u003eAll through dinner time, Mrs. Fayre was somewh...\u003c/td\u003e\n","      \u003ctd\u003e-0.315372\u003c/td\u003e\n","      \u003ctd\u003e0.480805\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003eb69ac6792\u003c/td\u003e\n","      \u003ctd\u003eNaN\u003c/td\u003e\n","      \u003ctd\u003eNaN\u003c/td\u003e\n","      \u003ctd\u003eAs Roger had predicted, the snow departed as q...\u003c/td\u003e\n","      \u003ctd\u003e-0.580118\u003c/td\u003e\n","      \u003ctd\u003e0.476676\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003edd1000b26\u003c/td\u003e\n","      \u003ctd\u003eNaN\u003c/td\u003e\n","      \u003ctd\u003eNaN\u003c/td\u003e\n","      \u003ctd\u003eAnd outside before the palace a great garden w...\u003c/td\u003e\n","      \u003ctd\u003e-1.054013\u003c/td\u003e\n","      \u003ctd\u003e0.450007\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e37c1b32fb\u003c/td\u003e\n","      \u003ctd\u003eNaN\u003c/td\u003e\n","      \u003ctd\u003eNaN\u003c/td\u003e\n","      \u003ctd\u003eOnce upon a time there were Three Bears who li...\u003c/td\u003e\n","      \u003ctd\u003e0.247197\u003c/td\u003e\n","      \u003ctd\u003e0.510845\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e"],"text/plain":["          id url_legal  ...    target standard_error\n","0  c12129c31       NaN  ... -0.340259       0.464009\n","1  85aa80a4c       NaN  ... -0.315372       0.480805\n","2  b69ac6792       NaN  ... -0.580118       0.476676\n","3  dd1000b26       NaN  ... -1.054013       0.450007\n","4  37c1b32fb       NaN  ...  0.247197       0.510845\n","\n","[5 rows x 6 columns]"]},"execution_count":12,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["train_df.head()\n"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":213},"executionInfo":{"elapsed":5391,"status":"ok","timestamp":1626475668968,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"},"user_tz":-540},"id":"xf0662k4XecF","outputId":"cb5b83a7-143d-4232-bdb1-58d38fcea19c"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a8e7333f3b9541e5a2d6a86e51fa552f","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=482.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3ec8de89c55f4988956990f947f67ac5","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dd102acd4c834a7b87243d3828f84c26","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9c6035ce8b254d379a9de0da554af9ed","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355863.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]}],"source":["# tokenizerを指定\n","tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)"]},{"cell_type":"markdown","metadata":{"id":"N6aaghNkXecG"},"source":["# Dataset"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1626475668969,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"},"user_tz":-540},"id":"zkopT0U1XecG"},"outputs":[],"source":["# Dataset用のClass。おそらく、trainとtestでインスタンスを生成し、DataFrameと同じように扱えるような思想。\n","class LitDataset(Dataset):\n","    def __init__(self, df, inference_only=False):\n","        super().__init__()\n","\n","        self.df = df        \n","        self.inference_only = inference_only # Testデータ用フラグ\n","        self.text = df.excerpt.tolist() # 分析対象カラムをlistにする。(分かち書きではなく、Seriesをlistへ変換するような処理)\n","        #self.text = [text.replace(\"\\n\", \" \") for text in self.text] # 単語単位で分かち書きする場合\n","        \n","        if not self.inference_only:\n","            self.target = torch.tensor(df.target.values, dtype=torch.float32) # trainのみ、targetをtensorに変換\n","            self.standard_error = torch.tensor(df.standard_error.values, dtype=torch.float32) \n","\n","        self.encoded = tokenizer.batch_encode_plus( # textをtokenize\n","            self.text,\n","            padding = 'max_length',            \n","            max_length = MAX_LEN,\n","            truncation = True, # 最大長を超える文字は切り捨て\n","            return_attention_mask=True\n","        )        \n"," \n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    \n","    def __getitem__(self, index): # 変換結果を返す\n","        input_ids = torch.tensor(self.encoded['input_ids'][index])\n","        attention_mask = torch.tensor(self.encoded['attention_mask'][index])\n","        \n","        if self.inference_only:\n","            return (input_ids, attention_mask)            \n","        else:\n","            target = self.target[index]\n","            standard_error = self.standard_error[index]\n","            return (input_ids, attention_mask, target, standard_error)"]},{"cell_type":"markdown","metadata":{"id":"KKtdy32wXecG"},"source":["# Model\n","The model is inspired by the one from [Maunish](https://www.kaggle.com/maunish/clrp-roberta-svm)."]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1626475668970,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"},"user_tz":-540},"id":"BpkxjXEUXecH"},"outputs":[],"source":["class LitModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        config = AutoConfig.from_pretrained(ROBERTA_PATH) # pretrainedからconfigを読み込み\n","        config.update({\"output_hidden_states\":True, # config更新: embedding層を抽出\n","                       \"hidden_dropout_prob\": 0.0, # config更新: dropoutしない\n","                       \"layer_norm_eps\": 1e-7}) # config更新: layer normalizationのepsilon                      \n","        \n","        self.roberta = AutoModel.from_pretrained(ROBERTA_PATH, config=config) # cpuで処理する\n","            \n","        self.attention = nn.Sequential(# attentionレイヤー            \n","            nn.Linear(config.hidden_size, 512),      \n","            nn.Tanh(),                       \n","            nn.Linear(512, 1),\n","            nn.Softmax(dim=1)\n","        )\n","\n","        self.regressor = nn.Sequential( # 出力レイヤー                    \n","            nn.Linear(config.hidden_size*2, 2)                        \n","        )\n","\n","    def forward(self, input_ids, attention_mask):\n","        roberta_output = self.roberta(input_ids=input_ids, # robertaに入力データを流し、出力としてrobertaモデル(layerの複合体)を得る\n","                                      attention_mask=attention_mask)     \n","\n","        last_hidden_state_att = roberta_output.hidden_states[-1] # robertaモデルの最後のlayerを得る\n","        weights = self.attention(last_hidden_state_att) # robertaの最後のlayerをattentionへ入力し、出力として重みを得る                \n","        context_vector = torch.sum(weights * last_hidden_state_att, dim=1) # 重み×最後の層を足し合わせて文書ベクトルとする。\n","        \n","\n","        # https://www.kaggle.com/rhtsingh/utilizing-transformer-representations-efficiently\n","        last_hidden_state_mn = roberta_output[0]\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state_mn.size()).float()\n","        sum_embeddings = torch.sum(last_hidden_state_mn * input_mask_expanded, 1)\n","        sum_mask = input_mask_expanded.sum(1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        mean_embeddings = sum_embeddings / sum_mask\n","        \n","        cat_embeddings = torch.cat([context_vector, mean_embeddings], dim=1)\n","        # Now we reduce the context vector to the prediction score.\n","        return self.regressor(cat_embeddings)"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1626475668970,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"},"user_tz":-540},"id":"bB4jvQTxXecH"},"outputs":[],"source":["# 評価指標(MSE)の計算。最終的に、ルートしてRMSEにすると思われる。\n","def eval_mse(model, data_loader):\n","    \"\"\"Evaluates the mean squared error of the |model| on |data_loader|\"\"\"\n","    model.eval() # evalモードを選択。Batch Normとかdropoutをしなくなる           \n","    mse_mean_sum = 0\n","    mse_std_sum = 0\n","\n","    with torch.no_grad(): # 勾配の計算をしないBlock\n","        for batch_num, (input_ids, attention_mask, target, standard_error) in enumerate(data_loader): # data_loaderからinput, attentin_mask, targetをbatchごとに取り出す\n","            input_ids = input_ids.to(DEVICE)   \n","            attention_mask = attention_mask.to(DEVICE)   \n","            target = target.to(DEVICE)      \n","            standard_error = standard_error.to(DEVICE) \n","            \n","            output = model(input_ids, attention_mask) # 取得した値をモデルへ入力し、出力として予測値を得る。\n","\n","            mse_mean_sum += nn.MSELoss(reduction=\"sum\")(output[:,0].flatten(), target).item() # 誤差の合計を得る(Batchごとに計算した誤差を足し上げる)\n","            mse_std_sum += nn.MSELoss(reduction=\"sum\")(output[:,1].flatten(), target).item() # 誤差の合計を得る(Batchごとに計算した誤差を足し上げる)\n","\n","    del input_ids\n","    del attention_mask\n","    del target\n","\n","    mse_mean_result = mse_mean_sum / len(data_loader.dataset)\n","    mse_std_result = mse_std_sum / len(data_loader.dataset)\n","  \n","    return mse_mean_result, mse_std_result # 誤差の合計をdataset長で除し、mseを取得＆返す"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1626475668971,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"},"user_tz":-540},"id":"47bDno_LXecI"},"outputs":[],"source":["# 推論結果を返す\n","def predict(model, data_loader):\n","    \"\"\"Returns an np.array with predictions of the |model| on |data_loader|\"\"\"\n","    model.eval() # evalモード(dropout, batch_normしない)\n","\n","    result = np.zeros(len(data_loader.dataset)) # 結果をdataset長のzero配列として用意\n","    index = 0\n","    \n","    with torch.no_grad(): # 勾配の計算をしないblock(inputすると、現状の重みによる推論結果を返す)\n","        for batch_num, (input_ids, attention_mask) in enumerate(data_loader): # data_loaderからbatchごとにinputを得る\n","            input_ids = input_ids.to(DEVICE)\n","            attention_mask = attention_mask.to(DEVICE)\n","                        \n","            output = model(input_ids, attention_mask) # modelにinputを入力し、予測結果を得る。\n","\n","            result[index : index + output[:,0].shape[0]] = output[:,0].flatten().to(\"cpu\") # result[index ~ predの長さ]へ、予測結果を格納\n","            index += pred.shape[0] # indexを更新\n","\n","    return result # 全batchで推論が終わったら、結果を返す"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":555,"status":"ok","timestamp":1626475669518,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"},"user_tz":-540},"id":"oInneuAmXecI"},"outputs":[],"source":["# 学習\n","def train(model, # モデル\n","          model_path, # モデルのアウトプット先\n","          train_loader, # train-setのdata_loader\n","          val_loader, # valid-setのdata_loader\n","          optimizer, # optimizer\n","          scheduler=None, # scheduler, デフォルトはNone\n","          num_epochs=NUM_EPOCHS # epoch数、notebook冒頭で指定した値\n","         ):    \n","    \n","    best_val_rmse = None\n","    best_epoch = 0\n","    step = 0\n","    last_eval_step = 0\n","    eval_period = EVAL_SCHEDULE[0][1] # eval期間(って何？) 冒頭で決めたEVAL_SCHEDULEの最初のtupleの[1]を取得\n","\n","    start = time.time() # 時間計測用\n","\n","    for epoch in range(num_epochs): # 指定したEpoch数だけ繰り返し\n","        val_rmse = None         \n","\n","        for batch_num, (input_ids, attention_mask, target, standard_error) in enumerate(train_loader): # train_loaderからinput, targetを取得\n","            input_ids = input_ids.to(DEVICE) # inputをDEVICEへ突っ込む\n","            attention_mask = attention_mask.to(DEVICE)       \n","            target = target.to(DEVICE)\n","            standard_error = standard_error.to(DEVICE)  \n","\n","            optimizer.zero_grad() # 勾配を初期化            \n","            model.train() # 学習モード開始\n","\n","            # https://www.kaggle.com/c/commonlitreadabilityprize/discussion/239421\n","            output = model(input_ids, attention_mask) # input,attention_maskを入力し、予測結果を得る\n","            p = torch.distributions.Normal(output[:,0], torch.sqrt(output[:,1]**2))\n","            q = torch.distributions.Normal(target, standard_error)\n","            kl_vector = torch.distributions.kl_divergence(p, q)\n","            loss = kl_vector.mean()\n","\n","            loss.backward() # 誤差逆伝播法により勾配を得る\n","            optimizer.step() # 重みを更新する\n","\n","            if scheduler:\n","                scheduler.step() # schedulerが与えられた場合は、schedulerの学習率更新\n","            \n","            if step \u003e= last_eval_step + eval_period: # batchを回すごとにstepを増やしていって、「前回evalしたstep + eval_period(16)」を超えたら実行。\n","                # Evaluate the model on val_loader.\n","                elapsed_seconds = time.time() - start # 経過時間\n","                num_steps = step - last_eval_step # 経過ステップ数\n","                print(f\"\\n{num_steps} steps took {elapsed_seconds:0.3} seconds\")\n","                last_eval_step = step # 前回stepの更新\n","                \n","                # valid-setによるrmse計算\n","                train_mean_mse = nn.MSELoss(reduction=\"mean\")(output[:,0].flatten(), target) \n","                train_std_mse = nn.MSELoss(reduction=\"mean\")(torch.sqrt(output[:,1]**2).flatten(), standard_error) \n","\n","                train_mean_rmse = math.sqrt(train_mean_mse)\n","                train_std_rmse = math.sqrt(train_std_mse)\n","\n","                val_mean_mse, val_std_mse = eval_mse(model, val_loader)\n","                val_mean_rmse = math.sqrt(val_mean_mse)                            \n","                val_std_rmse = math.sqrt(val_std_mse)                            \n","\n","                print(f\"Epoch: {epoch} batch_num: {batch_num}\")\n","                print(f\"train_rmse_target: {train_mean_rmse:0.4}\",\n","                      f\"train_rmse_stderror: {train_std_rmse:0.4}\",\n","                      f\"train_kl_div: {loss:0.4}\",\n","                      )\n","                print(f\"val_rmse_target: {val_mean_rmse:0.4}\",\n","                      f\"val_rmse_stderror: {val_std_rmse:0.4}\"\n","                      )\n","\n","                for rmse, period in EVAL_SCHEDULE: # eval_periodをvalid-rmseで切り替える処理\n","                    if val_mean_rmse \u003e= rmse: # valid rmseをEVAL_SCHEDULEと比較し、0項 \u003e valid rmseとなるまで回す : EVAL_SCHEDULE = [(0.50, 16), (0.49, 8), (0.48, 4), (0.47, 2), (-1., 1)]\n","                        eval_period = period # eval_periodを更新\n","                        break                               \n","\n","                if not best_val_rmse or val_mean_rmse \u003c best_val_rmse: # 初回(best_val_rmse==None), またはbest_val_rmseを更新したらモデルを保存する\n","                    best_val_rmse = val_mean_rmse\n","                    best_epoch = epoch\n","                    torch.save(model.state_dict(), model_path) # 最高の自分を保存\n","                    print(f\"New best_val_rmse: {best_val_rmse:0.4}\")\n","                else:       \n","                    print(f\"Still best_val_rmse: {best_val_rmse:0.4}\", # 更新されない場合は、元のスコアを表示\n","                          f\"(from epoch {best_epoch})\")      \n","                                                  \n","                start = time.time()\n","            \n","            # batchごとにメモリ解放\n","            del input_ids\n","            del attention_mask\n","            del target\n","            torch.cuda.empty_cache()                                            \n","            step += 1\n","    \n","    return best_val_rmse"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":30,"status":"ok","timestamp":1626475669521,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"},"user_tz":-540},"id":"rMY0fjXwXecJ"},"outputs":[],"source":["# optimizerの作成\n","def create_optimizer(model):\n","    named_parameters = list(model.named_parameters()) # モデルパラメータの取得\n","    \n","    roberta_parameters = list(model.roberta.named_parameters())[:-2] # パラメータをroberta用、attention用、regressor用に格納。(直接引っ張ってくる形式に変更)\n","    attention_parameters = list(model.attention.named_parameters())\n","    regressor_parameters = list(model.regressor.named_parameters())\n","        \n","    attention_group = [params for (name, params) in attention_parameters] # attention用パラメータをリストとして取得\n","    regressor_group = [params for (name, params) in regressor_parameters] # reg用パラメータをリストとして取得\n","\n","    parameters = []\n","    parameters.append({\"params\": attention_group}) # パラメータをリストに辞書として格納していく\n","    parameters.append({\"params\": regressor_group})\n","\n","    for layer_num, (name, params) in enumerate(roberta_parameters): # レイヤーごとにname, paramsを取得していろんな処理\n","        weight_decay = 0.0 if \"bias\" in name else 0.01\n","\n","        lr = 2e-7\n","\n","        if layer_num \u003e= 69:        \n","            lr = 5e-7\n","\n","        if layer_num \u003e= 133:\n","            lr = 1e-6\n","\n","        parameters.append({\"params\": params,\n","                           \"weight_decay\": weight_decay,\n","                           \"lr\": lr})\n","\n","    return AdamW(parameters) # 最終的に、AdamWにパラメータを入力する。\n"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":29,"status":"ok","timestamp":1626475669522,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"},"user_tz":-540},"id":"EbaJojz0Zjif"},"outputs":[],"source":["# https://www.kaggle.com/abhishek/step-1-create-folds\n","def create_folds(data, num_splits, SEED, return_df=False):\n","    # we create a new column called kfold and fill it with -1\n","    data[\"kfold\"] = -1\n","    \n","    # the next step is to randomize the rows of the data\n","    data = data.sample(frac=1).reset_index(drop=True)\n","\n","    # calculate number of bins by Sturge's rule\n","    # I take the floor of the value, you can also\n","    # just round it\n","    num_bins = int(np.floor(1 + np.log2(len(data))))\n","    \n","    # bin targets\n","    data.loc[:, \"bins_tg\"] = pd.cut(\n","        data[\"target\"], bins=num_bins, labels=False\n","    ).map(lambda x: str(x))\n","\n","    # bin standard_error\n","    data.loc[:, \"bins_std\"] = pd.cut(\n","        data[\"standard_error\"], bins=num_bins, labels=False\n","    )\n","\n","    # bins\n","    data.loc[:, \"bins\"] = data['bins_tg'].map(lambda x: str(x)) + data['bins_std'].map(lambda x: str(x))\n","\n","    # initiate the kfold class from model_selection module\n","    kf = StratifiedKFold(n_splits=5, random_state=SEED, shuffle=True)\n","\n","    # note that, instead of targets, we use bins!\n","    if return_df:\n","      for f, (t_, v_) in enumerate(kf.split(X=data, y=data.bins.values)):\n","        data.loc[v_, 'kfold'] = f\n","      return data\n","    else:\n","      return kf.split(X=data, y=data.bins.values)"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1626475669523,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"},"user_tz":-540},"id":"vAmhaYaylMk5","outputId":"752083c8-9f42-46b7-ed58-42edda73bd28"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  % (min_groups, self.n_splits)), UserWarning)\n"]},{"data":{"text/html":["\u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","\n","    .dataframe thead tr:last-of-type th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth colspan=\"3\" halign=\"left\"\u003ebins_tg\u003c/th\u003e\n","      \u003cth colspan=\"3\" halign=\"left\"\u003ebins_std\u003c/th\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003emin\u003c/th\u003e\n","      \u003cth\u003emax\u003c/th\u003e\n","      \u003cth\u003emean\u003c/th\u003e\n","      \u003cth\u003emin\u003c/th\u003e\n","      \u003cth\u003emax\u003c/th\u003e\n","      \u003cth\u003emean\u003c/th\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003ekfold\u003c/th\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e11.0\u003c/td\u003e\n","      \u003ctd\u003e5.492063\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e11.0\u003c/td\u003e\n","      \u003ctd\u003e2.941799\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e11.0\u003c/td\u003e\n","      \u003ctd\u003e5.580247\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e11.0\u003c/td\u003e\n","      \u003ctd\u003e2.936508\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e11.0\u003c/td\u003e\n","      \u003ctd\u003e5.566138\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e11.0\u003c/td\u003e\n","      \u003ctd\u003e2.945326\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e11.0\u003c/td\u003e\n","      \u003ctd\u003e5.563604\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e11.0\u003c/td\u003e\n","      \u003ctd\u003e2.924028\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e11.0\u003c/td\u003e\n","      \u003ctd\u003e5.547703\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e11.0\u003c/td\u003e\n","      \u003ctd\u003e2.897527\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e"],"text/plain":["      bins_tg                 bins_std                \n","          min   max      mean      min   max      mean\n","kfold                                                 \n","0         0.0  11.0  5.492063      0.0  11.0  2.941799\n","1         0.0  11.0  5.580247      0.0  11.0  2.936508\n","2         0.0  11.0  5.566138      0.0  11.0  2.945326\n","3         0.0  11.0  5.563604      0.0  11.0  2.924028\n","4         0.0  11.0  5.547703      0.0  11.0  2.897527"]},"execution_count":21,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["# 検証用\n","SEED = 1000\n","st_kfold_bins_df = create_folds(train_df, num_splits=5, SEED=SEED, return_df=True)\n","st_kfold_bins_df['bins_tg'] = st_kfold_bins_df['bins_tg'].map(lambda x: float(x))\n","st_kfold_bins_df['bins_std'] = st_kfold_bins_df['bins_std'].map(lambda x: float(x))\n","st_kfold_bins_df.groupby('kfold').agg({'bins_tg': ['min', 'max', 'mean'],\n","                                    'bins_std': ['min', 'max', 'mean']})"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1626475669524,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"},"user_tz":-540},"id":"TyjgRCu3mmqG"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1626475669526,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"},"user_tz":-540},"id":"4PLKHwvKtNBn"},"outputs":[],"source":["def train_and_save_model(train_indices, val_indices, model_path):\n","    train_dataset = LitDataset(train_df.loc[train_indices]) # train, validのDataset\n","    val_dataset = LitDataset(train_df.loc[val_indices])\n","        \n","    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n","                              drop_last=True, shuffle=True, num_workers=2) # train, validのDataLoader\n","    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n","                            drop_last=False, shuffle=False, num_workers=2)    \n","\n","    model = LitModel().to(DEVICE) # modelをDEVICEへぶち込む\n","    optimizer = create_optimizer(model) # optimizerをモデルから作成\n","    scheduler = get_cosine_schedule_with_warmup( # schedulerを作成\n","        optimizer,\n","        num_training_steps=NUM_EPOCHS * len(train_loader),\n","        num_warmup_steps=50)    \n","    rmse = train(model, model_path, train_loader, val_loader, optimizer, scheduler=scheduler)\n","\n","    del train_dataset\n","    del val_dataset\n","    del train_loader\n","    del val_loader\n","    del model\n","    del optimizer\n","    del scheduler\n","    gc.collect() \n","    torch.cuda.empty_cache()\n","    return rmse"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":0},"id":"k2LGJD3XXecK"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  % (min_groups, self.n_splits)), UserWarning)\n"]},{"name":"stdout","output_type":"stream","text":["\n","Fold 1/5\n","{'total_MiB': 16280, 'used_MiB': 2}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b351a438bb134735b3be4af54c11a560","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1425941629.0, style=ProgressStyle(descr…"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["\n","64 steps took 82.5 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.8285 train_rmse_stderror: 0.09938 train_kl_div: 1.151\n","val_rmse_target: 0.7185 val_rmse_stderror: 1.791\n","New best_val_rmse: 0.7185\n","\n","64 steps took 81.5 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.4554 train_rmse_stderror: 0.0756 train_kl_div: 0.4474\n","val_rmse_target: 0.662 val_rmse_stderror: 1.782\n","New best_val_rmse: 0.662\n","\n","64 steps took 81.7 seconds\n","Epoch: 1 batch_num: 4\n","train_rmse_target: 0.4869 train_rmse_stderror: 0.04276 train_kl_div: 0.5397\n","val_rmse_target: 0.6347 val_rmse_stderror: 1.789\n","New best_val_rmse: 0.6347\n","\n","64 steps took 81.5 seconds\n","Epoch: 1 batch_num: 68\n","train_rmse_target: 0.5851 train_rmse_stderror: 0.04515 train_kl_div: 0.7228\n","val_rmse_target: 0.5683 val_rmse_stderror: 1.765\n","New best_val_rmse: 0.5683\n","\n","64 steps took 81.5 seconds\n","Epoch: 1 batch_num: 132\n","train_rmse_target: 0.3935 train_rmse_stderror: 0.04284 train_kl_div: 0.3415\n","val_rmse_target: 0.5642 val_rmse_stderror: 1.776\n","New best_val_rmse: 0.5642\n","\n","64 steps took 81.7 seconds\n","Epoch: 2 batch_num: 8\n","train_rmse_target: 0.3081 train_rmse_stderror: 0.04513 train_kl_div: 0.2145\n","val_rmse_target: 0.5507 val_rmse_stderror: 1.785\n","New best_val_rmse: 0.5507\n","\n","64 steps took 81.5 seconds\n","Epoch: 2 batch_num: 72\n","train_rmse_target: 0.5734 train_rmse_stderror: 0.06289 train_kl_div: 0.5674\n","val_rmse_target: 0.5398 val_rmse_stderror: 1.79\n","New best_val_rmse: 0.5398\n","\n","32 steps took 40.8 seconds\n","Epoch: 2 batch_num: 104\n","train_rmse_target: 0.5229 train_rmse_stderror: 0.04265 train_kl_div: 0.5853\n","val_rmse_target: 0.54 val_rmse_stderror: 1.764\n","Still best_val_rmse: 0.5398 (from epoch 2)\n","\n","32 steps took 40.8 seconds\n","Epoch: 2 batch_num: 136\n","train_rmse_target: 0.4737 train_rmse_stderror: 0.02428 train_kl_div: 0.454\n","val_rmse_target: 0.5739 val_rmse_stderror: 1.797\n","Still best_val_rmse: 0.5398 (from epoch 2)\n","\n","64 steps took 81.7 seconds\n","Epoch: 3 batch_num: 12\n","train_rmse_target: 0.4687 train_rmse_stderror: 0.03773 train_kl_div: 0.4478\n","val_rmse_target: 0.54 val_rmse_stderror: 1.787\n","Still best_val_rmse: 0.5398 (from epoch 2)\n","\n","32 steps took 40.8 seconds\n","Epoch: 3 batch_num: 44\n","train_rmse_target: 0.4964 train_rmse_stderror: 0.02914 train_kl_div: 0.5029\n","val_rmse_target: 0.5677 val_rmse_stderror: 1.787\n","Still best_val_rmse: 0.5398 (from epoch 2)\n","\n","64 steps took 81.5 seconds\n","Epoch: 3 batch_num: 108\n","train_rmse_target: 0.3951 train_rmse_stderror: 0.0524 train_kl_div: 0.2926\n","val_rmse_target: 0.5375 val_rmse_stderror: 1.774\n","New best_val_rmse: 0.5375\n","\n","32 steps took 40.8 seconds\n","Epoch: 3 batch_num: 140\n","train_rmse_target: 0.4554 train_rmse_stderror: 0.03035 train_kl_div: 0.4202\n","val_rmse_target: 0.5343 val_rmse_stderror: 1.769\n","New best_val_rmse: 0.5343\n","\n","32 steps took 40.7 seconds\n","Epoch: 3 batch_num: 172\n","train_rmse_target: 0.4606 train_rmse_stderror: 0.0406 train_kl_div: 0.427\n","val_rmse_target: 0.5339 val_rmse_stderror: 1.774\n","New best_val_rmse: 0.5339\n","\n","32 steps took 40.9 seconds\n","Epoch: 4 batch_num: 16\n","train_rmse_target: 0.5501 train_rmse_stderror: 0.02821 train_kl_div: 0.5639\n","val_rmse_target: 0.5304 val_rmse_stderror: 1.787\n","New best_val_rmse: 0.5304\n","\n","32 steps took 40.7 seconds\n","Epoch: 4 batch_num: 48\n","train_rmse_target: 0.4531 train_rmse_stderror: 0.02909 train_kl_div: 0.4431\n","val_rmse_target: 0.5502 val_rmse_stderror: 1.775\n","Still best_val_rmse: 0.5304 (from epoch 4)\n","\n","64 steps took 81.5 seconds\n","Epoch: 4 batch_num: 112\n","train_rmse_target: 0.743 train_rmse_stderror: 0.03157 train_kl_div: 1.075\n","val_rmse_target: 0.5385 val_rmse_stderror: 1.781\n","Still best_val_rmse: 0.5304 (from epoch 4)\n","\n","32 steps took 40.7 seconds\n","Epoch: 4 batch_num: 144\n","train_rmse_target: 0.3844 train_rmse_stderror: 0.02564 train_kl_div: 0.3256\n","val_rmse_target: 0.5459 val_rmse_stderror: 1.774\n","Still best_val_rmse: 0.5304 (from epoch 4)\n","\n","32 steps took 40.7 seconds\n","Epoch: 4 batch_num: 176\n","train_rmse_target: 0.2823 train_rmse_stderror: 0.02381 train_kl_div: 0.1773\n","val_rmse_target: 0.5428 val_rmse_stderror: 1.775\n","Still best_val_rmse: 0.5304 (from epoch 4)\n","\n","Performance estimates:\n","[0.5303670332905114]\n","Mean: 0.5303670332905114\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 2/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["\n","64 steps took 82.4 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.7228 train_rmse_stderror: 0.0509 train_kl_div: 1.076\n","val_rmse_target: 0.7996 val_rmse_stderror: 1.744\n","New best_val_rmse: 0.7996\n","\n","64 steps took 81.5 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.7819 train_rmse_stderror: 0.05256 train_kl_div: 1.308\n","val_rmse_target: 0.6702 val_rmse_stderror: 1.754\n","New best_val_rmse: 0.6702\n","\n","64 steps took 81.7 seconds\n","Epoch: 1 batch_num: 4\n","train_rmse_target: 0.5494 train_rmse_stderror: 0.03839 train_kl_div: 0.5674\n","val_rmse_target: 0.6488 val_rmse_stderror: 1.745\n","New best_val_rmse: 0.6488\n","\n","64 steps took 81.5 seconds\n","Epoch: 1 batch_num: 68\n","train_rmse_target: 0.5429 train_rmse_stderror: 0.02624 train_kl_div: 0.6462\n","val_rmse_target: 0.65 val_rmse_stderror: 1.758\n","Still best_val_rmse: 0.6488 (from epoch 1)\n","\n","64 steps took 81.5 seconds\n","Epoch: 1 batch_num: 132\n","train_rmse_target: 0.4109 train_rmse_stderror: 0.03282 train_kl_div: 0.3495\n","val_rmse_target: 0.6234 val_rmse_stderror: 1.734\n","New best_val_rmse: 0.6234\n","\n","64 steps took 81.7 seconds\n","Epoch: 2 batch_num: 8\n","train_rmse_target: 0.4341 train_rmse_stderror: 0.04331 train_kl_div: 0.3359\n","val_rmse_target: 0.5803 val_rmse_stderror: 1.753\n","New best_val_rmse: 0.5803\n","\n","64 steps took 81.6 seconds\n","Epoch: 2 batch_num: 72\n","train_rmse_target: 0.54 train_rmse_stderror: 0.02715 train_kl_div: 0.6054\n","val_rmse_target: 0.5791 val_rmse_stderror: 1.742\n","New best_val_rmse: 0.5791\n","\n","64 steps took 81.5 seconds\n","Epoch: 2 batch_num: 136\n","train_rmse_target: 0.4675 train_rmse_stderror: 0.03455 train_kl_div: 0.4632\n","val_rmse_target: 0.5727 val_rmse_stderror: 1.745\n","New best_val_rmse: 0.5727\n","\n","64 steps took 81.8 seconds\n","Epoch: 3 batch_num: 12\n","train_rmse_target: 0.5363 train_rmse_stderror: 0.05052 train_kl_div: 0.6219\n","val_rmse_target: 0.5722 val_rmse_stderror: 1.76\n","New best_val_rmse: 0.5722\n","\n","64 steps took 81.6 seconds\n","Epoch: 3 batch_num: 76\n","train_rmse_target: 0.558 train_rmse_stderror: 0.02565 train_kl_div: 0.5681\n","val_rmse_target: 0.5752 val_rmse_stderror: 1.753\n","Still best_val_rmse: 0.5722 (from epoch 3)\n","\n","64 steps took 81.5 seconds\n","Epoch: 3 batch_num: 140\n","train_rmse_target: 0.3917 train_rmse_stderror: 0.04246 train_kl_div: 0.3189\n","val_rmse_target: 0.5679 val_rmse_stderror: 1.744\n","New best_val_rmse: 0.5679\n","\n","64 steps took 81.7 seconds\n","Epoch: 4 batch_num: 16\n","train_rmse_target: 0.4757 train_rmse_stderror: 0.03293 train_kl_div: 0.4658\n","val_rmse_target: 0.5664 val_rmse_stderror: 1.741\n","New best_val_rmse: 0.5664\n","\n","64 steps took 81.5 seconds\n","Epoch: 4 batch_num: 80\n","train_rmse_target: 0.346 train_rmse_stderror: 0.01936 train_kl_div: 0.2708\n","val_rmse_target: 0.571 val_rmse_stderror: 1.745\n","Still best_val_rmse: 0.5664 (from epoch 4)\n","\n","64 steps took 81.5 seconds\n","Epoch: 4 batch_num: 144\n","train_rmse_target: 0.4601 train_rmse_stderror: 0.04795 train_kl_div: 0.4008\n","val_rmse_target: 0.5678 val_rmse_stderror: 1.745\n","Still best_val_rmse: 0.5664 (from epoch 4)\n","\n","Performance estimates:\n","[0.5303670332905114, 0.5664163997923687]\n","Mean: 0.54839171654144\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 3/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["\n","64 steps took 82.5 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.5272 train_rmse_stderror: 0.06409 train_kl_div: 0.557\n","val_rmse_target: 0.7204 val_rmse_stderror: 1.231\n","New best_val_rmse: 0.7204\n","\n","64 steps took 81.5 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.3565 train_rmse_stderror: 0.03515 train_kl_div: 0.2718\n","val_rmse_target: 0.6238 val_rmse_stderror: 1.195\n","New best_val_rmse: 0.6238\n","\n","64 steps took 81.7 seconds\n","Epoch: 1 batch_num: 4\n","train_rmse_target: 0.5245 train_rmse_stderror: 0.03385 train_kl_div: 0.6074\n","val_rmse_target: 0.5914 val_rmse_stderror: 1.199\n","New best_val_rmse: 0.5914\n","\n","64 steps took 81.5 seconds\n","Epoch: 1 batch_num: 68\n","train_rmse_target: 0.3732 train_rmse_stderror: 0.0395 train_kl_div: 0.2958\n","val_rmse_target: 0.5707 val_rmse_stderror: 1.19\n","New best_val_rmse: 0.5707\n","\n","64 steps took 81.5 seconds\n","Epoch: 1 batch_num: 132\n","train_rmse_target: 0.5093 train_rmse_stderror: 0.03759 train_kl_div: 0.5392\n","val_rmse_target: 0.5861 val_rmse_stderror: 1.189\n","Still best_val_rmse: 0.5707 (from epoch 1)\n","\n","64 steps took 81.7 seconds\n","Epoch: 2 batch_num: 8\n","train_rmse_target: 0.5145 train_rmse_stderror: 0.02949 train_kl_div: 0.5423\n","val_rmse_target: 0.5704 val_rmse_stderror: 1.183\n","New best_val_rmse: 0.5704\n","\n","64 steps took 81.5 seconds\n","Epoch: 2 batch_num: 72\n","train_rmse_target: 0.3381 train_rmse_stderror: 0.03854 train_kl_div: 0.234\n","val_rmse_target: 0.5693 val_rmse_stderror: 1.182\n","New best_val_rmse: 0.5693\n","\n","64 steps took 81.6 seconds\n","Epoch: 2 batch_num: 136\n","train_rmse_target: 0.3184 train_rmse_stderror: 0.03992 train_kl_div: 0.2012\n","val_rmse_target: 0.5716 val_rmse_stderror: 1.182\n","Still best_val_rmse: 0.5693 (from epoch 2)\n","\n","64 steps took 81.8 seconds\n","Epoch: 3 batch_num: 12\n","train_rmse_target: 0.3036 train_rmse_stderror: 0.03089 train_kl_div: 0.1849\n","val_rmse_target: 0.5591 val_rmse_stderror: 1.188\n","New best_val_rmse: 0.5591\n","\n","64 steps took 81.5 seconds\n","Epoch: 3 batch_num: 76\n","train_rmse_target: 0.391 train_rmse_stderror: 0.033 train_kl_div: 0.3305\n","val_rmse_target: 0.553 val_rmse_stderror: 1.189\n","New best_val_rmse: 0.553\n","\n","64 steps took 81.5 seconds\n","Epoch: 3 batch_num: 140\n","train_rmse_target: 0.5038 train_rmse_stderror: 0.03391 train_kl_div: 0.482\n","val_rmse_target: 0.5638 val_rmse_stderror: 1.193\n","Still best_val_rmse: 0.553 (from epoch 3)\n","\n","64 steps took 81.7 seconds\n","Epoch: 4 batch_num: 16\n","train_rmse_target: 0.3086 train_rmse_stderror: 0.03332 train_kl_div: 0.1864\n","val_rmse_target: 0.5613 val_rmse_stderror: 1.192\n","Still best_val_rmse: 0.553 (from epoch 3)\n","\n","64 steps took 81.5 seconds\n","Epoch: 4 batch_num: 80\n","train_rmse_target: 0.2802 train_rmse_stderror: 0.02418 train_kl_div: 0.1676\n","val_rmse_target: 0.5619 val_rmse_stderror: 1.188\n","Still best_val_rmse: 0.553 (from epoch 3)\n","\n","64 steps took 81.5 seconds\n","Epoch: 4 batch_num: 144\n","train_rmse_target: 0.4488 train_rmse_stderror: 0.0369 train_kl_div: 0.3639\n","val_rmse_target: 0.5619 val_rmse_stderror: 1.19\n","Still best_val_rmse: 0.553 (from epoch 3)\n","\n","Performance estimates:\n","[0.5303670332905114, 0.5664163997923687, 0.5529953087767705]\n","Mean: 0.5499262472865502\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 4/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["\n","64 steps took 82.5 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.784 train_rmse_stderror: 0.06474 train_kl_div: 1.186\n","val_rmse_target: 0.7113 val_rmse_stderror: 1.105\n","New best_val_rmse: 0.7113\n","\n","64 steps took 81.5 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.7088 train_rmse_stderror: 0.07082 train_kl_div: 0.9495\n","val_rmse_target: 0.6257 val_rmse_stderror: 1.097\n","New best_val_rmse: 0.6257\n","\n","64 steps took 81.7 seconds\n","Epoch: 1 batch_num: 4\n","train_rmse_target: 0.5046 train_rmse_stderror: 0.02916 train_kl_div: 0.5054\n","val_rmse_target: 0.5996 val_rmse_stderror: 1.081\n","New best_val_rmse: 0.5996\n","\n","64 steps took 81.5 seconds\n","Epoch: 1 batch_num: 68\n","train_rmse_target: 0.5783 train_rmse_stderror: 0.0239 train_kl_div: 0.7603\n","val_rmse_target: 0.5747 val_rmse_stderror: 1.11\n","New best_val_rmse: 0.5747\n","\n","64 steps took 81.5 seconds\n","Epoch: 1 batch_num: 132\n","train_rmse_target: 0.5565 train_rmse_stderror: 0.04394 train_kl_div: 0.5218\n","val_rmse_target: 0.5712 val_rmse_stderror: 1.089\n","New best_val_rmse: 0.5712\n","\n","64 steps took 81.7 seconds\n","Epoch: 2 batch_num: 8\n","train_rmse_target: 0.68 train_rmse_stderror: 0.03227 train_kl_div: 0.8474\n","val_rmse_target: 0.5414 val_rmse_stderror: 1.102\n","New best_val_rmse: 0.5414\n","\n","32 steps took 40.8 seconds\n","Epoch: 2 batch_num: 40\n","train_rmse_target: 0.5976 train_rmse_stderror: 0.02015 train_kl_div: 0.7822\n","val_rmse_target: 0.5373 val_rmse_stderror: 1.092\n","New best_val_rmse: 0.5373\n","\n","32 steps took 40.8 seconds\n","Epoch: 2 batch_num: 72\n","train_rmse_target: 0.4556 train_rmse_stderror: 0.03559 train_kl_div: 0.4492\n","val_rmse_target: 0.541 val_rmse_stderror: 1.097\n","Still best_val_rmse: 0.5373 (from epoch 2)\n","\n","32 steps took 40.8 seconds\n","Epoch: 2 batch_num: 104\n","train_rmse_target: 0.7187 train_rmse_stderror: 0.05201 train_kl_div: 0.9836\n","val_rmse_target: 0.5336 val_rmse_stderror: 1.102\n","New best_val_rmse: 0.5336\n","\n","32 steps took 40.8 seconds\n","Epoch: 2 batch_num: 136\n","train_rmse_target: 0.5028 train_rmse_stderror: 0.05329 train_kl_div: 0.5622\n","val_rmse_target: 0.5412 val_rmse_stderror: 1.091\n","Still best_val_rmse: 0.5336 (from epoch 2)\n","\n","32 steps took 40.7 seconds\n","Epoch: 2 batch_num: 168\n","train_rmse_target: 0.4731 train_rmse_stderror: 0.0352 train_kl_div: 0.4107\n","val_rmse_target: 0.5288 val_rmse_stderror: 1.092\n","New best_val_rmse: 0.5288\n","\n","32 steps took 41.0 seconds\n","Epoch: 3 batch_num: 12\n","train_rmse_target: 0.3787 train_rmse_stderror: 0.0324 train_kl_div: 0.3203\n","val_rmse_target: 0.5306 val_rmse_stderror: 1.095\n","Still best_val_rmse: 0.5288 (from epoch 2)\n","\n","32 steps took 40.8 seconds\n","Epoch: 3 batch_num: 44\n","train_rmse_target: 0.3116 train_rmse_stderror: 0.02663 train_kl_div: 0.2015\n","val_rmse_target: 0.5294 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.5288 (from epoch 2)\n","\n","32 steps took 40.7 seconds\n","Epoch: 3 batch_num: 76\n","train_rmse_target: 0.6026 train_rmse_stderror: 0.0393 train_kl_div: 0.6596\n","val_rmse_target: 0.5325 val_rmse_stderror: 1.1\n","Still best_val_rmse: 0.5288 (from epoch 2)\n","\n","32 steps took 40.8 seconds\n","Epoch: 3 batch_num: 108\n","train_rmse_target: 0.4438 train_rmse_stderror: 0.04034 train_kl_div: 0.3543\n","val_rmse_target: 0.5254 val_rmse_stderror: 1.099\n","New best_val_rmse: 0.5254\n","\n","32 steps took 40.8 seconds\n","Epoch: 3 batch_num: 140\n","train_rmse_target: 0.4154 train_rmse_stderror: 0.02165 train_kl_div: 0.3536\n","val_rmse_target: 0.5313 val_rmse_stderror: 1.094\n","Still best_val_rmse: 0.5254 (from epoch 3)\n","\n","32 steps took 40.7 seconds\n","Epoch: 3 batch_num: 172\n","train_rmse_target: 0.555 train_rmse_stderror: 0.0364 train_kl_div: 0.6662\n","val_rmse_target: 0.5234 val_rmse_stderror: 1.097\n","New best_val_rmse: 0.5234\n","\n","32 steps took 41.0 seconds\n","Epoch: 4 batch_num: 16\n","train_rmse_target: 0.3368 train_rmse_stderror: 0.03779 train_kl_div: 0.2334\n","val_rmse_target: 0.5368 val_rmse_stderror: 1.099\n","Still best_val_rmse: 0.5234 (from epoch 3)\n","\n","32 steps took 40.8 seconds\n","Epoch: 4 batch_num: 48\n","train_rmse_target: 0.6089 train_rmse_stderror: 0.02623 train_kl_div: 0.7925\n","val_rmse_target: 0.523 val_rmse_stderror: 1.094\n","New best_val_rmse: 0.523\n","\n","32 steps took 40.8 seconds\n","Epoch: 4 batch_num: 80\n","train_rmse_target: 0.4198 train_rmse_stderror: 0.03798 train_kl_div: 0.3058\n","val_rmse_target: 0.5258 val_rmse_stderror: 1.097\n","Still best_val_rmse: 0.523 (from epoch 4)\n","\n","32 steps took 40.7 seconds\n","Epoch: 4 batch_num: 112\n","train_rmse_target: 0.2707 train_rmse_stderror: 0.02985 train_kl_div: 0.1623\n","val_rmse_target: 0.5244 val_rmse_stderror: 1.098\n","Still best_val_rmse: 0.523 (from epoch 4)\n","\n","32 steps took 40.7 seconds\n","Epoch: 4 batch_num: 144\n","train_rmse_target: 0.3938 train_rmse_stderror: 0.02647 train_kl_div: 0.2781\n","val_rmse_target: 0.5233 val_rmse_stderror: 1.096\n","Still best_val_rmse: 0.523 (from epoch 4)\n","\n","32 steps took 40.8 seconds\n","Epoch: 4 batch_num: 176\n","train_rmse_target: 0.3843 train_rmse_stderror: 0.02753 train_kl_div: 0.3079\n","val_rmse_target: 0.5231 val_rmse_stderror: 1.096\n","Still best_val_rmse: 0.523 (from epoch 4)\n","\n","Performance estimates:\n","[0.5303670332905114, 0.5664163997923687, 0.5529953087767705, 0.5230427202828177]\n","Mean: 0.543205365535617\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 5/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["\n","64 steps took 82.5 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.8079 train_rmse_stderror: 0.06373 train_kl_div: 1.289\n","val_rmse_target: 0.7541 val_rmse_stderror: 1.871\n","New best_val_rmse: 0.7541\n","\n","64 steps took 81.5 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.5931 train_rmse_stderror: 0.03441 train_kl_div: 0.6566\n","val_rmse_target: 0.6311 val_rmse_stderror: 1.833\n","New best_val_rmse: 0.6311\n","\n","64 steps took 81.7 seconds\n","Epoch: 1 batch_num: 4\n","train_rmse_target: 0.5616 train_rmse_stderror: 0.04589 train_kl_div: 0.6328\n","val_rmse_target: 0.5873 val_rmse_stderror: 1.83\n","New best_val_rmse: 0.5873\n","\n","64 steps took 81.5 seconds\n","Epoch: 1 batch_num: 68\n","train_rmse_target: 0.6852 train_rmse_stderror: 0.05075 train_kl_div: 0.8223\n","val_rmse_target: 0.563 val_rmse_stderror: 1.809\n","New best_val_rmse: 0.563\n","\n","64 steps took 81.5 seconds\n","Epoch: 1 batch_num: 132\n","train_rmse_target: 0.4654 train_rmse_stderror: 0.03924 train_kl_div: 0.4931\n","val_rmse_target: 0.5763 val_rmse_stderror: 1.788\n","Still best_val_rmse: 0.563 (from epoch 1)\n","\n","64 steps took 81.7 seconds\n","Epoch: 2 batch_num: 8\n","train_rmse_target: 0.2985 train_rmse_stderror: 0.04382 train_kl_div: 0.2016\n","val_rmse_target: 0.5473 val_rmse_stderror: 1.826\n","New best_val_rmse: 0.5473\n","\n","32 steps took 40.8 seconds\n","Epoch: 2 batch_num: 40\n","train_rmse_target: 0.5115 train_rmse_stderror: 0.03231 train_kl_div: 0.5363\n","val_rmse_target: 0.5588 val_rmse_stderror: 1.826\n","Still best_val_rmse: 0.5473 (from epoch 2)\n","\n","64 steps took 81.5 seconds\n","Epoch: 2 batch_num: 104\n","train_rmse_target: 0.6221 train_rmse_stderror: 0.05951 train_kl_div: 0.6919\n","val_rmse_target: 0.5477 val_rmse_stderror: 1.822\n","Still best_val_rmse: 0.5473 (from epoch 2)\n","\n","32 steps took 40.7 seconds\n","Epoch: 2 batch_num: 136\n","train_rmse_target: 0.5286 train_rmse_stderror: 0.03582 train_kl_div: 0.5774\n","val_rmse_target: 0.5494 val_rmse_stderror: 1.814\n","Still best_val_rmse: 0.5473 (from epoch 2)\n","\n","32 steps took 40.7 seconds\n","Epoch: 2 batch_num: 168\n","train_rmse_target: 0.4872 train_rmse_stderror: 0.03348 train_kl_div: 0.4795\n","val_rmse_target: 0.5757 val_rmse_stderror: 1.819\n","Still best_val_rmse: 0.5473 (from epoch 2)\n","\n","64 steps took 81.7 seconds\n","Epoch: 3 batch_num: 44\n","train_rmse_target: 0.4222 train_rmse_stderror: 0.02318 train_kl_div: 0.3887\n","val_rmse_target: 0.5573 val_rmse_stderror: 1.836\n","Still best_val_rmse: 0.5473 (from epoch 2)\n","\n","64 steps took 81.5 seconds\n","Epoch: 3 batch_num: 108\n","train_rmse_target: 0.4179 train_rmse_stderror: 0.05461 train_kl_div: 0.327\n","val_rmse_target: 0.5658 val_rmse_stderror: 1.811\n","Still best_val_rmse: 0.5473 (from epoch 2)\n","\n","64 steps took 81.5 seconds\n","Epoch: 3 batch_num: 172\n","train_rmse_target: 0.4059 train_rmse_stderror: 0.03492 train_kl_div: 0.3233\n","val_rmse_target: 0.5724 val_rmse_stderror: 1.818\n","Still best_val_rmse: 0.5473 (from epoch 2)\n","\n","64 steps took 81.7 seconds\n","Epoch: 4 batch_num: 48\n","train_rmse_target: 0.3004 train_rmse_stderror: 0.03249 train_kl_div: 0.197\n","val_rmse_target: 0.5607 val_rmse_stderror: 1.822\n","Still best_val_rmse: 0.5473 (from epoch 2)\n","\n","64 steps took 81.4 seconds\n","Epoch: 4 batch_num: 112\n","train_rmse_target: 0.375 train_rmse_stderror: 0.03379 train_kl_div: 0.2662\n","val_rmse_target: 0.5571 val_rmse_stderror: 1.819\n","Still best_val_rmse: 0.5473 (from epoch 2)\n","\n","64 steps took 81.4 seconds\n","Epoch: 4 batch_num: 176\n","train_rmse_target: 0.4661 train_rmse_stderror: 0.0253 train_kl_div: 0.418\n","val_rmse_target: 0.5546 val_rmse_stderror: 1.815\n","Still best_val_rmse: 0.5473 (from epoch 2)\n","\n","Performance estimates:\n","[0.5303670332905114, 0.5664163997923687, 0.5529953087767705, 0.5230427202828177, 0.5472739501887632]\n","Mean: 0.5440190824662463\n","{'total_MiB': 16280, 'used_MiB': 927}\n"]}],"source":["# 実行処理。 KFold \u0026 学習\n","SEED = 1000\n","list_val_rmse = []\n","\n","#kfold = KFold(n_splits=NUM_FOLDS, random_state=SEED, shuffle=True)\n","kfold = create_folds(train_df, 5, SEED=SEED, return_df=False) # binsで切る場合\n","\n","for fold, (train_indices, val_indices) in enumerate(kfold):    \n","    print(f\"\\nFold {fold + 1}/{NUM_FOLDS}\")\n","    print(gpuinfo())\n","    model_path = f\"model_{fold + 1}.pth\" # model_fold数_.pth\n","    set_random_seed(SEED + fold) # SEEDはfold別に変わるようにする\n","    list_val_rmse.append(train_and_save_model(train_indices, val_indices, model_path))\n","\n","    print(\"\\nPerformance estimates:\")\n","    print(list_val_rmse)\n","    print(\"Mean:\", np.array(list_val_rmse).mean())\n","    print(gpuinfo())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"HgUJCFeLhLaP"},"outputs":[{"name":"stdout","output_type":"stream","text":["[ Top 10 ]\n","/usr/lib/python3.7/codeop.py:141: size=189 B, count=2, average=94 B\n","/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2820: size=112 B, count=3, average=37 B\n"]}],"source":["import tracemalloc\n","\n","tracemalloc.start()\n","\n","# ... run your application ...\n","\n","snapshot = tracemalloc.take_snapshot()\n","top_stats = snapshot.statistics('lineno')\n","\n","print(\"[ Top 10 ]\")\n","for stat in top_stats[:10]:\n","    print(stat)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"m4v-cGx-Mv7S"},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.5303670332905114, 0.5664163997923687, 0.5529953087767705, 0.5230427202828177, 0.5472739501887632]\n"]}],"source":["print(list_val_rmse)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"q2CdCMuIKDMP"},"outputs":[],"source":["#rep = MemReporter(model)\n","#rep.report()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"eLl1yDOOKIe7"},"outputs":[],"source":["#rep = MemReporter(model.roberta)\n","#rep.report()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"7qkqnknA_m9D"},"outputs":[],"source":["#gpuinfo()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"PwrqSMdYA6Pu"},"outputs":[],"source":["#del model\n","#del optimizer \n","#del train_loader\n","#del val_loader\n","#del scheduler \n","#del list_val_rmse\n","#del train_indices\n","#del val_indices\n","#del tokenizer\n","#torch.cuda.empty_cache()\n","#gpuinfo()"]},{"cell_type":"markdown","metadata":{"id":"wXcHyUSJXecL"},"source":["# Inference"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"YIV6UllSIGoa"},"outputs":[{"name":"stdout","output_type":"stream","text":["/root\n"]}],"source":["%cd\n","!mkdir .kaggle\n","!mkdir /content/model\n","!cp /content/drive/MyDrive/Colab_Files/kaggle-api/kaggle.json .kaggle/\n","\n","!cp -r /content/model_1.pth /content/model/model_1.pth\n","!cp -r /content/model_2.pth /content/model/model_2.pth\n","!cp -r /content/model_3.pth /content/model/model_3.pth\n","!cp -r /content/model_4.pth /content/model/model_4.pth\n","!cp -r /content/model_5.pth /content/model/model_5.pth"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"14ddOZH4IMam"},"outputs":[{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0.00/1.33G [00:00\u003c?, ?B/s]"]},{"name":"stdout","output_type":"stream","text":["Starting upload for file model_3.pth\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1.33G/1.33G [00:32\u003c00:00, 44.3MB/s]\n","  0%|          | 0.00/1.33G [00:00\u003c?, ?B/s]"]},{"name":"stdout","output_type":"stream","text":["Upload successful: model_3.pth (1GB)\n","Starting upload for file model_2.pth\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1.33G/1.33G [00:34\u003c00:00, 41.3MB/s]\n","  0%|          | 0.00/1.33G [00:00\u003c?, ?B/s]"]},{"name":"stdout","output_type":"stream","text":["Upload successful: model_2.pth (1GB)\n","Starting upload for file model_1.pth\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1.33G/1.33G [00:27\u003c00:00, 52.7MB/s]\n","  0%|          | 0.00/1.33G [00:00\u003c?, ?B/s]"]},{"name":"stdout","output_type":"stream","text":["Upload successful: model_1.pth (1GB)\n","Starting upload for file model_4.pth\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1.33G/1.33G [00:33\u003c00:00, 42.6MB/s]\n","  0%|          | 0.00/1.33G [00:00\u003c?, ?B/s]"]},{"name":"stdout","output_type":"stream","text":["Upload successful: model_4.pth (1GB)\n","Starting upload for file model_5.pth\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1.33G/1.33G [00:25\u003c00:00, 56.2MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: model_5.pth (1GB)\n"]}],"source":["\n","\n","def dataset_upload():\n","    import json\n","    from kaggle.api.kaggle_api_extended import KaggleApi\n","\n","    id = f'{USERID}/{EX_NO}'\n","\n","    dataset_metadata = {}\n","    dataset_metadata['id'] = id\n","    dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n","    dataset_metadata['title'] = f'{EX_NO}'\n","\n","    with open(UPLOAD_DIR / 'dataset-metadata.json', 'w') as f:\n","        json.dump(dataset_metadata, f, indent=4)\n","\n","    api = KaggleApi()\n","    api.authenticate()\n","\n","    # データセットがない場合\n","    if f'{USERID}/{EX_NO}' not in [str(d) for d in api.dataset_list(user=USERID, search=f'\"{EX_NO}\"')]:\n","        api.dataset_create_new(folder=UPLOAD_DIR,\n","                               convert_to_csv=False,\n","                               dir_mode='skip')\n","    # データセットがある場合\n","    else:\n","        api.dataset_create_version(folder=UPLOAD_DIR,\n","                                   version_notes='update',\n","                                   convert_to_csv=False,\n","                                   delete_old_versions=True,\n","                                   dir_mode='skip')\n","dataset_upload()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"huJwVMSAPuDO"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"0zzuBPobmLFu"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Wpc8ro9hmNci"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ceDI72NumT5-"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"044-train-04.ipynb","provenance":[{"file_id":"11GjYTJw9xCeaLJHPajPSE4uerhSdpNA0","timestamp":1626475451439},{"file_id":"1bhhkorT--y8XXaVLM8hibVgC-tLqZ16P","timestamp":1626358153868},{"file_id":"1WtT2hX6O9Qbt_hb9sF50nM2QmDXFi-XA","timestamp":1626338366006},{"file_id":"1k_p5wftcUeo711Xho1-T5an2Xkneau-J","timestamp":1626323813472},{"file_id":"1Vz2GB2BNTWuefEFkCSh3TBPEIel7KG1t","timestamp":1626317426487},{"file_id":"1djoMWojeaIPopG5tS1jNMohn8ineblRh","timestamp":1626306831897},{"file_id":"1-6tlDO8158Pi6TpptIF884oFaEiT4Uxb","timestamp":1626276420047},{"file_id":"1js8eA3mDNS8mwSpCiHuzPeARFlUPAVrg","timestamp":1626272452526},{"file_id":"1yhcPgulwJtjJKUK9IuRKmNMhJ-4YXGol","timestamp":1626267205517},{"file_id":"1mnnSv0Pofn1QxArywV81VYqnZPB8uUWN","timestamp":1626180468522},{"file_id":"1RRdjt_UAeHmr5QQBAMyC82Fq1s31OWdK","timestamp":1625833136005},{"file_id":"1JPgg44HFemzwk8VSCXih3PejL0idy-C4","timestamp":1625825483466},{"file_id":"1Ye6wqVX71xAAAhmjXkw9IpRvTqeUyJDA","timestamp":1625812137500}],"version":""},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0926da660de341809fb55ecfb6c5e1a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13d36e9c11764fa3855df92b629cd2d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"214e25c547584b22b1d9d18ed75dc3a1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"314011e2d83a4c638a8d409c93658c4a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"3b833a1383c847be99f89f28d80eee9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b97432495b24dfc81d6ca6d806dea6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ec8de89c55f4988956990f947f67ac5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e6d7934c85834ccf9c54f159aafa2f98","IPY_MODEL_f78e59935ddc415e977eb0fd95135e23"],"layout":"IPY_MODEL_0926da660de341809fb55ecfb6c5e1a6"}},"4c1df3ad59244ffb8598631a0de29f6b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56b1ea52577c45e5831de5546a93f1c0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"60bb9eec4b3b4945af7cd05cb03de36a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_beab88da0be24cf1b6822804004eac97","placeholder":"​","style":"IPY_MODEL_f37d8c8c08c543468b1378638208586b","value":" 1.43G/1.43G [00:40\u0026lt;00:00, 34.8MB/s]"}},"629b984b752c477581795164cbfd6215":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b91634fd03b4e71a07378d110a28830":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6fe45a0e3c7947048a2024005be86e17":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"77260f8603c54361939d4e25d0dd26cf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7d284c82c7e1465faecc00ee9f1a5d25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8230757510f0438496d9b3393cbec9ad":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"Downloading: 100%","description_tooltip":null,"layout":"IPY_MODEL_e2397f50e00e488a95c83b0db06ba7b0","max":482,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d8816136d3b04371ae62eb6f71820b27","value":482}},"867d004b9334404482f5fc7215dbacac":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"Downloading: 100%","description_tooltip":null,"layout":"IPY_MODEL_b1c1cdb9bc784e649e3b18d5ce0b5262","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_56b1ea52577c45e5831de5546a93f1c0","value":456318}},"8b504380b199466c974e0d555b396798":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"Downloading: 100%","description_tooltip":null,"layout":"IPY_MODEL_4c1df3ad59244ffb8598631a0de29f6b","max":1425941629,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cbc5b72b4bd143fe8ef9df3e29d264e0","value":1425941629}},"8de29f6229cc4236a9ddd7ea500a0ec7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e34a121b29e4c3389810d31d7e75000":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"Downloading: 100%","description_tooltip":null,"layout":"IPY_MODEL_db4e17380fce48aca411698218325ab6","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_314011e2d83a4c638a8d409c93658c4a","value":1355863}},"953880b73283481b990c40eecf2beaea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96ba14d5a2df4957871ecb1698abf33a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c6035ce8b254d379a9de0da554af9ed":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8e34a121b29e4c3389810d31d7e75000","IPY_MODEL_c7e14198118e43029ae5468bdc283b34"],"layout":"IPY_MODEL_13d36e9c11764fa3855df92b629cd2d9"}},"a775dd14ce104b668b18d2b69d9cba9b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d284c82c7e1465faecc00ee9f1a5d25","placeholder":"​","style":"IPY_MODEL_214e25c547584b22b1d9d18ed75dc3a1","value":" 482/482 [00:00\u0026lt;00:00, 783B/s]"}},"a79948fa4fef4c95aae198490f0217f2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_96ba14d5a2df4957871ecb1698abf33a","placeholder":"​","style":"IPY_MODEL_d14a3c6df93a4f65bb08f7e7e6e3d93b","value":" 456k/456k [00:03\u0026lt;00:00, 144kB/s]"}},"a8e7333f3b9541e5a2d6a86e51fa552f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8230757510f0438496d9b3393cbec9ad","IPY_MODEL_a775dd14ce104b668b18d2b69d9cba9b"],"layout":"IPY_MODEL_c34b7b9764c040b0a8abca5f0024801f"}},"b1c1cdb9bc784e649e3b18d5ce0b5262":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b351a438bb134735b3be4af54c11a560":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8b504380b199466c974e0d555b396798","IPY_MODEL_60bb9eec4b3b4945af7cd05cb03de36a"],"layout":"IPY_MODEL_3b833a1383c847be99f89f28d80eee9c"}},"beab88da0be24cf1b6822804004eac97":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c34b7b9764c040b0a8abca5f0024801f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7e14198118e43029ae5468bdc283b34":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_953880b73283481b990c40eecf2beaea","placeholder":"​","style":"IPY_MODEL_6b91634fd03b4e71a07378d110a28830","value":" 1.36M/1.36M [00:02\u0026lt;00:00, 554kB/s]"}},"cbc5b72b4bd143fe8ef9df3e29d264e0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"d14a3c6df93a4f65bb08f7e7e6e3d93b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d8816136d3b04371ae62eb6f71820b27":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"db4e17380fce48aca411698218325ab6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd102acd4c834a7b87243d3828f84c26":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_867d004b9334404482f5fc7215dbacac","IPY_MODEL_a79948fa4fef4c95aae198490f0217f2"],"layout":"IPY_MODEL_629b984b752c477581795164cbfd6215"}},"e2397f50e00e488a95c83b0db06ba7b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6d7934c85834ccf9c54f159aafa2f98":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"Downloading: 100%","description_tooltip":null,"layout":"IPY_MODEL_3b97432495b24dfc81d6ca6d806dea6c","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6fe45a0e3c7947048a2024005be86e17","value":898823}},"f37d8c8c08c543468b1378638208586b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f78e59935ddc415e977eb0fd95135e23":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8de29f6229cc4236a9ddd7ea500a0ec7","placeholder":"​","style":"IPY_MODEL_77260f8603c54361939d4e25d0dd26cf","value":" 899k/899k [26:39\u0026lt;00:00, 562B/s]"}}}}},"nbformat":4,"nbformat_minor":0}