{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"055-054-train-03.ipynb","provenance":[{"file_id":"10ke_cv7Phs9nPIFwY0HsojNaHk9rq4Pw","timestamp":1627694048586},{"file_id":"1ANF2nhdHdZW664fcSoIBbMi92Gs0FBR5","timestamp":1627431232882},{"file_id":"17BUK8yRF7SDX0khlOXoHcFRTEFffkvRb","timestamp":1627395077423},{"file_id":"1wNpTEKAuuKP7ivTcm1f9j0sdmYU1RyzA","timestamp":1627306793279},{"file_id":"1uE__yBR1oxeYaUIrUTMEOffmeyuJBRAU","timestamp":1627305921964},{"file_id":"1PbEPh6kL5p5cdH5HC8iHoMVCIzA0MqvB","timestamp":1627284576770},{"file_id":"1TlxQ4e-ZX1Zy51dKLuhNdrBWg1qhojqP","timestamp":1627273765934},{"file_id":"17a4F4aC9L0QBqU8BRTrdqPn0WwJ0b08b","timestamp":1626746992716},{"file_id":"1G_W9irFTrEmDeHR0S6_u0bjpk8nxipXW","timestamp":1626689695352},{"file_id":"1bhhkorT--y8XXaVLM8hibVgC-tLqZ16P","timestamp":1626358153868},{"file_id":"1WtT2hX6O9Qbt_hb9sF50nM2QmDXFi-XA","timestamp":1626338366006},{"file_id":"1k_p5wftcUeo711Xho1-T5an2Xkneau-J","timestamp":1626323813472},{"file_id":"1Vz2GB2BNTWuefEFkCSh3TBPEIel7KG1t","timestamp":1626317426487},{"file_id":"1djoMWojeaIPopG5tS1jNMohn8ineblRh","timestamp":1626306831897},{"file_id":"1-6tlDO8158Pi6TpptIF884oFaEiT4Uxb","timestamp":1626276420047},{"file_id":"1js8eA3mDNS8mwSpCiHuzPeARFlUPAVrg","timestamp":1626272452526},{"file_id":"1yhcPgulwJtjJKUK9IuRKmNMhJ-4YXGol","timestamp":1626267205517},{"file_id":"1mnnSv0Pofn1QxArywV81VYqnZPB8uUWN","timestamp":1626180468522},{"file_id":"1RRdjt_UAeHmr5QQBAMyC82Fq1s31OWdK","timestamp":1625833136005},{"file_id":"1JPgg44HFemzwk8VSCXih3PejL0idy-C4","timestamp":1625825483466},{"file_id":"1Ye6wqVX71xAAAhmjXkw9IpRvTqeUyJDA","timestamp":1625812137500}],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ucCbvGD1XvG7","executionInfo":{"status":"ok","timestamp":1627710328191,"user_tz":-540,"elapsed":10,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"ef7ab722-c18c-4a24-e699-ba038aeec499"},"source":["import sys\n","if 'google.colab' in sys.modules:  # colab特有の処理_2回目以降\n","  # Google Driveのマウント\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","\n","  # ライブラリのパス指定\n","  sys.path.append('/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules')\n"],"execution_count":54,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FACwJ6icpxrR","executionInfo":{"status":"ok","timestamp":1627694425166,"user_tz":-540,"elapsed":43670,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# データセットをDriveから取得\n","!mkdir -p 'input'\n","!mkdir -p 'clrp-pre-trained'\n","\n","!cp -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/00_input/commonlitreadabilityprize/' '/content/input'\n","!cp -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/97_pre_trained/clrp_pretrained_manish_epoch5/pre-trained-roberta/clrp_roberta_large/' '/content/clrp-pre-trained'"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"RV9-VwbpZLZ9","executionInfo":{"status":"ok","timestamp":1627694425168,"user_tz":-540,"elapsed":20,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["from pathlib import Path\n","\n","# input\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    DATA_DIR = Path('../input/commonlitreadabilityprize/')\n","\n","elif 'google.colab' in sys.modules: # Colab環境\n","    DATA_DIR = Path('/content/input/commonlitreadabilityprize')\n","\n","else:\n","    DATA_DIR = Path('../00_input/commonlitreadabilityprize/')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"x5difyXe00UV","executionInfo":{"status":"ok","timestamp":1627694425168,"user_tz":-540,"elapsed":14,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["from pathlib import Path\n","\n","# tokenizer\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    TOKENIZER_DIR = '../input/roberta-transformers-pytorch/roberta-large'\n","elif 'google.colab' in sys.modules: # Colab環境\n","    TOKENIZER_DIR = '/content/clrp-pre-trained/clrp_roberta_large' # 仮で、毎回DLする想定のモデル名を指定。あとで変更予定。\n","else:\n","    TOKENIZER_DIR = 'roberta-large'"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"tKjsUxnOeDYl","executionInfo":{"status":"ok","timestamp":1627694425169,"user_tz":-540,"elapsed":14,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["from pathlib import Path\n","\n","# pre-trained model\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    PRE_TRAINED_MODEL_DIR = '../input/roberta-transformers-pytorch/roberta-large'\n","elif 'google.colab' in sys.modules: # Colab環境\n","    PRE_TRAINED_MODEL_DIR = '/content/clrp-pre-trained/clrp_roberta_large' # 仮で、毎回DLする想定のモデル名を指定。あとで変更予定。\n","else:\n","    PRE_TRAINED_MODEL_DIR = 'roberta-large'"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZLaT2V0ReoAZ","executionInfo":{"status":"ok","timestamp":1627694425169,"user_tz":-540,"elapsed":13,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["UPLOAD_DIR = Path('/content/model')\n","EX_NO = '055-054-train-03'  # 実験番号などを入れる、folderのpathにする\n","USERID = 'calpis10000'"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"hOGjAb4pAJ0F","executionInfo":{"status":"ok","timestamp":1627694425170,"user_tz":-540,"elapsed":13,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["import subprocess\n","import shlex\n","\n","def gpuinfo():\n","    \"\"\"\n","    Returns size of total GPU RAM and used GPU RAM.\n","\n","    Parameters\n","    ----------\n","    None\n","\n","    Returns\n","    -------\n","    info : dict\n","        Total GPU RAM in integer for key 'total_MiB'.\n","        Used GPU RAM in integer for key 'used_MiB'.\n","    \"\"\"\n","\n","    command = 'nvidia-smi -q -d MEMORY | sed -n \"/FB Memory Usage/,/Free/p\" | sed -e \"1d\" -e \"4d\" -e \"s/ MiB//g\" | cut -d \":\" -f 2 | cut -c2-'\n","    commands = [shlex.split(part) for part in command.split(' | ')]\n","    for i, cmd in enumerate(commands):\n","        if i==0:\n","            res = subprocess.Popen(cmd, stdout=subprocess.PIPE)\n","        else:\n","            res = subprocess.Popen(cmd, stdin=res.stdout, stdout=subprocess.PIPE)\n","    total, used = map(int, res.communicate()[0].decode('utf-8').strip().split('\\n'))\n","    info = {'total_MiB':total, 'used_MiB':used}\n","    return info\n"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g3-6m5MKXecB"},"source":["# Overview\n","This nb is based on copy from https://www.kaggle.com/andretugan/lightweight-roberta-solution-in-pytorch .\n","\n","Acknowledgments(from base nb): \n","some ideas were taken from kernels by [Torch](https://www.kaggle.com/rhtsingh) and [Maunish](https://www.kaggle.com/maunish)."]},{"cell_type":"code","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-04T06:26:32.834365Z","iopub.execute_input":"2021-07-04T06:26:32.834903Z","iopub.status.idle":"2021-07-04T06:26:40.143740Z","shell.execute_reply.started":"2021-07-04T06:26:32.834785Z","shell.execute_reply":"2021-07-04T06:26:40.142864Z"},"trusted":true,"id":"HRsRZ06WXecD","executionInfo":{"status":"ok","timestamp":1627694721939,"user_tz":-540,"elapsed":296781,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["import os\n","import math\n","import random\n","import time\n","\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","\n","from transformers import AdamW # optimizer\n","from transformers import AutoTokenizer\n","from transformers import AutoModel\n","from transformers import AutoConfig\n","from transformers import get_cosine_schedule_with_warmup # scheduler\n","from pytorch_memlab import profile\n","import pytorch_memlab\n","from pytorch_memlab import MemReporter\n","\n","from sklearn.model_selection import KFold, StratifiedKFold\n","\n","import pickle\n","import gc\n","gc.enable()"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.145217Z","iopub.execute_input":"2021-07-04T06:26:40.145539Z","iopub.status.idle":"2021-07-04T06:26:40.201326Z","shell.execute_reply.started":"2021-07-04T06:26:40.145504Z","shell.execute_reply":"2021-07-04T06:26:40.200136Z"},"trusted":true,"id":"omBfwshTXecE","executionInfo":{"status":"ok","timestamp":1627694721940,"user_tz":-540,"elapsed":20,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["NUM_FOLDS = 5 # K Fold\n","NUM_EPOCHS = 5 # Epochs\n","BATCH_SIZE = 8 # Batch Size\n","MAX_LEN = 248 # ベクトル長\n","TFIDF_MAX_FEAT = 1024\n","\n","EVAL_SCHEDULE = [(0.55, 64), (-1., 32)] # schedulerの何らかの設定？\n","ROBERTA_PATH = PRE_TRAINED_MODEL_DIR # roberta pre-trainedモデル(モデルとして指定)\n","TOKENIZER_PATH = TOKENIZER_DIR # roberta pre-trainedモデル(Tokenizerとして指定)\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\" # cudaがなければcpuを使えばいいじゃない"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.203398Z","iopub.execute_input":"2021-07-04T06:26:40.204055Z","iopub.status.idle":"2021-07-04T06:26:40.211572Z","shell.execute_reply.started":"2021-07-04T06:26:40.204015Z","shell.execute_reply":"2021-07-04T06:26:40.210762Z"},"trusted":true,"id":"4qcuXqwtXecF","executionInfo":{"status":"ok","timestamp":1627694721941,"user_tz":-540,"elapsed":19,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["def set_random_seed(random_seed):\n","    random.seed(random_seed)\n","    np.random.seed(random_seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(random_seed)\n","\n","    torch.manual_seed(random_seed)\n","    torch.cuda.manual_seed(random_seed)\n","    torch.cuda.manual_seed_all(random_seed)\n","\n","    torch.backends.cudnn.deterministic = True# cudnnによる最適化で結果が変わらないためのおまじない "],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.214188Z","iopub.execute_input":"2021-07-04T06:26:40.214809Z","iopub.status.idle":"2021-07-04T06:26:40.309744Z","shell.execute_reply.started":"2021-07-04T06:26:40.214769Z","shell.execute_reply":"2021-07-04T06:26:40.308926Z"},"trusted":true,"id":"70PyLsJTXecF","executionInfo":{"status":"ok","timestamp":1627694721942,"user_tz":-540,"elapsed":19,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# read train_df(kfold)\n","train_kf_df = pd.read_csv(DATA_DIR/\"train_kfold.csv\")"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.311021Z","iopub.execute_input":"2021-07-04T06:26:40.311347Z","iopub.status.idle":"2021-07-04T06:26:40.624393Z","shell.execute_reply.started":"2021-07-04T06:26:40.311314Z","shell.execute_reply":"2021-07-04T06:26:40.623347Z"},"trusted":true,"id":"xf0662k4XecF","executionInfo":{"status":"ok","timestamp":1627694731484,"user_tz":-540,"elapsed":853,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# tokenizerを指定\n","tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N6aaghNkXecG"},"source":["# Dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UU5uZKIcDjkV","executionInfo":{"status":"ok","timestamp":1627694736134,"user_tz":-540,"elapsed":4107,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"7bf17a03-1870-433a-8b2a-89b1413bfcb8"},"source":["# 前処理用\n","import string\n","import re\n","# ローカルの場合、stopwordsをダウンロード\n","import nltk\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    pass\n","else:\n","    import nltk\n","    nltk.download('stopwords')\n","    nltk.download('averaged_perceptron_tagger')\n","    os.listdir(os.path.expanduser('~/nltk_data/corpora/stopwords/'))\n","\n","# テキスト前処理\n","# https://www.kaggle.com/alaasedeeq/commonlit-readability-eda\n","\n","#filtering the unwanted symbols, spaces, ....etc\n","to_replace_by_space = re.compile('[/(){}\\[\\]|@,;]')\n","punctuation = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n","bad_symbols = re.compile('[^0-9a-z #+_]')\n","stopwords = set(nltk.corpus.stopwords.words('english'))\n","\n","def text_prepare(text):\n","    '''\n","    text: a string\n","    returna modified version of the string\n","    '''\n","    text = text.lower() # lowercase text\n","    text = re.sub(punctuation, '',text)\n","    text = re.sub(to_replace_by_space, \" \", text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n","    text = re.sub(bad_symbols, \"\", text)         # delete symbols which are in BAD_SYMBOLS_RE from text\n","    text = \" \".join([word for word in text.split(\" \") if word not in stopwords]) # delete stopwords from text\n","    text = re.sub(' +', ' ', text)\n","    return text\n","\n","def text_normalization(s:pd.Series):\n","    x = s.apply(text_prepare)\n","    return x\n","\n","# Counterオブジェクトを取得\n","def get_counter(text:str):\n","    text_list = [wrd for wrd in text.split(\" \") if wrd not in ('', '\\n')]\n","    counter = collections.Counter(text_list)\n","    return counter\n"],"execution_count":14,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kqqJmgKBT6Xx","executionInfo":{"status":"ok","timestamp":1627694736971,"user_tz":-540,"elapsed":12,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 参考: https://www.guruguru.science/competitions/16/discussions/556029f7-484d-40d4-ad6a-9d86337487e2/\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","# ベースとなる継承元のクラス\n","class BaseBlock(object):\n","    def fit(self, input_df, y=None):\n","        return self.transform(input_df)\n","    def transform(self, input_df):\n","        raise NotImplementedError()\n","\n","\n","class TfidfSimpleBlock(BaseBlock):\n","    \"\"\"シンプルなTF-IDF特徴を作成する block\"\"\"\n","    def __init__(self, column: str, max_features=50, ngram_range=(1,1), use_idf=True):\n","        \"\"\"\n","        args:\n","            column: str\n","                変換対象のカラム名\n","        \"\"\"\n","        self.column = column\n","        self.max_features=max_features\n","        self.ngram_range=ngram_range\n","        self.use_idf=use_idf\n","        self.param_prefix=f\"col={column}_max_features={max_features}_\\\n","                              ngram={ngram_range[0]}_{ngram_range[1]}_use_idf={use_idf}\"\n","\n","    def preprocess(self, input_df):\n","        x = text_normalization(input_df[self.column])\n","        return x\n","\n","    def get_master(self, _master_df):\n","        \"\"\"tdidfを計算するための全体集合を返す.\"\"\"\n","        return _master_df\n","    def fit(self, \n","            input_df, \n","            _master_df=None, \n","            y=None\n","           ):\n","        master_df = input_df if _master_df is None else self.get_master(_master_df)\n","        text = self.preprocess(master_df)\n","        self.vectorizer_ = TfidfVectorizer(max_features=self.max_features\n","                                      ,ngram_range=self.ngram_range\n","                                      ,use_idf=self.use_idf)\n","\n","        self.vectorizer_.fit(text)\n","        self.prefix = 'tfidf' if self.use_idf == True else 'tf'\n","        return self.transform(input_df)\n","\n","    def transform(self, input_df):\n","        text = self.preprocess(input_df)\n","        z = self.vectorizer_.transform(text)\n","\n","        out_df = pd.DataFrame(z.toarray())\n","        out_df.columns = self.vectorizer_.get_feature_names()\n","        return out_df.add_prefix(f'{self.prefix}_')"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"iAse0IDWDjho","executionInfo":{"status":"ok","timestamp":1627694736972,"user_tz":-540,"elapsed":11,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["class LitDataset(Dataset):\n","    def __init__(self, df, tfidf, inference_only=False):\n","        super().__init__()\n","\n","        self.df = df        \n","        self.inference_only = inference_only # Testデータ用フラグ\n","        self.text = df.excerpt.tolist() # 分析対象カラムをlistにする。(分かち書きではなく、Seriesをlistへ変換するような処理)\n","        #self.text = [text.replace(\"\\n\", \" \") for text in self.text] # 単語単位で分かち書きする場合\n","        self.text_len = text_normalization(df.excerpt).map(lambda x: [0 if i >= len(x.split(' ')) else len(x.split(' ')[i]) for i in range(132)])\n","        self.tfidf = tfidf # fit済みのものを入力する。（クラス内ではtransformのみ行う）\n","        self.tfidf_vector = tfidf.transform(df).values\n","\n","        if not self.inference_only:\n","            self.target = torch.tensor(df.target.values, dtype=torch.float32) # trainのみ、targetをtensorに変換\n","            self.standard_error = torch.tensor(df.standard_error.values, dtype=torch.float32) \n","\n","        self.encoded = tokenizer.batch_encode_plus( # textをtokenize\n","            self.text,\n","            padding = 'max_length',            \n","            max_length = MAX_LEN,\n","            truncation = True, # 最大長を超える文字は切り捨て\n","            return_attention_mask=True\n","        )        \n"," \n","\n","    def __len__(self):\n","        return len(self.df)\n","    \n","    def __getitem__(self, index): # 変換結果を返す\n","        input_ids = torch.tensor(self.encoded['input_ids'][index])\n","        attention_mask = torch.tensor(self.encoded['attention_mask'][index])\n","        input_len = torch.tensor(self.text_len.iloc[index], dtype=torch.float32)\n","        input_tfidf = torch.tensor(self.tfidf_vector[index, :], dtype=torch.float32)\n","\n","        if self.inference_only:\n","            return (input_ids, attention_mask, input_len, input_tfidf)            \n","        else:\n","            target = self.target[index]\n","            standard_error = self.standard_error[index]\n","            return (input_ids, attention_mask, input_len, input_tfidf, target, standard_error)"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KKtdy32wXecG"},"source":["# Model\n","The model is inspired by the one from [Maunish](https://www.kaggle.com/maunish/clrp-roberta-svm)."]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.649629Z","iopub.execute_input":"2021-07-04T06:26:40.650066Z","iopub.status.idle":"2021-07-04T06:26:40.666374Z","shell.execute_reply.started":"2021-07-04T06:26:40.650002Z","shell.execute_reply":"2021-07-04T06:26:40.665211Z"},"trusted":true,"id":"BpkxjXEUXecH","executionInfo":{"status":"ok","timestamp":1627694736972,"user_tz":-540,"elapsed":10,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["class LitModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        config = AutoConfig.from_pretrained(ROBERTA_PATH) # pretrainedからconfigを読み込み\n","        config.update({\"output_hidden_states\":True, # config更新: embedding層を抽出\n","                       \"hidden_dropout_prob\": 0.0, # config更新: dropoutしない\n","                       \"layer_norm_eps\": 1e-7}) # config更新: layer normalizationのepsilon                      \n","        \n","        self.roberta = AutoModel.from_pretrained(ROBERTA_PATH, config=config) # cpuで処理する\n","            \n","        self.attention = nn.Sequential(# attentionレイヤー            \n","            nn.Linear(config.hidden_size, 512),      \n","            nn.Tanh(),                       \n","            nn.Linear(512, 1),\n","            nn.Softmax(dim=1)\n","        )\n","\n","        self.mlm_wordlen = nn.Sequential(\n","            nn.Linear(132, 64),\n","            nn.ReLU(),\n","            nn.Linear(64, 64)\n","        )\n","\n","        self.mlm_tfidf = nn.Sequential(\n","            nn.Linear(TFIDF_MAX_FEAT, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 64),\n","            nn.ReLU(),\n","            nn.Linear(64, 64)\n","        )\n","\n","        self.regressor = nn.Sequential( # 出力レイヤー                    \n","            nn.Linear(config.hidden_size + 64 + 64, 2)                        \n","        )\n","\n","    def forward(self, input_ids, attention_mask, input_len, input_tfidf):\n","        roberta_output = self.roberta(input_ids=input_ids, # robertaに入力データを流し、出力としてrobertaモデル(layerの複合体)を得る\n","                                      attention_mask=attention_mask)     \n","        # attention_pooling\n","        last_hidden_state = roberta_output.hidden_states[-1] # robertaモデルの最後のlayerを得る\n","        weights = self.attention(last_hidden_state) # robertaの最後のlayerをattentionへ入力し、出力として重みを得る                \n","        context_vector = torch.sum(weights * last_hidden_state, dim=1) # 重み×最後の層を足し合わせて文書ベクトルとする。\n","\n","        # word_length_conv1d\n","        #input_chnl = input_len.unsqueeze(1)\n","        #conv1_layers = self.conv1_layers(input_chnl)\n","        #conv1_layers_v = conv1_layers.view(conv1_layers.size(0),-1)\n","\n","        # mlm_layers\n","        mlm_wordlen = self.mlm_wordlen(input_len)\n","        mlm_tfidf = self.mlm_tfidf(input_tfidf)\n","\n","        # https://www.kaggle.com/rhtsingh/utilizing-transformer-representations-efficiently\n","        # last_hidden_state = roberta_output[0]\n","        # input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        # sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        # sum_mask = input_mask_expanded.sum(1)\n","        # sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        # mean_embeddings = sum_embeddings / sum_mask\n","\n","        # concat_embeddings\n","        cat_embeddings = torch.cat([context_vector, mlm_wordlen, mlm_tfidf], dim=1)        \n","        return self.regressor(cat_embeddings) # 文書ベクトルを線形層に入力し、targetを出力する\n","        \n","        # Now we reduce the context vector to the prediction score.\n","        #return self.regressor(mean_embeddings) # 文書ベクトルを線形層に入力し、targetを出力する"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.672515Z","iopub.execute_input":"2021-07-04T06:26:40.672944Z","iopub.status.idle":"2021-07-04T06:26:40.684593Z","shell.execute_reply.started":"2021-07-04T06:26:40.672908Z","shell.execute_reply":"2021-07-04T06:26:40.683569Z"},"trusted":true,"id":"bB4jvQTxXecH","executionInfo":{"status":"ok","timestamp":1627694736973,"user_tz":-540,"elapsed":10,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 評価指標(MSE)の計算。最終的に、ルートしてRMSEにすると思われる。\n","def eval_mse(model, data_loader):\n","    \"\"\"Evaluates the mean squared error of the |model| on |data_loader|\"\"\"\n","    model.eval() # evalモードを選択。Batch Normとかdropoutをしなくなる           \n","    mse_mean_sum = 0\n","    mse_std_sum = 0\n","\n","    with torch.no_grad(): # 勾配の計算をしないBlock\n","        for batch_num, (input_ids, attention_mask, input_len, input_tfidf, target, standard_error) in enumerate(data_loader): # data_loaderからinput, attentin_mask, targetをbatchごとに取り出す\n","            input_ids = input_ids.to(DEVICE)   \n","            attention_mask = attention_mask.to(DEVICE)  \n","            input_len = input_len.to(DEVICE) \n","            input_tfidf = input_tfidf.to(DEVICE)\n","            target = target.to(DEVICE)      \n","            standard_error = standard_error.to(DEVICE) \n","            \n","            output = model(input_ids, attention_mask, input_len, input_tfidf) # 取得した値をモデルへ入力し、出力として予測値を得る。\n","\n","            mse_mean_sum += nn.MSELoss(reduction=\"sum\")(output[:,0].flatten(), target).item() # 誤差の合計を得る(Batchごとに計算した誤差を足し上げる)\n","            mse_std_sum += nn.MSELoss(reduction=\"sum\")(output[:,1].flatten(), target).item() # 誤差の合計を得る(Batchごとに計算した誤差を足し上げる)\n","\n","    del input_ids\n","    del attention_mask\n","    del target\n","    del input_len\n","    del input_tfidf\n","\n","    mse_mean_result = mse_mean_sum / len(data_loader.dataset)\n","    mse_std_result = mse_std_sum / len(data_loader.dataset)\n","  \n","    return mse_mean_result, mse_std_result # 誤差の合計をdataset長で除し、mseを取得＆返す"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.690155Z","iopub.execute_input":"2021-07-04T06:26:40.692530Z","iopub.status.idle":"2021-07-04T06:26:40.703425Z","shell.execute_reply.started":"2021-07-04T06:26:40.692488Z","shell.execute_reply":"2021-07-04T06:26:40.702366Z"},"trusted":true,"id":"47bDno_LXecI","executionInfo":{"status":"ok","timestamp":1627694736973,"user_tz":-540,"elapsed":10,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 推論結果を返す\n","def predict(model, data_loader):\n","    \"\"\"Returns an np.array with predictions of the |model| on |data_loader|\"\"\"\n","    model.eval() # evalモード(dropout, batch_normしない)\n","\n","    result = np.zeros(len(data_loader.dataset)) # 結果をdataset長のzero配列として用意\n","    index = 0\n","    \n","    with torch.no_grad(): # 勾配の計算をしないblock(inputすると、現状の重みによる推論結果を返す)\n","        for batch_num, (input_ids, attention_mask, input_len, input_tfidf) in enumerate(data_loader): # data_loaderからbatchごとにinputを得る\n","            input_ids = input_ids.to(DEVICE)\n","            attention_mask = attention_mask.to(DEVICE)\n","            input_len = input_len.to(DEVICE)\n","            input_tfidf = input_tfidf.to(DEVICE)\n","                        \n","            output = model(input_ids, attention_mask, input_len, input_tfidf) # modelにinputを入力し、予測結果を得る。\n","\n","            result[index : index + output[:,0].shape[0]] = output[:,0].flatten().to(\"cpu\") # result[index ~ predの長さ]へ、予測結果を格納\n","            index += output.shape[0] # indexを更新\n","\n","    return result # 全batchで推論が終わったら、結果を返す"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.708605Z","iopub.execute_input":"2021-07-04T06:26:40.709024Z","iopub.status.idle":"2021-07-04T06:26:40.730675Z","shell.execute_reply.started":"2021-07-04T06:26:40.708983Z","shell.execute_reply":"2021-07-04T06:26:40.729705Z"},"trusted":true,"id":"oInneuAmXecI","executionInfo":{"status":"ok","timestamp":1627694736974,"user_tz":-540,"elapsed":10,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 学習\n","def train(model, # モデル\n","          model_path, # モデルのアウトプット先\n","          train_loader, # train-setのdata_loader\n","          val_loader, # valid-setのdata_loader\n","          optimizer, # optimizer\n","          scheduler=None, # scheduler, デフォルトはNone\n","          num_epochs=NUM_EPOCHS # epoch数、notebook冒頭で指定した値\n","         ):    \n","    \n","    best_val_rmse = None\n","    best_epoch = 0\n","    step = 0\n","    last_eval_step = 0\n","    eval_period = EVAL_SCHEDULE[0][1] # eval期間(って何？) 冒頭で決めたEVAL_SCHEDULEの最初のtupleの[1]を取得\n","\n","    start = time.time() # 時間計測用\n","\n","    for epoch in range(num_epochs): # 指定したEpoch数だけ繰り返し\n","        val_rmse = None         \n","\n","        for batch_num, (input_ids, attention_mask, input_len, input_tfidf, target, standard_error) in enumerate(train_loader): # train_loaderからinput, targetを取得\n","            input_ids = input_ids.to(DEVICE) # inputをDEVICEへ突っ込む\n","            attention_mask = attention_mask.to(DEVICE)   \n","            input_len = input_len.to(DEVICE)\n","            input_tfidf = input_tfidf.to(DEVICE)\n","            target = target.to(DEVICE)\n","            standard_error = standard_error.to(DEVICE)  \n","\n","            optimizer.zero_grad() # 勾配を初期化            \n","            model.train() # 学習モード開始\n","\n","            # https://www.kaggle.com/c/commonlitreadabilityprize/discussion/239421\n","            output = model(input_ids, attention_mask, input_len, input_tfidf) # input,attention_maskを入力し、予測結果を得る\n","            p = torch.distributions.Normal(output[:,0], torch.sqrt(output[:,1]**2))\n","            q = torch.distributions.Normal(target, standard_error)\n","            kl_vector = torch.distributions.kl_divergence(p, q)\n","            loss = kl_vector.mean()\n","\n","            loss.backward() # 誤差逆伝播法により勾配を得る\n","            optimizer.step() # 重みを更新する\n","\n","            if scheduler:\n","                scheduler.step() # schedulerが与えられた場合は、schedulerの学習率更新\n","            \n","            if step >= last_eval_step + eval_period: # batchを回すごとにstepを増やしていって、「前回evalしたstep + eval_period(16)」を超えたら実行。\n","                # Evaluate the model on val_loader.\n","                elapsed_seconds = time.time() - start # 経過時間\n","                num_steps = step - last_eval_step # 経過ステップ数\n","                print(f\"\\n{num_steps} steps took {elapsed_seconds:0.3} seconds\")\n","                last_eval_step = step # 前回stepの更新\n","                \n","                # valid-setによるrmse計算\n","                train_mean_mse = nn.MSELoss(reduction=\"mean\")(output[:,0].flatten(), target) \n","                train_std_mse = nn.MSELoss(reduction=\"mean\")(torch.sqrt(output[:,1]**2).flatten(), standard_error) \n","\n","                train_mean_rmse = math.sqrt(train_mean_mse)\n","                train_std_rmse = math.sqrt(train_std_mse)\n","\n","                val_mean_mse, val_std_mse = eval_mse(model, val_loader)\n","                val_mean_rmse = math.sqrt(val_mean_mse)                            \n","                val_std_rmse = math.sqrt(val_std_mse)                            \n","\n","                print(f\"Epoch: {epoch} batch_num: {batch_num}\")\n","                print(f\"train_rmse_target: {train_mean_rmse:0.4}\",\n","                      f\"train_rmse_stderror: {train_std_rmse:0.4}\",\n","                      f\"train_kl_div: {loss:0.4}\",\n","                      )\n","                print(f\"val_rmse_target: {val_mean_rmse:0.4}\",\n","                      f\"val_rmse_stderror: {val_std_rmse:0.4}\"\n","                      )\n","\n","                for rmse, period in EVAL_SCHEDULE: # eval_periodをvalid-rmseで切り替える処理\n","                    if val_mean_rmse >= rmse: # valid rmseをEVAL_SCHEDULEと比較し、0項 > valid rmseとなるまで回す : EVAL_SCHEDULE = [(0.50, 16), (0.49, 8), (0.48, 4), (0.47, 2), (-1., 1)]\n","                        eval_period = period # eval_periodを更新\n","                        break                               \n","\n","                if not best_val_rmse or val_mean_rmse < best_val_rmse: # 初回(best_val_rmse==None), またはbest_val_rmseを更新したらモデルを保存する\n","                    best_val_rmse = val_mean_rmse\n","                    best_epoch = epoch\n","                    torch.save(model.state_dict(), model_path) # 最高の自分を保存\n","                    print(f\"New best_val_rmse: {best_val_rmse:0.4}\")\n","                else:       \n","                    print(f\"Still best_val_rmse: {best_val_rmse:0.4}\", # 更新されない場合は、元のスコアを表示\n","                          f\"(from epoch {best_epoch})\")      \n","                                                  \n","                start = time.time()\n","            \n","            # batchごとにメモリ解放\n","            del input_ids\n","            del attention_mask\n","            del target\n","            torch.cuda.empty_cache()                                            \n","            step += 1\n","    \n","    return best_val_rmse"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.735798Z","iopub.execute_input":"2021-07-04T06:26:40.738398Z","iopub.status.idle":"2021-07-04T06:26:40.750876Z","shell.execute_reply.started":"2021-07-04T06:26:40.738356Z","shell.execute_reply":"2021-07-04T06:26:40.749635Z"},"trusted":true,"id":"rMY0fjXwXecJ","executionInfo":{"status":"ok","timestamp":1627694736974,"user_tz":-540,"elapsed":9,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# optimizerの作成\n","def create_optimizer(model):\n","    parameters = []\n","\n","    named_parameters = list(model.named_parameters()) # モデルパラメータの取得\n","    roberta_parameters = list(model.roberta.named_parameters())[:-2] # パラメータをroberta用、attention用、regressor用に格納。(直接引っ張ってくる形式に変更)\n","\n","    attention_parameters = list(model.attention.named_parameters())\n","    attention_group = [{'params': params, 'lr': 2e-5} for (name, params) in attention_parameters] # attention用パラメータをリストとして取得\n","    parameters += attention_group\n","\n","    #norm_parameters = list(model.layer_norm.named_parameters())\n","    #norm_group = [{'params': params, 'lr': 2e-5} for (name, params) in norm_parameters]\n","    #parameters += norm_group\n","\n","    mlm_wrd_parameters = list(model.mlm_wordlen.named_parameters())\n","    mlm_wrd_group = [{'params': params, 'lr': 2e-5} for (name, params) in mlm_wrd_parameters] # reg用パラメータをリストとして取得\n","    parameters += mlm_wrd_group\n","\n","    mlm_tfidf_parameters = list(model.mlm_tfidf.named_parameters())\n","    mlm_tfidf_group = [{'params': params, 'lr': 2e-5} for (name, params) in mlm_tfidf_parameters] # reg用パラメータをリストとして取得\n","    parameters += mlm_tfidf_group\n","\n","    regressor_parameters = list(model.regressor.named_parameters())\n","    regressor_group = [{'params': params, 'lr': 2e-5} for (name, params) in regressor_parameters] # reg用パラメータをリストとして取得\n","    parameters += regressor_group\n","\n","    for layer_num, (name, params) in enumerate(roberta_parameters): # レイヤーごとにname, paramsを取得していろんな処理\n","        weight_decay = 0.0 if \"bias\" in name else 0.01\n","\n","        lr = 8e-6\n","\n","        if layer_num >= 69:        \n","            lr = 2e-5\n","\n","        if layer_num >= 133:\n","            lr = 4e-5\n","\n","        parameters.append({\"params\": params,\n","                           \"weight_decay\": weight_decay,\n","                           \"lr\": lr})\n","\n","    return AdamW(parameters) # 最終的に、AdamWにパラメータを入力する。\n"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"EbaJojz0Zjif","executionInfo":{"status":"ok","timestamp":1627694741205,"user_tz":-540,"elapsed":342,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# https://www.kaggle.com/abhishek/step-1-create-folds\n","def create_folds(data, num_splits, SEED, return_df=False):\n","    # we create a new column called kfold and fill it with -1\n","    data[\"kfold\"] = -1\n","    \n","    # the next step is to randomize the rows of the data\n","    data = data.sample(frac=1).reset_index(drop=True)\n","\n","    # calculate number of bins by Sturge's rule\n","    # I take the floor of the value, you can also\n","    # just round it\n","    num_bins = int(np.floor(1 + np.log2(len(data))))\n","    \n","    # bin targets\n","    data.loc[:, \"bins_tg\"] = pd.cut(\n","        data[\"target\"], bins=num_bins, labels=False\n","    ).map(lambda x: str(x))\n","\n","    # bin standard_error\n","    data.loc[:, \"bins_std\"] = pd.cut(\n","        data[\"standard_error\"], bins=num_bins, labels=False\n","    )\n","\n","    # bins\n","    data.loc[:, \"bins\"] = data['bins_tg'].map(lambda x: str(x)) + data['bins_std'].map(lambda x: str(x))\n","\n","    # initiate the kfold class from model_selection module\n","    kf = StratifiedKFold(n_splits=5, random_state=SEED, shuffle=True)\n","\n","    # note that, instead of targets, we use bins!\n","    if return_df:\n","      for f, (t_, v_) in enumerate(kf.split(X=data, y=data.bins.values)):\n","        data.loc[v_, 'kfold'] = f\n","      return data\n","    else:\n","      return kf.split(X=data, y=data.bins.values)"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"4PLKHwvKtNBn","executionInfo":{"status":"ok","timestamp":1627694855452,"user_tz":-540,"elapsed":824,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["def train_and_save_model(train_indices, val_indices, model_path, feat_suffix):\n","    tfidf = TfidfSimpleBlock('excerpt', max_features=TFIDF_MAX_FEAT)\n","    df_tfidf = tfidf.fit(train_kf_df.loc[train_indices]) # TODO: fit_transformみたいなメソッド作って、fitではdfが返らないようにする。\n","\n","    with open(f'TFIDF_{feat_suffix}', 'wb') as f:\n","      pickle.dump(tfidf, f)\n","\n","    train_dataset = LitDataset(train_kf_df.loc[train_indices], tfidf) # train, validのDataset\n","    val_dataset = LitDataset(train_kf_df.loc[val_indices], tfidf)\n","        \n","    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n","                              drop_last=True, shuffle=True, num_workers=2) # train, validのDataLoader\n","    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n","                            drop_last=False, shuffle=False, num_workers=2)    \n","\n","    model = LitModel().to(DEVICE) # modelをDEVICEへぶち込む\n","    optimizer = create_optimizer(model) # optimizerをモデルから作成\n","    scheduler = get_cosine_schedule_with_warmup( # schedulerを作成\n","        optimizer,\n","        num_training_steps=NUM_EPOCHS * len(train_loader),\n","        num_warmup_steps=50)    \n","    rmse = train(model, model_path, train_loader, val_loader, optimizer, scheduler=scheduler)\n","\n","    del train_dataset\n","    del val_dataset\n","    del train_loader\n","    del val_loader\n","    del model\n","    del optimizer\n","    del scheduler\n","    gc.collect() \n","    torch.cuda.empty_cache()\n","    return rmse"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.755813Z","iopub.execute_input":"2021-07-04T06:26:40.758373Z","iopub.status.idle":"2021-07-04T06:27:12.493221Z","shell.execute_reply.started":"2021-07-04T06:26:40.758265Z","shell.execute_reply":"2021-07-04T06:27:12.490139Z"},"trusted":true,"id":"k2LGJD3XXecK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627704999855,"user_tz":-540,"elapsed":10142565,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"07d8d088-89d8-4f9b-ca5f-6cd6b1cebaed"},"source":["# 実行処理。 KFold & 学習\n","SEED = 1000\n","list_val_rmse = []\n","\n","for fold in sorted(train_kf_df['kfold'].unique()):\n","    print(f\"\\nFold {fold + 1}/{NUM_FOLDS}\")\n","    print(gpuinfo())\n","    model_path = f\"model_{fold + 1}.pth\" # model_fold数_.pth\n","    set_random_seed(SEED + fold) # SEEDはfold別に変わるようにする\n","    feat_suffix = f\"{fold + 1}.pkl\" \n","\n","    train_indices = (train_kf_df['kfold'] != fold)\n","    val_indices = (train_kf_df['kfold'] == fold)\n","    list_val_rmse.append(train_and_save_model(train_indices, val_indices, model_path, feat_suffix))\n","    print(\"\\nPerformance estimates:\")\n","    print(list_val_rmse)\n","    print(\"Mean:\", np.array(list_val_rmse).mean())\n","    print(gpuinfo())"],"execution_count":29,"outputs":[{"output_type":"stream","text":["\n","Fold 1/5\n","{'total_MiB': 16280, 'used_MiB': 2}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 63.1 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.389 train_rmse_stderror: 0.138 train_kl_div: 0.4139\n","val_rmse_target: 0.9389 val_rmse_stderror: 1.05\n","New best_val_rmse: 0.9389\n","\n","64 steps took 62.3 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.4826 train_rmse_stderror: 0.06585 train_kl_div: 0.5036\n","val_rmse_target: 0.6195 val_rmse_stderror: 1.146\n","New best_val_rmse: 0.6195\n","\n","64 steps took 62.3 seconds\n","Epoch: 0 batch_num: 192\n","train_rmse_target: 0.6128 train_rmse_stderror: 0.08137 train_kl_div: 0.7708\n","val_rmse_target: 0.6363 val_rmse_stderror: 1.178\n","Still best_val_rmse: 0.6195 (from epoch 0)\n","\n","64 steps took 62.3 seconds\n","Epoch: 0 batch_num: 256\n","train_rmse_target: 0.6327 train_rmse_stderror: 0.09523 train_kl_div: 0.878\n","val_rmse_target: 0.5524 val_rmse_stderror: 1.155\n","New best_val_rmse: 0.5524\n","\n","64 steps took 62.4 seconds\n","Epoch: 1 batch_num: 37\n","train_rmse_target: 0.525 train_rmse_stderror: 0.06685 train_kl_div: 0.6303\n","val_rmse_target: 0.5607 val_rmse_stderror: 1.149\n","Still best_val_rmse: 0.5524 (from epoch 0)\n","\n","64 steps took 62.3 seconds\n","Epoch: 1 batch_num: 101\n","train_rmse_target: 0.3407 train_rmse_stderror: 0.0933 train_kl_div: 0.2547\n","val_rmse_target: 0.5495 val_rmse_stderror: 1.129\n","New best_val_rmse: 0.5495\n","\n","32 steps took 31.2 seconds\n","Epoch: 1 batch_num: 133\n","train_rmse_target: 0.4903 train_rmse_stderror: 0.0561 train_kl_div: 0.5318\n","val_rmse_target: 0.5594 val_rmse_stderror: 1.143\n","Still best_val_rmse: 0.5495 (from epoch 1)\n","\n","64 steps took 62.3 seconds\n","Epoch: 1 batch_num: 197\n","train_rmse_target: 0.3131 train_rmse_stderror: 0.03615 train_kl_div: 0.216\n","val_rmse_target: 0.5277 val_rmse_stderror: 1.157\n","New best_val_rmse: 0.5277\n","\n","32 steps took 31.1 seconds\n","Epoch: 1 batch_num: 229\n","train_rmse_target: 0.5438 train_rmse_stderror: 0.05933 train_kl_div: 0.5987\n","val_rmse_target: 0.5384 val_rmse_stderror: 1.123\n","Still best_val_rmse: 0.5277 (from epoch 1)\n","\n","32 steps took 31.2 seconds\n","Epoch: 1 batch_num: 261\n","train_rmse_target: 0.2996 train_rmse_stderror: 0.04874 train_kl_div: 0.1796\n","val_rmse_target: 0.5748 val_rmse_stderror: 1.14\n","Still best_val_rmse: 0.5277 (from epoch 1)\n","\n","64 steps took 62.5 seconds\n","Epoch: 2 batch_num: 42\n","train_rmse_target: 0.2717 train_rmse_stderror: 0.04964 train_kl_div: 0.1601\n","val_rmse_target: 0.5241 val_rmse_stderror: 1.142\n","New best_val_rmse: 0.5241\n","\n","32 steps took 31.2 seconds\n","Epoch: 2 batch_num: 74\n","train_rmse_target: 0.1942 train_rmse_stderror: 0.0536 train_kl_div: 0.09163\n","val_rmse_target: 0.536 val_rmse_stderror: 1.149\n","Still best_val_rmse: 0.5241 (from epoch 2)\n","\n","32 steps took 31.1 seconds\n","Epoch: 2 batch_num: 106\n","train_rmse_target: 0.334 train_rmse_stderror: 0.05644 train_kl_div: 0.2095\n","val_rmse_target: 0.5081 val_rmse_stderror: 1.129\n","New best_val_rmse: 0.5081\n","\n","32 steps took 31.2 seconds\n","Epoch: 2 batch_num: 138\n","train_rmse_target: 0.2158 train_rmse_stderror: 0.03101 train_kl_div: 0.09996\n","val_rmse_target: 0.5095 val_rmse_stderror: 1.125\n","Still best_val_rmse: 0.5081 (from epoch 2)\n","\n","32 steps took 31.1 seconds\n","Epoch: 2 batch_num: 170\n","train_rmse_target: 0.2059 train_rmse_stderror: 0.08016 train_kl_div: 0.107\n","val_rmse_target: 0.5162 val_rmse_stderror: 1.141\n","Still best_val_rmse: 0.5081 (from epoch 2)\n","\n","32 steps took 31.1 seconds\n","Epoch: 2 batch_num: 202\n","train_rmse_target: 0.2403 train_rmse_stderror: 0.04911 train_kl_div: 0.1311\n","val_rmse_target: 0.5173 val_rmse_stderror: 1.142\n","Still best_val_rmse: 0.5081 (from epoch 2)\n","\n","32 steps took 31.1 seconds\n","Epoch: 2 batch_num: 234\n","train_rmse_target: 0.2718 train_rmse_stderror: 0.05741 train_kl_div: 0.1788\n","val_rmse_target: 0.5104 val_rmse_stderror: 1.138\n","Still best_val_rmse: 0.5081 (from epoch 2)\n","\n","32 steps took 31.2 seconds\n","Epoch: 2 batch_num: 266\n","train_rmse_target: 0.157 train_rmse_stderror: 0.06447 train_kl_div: 0.07166\n","val_rmse_target: 0.5218 val_rmse_stderror: 1.157\n","Still best_val_rmse: 0.5081 (from epoch 2)\n","\n","32 steps took 31.3 seconds\n","Epoch: 3 batch_num: 15\n","train_rmse_target: 0.1469 train_rmse_stderror: 0.04403 train_kl_div: 0.05185\n","val_rmse_target: 0.4994 val_rmse_stderror: 1.158\n","New best_val_rmse: 0.4994\n","\n","32 steps took 31.1 seconds\n","Epoch: 3 batch_num: 47\n","train_rmse_target: 0.07799 train_rmse_stderror: 0.03055 train_kl_div: 0.01714\n","val_rmse_target: 0.5019 val_rmse_stderror: 1.133\n","Still best_val_rmse: 0.4994 (from epoch 3)\n","\n","32 steps took 31.2 seconds\n","Epoch: 3 batch_num: 79\n","train_rmse_target: 0.08002 train_rmse_stderror: 0.04555 train_kl_div: 0.02282\n","val_rmse_target: 0.5005 val_rmse_stderror: 1.157\n","Still best_val_rmse: 0.4994 (from epoch 3)\n","\n","32 steps took 31.1 seconds\n","Epoch: 3 batch_num: 111\n","train_rmse_target: 0.1466 train_rmse_stderror: 0.04646 train_kl_div: 0.05578\n","val_rmse_target: 0.4952 val_rmse_stderror: 1.16\n","New best_val_rmse: 0.4952\n","\n","32 steps took 31.2 seconds\n","Epoch: 3 batch_num: 143\n","train_rmse_target: 0.1713 train_rmse_stderror: 0.05799 train_kl_div: 0.07882\n","val_rmse_target: 0.4998 val_rmse_stderror: 1.153\n","Still best_val_rmse: 0.4952 (from epoch 3)\n","\n","32 steps took 31.2 seconds\n","Epoch: 3 batch_num: 175\n","train_rmse_target: 0.1497 train_rmse_stderror: 0.03769 train_kl_div: 0.05011\n","val_rmse_target: 0.5 val_rmse_stderror: 1.157\n","Still best_val_rmse: 0.4952 (from epoch 3)\n","\n","32 steps took 31.1 seconds\n","Epoch: 3 batch_num: 207\n","train_rmse_target: 0.1445 train_rmse_stderror: 0.03119 train_kl_div: 0.04992\n","val_rmse_target: 0.4933 val_rmse_stderror: 1.152\n","New best_val_rmse: 0.4933\n","\n","32 steps took 31.1 seconds\n","Epoch: 3 batch_num: 239\n","train_rmse_target: 0.1349 train_rmse_stderror: 0.02432 train_kl_div: 0.03889\n","val_rmse_target: 0.4975 val_rmse_stderror: 1.153\n","Still best_val_rmse: 0.4933 (from epoch 3)\n","\n","32 steps took 31.2 seconds\n","Epoch: 3 batch_num: 271\n","train_rmse_target: 0.1187 train_rmse_stderror: 0.05635 train_kl_div: 0.04607\n","val_rmse_target: 0.4962 val_rmse_stderror: 1.149\n","Still best_val_rmse: 0.4933 (from epoch 3)\n","\n","32 steps took 31.3 seconds\n","Epoch: 4 batch_num: 20\n","train_rmse_target: 0.1048 train_rmse_stderror: 0.03978 train_kl_div: 0.03097\n","val_rmse_target: 0.4986 val_rmse_stderror: 1.151\n","Still best_val_rmse: 0.4933 (from epoch 3)\n","\n","32 steps took 31.1 seconds\n","Epoch: 4 batch_num: 52\n","train_rmse_target: 0.07777 train_rmse_stderror: 0.02973 train_kl_div: 0.01673\n","val_rmse_target: 0.4957 val_rmse_stderror: 1.155\n","Still best_val_rmse: 0.4933 (from epoch 3)\n","\n","32 steps took 31.2 seconds\n","Epoch: 4 batch_num: 84\n","train_rmse_target: 0.09241 train_rmse_stderror: 0.0439 train_kl_div: 0.02555\n","val_rmse_target: 0.496 val_rmse_stderror: 1.15\n","Still best_val_rmse: 0.4933 (from epoch 3)\n","\n","32 steps took 31.1 seconds\n","Epoch: 4 batch_num: 116\n","train_rmse_target: 0.0802 train_rmse_stderror: 0.04293 train_kl_div: 0.02077\n","val_rmse_target: 0.4972 val_rmse_stderror: 1.154\n","Still best_val_rmse: 0.4933 (from epoch 3)\n","\n","32 steps took 31.1 seconds\n","Epoch: 4 batch_num: 148\n","train_rmse_target: 0.08734 train_rmse_stderror: 0.0432 train_kl_div: 0.02299\n","val_rmse_target: 0.4968 val_rmse_stderror: 1.151\n","Still best_val_rmse: 0.4933 (from epoch 3)\n","\n","32 steps took 31.2 seconds\n","Epoch: 4 batch_num: 180\n","train_rmse_target: 0.1248 train_rmse_stderror: 0.03305 train_kl_div: 0.03259\n","val_rmse_target: 0.4963 val_rmse_stderror: 1.151\n","Still best_val_rmse: 0.4933 (from epoch 3)\n","\n","32 steps took 31.1 seconds\n","Epoch: 4 batch_num: 212\n","train_rmse_target: 0.07731 train_rmse_stderror: 0.03972 train_kl_div: 0.01857\n","val_rmse_target: 0.497 val_rmse_stderror: 1.151\n","Still best_val_rmse: 0.4933 (from epoch 3)\n","\n","32 steps took 31.1 seconds\n","Epoch: 4 batch_num: 244\n","train_rmse_target: 0.09686 train_rmse_stderror: 0.02517 train_kl_div: 0.02057\n","val_rmse_target: 0.497 val_rmse_stderror: 1.151\n","Still best_val_rmse: 0.4933 (from epoch 3)\n","\n","32 steps took 31.1 seconds\n","Epoch: 4 batch_num: 276\n","train_rmse_target: 0.1262 train_rmse_stderror: 0.05113 train_kl_div: 0.03962\n","val_rmse_target: 0.497 val_rmse_stderror: 1.151\n","Still best_val_rmse: 0.4933 (from epoch 3)\n","\n","Performance estimates:\n","[0.49326516850487867]\n","Mean: 0.49326516850487867\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 2/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 63.0 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.5768 train_rmse_stderror: 0.0939 train_kl_div: 0.7551\n","val_rmse_target: 0.6142 val_rmse_stderror: 1.759\n","New best_val_rmse: 0.6142\n","\n","64 steps took 62.3 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.5006 train_rmse_stderror: 0.1093 train_kl_div: 0.5146\n","val_rmse_target: 0.6226 val_rmse_stderror: 1.832\n","Still best_val_rmse: 0.6142 (from epoch 0)\n","\n","64 steps took 62.3 seconds\n","Epoch: 0 batch_num: 192\n","train_rmse_target: 0.5199 train_rmse_stderror: 0.04345 train_kl_div: 0.593\n","val_rmse_target: 0.5503 val_rmse_stderror: 1.767\n","New best_val_rmse: 0.5503\n","\n","64 steps took 62.3 seconds\n","Epoch: 0 batch_num: 256\n","train_rmse_target: 0.4426 train_rmse_stderror: 0.08354 train_kl_div: 0.4472\n","val_rmse_target: 0.5229 val_rmse_stderror: 1.835\n","New best_val_rmse: 0.5229\n","\n","32 steps took 31.3 seconds\n","Epoch: 1 batch_num: 5\n","train_rmse_target: 0.4521 train_rmse_stderror: 0.08932 train_kl_div: 0.3887\n","val_rmse_target: 0.5329 val_rmse_stderror: 1.785\n","Still best_val_rmse: 0.5229 (from epoch 0)\n","\n","32 steps took 31.1 seconds\n","Epoch: 1 batch_num: 37\n","train_rmse_target: 0.4304 train_rmse_stderror: 0.05832 train_kl_div: 0.3867\n","val_rmse_target: 0.5372 val_rmse_stderror: 1.812\n","Still best_val_rmse: 0.5229 (from epoch 0)\n","\n","32 steps took 31.2 seconds\n","Epoch: 1 batch_num: 69\n","train_rmse_target: 0.2131 train_rmse_stderror: 0.0657 train_kl_div: 0.114\n","val_rmse_target: 0.5227 val_rmse_stderror: 1.791\n","New best_val_rmse: 0.5227\n","\n","32 steps took 31.2 seconds\n","Epoch: 1 batch_num: 101\n","train_rmse_target: 0.4227 train_rmse_stderror: 0.0594 train_kl_div: 0.3921\n","val_rmse_target: 0.5043 val_rmse_stderror: 1.802\n","New best_val_rmse: 0.5043\n","\n","32 steps took 31.2 seconds\n","Epoch: 1 batch_num: 133\n","train_rmse_target: 0.3796 train_rmse_stderror: 0.1073 train_kl_div: 0.3556\n","val_rmse_target: 0.5 val_rmse_stderror: 1.773\n","New best_val_rmse: 0.5\n","\n","32 steps took 31.2 seconds\n","Epoch: 1 batch_num: 165\n","train_rmse_target: 0.3792 train_rmse_stderror: 0.05569 train_kl_div: 0.3132\n","val_rmse_target: 0.5125 val_rmse_stderror: 1.773\n","Still best_val_rmse: 0.5 (from epoch 1)\n","\n","32 steps took 31.1 seconds\n","Epoch: 1 batch_num: 197\n","train_rmse_target: 0.4241 train_rmse_stderror: 0.06425 train_kl_div: 0.3898\n","val_rmse_target: 0.4957 val_rmse_stderror: 1.826\n","New best_val_rmse: 0.4957\n","\n","32 steps took 31.1 seconds\n","Epoch: 1 batch_num: 229\n","train_rmse_target: 0.3506 train_rmse_stderror: 0.07532 train_kl_div: 0.2676\n","val_rmse_target: 0.5474 val_rmse_stderror: 1.819\n","Still best_val_rmse: 0.4957 (from epoch 1)\n","\n","32 steps took 31.1 seconds\n","Epoch: 1 batch_num: 261\n","train_rmse_target: 1.074 train_rmse_stderror: 0.05879 train_kl_div: 1.97\n","val_rmse_target: 1.041 val_rmse_stderror: 1.795\n","Still best_val_rmse: 0.4957 (from epoch 1)\n","\n","64 steps took 62.5 seconds\n","Epoch: 2 batch_num: 42\n","train_rmse_target: 1.02 train_rmse_stderror: 0.0698 train_kl_div: 1.973\n","val_rmse_target: 1.029 val_rmse_stderror: 1.79\n","Still best_val_rmse: 0.4957 (from epoch 1)\n","\n","64 steps took 62.3 seconds\n","Epoch: 2 batch_num: 106\n","train_rmse_target: 0.8971 train_rmse_stderror: 0.05039 train_kl_div: 1.669\n","val_rmse_target: 1.039 val_rmse_stderror: 1.799\n","Still best_val_rmse: 0.4957 (from epoch 1)\n","\n","64 steps took 62.3 seconds\n","Epoch: 2 batch_num: 170\n","train_rmse_target: 0.6305 train_rmse_stderror: 0.05486 train_kl_div: 0.8556\n","val_rmse_target: 1.025 val_rmse_stderror: 1.79\n","Still best_val_rmse: 0.4957 (from epoch 1)\n","\n","64 steps took 62.3 seconds\n","Epoch: 2 batch_num: 234\n","train_rmse_target: 0.7985 train_rmse_stderror: 0.05262 train_kl_div: 1.186\n","val_rmse_target: 1.022 val_rmse_stderror: 1.796\n","Still best_val_rmse: 0.4957 (from epoch 1)\n","\n","64 steps took 62.5 seconds\n","Epoch: 3 batch_num: 15\n","train_rmse_target: 1.101 train_rmse_stderror: 0.06242 train_kl_div: 2.438\n","val_rmse_target: 1.021 val_rmse_stderror: 1.805\n","Still best_val_rmse: 0.4957 (from epoch 1)\n","\n","64 steps took 62.3 seconds\n","Epoch: 3 batch_num: 79\n","train_rmse_target: 1.348 train_rmse_stderror: 0.06957 train_kl_div: 2.933\n","val_rmse_target: 1.019 val_rmse_stderror: 1.791\n","Still best_val_rmse: 0.4957 (from epoch 1)\n","\n","64 steps took 62.3 seconds\n","Epoch: 3 batch_num: 143\n","train_rmse_target: 0.8573 train_rmse_stderror: 0.02036 train_kl_div: 1.303\n","val_rmse_target: 1.018 val_rmse_stderror: 1.801\n","Still best_val_rmse: 0.4957 (from epoch 1)\n","\n","64 steps took 62.3 seconds\n","Epoch: 3 batch_num: 207\n","train_rmse_target: 1.258 train_rmse_stderror: 0.07251 train_kl_div: 2.493\n","val_rmse_target: 1.023 val_rmse_stderror: 1.793\n","Still best_val_rmse: 0.4957 (from epoch 1)\n","\n","64 steps took 62.3 seconds\n","Epoch: 3 batch_num: 271\n","train_rmse_target: 1.211 train_rmse_stderror: 0.05329 train_kl_div: 2.634\n","val_rmse_target: 1.017 val_rmse_stderror: 1.789\n","Still best_val_rmse: 0.4957 (from epoch 1)\n","\n","64 steps took 62.5 seconds\n","Epoch: 4 batch_num: 52\n","train_rmse_target: 0.7712 train_rmse_stderror: 0.0461 train_kl_div: 1.239\n","val_rmse_target: 1.018 val_rmse_stderror: 1.792\n","Still best_val_rmse: 0.4957 (from epoch 1)\n","\n","64 steps took 62.3 seconds\n","Epoch: 4 batch_num: 116\n","train_rmse_target: 0.9393 train_rmse_stderror: 0.06227 train_kl_div: 1.704\n","val_rmse_target: 1.02 val_rmse_stderror: 1.795\n","Still best_val_rmse: 0.4957 (from epoch 1)\n","\n","64 steps took 62.3 seconds\n","Epoch: 4 batch_num: 180\n","train_rmse_target: 1.097 train_rmse_stderror: 0.04999 train_kl_div: 2.108\n","val_rmse_target: 1.018 val_rmse_stderror: 1.793\n","Still best_val_rmse: 0.4957 (from epoch 1)\n","\n","64 steps took 62.3 seconds\n","Epoch: 4 batch_num: 244\n","train_rmse_target: 0.8599 train_rmse_stderror: 0.05117 train_kl_div: 1.492\n","val_rmse_target: 1.017 val_rmse_stderror: 1.793\n","Still best_val_rmse: 0.4957 (from epoch 1)\n","\n","Performance estimates:\n","[0.49326516850487867, 0.4956635460774873]\n","Mean: 0.494464357291183\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 3/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 63.0 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.5181 train_rmse_stderror: 0.1193 train_kl_div: 0.6488\n","val_rmse_target: 0.6591 val_rmse_stderror: 1.843\n","New best_val_rmse: 0.6591\n","\n","64 steps took 62.3 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.2809 train_rmse_stderror: 0.1073 train_kl_div: 0.2286\n","val_rmse_target: 0.5916 val_rmse_stderror: 1.755\n","New best_val_rmse: 0.5916\n","\n","64 steps took 62.3 seconds\n","Epoch: 0 batch_num: 192\n","train_rmse_target: 0.5968 train_rmse_stderror: 0.07338 train_kl_div: 0.7695\n","val_rmse_target: 0.5865 val_rmse_stderror: 1.778\n","New best_val_rmse: 0.5865\n","\n","64 steps took 62.4 seconds\n","Epoch: 0 batch_num: 256\n","train_rmse_target: 0.4606 train_rmse_stderror: 0.08485 train_kl_div: 0.4642\n","val_rmse_target: 0.5934 val_rmse_stderror: 1.793\n","Still best_val_rmse: 0.5865 (from epoch 0)\n","\n","64 steps took 62.5 seconds\n","Epoch: 1 batch_num: 37\n","train_rmse_target: 0.3621 train_rmse_stderror: 0.07902 train_kl_div: 0.3314\n","val_rmse_target: 0.5114 val_rmse_stderror: 1.769\n","New best_val_rmse: 0.5114\n","\n","32 steps took 31.2 seconds\n","Epoch: 1 batch_num: 69\n","train_rmse_target: 0.3848 train_rmse_stderror: 0.08173 train_kl_div: 0.3029\n","val_rmse_target: 0.5605 val_rmse_stderror: 1.776\n","Still best_val_rmse: 0.5114 (from epoch 1)\n","\n","64 steps took 62.3 seconds\n","Epoch: 1 batch_num: 133\n","train_rmse_target: 0.6037 train_rmse_stderror: 0.06173 train_kl_div: 0.8013\n","val_rmse_target: 0.5421 val_rmse_stderror: 1.76\n","Still best_val_rmse: 0.5114 (from epoch 1)\n","\n","32 steps took 31.2 seconds\n","Epoch: 1 batch_num: 165\n","train_rmse_target: 0.3504 train_rmse_stderror: 0.04416 train_kl_div: 0.272\n","val_rmse_target: 0.5367 val_rmse_stderror: 1.768\n","Still best_val_rmse: 0.5114 (from epoch 1)\n","\n","32 steps took 31.1 seconds\n","Epoch: 1 batch_num: 197\n","train_rmse_target: 0.1812 train_rmse_stderror: 0.0566 train_kl_div: 0.08776\n","val_rmse_target: 0.5288 val_rmse_stderror: 1.756\n","Still best_val_rmse: 0.5114 (from epoch 1)\n","\n","32 steps took 31.2 seconds\n","Epoch: 1 batch_num: 229\n","train_rmse_target: 0.4334 train_rmse_stderror: 0.08318 train_kl_div: 0.43\n","val_rmse_target: 0.5029 val_rmse_stderror: 1.762\n","New best_val_rmse: 0.5029\n","\n","32 steps took 31.1 seconds\n","Epoch: 1 batch_num: 261\n","train_rmse_target: 0.5212 train_rmse_stderror: 0.04531 train_kl_div: 0.5907\n","val_rmse_target: 0.5386 val_rmse_stderror: 1.744\n","Still best_val_rmse: 0.5029 (from epoch 1)\n","\n","32 steps took 31.3 seconds\n","Epoch: 2 batch_num: 10\n","train_rmse_target: 0.236 train_rmse_stderror: 0.07298 train_kl_div: 0.1393\n","val_rmse_target: 0.4956 val_rmse_stderror: 1.769\n","New best_val_rmse: 0.4956\n","\n","32 steps took 31.2 seconds\n","Epoch: 2 batch_num: 42\n","train_rmse_target: 0.3007 train_rmse_stderror: 0.1119 train_kl_div: 0.2282\n","val_rmse_target: 0.4776 val_rmse_stderror: 1.783\n","New best_val_rmse: 0.4776\n","\n","32 steps took 31.2 seconds\n","Epoch: 2 batch_num: 74\n","train_rmse_target: 0.3356 train_rmse_stderror: 0.03776 train_kl_div: 0.2123\n","val_rmse_target: 0.5027 val_rmse_stderror: 1.778\n","Still best_val_rmse: 0.4776 (from epoch 2)\n","\n","32 steps took 31.1 seconds\n","Epoch: 2 batch_num: 106\n","train_rmse_target: 0.3083 train_rmse_stderror: 0.09554 train_kl_div: 0.1825\n","val_rmse_target: 0.4771 val_rmse_stderror: 1.766\n","New best_val_rmse: 0.4771\n","\n","32 steps took 31.2 seconds\n","Epoch: 2 batch_num: 138\n","train_rmse_target: 0.362 train_rmse_stderror: 0.06339 train_kl_div: 0.3083\n","val_rmse_target: 0.4876 val_rmse_stderror: 1.771\n","Still best_val_rmse: 0.4771 (from epoch 2)\n","\n","32 steps took 31.1 seconds\n","Epoch: 2 batch_num: 170\n","train_rmse_target: 0.1355 train_rmse_stderror: 0.0376 train_kl_div: 0.04169\n","val_rmse_target: 0.4771 val_rmse_stderror: 1.781\n","Still best_val_rmse: 0.4771 (from epoch 2)\n","\n","32 steps took 31.1 seconds\n","Epoch: 2 batch_num: 202\n","train_rmse_target: 0.2356 train_rmse_stderror: 0.0701 train_kl_div: 0.1296\n","val_rmse_target: 0.4721 val_rmse_stderror: 1.776\n","New best_val_rmse: 0.4721\n","\n","32 steps took 31.1 seconds\n","Epoch: 2 batch_num: 234\n","train_rmse_target: 0.221 train_rmse_stderror: 0.03436 train_kl_div: 0.1022\n","val_rmse_target: 0.4764 val_rmse_stderror: 1.749\n","Still best_val_rmse: 0.4721 (from epoch 2)\n","\n","32 steps took 31.1 seconds\n","Epoch: 2 batch_num: 266\n","train_rmse_target: 0.2743 train_rmse_stderror: 0.0578 train_kl_div: 0.1793\n","val_rmse_target: 0.4725 val_rmse_stderror: 1.777\n","Still best_val_rmse: 0.4721 (from epoch 2)\n","\n","32 steps took 31.3 seconds\n","Epoch: 3 batch_num: 15\n","train_rmse_target: 0.1122 train_rmse_stderror: 0.04009 train_kl_div: 0.03288\n","val_rmse_target: 0.4826 val_rmse_stderror: 1.774\n","Still best_val_rmse: 0.4721 (from epoch 2)\n","\n","32 steps took 31.2 seconds\n","Epoch: 3 batch_num: 47\n","train_rmse_target: 0.0675 train_rmse_stderror: 0.0369 train_kl_div: 0.01431\n","val_rmse_target: 0.477 val_rmse_stderror: 1.764\n","Still best_val_rmse: 0.4721 (from epoch 2)\n","\n","32 steps took 31.1 seconds\n","Epoch: 3 batch_num: 79\n","train_rmse_target: 0.05488 train_rmse_stderror: 0.02938 train_kl_div: 0.01027\n","val_rmse_target: 0.4813 val_rmse_stderror: 1.762\n","Still best_val_rmse: 0.4721 (from epoch 2)\n","\n","32 steps took 31.1 seconds\n","Epoch: 3 batch_num: 111\n","train_rmse_target: 0.1728 train_rmse_stderror: 0.0597 train_kl_div: 0.05302\n","val_rmse_target: 0.4719 val_rmse_stderror: 1.763\n","New best_val_rmse: 0.4719\n","\n","32 steps took 31.1 seconds\n","Epoch: 3 batch_num: 143\n","train_rmse_target: 0.09528 train_rmse_stderror: 0.04585 train_kl_div: 0.02665\n","val_rmse_target: 0.4814 val_rmse_stderror: 1.756\n","Still best_val_rmse: 0.4719 (from epoch 3)\n","\n","32 steps took 31.1 seconds\n","Epoch: 3 batch_num: 175\n","train_rmse_target: 0.2 train_rmse_stderror: 0.05175 train_kl_div: 0.08105\n","val_rmse_target: 0.47 val_rmse_stderror: 1.752\n","New best_val_rmse: 0.47\n","\n","32 steps took 31.2 seconds\n","Epoch: 3 batch_num: 207\n","train_rmse_target: 0.08809 train_rmse_stderror: 0.06482 train_kl_div: 0.03371\n","val_rmse_target: 0.4702 val_rmse_stderror: 1.767\n","Still best_val_rmse: 0.47 (from epoch 3)\n","\n","32 steps took 31.1 seconds\n","Epoch: 3 batch_num: 239\n","train_rmse_target: 0.1395 train_rmse_stderror: 0.04249 train_kl_div: 0.04286\n","val_rmse_target: 0.4737 val_rmse_stderror: 1.755\n","Still best_val_rmse: 0.47 (from epoch 3)\n","\n","32 steps took 31.1 seconds\n","Epoch: 3 batch_num: 271\n","train_rmse_target: 0.1278 train_rmse_stderror: 0.04078 train_kl_div: 0.04383\n","val_rmse_target: 0.4747 val_rmse_stderror: 1.754\n","Still best_val_rmse: 0.47 (from epoch 3)\n","\n","32 steps took 31.3 seconds\n","Epoch: 4 batch_num: 20\n","train_rmse_target: 0.1108 train_rmse_stderror: 0.03938 train_kl_div: 0.03243\n","val_rmse_target: 0.4757 val_rmse_stderror: 1.753\n","Still best_val_rmse: 0.47 (from epoch 3)\n","\n","32 steps took 31.1 seconds\n","Epoch: 4 batch_num: 52\n","train_rmse_target: 0.1587 train_rmse_stderror: 0.06051 train_kl_div: 0.07508\n","val_rmse_target: 0.4767 val_rmse_stderror: 1.766\n","Still best_val_rmse: 0.47 (from epoch 3)\n","\n","32 steps took 31.1 seconds\n","Epoch: 4 batch_num: 84\n","train_rmse_target: 0.08907 train_rmse_stderror: 0.04133 train_kl_div: 0.02378\n","val_rmse_target: 0.4745 val_rmse_stderror: 1.763\n","Still best_val_rmse: 0.47 (from epoch 3)\n","\n","32 steps took 31.1 seconds\n","Epoch: 4 batch_num: 116\n","train_rmse_target: 0.07422 train_rmse_stderror: 0.03762 train_kl_div: 0.0185\n","val_rmse_target: 0.4724 val_rmse_stderror: 1.762\n","Still best_val_rmse: 0.47 (from epoch 3)\n","\n","32 steps took 31.1 seconds\n","Epoch: 4 batch_num: 148\n","train_rmse_target: 0.06992 train_rmse_stderror: 0.03498 train_kl_div: 0.01506\n","val_rmse_target: 0.4739 val_rmse_stderror: 1.762\n","Still best_val_rmse: 0.47 (from epoch 3)\n","\n","32 steps took 31.2 seconds\n","Epoch: 4 batch_num: 180\n","train_rmse_target: 0.07774 train_rmse_stderror: 0.02108 train_kl_div: 0.01365\n","val_rmse_target: 0.4734 val_rmse_stderror: 1.765\n","Still best_val_rmse: 0.47 (from epoch 3)\n","\n","32 steps took 31.1 seconds\n","Epoch: 4 batch_num: 212\n","train_rmse_target: 0.07831 train_rmse_stderror: 0.03235 train_kl_div: 0.01819\n","val_rmse_target: 0.4725 val_rmse_stderror: 1.764\n","Still best_val_rmse: 0.47 (from epoch 3)\n","\n","32 steps took 31.1 seconds\n","Epoch: 4 batch_num: 244\n","train_rmse_target: 0.1831 train_rmse_stderror: 0.03205 train_kl_div: 0.04572\n","val_rmse_target: 0.4725 val_rmse_stderror: 1.763\n","Still best_val_rmse: 0.47 (from epoch 3)\n","\n","32 steps took 31.2 seconds\n","Epoch: 4 batch_num: 276\n","train_rmse_target: 0.06147 train_rmse_stderror: 0.03984 train_kl_div: 0.0129\n","val_rmse_target: 0.4725 val_rmse_stderror: 1.763\n","Still best_val_rmse: 0.47 (from epoch 3)\n","\n","Performance estimates:\n","[0.49326516850487867, 0.4956635460774873, 0.46999458461486887]\n","Mean: 0.4863077663990783\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 4/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 63.0 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.4826 train_rmse_stderror: 0.07081 train_kl_div: 0.4872\n","val_rmse_target: 0.6624 val_rmse_stderror: 1.747\n","New best_val_rmse: 0.6624\n","\n","64 steps took 62.3 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.8685 train_rmse_stderror: 0.09114 train_kl_div: 1.478\n","val_rmse_target: 0.7096 val_rmse_stderror: 1.751\n","Still best_val_rmse: 0.6624 (from epoch 0)\n","\n","64 steps took 62.3 seconds\n","Epoch: 0 batch_num: 192\n","train_rmse_target: 0.8036 train_rmse_stderror: 0.04996 train_kl_div: 1.405\n","val_rmse_target: 0.5994 val_rmse_stderror: 1.764\n","New best_val_rmse: 0.5994\n","\n","64 steps took 62.3 seconds\n","Epoch: 0 batch_num: 256\n","train_rmse_target: 0.5249 train_rmse_stderror: 0.04096 train_kl_div: 0.5826\n","val_rmse_target: 0.5123 val_rmse_stderror: 1.781\n","New best_val_rmse: 0.5123\n","\n","32 steps took 31.3 seconds\n","Epoch: 1 batch_num: 5\n","train_rmse_target: 0.5954 train_rmse_stderror: 0.05017 train_kl_div: 0.6327\n","val_rmse_target: 0.5511 val_rmse_stderror: 1.771\n","Still best_val_rmse: 0.5123 (from epoch 0)\n","\n","64 steps took 62.3 seconds\n","Epoch: 1 batch_num: 69\n","train_rmse_target: 0.2703 train_rmse_stderror: 0.08108 train_kl_div: 0.1959\n","val_rmse_target: 0.6167 val_rmse_stderror: 1.791\n","Still best_val_rmse: 0.5123 (from epoch 0)\n","\n","64 steps took 62.3 seconds\n","Epoch: 1 batch_num: 133\n","train_rmse_target: 0.2916 train_rmse_stderror: 0.02682 train_kl_div: 0.1867\n","val_rmse_target: 0.5127 val_rmse_stderror: 1.758\n","Still best_val_rmse: 0.5123 (from epoch 0)\n","\n","32 steps took 31.2 seconds\n","Epoch: 1 batch_num: 165\n","train_rmse_target: 0.6359 train_rmse_stderror: 0.05779 train_kl_div: 0.8181\n","val_rmse_target: 0.5862 val_rmse_stderror: 1.763\n","Still best_val_rmse: 0.5123 (from epoch 0)\n","\n","64 steps took 62.3 seconds\n","Epoch: 1 batch_num: 229\n","train_rmse_target: 0.5683 train_rmse_stderror: 0.02538 train_kl_div: 0.6778\n","val_rmse_target: 0.5521 val_rmse_stderror: 1.773\n","Still best_val_rmse: 0.5123 (from epoch 0)\n","\n","64 steps took 62.5 seconds\n","Epoch: 2 batch_num: 10\n","train_rmse_target: 0.4633 train_rmse_stderror: 0.03887 train_kl_div: 0.447\n","val_rmse_target: 0.4803 val_rmse_stderror: 1.767\n","New best_val_rmse: 0.4803\n","\n","32 steps took 31.2 seconds\n","Epoch: 2 batch_num: 42\n","train_rmse_target: 0.2383 train_rmse_stderror: 0.04102 train_kl_div: 0.1197\n","val_rmse_target: 0.4867 val_rmse_stderror: 1.756\n","Still best_val_rmse: 0.4803 (from epoch 2)\n","\n","32 steps took 31.1 seconds\n","Epoch: 2 batch_num: 74\n","train_rmse_target: 0.3705 train_rmse_stderror: 0.04685 train_kl_div: 0.2926\n","val_rmse_target: 0.5625 val_rmse_stderror: 1.765\n","Still best_val_rmse: 0.4803 (from epoch 2)\n","\n","64 steps took 62.3 seconds\n","Epoch: 2 batch_num: 138\n","train_rmse_target: 0.2494 train_rmse_stderror: 0.03367 train_kl_div: 0.1371\n","val_rmse_target: 0.5017 val_rmse_stderror: 1.78\n","Still best_val_rmse: 0.4803 (from epoch 2)\n","\n","32 steps took 31.1 seconds\n","Epoch: 2 batch_num: 170\n","train_rmse_target: 0.356 train_rmse_stderror: 0.03252 train_kl_div: 0.2782\n","val_rmse_target: 0.4846 val_rmse_stderror: 1.768\n","Still best_val_rmse: 0.4803 (from epoch 2)\n","\n","32 steps took 31.1 seconds\n","Epoch: 2 batch_num: 202\n","train_rmse_target: 0.374 train_rmse_stderror: 0.03236 train_kl_div: 0.3352\n","val_rmse_target: 0.5122 val_rmse_stderror: 1.766\n","Still best_val_rmse: 0.4803 (from epoch 2)\n","\n","32 steps took 31.2 seconds\n","Epoch: 2 batch_num: 234\n","train_rmse_target: 0.4211 train_rmse_stderror: 0.03545 train_kl_div: 0.3645\n","val_rmse_target: 0.4841 val_rmse_stderror: 1.768\n","Still best_val_rmse: 0.4803 (from epoch 2)\n","\n","32 steps took 31.1 seconds\n","Epoch: 2 batch_num: 266\n","train_rmse_target: 0.22 train_rmse_stderror: 0.05246 train_kl_div: 0.1223\n","val_rmse_target: 0.4885 val_rmse_stderror: 1.76\n","Still best_val_rmse: 0.4803 (from epoch 2)\n","\n","32 steps took 31.4 seconds\n","Epoch: 3 batch_num: 15\n","train_rmse_target: 0.2197 train_rmse_stderror: 0.04913 train_kl_div: 0.1207\n","val_rmse_target: 0.4935 val_rmse_stderror: 1.758\n","Still best_val_rmse: 0.4803 (from epoch 2)\n","\n","32 steps took 31.1 seconds\n","Epoch: 3 batch_num: 47\n","train_rmse_target: 0.3033 train_rmse_stderror: 0.02551 train_kl_div: 0.1638\n","val_rmse_target: 0.4882 val_rmse_stderror: 1.753\n","Still best_val_rmse: 0.4803 (from epoch 2)\n","\n","32 steps took 31.1 seconds\n","Epoch: 3 batch_num: 79\n","train_rmse_target: 0.1683 train_rmse_stderror: 0.02962 train_kl_div: 0.06535\n","val_rmse_target: 0.4963 val_rmse_stderror: 1.773\n","Still best_val_rmse: 0.4803 (from epoch 2)\n","\n","32 steps took 31.1 seconds\n","Epoch: 3 batch_num: 111\n","train_rmse_target: 0.1251 train_rmse_stderror: 0.02794 train_kl_div: 0.03732\n","val_rmse_target: 0.4882 val_rmse_stderror: 1.769\n","Still best_val_rmse: 0.4803 (from epoch 2)\n","\n","32 steps took 31.2 seconds\n","Epoch: 3 batch_num: 143\n","train_rmse_target: 0.1669 train_rmse_stderror: 0.02997 train_kl_div: 0.05555\n","val_rmse_target: 0.4801 val_rmse_stderror: 1.765\n","New best_val_rmse: 0.4801\n","\n","32 steps took 31.2 seconds\n","Epoch: 3 batch_num: 175\n","train_rmse_target: 0.2919 train_rmse_stderror: 0.05252 train_kl_div: 0.1495\n","val_rmse_target: 0.4862 val_rmse_stderror: 1.761\n","Still best_val_rmse: 0.4801 (from epoch 3)\n","\n","32 steps took 31.1 seconds\n","Epoch: 3 batch_num: 207\n","train_rmse_target: 0.1844 train_rmse_stderror: 0.04413 train_kl_div: 0.06897\n","val_rmse_target: 0.4873 val_rmse_stderror: 1.761\n","Still best_val_rmse: 0.4801 (from epoch 3)\n","\n","32 steps took 31.1 seconds\n","Epoch: 3 batch_num: 239\n","train_rmse_target: 0.18 train_rmse_stderror: 0.03792 train_kl_div: 0.06064\n","val_rmse_target: 0.4805 val_rmse_stderror: 1.769\n","Still best_val_rmse: 0.4801 (from epoch 3)\n","\n","32 steps took 31.1 seconds\n","Epoch: 3 batch_num: 271\n","train_rmse_target: 0.2125 train_rmse_stderror: 0.04071 train_kl_div: 0.08751\n","val_rmse_target: 0.4817 val_rmse_stderror: 1.756\n","Still best_val_rmse: 0.4801 (from epoch 3)\n","\n","32 steps took 31.4 seconds\n","Epoch: 4 batch_num: 20\n","train_rmse_target: 0.2018 train_rmse_stderror: 0.06482 train_kl_div: 0.083\n","val_rmse_target: 0.4873 val_rmse_stderror: 1.753\n","Still best_val_rmse: 0.4801 (from epoch 3)\n","\n","32 steps took 31.2 seconds\n","Epoch: 4 batch_num: 52\n","train_rmse_target: 0.1513 train_rmse_stderror: 0.0319 train_kl_div: 0.04007\n","val_rmse_target: 0.485 val_rmse_stderror: 1.764\n","Still best_val_rmse: 0.4801 (from epoch 3)\n","\n","32 steps took 31.1 seconds\n","Epoch: 4 batch_num: 84\n","train_rmse_target: 0.1339 train_rmse_stderror: 0.02965 train_kl_div: 0.04196\n","val_rmse_target: 0.4831 val_rmse_stderror: 1.763\n","Still best_val_rmse: 0.4801 (from epoch 3)\n","\n","32 steps took 31.1 seconds\n","Epoch: 4 batch_num: 116\n","train_rmse_target: 0.1988 train_rmse_stderror: 0.02788 train_kl_div: 0.07397\n","val_rmse_target: 0.4791 val_rmse_stderror: 1.764\n","New best_val_rmse: 0.4791\n","\n","32 steps took 31.2 seconds\n","Epoch: 4 batch_num: 148\n","train_rmse_target: 0.07769 train_rmse_stderror: 0.02275 train_kl_div: 0.01611\n","val_rmse_target: 0.4813 val_rmse_stderror: 1.763\n","Still best_val_rmse: 0.4791 (from epoch 4)\n","\n","32 steps took 31.1 seconds\n","Epoch: 4 batch_num: 180\n","train_rmse_target: 0.07857 train_rmse_stderror: 0.04436 train_kl_div: 0.01883\n","val_rmse_target: 0.4823 val_rmse_stderror: 1.76\n","Still best_val_rmse: 0.4791 (from epoch 4)\n","\n","32 steps took 31.1 seconds\n","Epoch: 4 batch_num: 212\n","train_rmse_target: 0.1362 train_rmse_stderror: 0.02648 train_kl_div: 0.04417\n","val_rmse_target: 0.4829 val_rmse_stderror: 1.763\n","Still best_val_rmse: 0.4791 (from epoch 4)\n","\n","32 steps took 31.1 seconds\n","Epoch: 4 batch_num: 244\n","train_rmse_target: 0.1741 train_rmse_stderror: 0.02356 train_kl_div: 0.05249\n","val_rmse_target: 0.4824 val_rmse_stderror: 1.764\n","Still best_val_rmse: 0.4791 (from epoch 4)\n","\n","32 steps took 31.1 seconds\n","Epoch: 4 batch_num: 276\n","train_rmse_target: 0.1987 train_rmse_stderror: 0.02403 train_kl_div: 0.07135\n","val_rmse_target: 0.4821 val_rmse_stderror: 1.764\n","Still best_val_rmse: 0.4791 (from epoch 4)\n","\n","Performance estimates:\n","[0.49326516850487867, 0.4956635460774873, 0.46999458461486887, 0.4791137372851385]\n","Mean: 0.4845092591205934\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 5/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 63.0 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.6596 train_rmse_stderror: 0.09075 train_kl_div: 0.8343\n","val_rmse_target: 0.6192 val_rmse_stderror: 1.818\n","New best_val_rmse: 0.6192\n","\n","64 steps took 62.3 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.4754 train_rmse_stderror: 0.1144 train_kl_div: 0.5214\n","val_rmse_target: 0.5743 val_rmse_stderror: 1.854\n","New best_val_rmse: 0.5743\n","\n","64 steps took 62.3 seconds\n","Epoch: 0 batch_num: 192\n","train_rmse_target: 0.5386 train_rmse_stderror: 0.06016 train_kl_div: 0.5953\n","val_rmse_target: 0.5369 val_rmse_stderror: 1.842\n","New best_val_rmse: 0.5369\n","\n","32 steps took 31.2 seconds\n","Epoch: 0 batch_num: 224\n","train_rmse_target: 0.4075 train_rmse_stderror: 0.07303 train_kl_div: 0.4009\n","val_rmse_target: 0.5562 val_rmse_stderror: 1.788\n","Still best_val_rmse: 0.5369 (from epoch 0)\n","\n","64 steps took 62.5 seconds\n","Epoch: 1 batch_num: 5\n","train_rmse_target: 0.2914 train_rmse_stderror: 0.07295 train_kl_div: 0.211\n","val_rmse_target: 0.5279 val_rmse_stderror: 1.808\n","New best_val_rmse: 0.5279\n","\n","32 steps took 31.1 seconds\n","Epoch: 1 batch_num: 37\n","train_rmse_target: 0.4443 train_rmse_stderror: 0.05383 train_kl_div: 0.4349\n","val_rmse_target: 0.5269 val_rmse_stderror: 1.779\n","New best_val_rmse: 0.5269\n","\n","32 steps took 31.2 seconds\n","Epoch: 1 batch_num: 69\n","train_rmse_target: 0.3422 train_rmse_stderror: 0.1191 train_kl_div: 0.3031\n","val_rmse_target: 0.5535 val_rmse_stderror: 1.858\n","Still best_val_rmse: 0.5269 (from epoch 1)\n","\n","64 steps took 62.3 seconds\n","Epoch: 1 batch_num: 133\n","train_rmse_target: 0.2394 train_rmse_stderror: 0.05521 train_kl_div: 0.1293\n","val_rmse_target: 0.5016 val_rmse_stderror: 1.77\n","New best_val_rmse: 0.5016\n","\n","32 steps took 31.2 seconds\n","Epoch: 1 batch_num: 165\n","train_rmse_target: 0.2603 train_rmse_stderror: 0.05529 train_kl_div: 0.1558\n","val_rmse_target: 0.5446 val_rmse_stderror: 1.796\n","Still best_val_rmse: 0.5016 (from epoch 1)\n","\n","32 steps took 31.1 seconds\n","Epoch: 1 batch_num: 197\n","train_rmse_target: 0.5388 train_rmse_stderror: 0.07459 train_kl_div: 0.6794\n","val_rmse_target: 0.5497 val_rmse_stderror: 1.772\n","Still best_val_rmse: 0.5016 (from epoch 1)\n","\n","32 steps took 31.1 seconds\n","Epoch: 1 batch_num: 229\n","train_rmse_target: 0.4611 train_rmse_stderror: 0.06287 train_kl_div: 0.4198\n","val_rmse_target: 0.5274 val_rmse_stderror: 1.785\n","Still best_val_rmse: 0.5016 (from epoch 1)\n","\n","32 steps took 31.1 seconds\n","Epoch: 1 batch_num: 261\n","train_rmse_target: 0.4861 train_rmse_stderror: 0.06169 train_kl_div: 0.5371\n","val_rmse_target: 0.5578 val_rmse_stderror: 1.8\n","Still best_val_rmse: 0.5016 (from epoch 1)\n","\n","64 steps took 62.5 seconds\n","Epoch: 2 batch_num: 42\n","train_rmse_target: 0.3456 train_rmse_stderror: 0.05181 train_kl_div: 0.2657\n","val_rmse_target: 0.4929 val_rmse_stderror: 1.787\n","New best_val_rmse: 0.4929\n","\n","32 steps took 31.2 seconds\n","Epoch: 2 batch_num: 74\n","train_rmse_target: 0.2482 train_rmse_stderror: 0.06455 train_kl_div: 0.1535\n","val_rmse_target: 0.5301 val_rmse_stderror: 1.771\n","Still best_val_rmse: 0.4929 (from epoch 2)\n","\n","32 steps took 31.1 seconds\n","Epoch: 2 batch_num: 106\n","train_rmse_target: 0.252 train_rmse_stderror: 0.03897 train_kl_div: 0.1336\n","val_rmse_target: 0.4967 val_rmse_stderror: 1.805\n","Still best_val_rmse: 0.4929 (from epoch 2)\n","\n","32 steps took 31.1 seconds\n","Epoch: 2 batch_num: 138\n","train_rmse_target: 0.2879 train_rmse_stderror: 0.06965 train_kl_div: 0.1777\n","val_rmse_target: 0.5067 val_rmse_stderror: 1.799\n","Still best_val_rmse: 0.4929 (from epoch 2)\n","\n","32 steps took 31.1 seconds\n","Epoch: 2 batch_num: 170\n","train_rmse_target: 0.2287 train_rmse_stderror: 0.06199 train_kl_div: 0.1105\n","val_rmse_target: 0.5132 val_rmse_stderror: 1.795\n","Still best_val_rmse: 0.4929 (from epoch 2)\n","\n","32 steps took 31.1 seconds\n","Epoch: 2 batch_num: 202\n","train_rmse_target: 0.3122 train_rmse_stderror: 0.03847 train_kl_div: 0.2017\n","val_rmse_target: 0.4919 val_rmse_stderror: 1.825\n","New best_val_rmse: 0.4919\n","\n","32 steps took 31.2 seconds\n","Epoch: 2 batch_num: 234\n","train_rmse_target: 0.3573 train_rmse_stderror: 0.04725 train_kl_div: 0.2317\n","val_rmse_target: 0.5199 val_rmse_stderror: 1.785\n","Still best_val_rmse: 0.4919 (from epoch 2)\n","\n","32 steps took 31.1 seconds\n","Epoch: 2 batch_num: 266\n","train_rmse_target: 0.3235 train_rmse_stderror: 0.06547 train_kl_div: 0.255\n","val_rmse_target: 0.5411 val_rmse_stderror: 1.801\n","Still best_val_rmse: 0.4919 (from epoch 2)\n","\n","32 steps took 31.3 seconds\n","Epoch: 3 batch_num: 15\n","train_rmse_target: 0.1477 train_rmse_stderror: 0.04266 train_kl_div: 0.04593\n","val_rmse_target: 0.5065 val_rmse_stderror: 1.815\n","Still best_val_rmse: 0.4919 (from epoch 2)\n","\n","32 steps took 31.1 seconds\n","Epoch: 3 batch_num: 47\n","train_rmse_target: 0.1553 train_rmse_stderror: 0.0223 train_kl_div: 0.04281\n","val_rmse_target: 0.481 val_rmse_stderror: 1.799\n","New best_val_rmse: 0.481\n","\n","32 steps took 31.2 seconds\n","Epoch: 3 batch_num: 79\n","train_rmse_target: 0.1223 train_rmse_stderror: 0.03463 train_kl_div: 0.03743\n","val_rmse_target: 0.4904 val_rmse_stderror: 1.822\n","Still best_val_rmse: 0.481 (from epoch 3)\n","\n","32 steps took 31.1 seconds\n","Epoch: 3 batch_num: 111\n","train_rmse_target: 0.1372 train_rmse_stderror: 0.04903 train_kl_div: 0.05032\n","val_rmse_target: 0.4841 val_rmse_stderror: 1.802\n","Still best_val_rmse: 0.481 (from epoch 3)\n","\n","32 steps took 31.1 seconds\n","Epoch: 3 batch_num: 143\n","train_rmse_target: 0.09491 train_rmse_stderror: 0.03956 train_kl_div: 0.02504\n","val_rmse_target: 0.4843 val_rmse_stderror: 1.793\n","Still best_val_rmse: 0.481 (from epoch 3)\n","\n","32 steps took 31.1 seconds\n","Epoch: 3 batch_num: 175\n","train_rmse_target: 0.1594 train_rmse_stderror: 0.0419 train_kl_div: 0.04515\n","val_rmse_target: 0.488 val_rmse_stderror: 1.805\n","Still best_val_rmse: 0.481 (from epoch 3)\n","\n","32 steps took 31.1 seconds\n","Epoch: 3 batch_num: 207\n","train_rmse_target: 0.1091 train_rmse_stderror: 0.04969 train_kl_div: 0.03418\n","val_rmse_target: 0.4865 val_rmse_stderror: 1.807\n","Still best_val_rmse: 0.481 (from epoch 3)\n","\n","32 steps took 31.1 seconds\n","Epoch: 3 batch_num: 239\n","train_rmse_target: 0.1686 train_rmse_stderror: 0.04176 train_kl_div: 0.0486\n","val_rmse_target: 0.4904 val_rmse_stderror: 1.806\n","Still best_val_rmse: 0.481 (from epoch 3)\n","\n","32 steps took 31.2 seconds\n","Epoch: 3 batch_num: 271\n","train_rmse_target: 0.09548 train_rmse_stderror: 0.04826 train_kl_div: 0.02928\n","val_rmse_target: 0.4848 val_rmse_stderror: 1.802\n","Still best_val_rmse: 0.481 (from epoch 3)\n","\n","32 steps took 31.3 seconds\n","Epoch: 4 batch_num: 20\n","train_rmse_target: 0.06775 train_rmse_stderror: 0.02811 train_kl_div: 0.009744\n","val_rmse_target: 0.4893 val_rmse_stderror: 1.801\n","Still best_val_rmse: 0.481 (from epoch 3)\n","\n","32 steps took 31.2 seconds\n","Epoch: 4 batch_num: 52\n","train_rmse_target: 0.1175 train_rmse_stderror: 0.03339 train_kl_div: 0.03195\n","val_rmse_target: 0.4888 val_rmse_stderror: 1.798\n","Still best_val_rmse: 0.481 (from epoch 3)\n","\n","32 steps took 31.1 seconds\n","Epoch: 4 batch_num: 84\n","train_rmse_target: 0.07276 train_rmse_stderror: 0.04212 train_kl_div: 0.01787\n","val_rmse_target: 0.4873 val_rmse_stderror: 1.793\n","Still best_val_rmse: 0.481 (from epoch 3)\n","\n","32 steps took 31.1 seconds\n","Epoch: 4 batch_num: 116\n","train_rmse_target: 0.1114 train_rmse_stderror: 0.04372 train_kl_div: 0.03098\n","val_rmse_target: 0.4893 val_rmse_stderror: 1.796\n","Still best_val_rmse: 0.481 (from epoch 3)\n","\n","32 steps took 31.1 seconds\n","Epoch: 4 batch_num: 148\n","train_rmse_target: 0.07911 train_rmse_stderror: 0.03694 train_kl_div: 0.01603\n","val_rmse_target: 0.4844 val_rmse_stderror: 1.802\n","Still best_val_rmse: 0.481 (from epoch 3)\n","\n","32 steps took 31.2 seconds\n","Epoch: 4 batch_num: 180\n","train_rmse_target: 0.06005 train_rmse_stderror: 0.03562 train_kl_div: 0.0121\n","val_rmse_target: 0.4868 val_rmse_stderror: 1.799\n","Still best_val_rmse: 0.481 (from epoch 3)\n","\n","32 steps took 31.1 seconds\n","Epoch: 4 batch_num: 212\n","train_rmse_target: 0.08994 train_rmse_stderror: 0.02093 train_kl_div: 0.01653\n","val_rmse_target: 0.4867 val_rmse_stderror: 1.798\n","Still best_val_rmse: 0.481 (from epoch 3)\n","\n","32 steps took 31.1 seconds\n","Epoch: 4 batch_num: 244\n","train_rmse_target: 0.05037 train_rmse_stderror: 0.03651 train_kl_div: 0.01052\n","val_rmse_target: 0.4863 val_rmse_stderror: 1.797\n","Still best_val_rmse: 0.481 (from epoch 3)\n","\n","32 steps took 31.2 seconds\n","Epoch: 4 batch_num: 276\n","train_rmse_target: 0.1467 train_rmse_stderror: 0.05802 train_kl_div: 0.04245\n","val_rmse_target: 0.4864 val_rmse_stderror: 1.797\n","Still best_val_rmse: 0.481 (from epoch 3)\n","\n","Performance estimates:\n","[0.49326516850487867, 0.4956635460774873, 0.46999458461486887, 0.4791137372851385, 0.481027933754232]\n","Mean: 0.4838129940473211\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"m4v-cGx-Mv7S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627704999856,"user_tz":-540,"elapsed":17,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"b17a4655-0a24-42dd-ea3f-5991a775bec7"},"source":["print(list_val_rmse)"],"execution_count":30,"outputs":[{"output_type":"stream","text":["[0.49326516850487867, 0.4956635460774873, 0.46999458461486887, 0.4791137372851385, 0.481027933754232]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XU4gRXHCBEpC","executionInfo":{"status":"ok","timestamp":1627705001004,"user_tz":-540,"elapsed":1155,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"iAb99KSKBEmd","executionInfo":{"status":"ok","timestamp":1627705001008,"user_tz":-540,"elapsed":18,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"jH0aFzWxBEkG","executionInfo":{"status":"ok","timestamp":1627705001008,"user_tz":-540,"elapsed":17,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"q2CdCMuIKDMP","executionInfo":{"status":"ok","timestamp":1627705001009,"user_tz":-540,"elapsed":17,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#rep = MemReporter(model)\n","#rep.report()"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"eLl1yDOOKIe7","executionInfo":{"status":"ok","timestamp":1627705001009,"user_tz":-540,"elapsed":16,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#rep = MemReporter(model.roberta)\n","#rep.report()"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"7qkqnknA_m9D","executionInfo":{"status":"ok","timestamp":1627705001010,"user_tz":-540,"elapsed":16,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#gpuinfo()"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"PwrqSMdYA6Pu","executionInfo":{"status":"ok","timestamp":1627705001010,"user_tz":-540,"elapsed":15,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#del model\n","#del optimizer \n","#del train_loader\n","#del val_loader\n","#del scheduler \n","#del list_val_rmse\n","#del train_indices\n","#del val_indices\n","#del tokenizer\n","#torch.cuda.empty_cache()\n","#gpuinfo()"],"execution_count":34,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wXcHyUSJXecL"},"source":["# upload models"]},{"cell_type":"code","metadata":{"id":"YIV6UllSIGoa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627705115598,"user_tz":-540,"elapsed":114603,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"5fa51962-8ea7-40d3-fc3b-33a8a9f2499b"},"source":["%cd\n","!mkdir .kaggle\n","!mkdir /content/model\n","!cp /content/drive/MyDrive/Colab_Files/kaggle-api/kaggle.json .kaggle/\n","\n","!cp -r /content/model_1.pth /content/model/model_1.pth\n","!cp -r /content/model_2.pth /content/model/model_2.pth\n","!cp -r /content/model_3.pth /content/model/model_3.pth\n","!cp -r /content/model_4.pth /content/model/model_4.pth\n","!cp -r /content/model_5.pth /content/model/model_5.pth\n","!cp -r /content/TFIDF_1.pkl /content/model/TFIDF_1.pkl\n","!cp -r /content/TFIDF_2.pkl /content/model/TFIDF_2.pkl\n","!cp -r /content/TFIDF_3.pkl /content/model/TFIDF_3.pkl\n","!cp -r /content/TFIDF_4.pkl /content/model/TFIDF_4.pkl\n","!cp -r /content/TFIDF_5.pkl /content/model/TFIDF_5.pkl"],"execution_count":35,"outputs":[{"output_type":"stream","text":["/root\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"14ddOZH4IMam","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627705589191,"user_tz":-540,"elapsed":473607,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"ce7a4d9a-7a95-4b5e-f702-8aef95041d25"},"source":["def dataset_upload():\n","    import json\n","    from kaggle.api.kaggle_api_extended import KaggleApi\n","\n","    id = f'{USERID}/{EX_NO}'\n","\n","    dataset_metadata = {}\n","    dataset_metadata['id'] = id\n","    dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n","    dataset_metadata['title'] = f'{EX_NO}'\n","\n","    with open(UPLOAD_DIR / 'dataset-metadata.json', 'w') as f:\n","        json.dump(dataset_metadata, f, indent=4)\n","\n","    api = KaggleApi()\n","    api.authenticate()\n","\n","    # データセットがない場合\n","    if f'{USERID}/{EX_NO}' not in [str(d) for d in api.dataset_list(user=USERID, search=f'\"{EX_NO}\"')]:\n","        api.dataset_create_new(folder=UPLOAD_DIR,\n","                               convert_to_csv=False,\n","                               dir_mode='skip')\n","    # データセットがある場合\n","    else:\n","        api.dataset_create_version(folder=UPLOAD_DIR,\n","                                   version_notes='update',\n","                                   convert_to_csv=False,\n","                                   delete_old_versions=True,\n","                                   dir_mode='skip')\n","dataset_upload()\n","\n"],"execution_count":36,"outputs":[{"output_type":"stream","text":["Starting upload for file model_4.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [01:21<00:00, 17.4MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_4.pth (1GB)\n","Starting upload for file TFIDF_5.pkl\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 563k/563k [00:08<00:00, 64.7kB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: TFIDF_5.pkl (563KB)\n","Starting upload for file TFIDF_1.pkl\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 559k/559k [00:09<00:00, 58.7kB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: TFIDF_1.pkl (559KB)\n","Starting upload for file TFIDF_2.pkl\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 561k/561k [00:04<00:00, 119kB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: TFIDF_2.pkl (561KB)\n","Starting upload for file TFIDF_3.pkl\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 560k/560k [00:07<00:00, 78.6kB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: TFIDF_3.pkl (560KB)\n","Starting upload for file model_1.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [01:24<00:00, 16.9MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_1.pth (1GB)\n","Starting upload for file model_5.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [01:23<00:00, 17.0MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_5.pth (1GB)\n","Starting upload for file TFIDF_4.pkl\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 559k/559k [00:10<00:00, 56.2kB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: TFIDF_4.pkl (559KB)\n","Starting upload for file model_3.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [01:25<00:00, 16.6MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_3.pth (1GB)\n","Starting upload for file model_2.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [01:27<00:00, 16.3MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_2.pth (1GB)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AhqGLA2QAiNd","executionInfo":{"status":"ok","timestamp":1627709128246,"user_tz":-540,"elapsed":141854,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"b5a80765-1286-4137-d2fd-7f5f9d36ba2d"},"source":["# validation再実行_予測結果取得\n","\n","all_predictions = np.zeros(len(train_kf_df)) # 推論結果について、「fold　× 推論df」のzero行列で枠を作る\n","\n","for fold_ in sorted(train_kf_df['kfold'].unique()):\n","    model_path = UPLOAD_DIR/f\"model_{fold_ + 1}.pth\" # 対応するモデルを読む\n","    tfidf_path = UPLOAD_DIR/f\"TFIDF_{fold_ + 1}.pkl\"\n","\n","    with open(tfidf_path, 'rb') as f:\n","        tfidf = pickle.load(f)\n","\n","    print(f\"\\nUsing {model_path}\")\n","\n","    val_idx = train_kf_df['kfold'] == fold_\n","    val_df = train_kf_df[val_idx]\n","    val_dataset = LitDataset(val_df, tfidf, inference_only=True) # TestのDataset(何で、もう一回作るのだろう？)\n","    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n","                          drop_last=False, shuffle=False, num_workers=2) # TestのDataLoader\n","\n","    model = LitModel()\n","    model.load_state_dict(torch.load(model_path))    # 対応するモデルから、重みを読み込む\n","    model.to(DEVICE) # モデルをDEVICEへぶち込む\n","\n","    all_predictions[val_idx] = predict(model, val_loader) # 推論結果行列の対象列に、推論結果を入力(以後、繰り返し)\n","\n","    del model\n","    gc.collect()\n"],"execution_count":40,"outputs":[{"output_type":"stream","text":["\n","Using /content/model/model_1.pth\n","\n","Using /content/model/model_1.pth\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Using /content/model/model_2.pth\n","\n","Using /content/model/model_2.pth\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Using /content/model/model_3.pth\n","\n","Using /content/model/model_3.pth\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Using /content/model/model_4.pth\n","\n","Using /content/model/model_4.pth\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Using /content/model/model_5.pth\n","\n","Using /content/model/model_5.pth\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"huJwVMSAPuDO","executionInfo":{"status":"ok","timestamp":1627709128247,"user_tz":-540,"elapsed":20,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["train_kf_df['pred'] = all_predictions\n","train_kf_df['diff_sq'] = (train_kf_df['target'] - train_kf_df['pred'])**2"],"execution_count":41,"outputs":[]},{"cell_type":"code","metadata":{"id":"0zzuBPobmLFu","colab":{"base_uri":"https://localhost:8080/","height":296},"executionInfo":{"status":"ok","timestamp":1627709129021,"user_tz":-540,"elapsed":792,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"e59346e7-e117-45b7-d73b-49305a30e034"},"source":["train_kf_df.plot(kind='scatter', x='target', y='diff_sq')"],"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7faa0376bed0>"]},"metadata":{"tags":[]},"execution_count":42},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"Wpc8ro9hmNci","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1627709129022,"user_tz":-540,"elapsed":17,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"5ce92c9d-a47c-46da-d021-41409e7063e4"},"source":["# 二乗誤差が2.0を超えるレコード\n","thr_ = 2.0 \n","train_kf_df[train_kf_df['diff_sq'] > thr_]"],"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>url_legal</th>\n","      <th>license</th>\n","      <th>excerpt</th>\n","      <th>target</th>\n","      <th>standard_error</th>\n","      <th>kfold</th>\n","      <th>bins_tg</th>\n","      <th>bins_std</th>\n","      <th>bins</th>\n","      <th>pred</th>\n","      <th>diff_sq</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>44</th>\n","      <td>47d6aff90</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>And it seemed to Tom Reynolds that all his Chr...</td>\n","      <td>0.320072</td>\n","      <td>0.501912</td>\n","      <td>3</td>\n","      <td>8</td>\n","      <td>3</td>\n","      <td>83</td>\n","      <td>-1.122609</td>\n","      <td>2.081331</td>\n","    </tr>\n","    <tr>\n","      <th>141</th>\n","      <td>bcd734621</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Midas was enjoying himself in his treasure-roo...</td>\n","      <td>0.943021</td>\n","      <td>0.537713</td>\n","      <td>0</td>\n","      <td>10</td>\n","      <td>5</td>\n","      <td>105</td>\n","      <td>-0.667733</td>\n","      <td>2.594528</td>\n","    </tr>\n","    <tr>\n","      <th>304</th>\n","      <td>f04e03fd8</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Jupiter, two hours high, was the herald of the...</td>\n","      <td>-3.229761</td>\n","      <td>0.551435</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>-1.477481</td>\n","      <td>3.070486</td>\n","    </tr>\n","    <tr>\n","      <th>990</th>\n","      <td>afeb324bd</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>On the morning of the 20th of March, a long se...</td>\n","      <td>0.401053</td>\n","      <td>0.481889</td>\n","      <td>0</td>\n","      <td>9</td>\n","      <td>2</td>\n","      <td>92</td>\n","      <td>-1.505391</td>\n","      <td>3.634529</td>\n","    </tr>\n","    <tr>\n","      <th>1152</th>\n","      <td>03b761fd9</td>\n","      <td>https://simple.wikipedia.org/wiki/Larva</td>\n","      <td>CC BY-SA 3.0 and GFDL</td>\n","      <td>Probably the most widely accepted theory expla...</td>\n","      <td>-2.778515</td>\n","      <td>0.533111</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>15</td>\n","      <td>-1.086422</td>\n","      <td>2.863180</td>\n","    </tr>\n","    <tr>\n","      <th>1412</th>\n","      <td>8f35441e3</td>\n","      <td>https://www.africanstorybook.org/#</td>\n","      <td>CC BY 4.0</td>\n","      <td>Every day, Emeka's father took him to school i...</td>\n","      <td>1.583847</td>\n","      <td>0.624776</td>\n","      <td>1</td>\n","      <td>11</td>\n","      <td>10</td>\n","      <td>1110</td>\n","      <td>-0.307797</td>\n","      <td>3.578315</td>\n","    </tr>\n","    <tr>\n","      <th>1628</th>\n","      <td>4cf4a2fa3</td>\n","      <td>https://kids.frontiersin.org/article/10.3389/f...</td>\n","      <td>CC BY 4.0</td>\n","      <td>Although anyone, from kids to the elderly, can...</td>\n","      <td>-1.802185</td>\n","      <td>0.518239</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>44</td>\n","      <td>0.104900</td>\n","      <td>3.636975</td>\n","    </tr>\n","    <tr>\n","      <th>1689</th>\n","      <td>8fb1cf05f</td>\n","      <td>https://www.africanstorybook.org/</td>\n","      <td>CC BY 4.0</td>\n","      <td>Yuadoo is scared of the dark. Everyone feels f...</td>\n","      <td>-2.199186</td>\n","      <td>0.479532</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>32</td>\n","      <td>-0.689919</td>\n","      <td>2.277889</td>\n","    </tr>\n","    <tr>\n","      <th>1879</th>\n","      <td>4ac78e5c3</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>The next morning Ethel Hollister walked up to ...</td>\n","      <td>-1.639354</td>\n","      <td>0.526015</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>5</td>\n","      <td>45</td>\n","      <td>-0.140140</td>\n","      <td>2.247640</td>\n","    </tr>\n","    <tr>\n","      <th>1944</th>\n","      <td>04ade0eb2</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>While I was hailing the brig, I spied a tract ...</td>\n","      <td>-3.315282</td>\n","      <td>0.544735</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>-1.471602</td>\n","      <td>3.399157</td>\n","    </tr>\n","    <tr>\n","      <th>2124</th>\n","      <td>76f92b721</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>The biggest desert in the world is in Africa, ...</td>\n","      <td>1.103341</td>\n","      <td>0.553751</td>\n","      <td>2</td>\n","      <td>10</td>\n","      <td>6</td>\n","      <td>106</td>\n","      <td>-0.434399</td>\n","      <td>2.364645</td>\n","    </tr>\n","    <tr>\n","      <th>2277</th>\n","      <td>7c732b8bb</td>\n","      <td>https://en.wikipedia.org/wiki/Environmental_sc...</td>\n","      <td>CC BY-SA 3.0</td>\n","      <td>Environmental science is an interdisciplinary ...</td>\n","      <td>-3.137143</td>\n","      <td>0.555843</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>16</td>\n","      <td>-1.548356</td>\n","      <td>2.524245</td>\n","    </tr>\n","    <tr>\n","      <th>2586</th>\n","      <td>551e0fc0b</td>\n","      <td>https://www.commonlit.org/texts/sweet-difficul...</td>\n","      <td>CC BY-NC-SA 2.0</td>\n","      <td>\"Hey, I'm Ashley,\" said a dark-haired girl at ...</td>\n","      <td>1.070988</td>\n","      <td>0.553791</td>\n","      <td>4</td>\n","      <td>10</td>\n","      <td>6</td>\n","      <td>106</td>\n","      <td>-0.449960</td>\n","      <td>2.313283</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             id  ...   diff_sq\n","44    47d6aff90  ...  2.081331\n","141   bcd734621  ...  2.594528\n","304   f04e03fd8  ...  3.070486\n","990   afeb324bd  ...  3.634529\n","1152  03b761fd9  ...  2.863180\n","1412  8f35441e3  ...  3.578315\n","1628  4cf4a2fa3  ...  3.636975\n","1689  8fb1cf05f  ...  2.277889\n","1879  4ac78e5c3  ...  2.247640\n","1944  04ade0eb2  ...  3.399157\n","2124  76f92b721  ...  2.364645\n","2277  7c732b8bb  ...  2.524245\n","2586  551e0fc0b  ...  2.313283\n","\n","[13 rows x 12 columns]"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"code","metadata":{"id":"ceDI72NumT5-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627709129023,"user_tz":-540,"elapsed":15,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"460648c6-1201-4030-9e55-d7abe2694d2a"},"source":["# 二乗誤差が2.0を超える文章\n","thr_ = 2.0 \n","tmp_df = train_kf_df[train_kf_df['diff_sq'] > thr_].copy()\n","for i in tmp_df.index:\n","  print(tmp_df.loc[i].target)\n","  #print(tmp_df.loc[i].standard_error)\n","  print(tmp_df.loc[i].pred)\n","  print(tmp_df.loc[i].excerpt)\n","  print('--------------------------')"],"execution_count":44,"outputs":[{"output_type":"stream","text":["0.32007246\n","-1.1226093769073486\n","And it seemed to Tom Reynolds that all his Christmas joy went skimming away behind him. The sun still shone, the ice still gleamed, the skaters laughed and sang, but Tom moved slowly on, with listless, heavy strokes. The \"Jolly Ramblers\" still twinkled beneath his feet, but he looked down at them no more. What was the use of \"Jolly Ramblers\" when Ralph Evans had a pair of \"Club House\" skates that cost a dollar more, had a graceful curve, and a faultless clamp, and were guaranteed for a year?\n","It was only four o'clock when Tom slipped his new skates carelessly over his shoulder and started up the bank for home. He was slouching down the main street, head down, hands thrust deep into his pockets, when, on turning a corner, he ran plump into—a full moon! Now I know it is rather unusual for full moons to be walking about the streets by daylight; but that is the only adequate description of the round, freckled face that beamed at Tom from behind a great box, held by two sturdy arms.\n","--------------------------\n","0.943020903\n","-0.6677330732345581\n","Midas was enjoying himself in his treasure-room, one day, as usual, when he perceived a shadow fall over the heaps of gold; and, looking suddenly up, what should he behold but the figure of a stranger, standing in the bright and narrow sunbeam! It was a young man, with a cheerful and ruddy face. Whether it was that the imagination of King Midas threw a yellow tinge over everything, or whatever the cause might be, he could not help fancying that the smile with which the stranger regarded him had a kind of golden radiance in it. Certainly, although his figure intercepted the sunshine, there was now a brighter gleam upon all the piled-up treasures than before. Even the remotest corners had their share of it, and were lighted up, when the stranger smiled, as with tips of flame and sparkles of fire.\n","--------------------------\n","-3.229761439\n","-1.4774811267852783\n","Jupiter, two hours high, was the herald of the day; the Pleiades, just above the horizon, shed their sweet influence in the east; Lyra sparkled near the zenith; Andromeda veiled her newly discovered glories from the naked eye in the south; the steady Pointers, far beneath the pole, looked meekly up from the depths of the north to their sovereign.\n","Such was the glorious spectacle as I entered the train. As we proceeded, the timid approach of twilight became more perceptible; the intense blue of the sky began to soften; the smaller stars, like little children, went first to rest; the sister-beams of the Pleiades soon melted together; but the bright constellations of the west and north remained unchanged. Steadily the wondrous transfiguration went on. Hands of angels, hidden from mortal eyes, shifted the scenery of the heavens; the glories of night dissolved into the glories of the dawn.\n","--------------------------\n","0.401052549\n","-1.5053914785385132\n","On the morning of the 20th of March, a long series of earthquakes spread alarm throughout all the cities and numerous villages that are scattered over the sides of Mt. Etna. The shocks followed each other at intervals of a few minutes; dull subterranean rumblings were heard; and a catastrophe was seen to be impending. Toward evening the ground cracked at the lower part of the south side of the mountain, at the limit of the cultivated zone, and at four kilometers to the north of the village of Nicolosi. There formed on the earth a large number of very wide fissures, through which escaped great volumes of steam and gases which enveloped the mountain in a thick haze; and toward night, a very bright red light, which, seen from Catania, seemed to come out in great waves from the foot of the mountain, announced the coming of the lava.\n","--------------------------\n","-2.778515087\n","-1.0864216089248657\n","Probably the most widely accepted theory explaining the evolution of larval stages is the need for dispersal. Sessile organisms such as barnacles and tunicates, and sea-floor groups like mussels and crabs, need some way to move their young into new territory, since they cannot move long distances as adults. Many species have relatively long pelagic larval stages (how long a larva is in the water column). During this time, larvae feed and grow, and many species move through several stages of development. For example, most barnacles molt through six nauplius larva stages before molting to a cipris, when they look to settle. The larvae eat different food from the adults, and disperse.\n","The other consideration is the small size of the eggs. If animals lay many small eggs (and most do), then the young stages cannot live the life the adults lead. They must live a separate life until they have the size and capability to live as an adult. This is what the larvae do.\n","--------------------------\n","1.583846826\n","-0.3077966868877411\n","Every day, Emeka's father took him to school in his car. He also brought Emeka home after school. One afternoon on their way home, Emeka's father stopped to buy something at a big shop. From the car, Emeka looked across the road and saw an old man. He was carrying a big load on his head. He was tired and walked slowly. Emeka kept looking at him. The old man sat under the shade of a tree on the walkway and opened his bag. He had two flat plastic water bottles, which he was making into shoes. Emeka thought about that old man for a long time. He felt sad. When he got home, he could not eat. He thought about what he could do. He got up and took some money from his money bag. He called Chita and jumped on his bicycle. Emeka rode to the shop where his father had shopped. The boy ran into the shop and came out with a bag. He went to where the old man was resting against a tree. Emeka called out, \"Good afternoon, sir.\" The man answered, \"Peace to you, my child.\"\n","--------------------------\n","-1.802185475\n","0.10490000247955322\n","Although anyone, from kids to the elderly, can come into contact with the bacterium Mycobacterium tuberculosis, the vast majority of people (about 90%) who are infected with this bacterium will eliminate it through the work of the immune system. However, some people (about 10%) who come into contact with M. tuberculosis cannot fully control the bacteria. These people can develop a disease called active tuberculosis (ATB), with fever, coughing, and weight loss. In these cases, M. tuberculosis makes its home within the lungs and can be transmitted to other people when the sick people expel the bacteria through coughing. In some people, another scenario occurs in which their immune system keeps the bacteria in a dormant or \"sleeping\" state. This is called latent TB. In these people, no fever, coughing, or weight loss will be apparent until their immune system stops working properly.\n","--------------------------\n","-2.1991863030000003\n","-0.6899185180664062\n","Yuadoo is scared of the dark. Everyone feels fear sometimes. But Yuadoo can ask for help. Chidubem is worried about his schoolwork. He can tell his teacher. He can ask for help. Lushan is playing around! It's okay to be silly sometimes. Eruro is feeling sad. It's okay to cry. Emotions come and go. Ayator is bursting with happiness. He is joyful. Emotions come and go. Hadiza is bored. She needs to find something to do. Ayo is angry. He is frustrated. Anger is a difficult feeling. Labake is excited. What's the cause of her excitement? Mother made her favorite food. Zege felt sleepy. He was very tired. \"But wait, is 'sleepy' an emotion?\" asks Efe. Efe is confused! Can you answer his question? Tega is feeling surprise and shock. He heard some gossip. Is it true? Yebo is sick. She feels miserable. She needs some medicine and rest to feel better. Sekyen is feeling content. She has finished her chores. Now she can play. Vandefan does not have chores today. He shows two thumbs up to Sekyen. \"Good job, now let's play!\" he says.\n","--------------------------\n","-1.639353583\n","-0.14014045894145966\n","The next morning Ethel Hollister walked up to Barnard and put in her application for admittance. The following week upon her first examination she failed, but she entered the class with conditions. The girl studied hard and soon made good.\n","She liked the girls of her class. They were intelligent, athletic, and agreeable.\n","Her former friends and companions from La Rue's declared that of late—in fact, since she had become a Camp Fire Girl—Ethel Hollister had developed fads. This Barnard was one. But as Ethel kept on steadily progressing in college, and she was so very young—not yet seventeen—people began to consider her a girl of great ability and intelligence. Mrs. Hollister grew to be proud of hearing her praised on every side and Archibald seemed less worried over money matters. She was rather glad that things had changed. Perhaps it was all for the best, and people would respect them no less.\n","--------------------------\n","-3.31528229\n","-1.4716020822525024\n","While I was hailing the brig, I spied a tract of water lying between us, where no great waves came, but which yet boiled white all over and bristled in the moon with rings and bubbles. Sometimes the whole tract swung to one side, like the tail of a live serpent; sometimes, for a glimpse, it would all disappear and then boil up again. What it was I had no guess, which for the time increased my fear of it; but I now know it must have been the roost or tide-race, which had carried me away so fast and tumbled me about so cruelly, and at last, as if tired of that play, had flung out me and the spare yard upon its landward margin.\n","I now lay quite becalmed, and began to feel that a man can die of cold as well as of drowning. The shores of Earraid were close in; I could see in the moonlight the dots of heather and the sparkling of the mica in the rocks.\n","--------------------------\n","1.103341259\n","-0.4343990087509155\n","The biggest desert in the world is in Africa, and is called the Sahara. It is almost as large as the Atlantic Ocean, but instead of water it is all sands and rocks. Like the ocean, it is visited with storms; dreadful gales, when the wind scoops up thousands of tons of sand and drives them forward, burying and crushing all they meet. And it has islands, too—small green patches, where springs bubble through the ground, and ferns and acacias and palm-trees grow. When a traveler sees one of these fertile spots afar off, he feels as a tempest-tossed sailor does at sight of land. It is delightful to quit the hot, baking sun, sit in shadow under the trees, and rest the eyes, long wearied with dazzling sands, on the sweet green and the clear spring. Oases, these islands are called. Long distances divide them. It is often a race for life to get across from one to the other.\n","--------------------------\n","-3.1371432610000003\n","-1.5483559370040894\n","Environmental science is an interdisciplinary academic field that integrates physical, biological and information sciences (including ecology, biology, physics, chemistry, zoology, mineralogy, oceanology, limnology, soil science, geology, atmospheric science, and geodesy) to the study of the environment, and the solution of environmental problems. Environmental science emerged from the fields of natural history and medicine during the Enlightenment. Today it provides an integrated, quantitative, and interdisciplinary approach to the study of environmental systems.\n","Related areas of study include environmental studies and environmental engineering. Environmental studies incorporate more of the social sciences for understanding human relationships, perceptions and policies towards the environment. Environmental engineering focuses on design and technology for improving environmental quality in every aspect. Environmental scientists work on subjects like the understanding of earth processes, evaluating alternative energy systems, pollution control and mitigation, natural resource management, and the effects of global climate change. Environmental issues almost always include an interaction of physical, chemical, and biological processes.\n","--------------------------\n","1.070987536\n","-0.4499604105949402\n","\"Hey, I'm Ashley,\" said a dark-haired girl at the locker next to hers removing her backpack from her shoulders. \"You new here?\"\n","Yes, Nothukula wanted to say. But not just to Freedman High School, she was also new to the country. She had arrived in the summer from Zimbabwe.\n","\"Can you speak English?\" Ashley asked. Nothukula stared at her. It wasn't that she didn't understand English. They had spoken it at school back home, and then there were the American soap operas that she loved to watch. \"Are you new?\" Ashley spoke loudly and slowly, like Nothukula had trouble hearing. She was still standing there, staring at Nothukula, as if tapping the glass of a fish tank, waiting for any reaction. It made Nothukula nervous, stiffening her tongue. With each wordless second that passed, she felt more pressure to make up for the awkwardness, say the right thing to Ashley and ensure it came out perfectly. She opened her mouth, but not a single thing came out.\n","Rolling her eyes, Ashley looked away, checking her face in a compact mirror and calling after one of her friends. Nothukula just stood there, like a deer in headlights.\n","--------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q8_oLwX5EBJp","executionInfo":{"status":"ok","timestamp":1627710378172,"user_tz":-540,"elapsed":33835,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"317efaaa-08df-4867-9322-8a43a8ee2280"},"source":["%env MODEL_OUT_DIR '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/98_model_inf/055-054-train-03'\n","!mkdir -p $MODEL_OUT_DIR\n","!cp -r /content/model/ $MODEL_OUT_DIR"],"execution_count":55,"outputs":[{"output_type":"stream","text":["env: MODEL_OUT_DIR='/content/drive/MyDrive/Colab_Files/kaggle/commonlit/98_model_inf/055-054-train-03'\n","^C\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5LQSg_DrGaGA"},"source":["!cp -r /content/model_1.pth /content/model/model_1.pth\n","!cp -r /content/model_2.pth /content/model/model_2.pth\n","!cp -r /content/model_3.pth /content/model/model_3.pth\n","!cp -r /content/model_4.pth /content/model/model_4.pth\n","!cp -r /content/model_5.pth /content/model/model_5.pth\n","!cp -r /content/TFIDF_1.pkl /content/model/TFIDF_1.pkl\n","!cp -r /content/TFIDF_2.pkl /content/model/TFIDF_2.pkl\n","!cp -r /content/TFIDF_3.pkl /content/model/TFIDF_3.pkl\n","!cp -r /content/TFIDF_4.pkl /content/model/TFIDF_4.pkl\n","!cp -r /content/TFIDF_5.pkl /content/model/TFIDF_5.pkl"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RXEPC4eLF9Ts","executionInfo":{"status":"ok","timestamp":1627710449242,"user_tz":-540,"elapsed":530,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["model_path_out = Path('/content/model/')"],"execution_count":59,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9i8yg_02Gc4M","executionInfo":{"status":"ok","timestamp":1627710596157,"user_tz":-540,"elapsed":8,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"fc9407e5-357b-412e-9d54-2fa477ee2d1d"},"source":["for i in list(model_path_out.iterdir()):\n","  print(i)"],"execution_count":65,"outputs":[{"output_type":"stream","text":["/content/model/model_4.pth\n","/content/model/TFIDF_5.pkl\n","/content/model/TFIDF_1.pkl\n","/content/model/TFIDF_2.pkl\n","/content/model/TFIDF_3.pkl\n","/content/model/model_1.pth\n","/content/model/model_5.pth\n","/content/model/dataset-metadata.json\n","/content/model/TFIDF_4.pkl\n","/content/model/model_3.pth\n","/content/model/model_2.pth\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XHp_ddnKG6mx","executionInfo":{"status":"ok","timestamp":1627710956340,"user_tz":-540,"elapsed":5,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["import shutil\n","tgdir = Path('/content/drive/MyDrive/Colab_Files/kaggle/commonlit/98_model_inf/055-054')\n","\n","for file_ in list(model_path_out.iterdir()):\n","  shutil.copy(file_, tgdir)"],"execution_count":70,"outputs":[]},{"cell_type":"code","metadata":{"id":"hvVp32J-HXGn"},"source":[""],"execution_count":null,"outputs":[]}]}