{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"060-train-02.ipynb","provenance":[{"file_id":"1jr4xt9VUg2tgtFpOFIr0-1IXf_lPIshQ","timestamp":1627882255097},{"file_id":"1CEQK5FqKSwMO6MjCXmCCM9_BGeLzsJbO","timestamp":1627819646939},{"file_id":"17BUK8yRF7SDX0khlOXoHcFRTEFffkvRb","timestamp":1627488927996},{"file_id":"1wNpTEKAuuKP7ivTcm1f9j0sdmYU1RyzA","timestamp":1627306793279},{"file_id":"1uE__yBR1oxeYaUIrUTMEOffmeyuJBRAU","timestamp":1627305921964},{"file_id":"1PbEPh6kL5p5cdH5HC8iHoMVCIzA0MqvB","timestamp":1627284576770},{"file_id":"1TlxQ4e-ZX1Zy51dKLuhNdrBWg1qhojqP","timestamp":1627273765934},{"file_id":"17a4F4aC9L0QBqU8BRTrdqPn0WwJ0b08b","timestamp":1626746992716},{"file_id":"1G_W9irFTrEmDeHR0S6_u0bjpk8nxipXW","timestamp":1626689695352},{"file_id":"1bhhkorT--y8XXaVLM8hibVgC-tLqZ16P","timestamp":1626358153868},{"file_id":"1WtT2hX6O9Qbt_hb9sF50nM2QmDXFi-XA","timestamp":1626338366006},{"file_id":"1k_p5wftcUeo711Xho1-T5an2Xkneau-J","timestamp":1626323813472},{"file_id":"1Vz2GB2BNTWuefEFkCSh3TBPEIel7KG1t","timestamp":1626317426487},{"file_id":"1djoMWojeaIPopG5tS1jNMohn8ineblRh","timestamp":1626306831897},{"file_id":"1-6tlDO8158Pi6TpptIF884oFaEiT4Uxb","timestamp":1626276420047},{"file_id":"1js8eA3mDNS8mwSpCiHuzPeARFlUPAVrg","timestamp":1626272452526},{"file_id":"1yhcPgulwJtjJKUK9IuRKmNMhJ-4YXGol","timestamp":1626267205517},{"file_id":"1mnnSv0Pofn1QxArywV81VYqnZPB8uUWN","timestamp":1626180468522},{"file_id":"1RRdjt_UAeHmr5QQBAMyC82Fq1s31OWdK","timestamp":1625833136005},{"file_id":"1JPgg44HFemzwk8VSCXih3PejL0idy-C4","timestamp":1625825483466},{"file_id":"1Ye6wqVX71xAAAhmjXkw9IpRvTqeUyJDA","timestamp":1625812137500}],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ucCbvGD1XvG7","executionInfo":{"status":"ok","timestamp":1627883438188,"user_tz":-540,"elapsed":450,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"5dc9d032-6c10-4928-ab20-4ea91aeaa4ce"},"source":["import sys\n","if 'google.colab' in sys.modules:  # colab特有の処理_2回目以降\n","  # Google Driveのマウント\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","\n","  # ライブラリのパス指定\n","  sys.path.append('/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules')\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FACwJ6icpxrR","executionInfo":{"status":"ok","timestamp":1627883446150,"user_tz":-540,"elapsed":7224,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# データセットをDriveから取得\n","!mkdir -p 'input'\n","!mkdir -p 'clrp-pre-trained'\n","\n","!cp -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/00_input/commonlitreadabilityprize/' '/content/input'\n","!cp -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/97_pre_trained/clrp_pretrained_manish_epoch5/pre-trained-roberta/clrp_roberta_large/' '/content/clrp-pre-trained'"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"RV9-VwbpZLZ9","executionInfo":{"status":"ok","timestamp":1627883446151,"user_tz":-540,"elapsed":24,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["from pathlib import Path\n","\n","# input\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    DATA_DIR = Path('../input/commonlitreadabilityprize/')\n","\n","elif 'google.colab' in sys.modules: # Colab環境\n","    DATA_DIR = Path('/content/input/commonlitreadabilityprize')\n","\n","else:\n","    DATA_DIR = Path('../00_input/commonlitreadabilityprize/')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"x5difyXe00UV","executionInfo":{"status":"ok","timestamp":1627883446151,"user_tz":-540,"elapsed":21,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["from pathlib import Path\n","\n","# tokenizer\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    TOKENIZER_DIR = '../input/roberta-transformers-pytorch/roberta-large'\n","elif 'google.colab' in sys.modules: # Colab環境\n","    TOKENIZER_DIR = '/content/clrp-pre-trained/clrp_roberta_large' # 仮で、毎回DLする想定のモデル名を指定。あとで変更予定。\n","else:\n","    TOKENIZER_DIR = 'roberta-large'"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"tKjsUxnOeDYl","executionInfo":{"status":"ok","timestamp":1627883446152,"user_tz":-540,"elapsed":21,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["from pathlib import Path\n","\n","# pre-trained model\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    PRE_TRAINED_MODEL_DIR = '../input/roberta-transformers-pytorch/roberta-large'\n","elif 'google.colab' in sys.modules: # Colab環境\n","    PRE_TRAINED_MODEL_DIR = '/content/clrp-pre-trained/clrp_roberta_large' # 仮で、毎回DLする想定のモデル名を指定。あとで変更予定。\n","else:\n","    PRE_TRAINED_MODEL_DIR = 'roberta-large'"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZLaT2V0ReoAZ","executionInfo":{"status":"ok","timestamp":1627883446152,"user_tz":-540,"elapsed":20,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["UPLOAD_DIR = Path('/content/model')\n","EX_NO = '060-train-02'  # 実験番号などを入れる、folderのpathにする\n","USERID = 'calpis10000'"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"hOGjAb4pAJ0F","executionInfo":{"status":"ok","timestamp":1627883446153,"user_tz":-540,"elapsed":21,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["import subprocess\n","import shlex\n","\n","def gpuinfo():\n","    \"\"\"\n","    Returns size of total GPU RAM and used GPU RAM.\n","\n","    Parameters\n","    ----------\n","    None\n","\n","    Returns\n","    -------\n","    info : dict\n","        Total GPU RAM in integer for key 'total_MiB'.\n","        Used GPU RAM in integer for key 'used_MiB'.\n","    \"\"\"\n","\n","    command = 'nvidia-smi -q -d MEMORY | sed -n \"/FB Memory Usage/,/Free/p\" | sed -e \"1d\" -e \"4d\" -e \"s/ MiB//g\" | cut -d \":\" -f 2 | cut -c2-'\n","    commands = [shlex.split(part) for part in command.split(' | ')]\n","    for i, cmd in enumerate(commands):\n","        if i==0:\n","            res = subprocess.Popen(cmd, stdout=subprocess.PIPE)\n","        else:\n","            res = subprocess.Popen(cmd, stdin=res.stdout, stdout=subprocess.PIPE)\n","    total, used = map(int, res.communicate()[0].decode('utf-8').strip().split('\\n'))\n","    info = {'total_MiB':total, 'used_MiB':used}\n","    return info\n"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g3-6m5MKXecB"},"source":["# Overview\n","This nb is based on copy from https://www.kaggle.com/andretugan/lightweight-roberta-solution-in-pytorch .\n","\n","Acknowledgments(from base nb): \n","some ideas were taken from kernels by [Torch](https://www.kaggle.com/rhtsingh) and [Maunish](https://www.kaggle.com/maunish)."]},{"cell_type":"code","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-04T06:26:32.834365Z","iopub.execute_input":"2021-07-04T06:26:32.834903Z","iopub.status.idle":"2021-07-04T06:26:40.143740Z","shell.execute_reply.started":"2021-07-04T06:26:32.834785Z","shell.execute_reply":"2021-07-04T06:26:40.142864Z"},"trusted":true,"id":"HRsRZ06WXecD","executionInfo":{"status":"ok","timestamp":1627883730425,"user_tz":-540,"elapsed":284292,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["import os\n","import math\n","import random\n","import time\n","\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","\n","from transformers import AdamW # optimizer\n","from transformers import AutoTokenizer\n","from transformers import AutoModel\n","from transformers import AutoConfig\n","from transformers import get_cosine_schedule_with_warmup # scheduler\n","from pytorch_memlab import profile\n","import pytorch_memlab\n","from pytorch_memlab import MemReporter\n","\n","from sklearn.model_selection import KFold, StratifiedKFold\n","\n","import pickle\n","import gc\n","gc.enable()"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.145217Z","iopub.execute_input":"2021-07-04T06:26:40.145539Z","iopub.status.idle":"2021-07-04T06:26:40.201326Z","shell.execute_reply.started":"2021-07-04T06:26:40.145504Z","shell.execute_reply":"2021-07-04T06:26:40.200136Z"},"trusted":true,"id":"omBfwshTXecE","executionInfo":{"status":"ok","timestamp":1627883730426,"user_tz":-540,"elapsed":22,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["NUM_FOLDS = 5 # K Fold\n","NUM_EPOCHS = 5 # Epochs\n","BATCH_SIZE = 12 # Batch Size\n","MAX_LEN = 248 # ベクトル長\n","TFIDF_MAX_FEAT = 1024\n","\n","EVAL_SCHEDULE = [(0.55, 64), (-1., 32)] # schedulerの何らかの設定？\n","ROBERTA_PATH = PRE_TRAINED_MODEL_DIR # roberta pre-trainedモデル(モデルとして指定)\n","TOKENIZER_PATH = TOKENIZER_DIR # roberta pre-trainedモデル(Tokenizerとして指定)\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\" # cudaがなければcpuを使えばいいじゃない"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.203398Z","iopub.execute_input":"2021-07-04T06:26:40.204055Z","iopub.status.idle":"2021-07-04T06:26:40.211572Z","shell.execute_reply.started":"2021-07-04T06:26:40.204015Z","shell.execute_reply":"2021-07-04T06:26:40.210762Z"},"trusted":true,"id":"4qcuXqwtXecF","executionInfo":{"status":"ok","timestamp":1627883730427,"user_tz":-540,"elapsed":20,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["def set_random_seed(random_seed):\n","    random.seed(random_seed)\n","    np.random.seed(random_seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(random_seed)\n","\n","    torch.manual_seed(random_seed)\n","    torch.cuda.manual_seed(random_seed)\n","    torch.cuda.manual_seed_all(random_seed)\n","\n","    torch.backends.cudnn.deterministic = True# cudnnによる最適化で結果が変わらないためのおまじない "],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.214188Z","iopub.execute_input":"2021-07-04T06:26:40.214809Z","iopub.status.idle":"2021-07-04T06:26:40.309744Z","shell.execute_reply.started":"2021-07-04T06:26:40.214769Z","shell.execute_reply":"2021-07-04T06:26:40.308926Z"},"trusted":true,"id":"70PyLsJTXecF","executionInfo":{"status":"ok","timestamp":1627883730427,"user_tz":-540,"elapsed":20,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# read train_df(kfold)\n","train_kf_df = pd.read_csv(DATA_DIR/\"train_kfold.csv\")"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.311021Z","iopub.execute_input":"2021-07-04T06:26:40.311347Z","iopub.status.idle":"2021-07-04T06:26:40.624393Z","shell.execute_reply.started":"2021-07-04T06:26:40.311314Z","shell.execute_reply":"2021-07-04T06:26:40.623347Z"},"trusted":true,"id":"xf0662k4XecF","executionInfo":{"status":"ok","timestamp":1627883730428,"user_tz":-540,"elapsed":20,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# tokenizerを指定\n","tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N6aaghNkXecG"},"source":["# Dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UU5uZKIcDjkV","executionInfo":{"status":"ok","timestamp":1627883733518,"user_tz":-540,"elapsed":3109,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"3356400e-92c3-46c7-fdc7-894f34b7f9ce"},"source":["# 前処理用\n","import string\n","import re\n","import collections\n","\n","# ローカルの場合、stopwordsをダウンロード\n","import nltk\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    pass\n","else:\n","    import nltk\n","    nltk.download('stopwords')\n","    nltk.download('averaged_perceptron_tagger')\n","    os.listdir(os.path.expanduser('~/nltk_data/corpora/stopwords/'))\n","\n","# テキスト前処理\n","# https://www.kaggle.com/alaasedeeq/commonlit-readability-eda\n","\n","#filtering the unwanted symbols, spaces, ....etc\n","to_replace_by_space = re.compile('[/(){}\\[\\]|@,;]')\n","punctuation = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n","bad_symbols = re.compile('[^0-9a-z #+_]')\n","stopwords = set(nltk.corpus.stopwords.words('english'))\n","\n","def text_prepare(text):\n","    '''\n","    text: a string\n","    returna modified version of the string\n","    '''\n","    text = text.lower() # lowercase text\n","    text = re.sub(punctuation, '',text)\n","    text = re.sub(to_replace_by_space, \" \", text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n","    text = re.sub(bad_symbols, \"\", text)         # delete symbols which are in BAD_SYMBOLS_RE from text\n","    text = \" \".join([word for word in text.split(\" \") if word not in stopwords]) # delete stopwords from text\n","    text = re.sub(' +', ' ', text)\n","    return text\n","\n","def text_normalization(s:pd.Series):\n","    x = s.apply(text_prepare)\n","    return x\n","\n","# Counterオブジェクトを取得\n","def get_counter(text:str):\n","    text_list = [wrd for wrd in text.split(\" \") if wrd not in ('', '\\n')]\n","    counter = collections.Counter(text_list)\n","    return counter\n","\n","# ベースとなる継承元のクラス\n","class BaseBlock(object):\n","    def fit(self, input_df, y=None):\n","        return self.transform(input_df)\n","    def transform(self, input_df):\n","        raise NotImplementedError()"],"execution_count":13,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ze-E2aCfgsfj","executionInfo":{"status":"ok","timestamp":1627883733519,"user_tz":-540,"elapsed":5,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["class TextDescriptionBlock(BaseBlock):\n","    \"\"\"テキストに関する統計量を返す block\"\"\"\n","    def __init__(self, column: str):\n","        \"\"\"\n","        args:\n","            column: str\n","                変換対象のカラム名\n","        \"\"\"\n","        self.column = column\n","        self.param_prefix = f'col={column}'\n","\n","    # 前処理\n","    def preprocess(self, input_df):\n","        x = text_normalization(input_df[self.column])\n","        return x\n","        \n","    def fit(self, input_df, y=None):\n","        return self.transform(input_df)\n","\n","    def transform(self, input_df):\n","        # 前処理\n","        self.text = self.preprocess(input_df)\n","        self.counters = self.text.map(get_counter)\n","\n","        # 変換処理\n","        _length = input_df[self.column].fillna('').map(lambda x: len(x) if x!='' else np.nan)\n","        _wrd_cnt = self.counters.map(lambda x: sum(x.values()))\n","        _wrd_nuniq = self.counters.map(lambda x: len(x))\n","        _wrd_mean = self.counters.map(lambda x: np.mean(list(x.values())))\n","        _wrd_max = self.counters.map(lambda x: np.max(list(x.values())))\n","        \n","        word_length = self.counters.map(lambda x: np.array([len(i) for i in x.keys()]))\n","        word_length_desc = word_length.map(lambda x: pd.Series(x.ravel()).describe())\n","        _word_length_desc_df = pd.DataFrame(word_length_desc.tolist()).iloc[:,1:]\n","        _word_length_desc_df = _word_length_desc_df.add_prefix('word_length_')\n","        \n","        out_df = pd.concat([_length, _wrd_cnt, _wrd_nuniq, _wrd_mean, _wrd_max], axis=1)\n","        out_df = out_df.reset_index().drop('index', axis='columns')\n","        out_df.columns = ['text_length', 'word_count', 'word_nunique', 'word_appearance_mean', 'word_appearance_max']\n","        out_df = pd.concat([out_df, _word_length_desc_df], axis=1).fillna(-1)\n","        return out_df.add_suffix(f'_{self.column}')"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z6lObnzFnYyK","executionInfo":{"status":"ok","timestamp":1627883734045,"user_tz":-540,"elapsed":19,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["class SentenceDescriptionBlock(BaseBlock):\n","    \"\"\"テキスト(センテンス)に関する統計量を返す block\"\"\"\n","    def __init__(self, column: str):\n","        \"\"\"\n","        args:\n","            column: str\n","                変換対象のカラム名\n","        \"\"\"\n","        self.column = column\n","        self.param_prefix = f'col={column}'\n","\n","    # 前処理\n","    def get_delimiter_feats(self, sentences: list):\n","      deli_df = pd.DataFrame([{'comma': i.count(','),\n","                                'colon': i.count(':'),\n","                                'semi-colon': i.count(';'),\n","                                'dash': i.count('—'),\n","                                'total': i.count(',') + i.count(':') + i.count(';') + i.count('—')\n","                                } for i in sentences])\n","      deli_disc = deli_df.describe().drop('count', axis='index')\n","      deli_disc.loc['sum', :] = deli_df.sum()\n","      deli_values = deli_disc.T.values.reshape(-1)\n","      col_list = []\n","      for col_ in deli_disc.columns:\n","        for idx_ in deli_disc.index:\n","          col_list.append(f'sentences_delim_{col_}_{idx_}')\n","      return pd.Series(data=deli_values, index=col_list)\n","\n","    def transform(self, input_df):\n","        self.text = input_df.reset_index().drop('index', axis='columns')[self.column]\n","        self.sentences = self.text.map(lambda x: [i for i in x.split('.') if len(i) > 0])\n","        out_df = pd.DataFrame()\n","\n","        # センテンス数\n","        out_df['sentences_cnt'] = self.sentences.map(lambda x: len(x)) \n","\n","        # センテンス長 × 各種統計量\n","        sentences_len = self.sentences.map(lambda x: [len(i) for i in x])\n","        sentences_len_df = pd.DataFrame(\n","                                        sentences_len.map(\n","                                            lambda x: pd.Series(x).describe().drop('count')\n","                                            ).tolist()\n","                                        ).add_prefix('sentence_length_')\n","\n","        # センテンスの単語数(クリーニング)\n","        sentences_clean = self.sentences.map(lambda x: [text_prepare(i) for i in x])\n","        sentences_wrd_counter = sentences_clean.map(lambda x: [get_counter(i) for i in x])\n","\n","        sentences_wrd_cnt_df = pd.DataFrame( # 単語数\n","                                        sentences_wrd_counter.map(\n","                                            lambda x: pd.Series([sum(i.values()) for i in x]).describe().drop('count')\n","                                            ).tolist()\n","                                        ).add_prefix('sentence_word_cnt_') \n","\n","        sentences_wrd_uniq_df = pd.DataFrame( # 単語のユニーク数\n","                                        sentences_wrd_counter.map(\n","                                            lambda x: pd.Series([len(i) for i in x]).describe().drop('count')\n","                                            ).tolist()\n","                                        ).add_prefix('sentence_word_uniq_')\n","\n","        # 区切り文字の数を取得\n","        sentences_deli_df = self.sentences.apply(self.get_delimiter_feats)       \n","        \n","        out_df = pd.concat([out_df, \n","                            sentences_len_df, \n","                            sentences_wrd_cnt_df, \n","                            sentences_wrd_uniq_df, \n","                            sentences_deli_df], axis=1)\n","        \n","        out_df = out_df.reset_index().drop('index', axis='columns')\n","        return out_df.add_suffix(f'_{self.column}')"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ca_p2ldNhU5X","executionInfo":{"status":"ok","timestamp":1627883734045,"user_tz":-540,"elapsed":17,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 参考: https://www.guruguru.science/competitions/16/discussions/556029f7-484d-40d4-ad6a-9d86337487e2/\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","# ベースとなる継承元のクラス\n","class BaseBlock(object):\n","    def fit(self, input_df, y=None):\n","        return self.transform(input_df)\n","    def transform(self, input_df):\n","        raise NotImplementedError()\n","\n","\n","class TfidfSimpleBlock(BaseBlock):\n","    \"\"\"シンプルなTF-IDF特徴を作成する block\"\"\"\n","    def __init__(self, column: str, max_features=50, ngram_range=(1,1), use_idf=True):\n","        \"\"\"\n","        args:\n","            column: str\n","                変換対象のカラム名\n","        \"\"\"\n","        self.column = column\n","        self.max_features=max_features\n","        self.ngram_range=ngram_range\n","        self.use_idf=use_idf\n","        self.param_prefix=f\"col={column}_max_features={max_features}_\\\n","                              ngram={ngram_range[0]}_{ngram_range[1]}_use_idf={use_idf}\"\n","\n","    def preprocess(self, input_df):\n","        x = text_normalization(input_df[self.column])\n","        return x\n","\n","    def get_master(self, _master_df):\n","        \"\"\"tdidfを計算するための全体集合を返す.\"\"\"\n","        return _master_df\n","    def fit(self, \n","            input_df, \n","            _master_df=None, \n","            y=None\n","           ):\n","        master_df = input_df if _master_df is None else self.get_master(_master_df)\n","        text = self.preprocess(master_df)\n","        self.vectorizer_ = TfidfVectorizer(max_features=self.max_features\n","                                      ,ngram_range=self.ngram_range\n","                                      ,use_idf=self.use_idf)\n","\n","        self.vectorizer_.fit(text)\n","        self.prefix = 'tfidf' if self.use_idf == True else 'tf'\n","        return self.transform(input_df)\n","\n","    def transform(self, input_df):\n","        text = self.preprocess(input_df)\n","        z = self.vectorizer_.transform(text)\n","\n","        out_df = pd.DataFrame(z.toarray())\n","        out_df.columns = self.vectorizer_.get_feature_names()\n","        return out_df.add_prefix(f'{self.prefix}_')"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"mfaWw86-WMIL","executionInfo":{"status":"ok","timestamp":1627883734046,"user_tz":-540,"elapsed":17,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["from sklearn.feature_extraction.text import CountVectorizer\n","\n","# ベースとなる継承元のクラス\n","class BaseBlock(object):\n","    def fit(self, input_df, y=None):\n","        return self.transform(input_df)\n","    def transform(self, input_df):\n","        raise NotImplementedError()\n","\n","class CountVectorizerSimpleBlock(BaseBlock):\n","    \"\"\"CountVectorizerのベクトルをそのまま返す block\"\"\"\n","    def __init__(self, column: str, master_df=None, max_features=50, ngram_range=(1,1)):\n","        \"\"\"\n","        args:\n","            column: str\n","                変換対象のカラム名\n","        \"\"\"\n","        self.column = column\n","        self.master_df=master_df\n","        self.max_features=max_features\n","        self.ngram_range=ngram_range\n","        self.param_prefix = f\"col={column}_feats={max_features}_ngram={''.join([str(i) for i in self.ngram_range])}\"\n","\n","    def preprocess(self, input_df):\n","        x = text_normalization(input_df[self.column])\n","        return x\n","\n","    def fit(self, \n","            input_df, \n","            y=None\n","           ):\n","        master_df = input_df if self.master_df is None else self.master_df\n","        text = self.preprocess(master_df)\n","        self.vectorizer_ = CountVectorizer(max_features=self.max_features, ngram_range=self.ngram_range)\n","\n","        self.vectorizer_.fit(text)\n","        self.prefix = 'countvec'\n","        return self.transform(input_df)\n","\n","    def transform(self, input_df):\n","        text = self.preprocess(input_df)\n","        z = self.vectorizer_.transform(text)\n","\n","        out_df = pd.DataFrame(z.toarray())\n","        out_df.columns = self.vectorizer_.get_feature_names()\n","        return out_df.add_prefix(f'{self.prefix}_')"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"iAse0IDWDjho","executionInfo":{"status":"ok","timestamp":1627883734046,"user_tz":-540,"elapsed":13,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# Dataset用のClass。\n","class LitDataset(Dataset):\n","    def __init__(self, df, tfidf, inference_only=False):\n","        super().__init__()\n","\n","        self.df = df        \n","        self.inference_only = inference_only # Testデータ用フラグ\n","        self.text = df.excerpt.tolist() # 分析対象カラムをlistにする。(分かち書きではなく、Seriesをlistへ変換するような処理)\n","        #self.text = [text.replace(\"\\n\", \" \") for text in self.text] # 単語単位で分かち書きする場合\n","        #self.text_len = text_normalization(df.excerpt).map(lambda x: [0 if i >= len(x.split(' ')) else len(x.split(' ')[i]) for i in range(132)])\n","\n","        # FEAT_TEXT DESC\n","        desc_block = TextDescriptionBlock('excerpt')\n","        sent_block = SentenceDescriptionBlock('excerpt')\n","        text_desc = desc_block.fit(self.df)\n","        text_sent = sent_block.fit(self.df)\n","        self.text_feats = pd.concat([text_desc, text_sent], axis='columns')\n","        # FEAT_TFIDF\n","        self.tfidf = tfidf # fit済みのものを入力する。（クラス内ではtransformのみ行う）\n","        self.tfidf_vector = tfidf.transform(df).values\n","\n","        if not self.inference_only:\n","            self.target = torch.tensor(df.target.values, dtype=torch.float32) # trainのみ、targetをtensorに変換\n","            self.standard_error = torch.tensor(df.standard_error.values, dtype=torch.float32) \n","\n","        self.encoded = tokenizer.batch_encode_plus( # textをtokenize\n","            self.text,\n","            padding = 'max_length',            \n","            max_length = MAX_LEN,\n","            truncation = True, # 最大長を超える文字は切り捨て\n","            return_attention_mask=True\n","        )        \n"," \n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    \n","    def __getitem__(self, index): # 変換結果を返す\n","        input_ids = torch.tensor(self.encoded['input_ids'][index])\n","        attention_mask = torch.tensor(self.encoded['attention_mask'][index])\n","        #input_len = torch.tensor(self.text_len.iloc[index], dtype=torch.float32)\n","        input_desc = torch.tensor(self.text_feats.values[index], dtype=torch.float32)\n","        input_tfidf = torch.tensor(self.tfidf_vector[index, :], dtype=torch.float32)\n","\n","        if self.inference_only:\n","            return (input_ids, attention_mask, input_desc, input_tfidf)            \n","        else:\n","            target = self.target[index]\n","            standard_error = self.standard_error[index]\n","            return (input_ids, attention_mask, input_desc, input_tfidf, target, standard_error)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"PmEiwD6Dqk4Q","executionInfo":{"status":"ok","timestamp":1627883734047,"user_tz":-540,"elapsed":13,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 検証\n","#litds = LitDataset(train_kf_df.loc[train_indices])\n","#litds[0][2].shape"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"vhjZwnZNoU1i","executionInfo":{"status":"ok","timestamp":1627883734047,"user_tz":-540,"elapsed":12,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 検証\n","#litds = LitDataset(train_kf_df)\n","#litds[0][2].shape"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KKtdy32wXecG"},"source":["# Model\n","The model is inspired by the one from [Maunish](https://www.kaggle.com/maunish/clrp-roberta-svm)."]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.649629Z","iopub.execute_input":"2021-07-04T06:26:40.650066Z","iopub.status.idle":"2021-07-04T06:26:40.666374Z","shell.execute_reply.started":"2021-07-04T06:26:40.650002Z","shell.execute_reply":"2021-07-04T06:26:40.665211Z"},"trusted":true,"id":"BpkxjXEUXecH","executionInfo":{"status":"ok","timestamp":1627883734048,"user_tz":-540,"elapsed":13,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["class LitModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        config = AutoConfig.from_pretrained(ROBERTA_PATH) # pretrainedからconfigを読み込み\n","        config.update({\"output_hidden_states\":True, # config更新: embedding層を抽出\n","                       \"hidden_dropout_prob\": 0.0, # config更新: dropoutしない\n","                       \"layer_norm_eps\": 1e-7}) # config更新: layer normalizationのepsilon                      \n","        \n","        self.roberta = AutoModel.from_pretrained(ROBERTA_PATH, config=config)\n","            \n","        self.attention = nn.Sequential(# attentionレイヤー            \n","            nn.Linear(config.hidden_size, 512),      \n","            nn.Tanh(),                       \n","            nn.Linear(512, 1),\n","            nn.Softmax(dim=1)\n","        )\n","\n","        self.numeric_feats = nn.Sequential(\n","            nn.Linear(74, 74),\n","            nn.BatchNorm1d(74),\n","            nn.ReLU(),\n","            nn.Dropout(0.2),\n","            nn.Linear(74, 74),\n","            nn.BatchNorm1d(74),\n","            nn.ReLU(),\n","            nn.Dropout(0.2)\n","        )\n","\n","        self.tfidf_feats = nn.Sequential(\n","            nn.Linear(TFIDF_MAX_FEAT, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 64),\n","            nn.ReLU(),\n","            nn.Linear(64, 64)\n","        )\n","\n","        self.regressor = nn.Sequential( # target、stderror                  \n","            nn.Linear(config.hidden_size + 74 + 64, 2),\n","        )\n","\n","        #self.bin_class = nn.Sequential( # target_sign\n","        #    nn.Linear(config.hidden_size + 64, 1),\n","        #    nn.Dropout(p=0.2),\n","        #    nn.Sigmoid()                       \n","        #)\n","\n","\n","    def forward(self, input_ids, attention_mask, input_desc, input_tfidf):\n","        roberta_output = self.roberta(input_ids=input_ids, # robertaに入力データを流し、出力としてrobertaモデル(layerの複合体)を得る\n","                                      attention_mask=attention_mask)     \n","        # attention_pooling\n","        last_hidden_state = roberta_output.hidden_states[-1] # robertaモデルの最後のlayerを得る\n","        weights = self.attention(last_hidden_state) # robertaの最後のlayerをattentionへ入力し、出力として重みを得る                \n","        context_vector = torch.sum(weights * last_hidden_state, dim=1) # 重み×最後の層を足し合わせて文書ベクトルとする。\n","        # word_length_conv1d\n","        #input_chnl = input_len.unsqueeze(1)\n","        #conv1_layers = self.conv1_layers(input_chnl)\n","        #conv1_layers_v = conv1_layers.view(conv1_layers.size(0),-1)\n","\n","        # numeric_feats\n","        numeric_feats = self.numeric_feats(input_desc)\n","        tfidf_feats = self.tfidf_feats(input_tfidf)\n","\n","        # https://www.kaggle.com/rhtsingh/utilizing-transformer-representations-efficiently\n","        # last_hidden_state = roberta_output[0]\n","        # input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        # sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        # sum_mask = input_mask_expanded.sum(1)\n","        # sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        # mean_embeddings = sum_embeddings / sum_mask\n","        cat_layers = torch.cat([context_vector, numeric_feats, tfidf_feats], dim=1)\n","        return self.regressor(cat_layers)\n","        \n","        # Now we reduce the context vector to the prediction score.\n","        #return self.regressor(mean_embeddings) # 文書ベクトルを線形層に入力し、targetを出力する"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.672515Z","iopub.execute_input":"2021-07-04T06:26:40.672944Z","iopub.status.idle":"2021-07-04T06:26:40.684593Z","shell.execute_reply.started":"2021-07-04T06:26:40.672908Z","shell.execute_reply":"2021-07-04T06:26:40.683569Z"},"trusted":true,"id":"bB4jvQTxXecH","executionInfo":{"status":"ok","timestamp":1627883734048,"user_tz":-540,"elapsed":12,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["def eval_mse(model, data_loader):\n","    \"\"\"Evaluates the mean squared error of the |model| on |data_loader|\"\"\"\n","    model.eval() # evalモードを選択。Batch Normとかdropoutをしなくなる           \n","    mse_mean_sum = 0\n","    mse_std_sum = 0\n","\n","    with torch.no_grad(): # 勾配の計算をしない(予測のみ行う)\n","        for batch_num, (input_ids, attention_mask, input_feats, input_tfidf, target, standard_error) in enumerate(data_loader): # data_loaderからinput, attentin_mask, targetをbatchごとに取り出す\n","            input_ids = input_ids.to(DEVICE)   \n","            attention_mask = attention_mask.to(DEVICE)  \n","            input_feats = input_feats.to(DEVICE) \n","            input_tfidf = input_tfidf.to(DEVICE)\n","            target = target.to(DEVICE)\n","            standard_error = standard_error.to(DEVICE)\n","            \n","            output = model(input_ids, attention_mask, input_feats, input_tfidf) # 取得した値をモデルへ入力し、出力として予測値を得る。\n","\n","            mse_mean_sum += nn.MSELoss(reduction=\"sum\")(output[:,0].flatten(), target).item() # 誤差の合計を得る(Batchごとに計算した誤差を足し上げる)\n","            mse_std_sum += nn.MSELoss(reduction=\"sum\")(output[:,1].flatten(), standard_error).item() # 誤差の合計を得る(Batchごとに計算した誤差を足し上げる)\n","\n","\n","    del input_ids\n","    del attention_mask\n","\n","    mse_mean_result = mse_mean_sum / len(data_loader.dataset)\n","    mse_std_result = mse_std_sum / len(data_loader.dataset)\n","\n","    return mse_mean_result, mse_std_result"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.690155Z","iopub.execute_input":"2021-07-04T06:26:40.692530Z","iopub.status.idle":"2021-07-04T06:26:40.703425Z","shell.execute_reply.started":"2021-07-04T06:26:40.692488Z","shell.execute_reply":"2021-07-04T06:26:40.702366Z"},"trusted":true,"id":"47bDno_LXecI","executionInfo":{"status":"ok","timestamp":1627883734049,"user_tz":-540,"elapsed":12,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 推論結果を返す\n","def predict(model, data_loader):\n","    \"\"\"Returns an np.array with predictions of the |model| on |data_loader|\"\"\"\n","    model.eval() # evalモード(dropout, batch_normしない)\n","\n","    result = np.zeros(len(data_loader.dataset)) # 結果をdataset長のzero配列として用意\n","    index = 0\n","    \n","    with torch.no_grad(): # 勾配の計算をしないblock(inputすると、現状の重みによる推論結果を返す)\n","        for batch_num, (input_ids, attention_mask, input_feats, input_tfidf) in enumerate(data_loader): # data_loaderからbatchごとにinputを得る\n","            input_ids = input_ids.to(DEVICE)\n","            attention_mask = attention_mask.to(DEVICE)\n","            input_feats = input_feats.to(DEVICE)\n","            input_tfidf = input_tfidf.to(DEVICE)\n","                        \n","            output = model(input_ids, attention_mask, input_feats, input_tfidf) # modelにinputを入力し、予測結果を得る。\n","            output_target = output[:,0]\n","\n","            result[index : index + output_target.shape[0]] = output_target.flatten().to(\"cpu\") # result[index ~ predの長さ]へ、予測結果を格納\n","            index += output_target.shape[0] # indexを更新\n","\n","    return result # 全batchで推論が終わったら、結果を返す"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.708605Z","iopub.execute_input":"2021-07-04T06:26:40.709024Z","iopub.status.idle":"2021-07-04T06:26:40.730675Z","shell.execute_reply.started":"2021-07-04T06:26:40.708983Z","shell.execute_reply":"2021-07-04T06:26:40.729705Z"},"trusted":true,"id":"oInneuAmXecI","executionInfo":{"status":"ok","timestamp":1627883734049,"user_tz":-540,"elapsed":12,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 学習\n","def train(model, # モデル\n","          model_path, # モデルのアウトプット先\n","          train_loader, # train-setのdata_loader\n","          val_loader, # valid-setのdata_loader\n","          optimizer, # optimizer\n","          scheduler=None, # scheduler, デフォルトはNone\n","          num_epochs=NUM_EPOCHS # epoch数、notebook冒頭で指定した値\n","         ):    \n","    \n","    best_val_rmse = None\n","    best_val_sign_bce = None\n","    best_epoch = 0\n","    step = 0\n","    last_eval_step = 0\n","    eval_period = EVAL_SCHEDULE[0][1] # eval期間(って何？) 冒頭で決めたEVAL_SCHEDULEの最初のtupleの[1]を取得\n","\n","    start = time.time() # 時間計測用\n","\n","    for epoch in range(num_epochs): # 指定したEpoch数だけ繰り返し\n","        val_rmse = None         \n","\n","        for batch_num, (input_ids, attention_mask, input_feats, input_tfidf, target, standard_error) in enumerate(train_loader): # train_loaderからinput, targetを取得\n","            input_ids = input_ids.to(DEVICE) # inputをDEVICEへ突っ込む\n","            attention_mask = attention_mask.to(DEVICE)   \n","            input_feats = input_feats.to(DEVICE)\n","            input_tfidf = input_tfidf.to(DEVICE)\n","            target = target.to(DEVICE)\n","            standard_error = standard_error.to(DEVICE)\n","\n","            optimizer.zero_grad() # 勾配を初期化            \n","            model.train() # 学習モード開始\n","\n","            # https://www.kaggle.com/c/commonlitreadabilityprize/discussion/239421\n","            output = model(input_ids, attention_mask, input_feats, input_tfidf) # input,attention_maskを入力し、予測結果を得る\n","            p = torch.distributions.Normal(output[:,0], torch.sqrt(output[:,1]**2))\n","            q = torch.distributions.Normal(target, standard_error)\n","            kl_vector = torch.distributions.kl_divergence(p, q)\n","\n","            loss = kl_vector.mean()\n","\n","            loss.backward() \n","            optimizer.step() # 重みを更新する\n","\n","            if scheduler:\n","                scheduler.step() # schedulerが与えられた場合は、schedulerの学習率更新\n","            \n","            if step >= last_eval_step + eval_period: # batchを回すごとにstepを増やしていって、「前回evalしたstep + eval_period(16)」を超えたら実行。\n","                print(gpuinfo())\n","                # Evaluate the model on val_loader.\n","                elapsed_seconds = time.time() - start # 経過時間\n","                num_steps = step - last_eval_step # 経過ステップ数\n","                print(f\"\\n{num_steps} steps took {elapsed_seconds:0.3} seconds\")\n","                last_eval_step = step # 前回stepの更新\n","                \n","                # valid-setによるrmse計算\n","                train_kldiv = loss\n","                \n","                val_mse_mean, val_mse_std = eval_mse(model, val_loader)\n","                val_rmse_mean = math.sqrt(val_mse_mean)                            \n","                val_rmse_std = math.sqrt(val_mse_std)                            \n","\n","                print(f\"Epoch: {epoch} batch_num: {batch_num}\")\n","                print(f\"train_kldiv: {train_kldiv:0.4}\"\n","                      )\n","                print(f\"val_rmse_mean: {val_rmse_mean:0.4}\",\n","                      f\"val_rmse_std: {val_rmse_std:0.4}\"\n","                      )\n","\n","                for rmse, period in EVAL_SCHEDULE: # eval_periodをvalid-rmseで切り替える処理\n","                    if val_rmse_mean >= rmse: # valid rmseをEVAL_SCHEDULEと比較し、0項 > valid rmseとなるまで回す : EVAL_SCHEDULE = [(0.50, 16), (0.49, 8), (0.48, 4), (0.47, 2), (-1., 1)]\n","                        eval_period = period # eval_periodを更新\n","                        break                               \n","\n","                if not best_val_rmse or val_rmse_mean < best_val_rmse: # 初回(best_val_rmse==None), またはbest_val_rmseを更新したらモデルを保存する\n","                    best_val_rmse = val_rmse_mean\n","                    best_epoch = epoch\n","                    torch.save(model.state_dict(), model_path) # 最高の自分を保存\n","                    print(f\"New best_val_rmse: {best_val_rmse:0.4}\")\n","                else:       \n","                    print(f\"Still best_val_rmse: {best_val_rmse:0.4}\", # 更新されない場合は、元のスコアを表示\n","                          f\"(from epoch {best_epoch})\")      \n","\n","                start = time.time()\n","            \n","            # batchごとにメモリ解放\n","            del input_ids\n","            del attention_mask\n","            torch.cuda.empty_cache()                                            \n","            step += 1\n","    \n","    return best_val_rmse"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.735798Z","iopub.execute_input":"2021-07-04T06:26:40.738398Z","iopub.status.idle":"2021-07-04T06:26:40.750876Z","shell.execute_reply.started":"2021-07-04T06:26:40.738356Z","shell.execute_reply":"2021-07-04T06:26:40.749635Z"},"trusted":true,"id":"rMY0fjXwXecJ","executionInfo":{"status":"ok","timestamp":1627883734050,"user_tz":-540,"elapsed":12,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# optimizerの作成\n","def create_optimizer(model):\n","    parameters = []\n","\n","    named_parameters = list(model.named_parameters()) # モデルパラメータの取得\n","    roberta_parameters = list(model.roberta.named_parameters())[:-2] # パラメータをroberta用、attention用、regressor用に格納。(直接引っ張ってくる形式に変更)\n","\n","    attention_parameters = list(model.attention.named_parameters())\n","    attention_group = [{'params': params, 'lr': 2e-5} for (name, params) in attention_parameters] # attention用パラメータをリストとして取得\n","    parameters += attention_group\n","\n","    regressor_parameters = list(model.regressor.named_parameters())\n","    regressor_group = [{'params': params, 'lr': 2e-5} for (name, params) in regressor_parameters] # reg用パラメータをリストとして取得\n","    parameters += regressor_group\n","\n","    numeric_feats_parameters = list(model.numeric_feats.named_parameters())\n","    numeric_feats_group = [{'params': params, 'lr': 2e-5} for (name, params) in numeric_feats_parameters] # reg用パラメータをリストとして取得\n","    parameters += numeric_feats_group\n","\n","    tfidf_feats_parameters = list(model.tfidf_feats.named_parameters())\n","    tfidf_feats_group = [{'params': params, 'lr': 2e-5} for (name, params) in tfidf_feats_parameters] # reg用パラメータをリストとして取得\n","    parameters += tfidf_feats_group\n","\n","    for layer_num, (name, params) in enumerate(roberta_parameters): # レイヤーごとにname, paramsを取得していろんな処理\n","        weight_decay = 0.0 if \"bias\" in name else 0.01\n","\n","        lr = 8e-6\n","\n","        if layer_num >= 69:        \n","            lr = 2e-5\n","\n","        if layer_num >= 133:\n","            lr = 4e-5\n","\n","        parameters.append({\"params\": params,\n","                           \"weight_decay\": weight_decay,\n","                           \"lr\": lr})\n","\n","    return AdamW(parameters) # 最終的に、AdamWにパラメータを入力する。\n"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"4PLKHwvKtNBn","executionInfo":{"status":"ok","timestamp":1627883734050,"user_tz":-540,"elapsed":12,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["def train_and_save_model(train_indices, val_indices, model_path, feat_suffix):\n","    tfidf = CountVectorizerSimpleBlock('excerpt', max_features=TFIDF_MAX_FEAT)\n","    df_tfidf = tfidf.fit(train_kf_df.loc[train_indices]) # TODO: fit_transformみたいなメソッド作って、fitではdfが返らないようにする。\n","\n","    with open(f'TFIDF_{feat_suffix}', 'wb') as f:\n","      pickle.dump(tfidf, f)\n","\n","    train_dataset = LitDataset(train_kf_df.loc[train_indices], tfidf) # train, validのDataset\n","    val_dataset = LitDataset(train_kf_df.loc[val_indices], tfidf)\n","        \n","    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n","                              drop_last=True, shuffle=True, num_workers=2) # train, validのDataLoader\n","    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n","                            drop_last=False, shuffle=False, num_workers=2)    \n","\n","    model = LitModel().to(DEVICE) # modelをDEVICEへぶち込む\n","    optimizer = create_optimizer(model) # optimizerをモデルから作成\n","    scheduler = get_cosine_schedule_with_warmup( # schedulerを作成\n","        optimizer,\n","        num_training_steps=NUM_EPOCHS * len(train_loader),\n","        num_warmup_steps=50)    \n","    rmse = train(model, model_path, train_loader, val_loader, optimizer, scheduler=scheduler)\n","\n","    del train_dataset\n","    del val_dataset\n","    del train_loader\n","    del val_loader\n","    del model\n","    del optimizer\n","    del scheduler\n","    gc.collect() \n","    torch.cuda.empty_cache()\n","    return rmse"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.755813Z","iopub.execute_input":"2021-07-04T06:26:40.758373Z","iopub.status.idle":"2021-07-04T06:27:12.493221Z","shell.execute_reply.started":"2021-07-04T06:26:40.758265Z","shell.execute_reply":"2021-07-04T06:27:12.490139Z"},"trusted":true,"id":"k2LGJD3XXecK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627892112991,"user_tz":-540,"elapsed":8378952,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"bbbcf23e-9504-4b75-f0cb-cda52c73da33"},"source":["# 実行処理。 KFold & 学習\n","SEED = 1000\n","list_val_rmse = []\n","\n","for fold in sorted(train_kf_df['kfold'].unique()):\n","    print(f\"\\nFold {fold + 1}/{NUM_FOLDS}\")\n","    print(gpuinfo())\n","    model_path = f\"model_{fold + 1}.pth\" # model_fold数_.pth\n","    feat_suffix = f\"CntVec_{fold + 1}.pkl\" \n","\n","    set_random_seed(SEED + fold) # SEEDはfold別に変わるようにする\n","\n","    train_indices = (train_kf_df['kfold'] != fold)\n","    val_indices = (train_kf_df['kfold'] == fold)\n","    list_val_rmse.append(train_and_save_model(train_indices, val_indices, model_path, feat_suffix))\n","    print(\"\\nPerformance estimates:\")\n","    print(list_val_rmse)\n","    print(\"Mean:\", np.array(list_val_rmse).mean())\n","    print(gpuinfo())"],"execution_count":27,"outputs":[{"output_type":"stream","text":["\n","Fold 1/5\n","{'total_MiB': 16280, 'used_MiB': 2}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","64 steps took 82.5 seconds\n","Epoch: 0 batch_num: 64\n","train_kldiv: 0.816\n","val_rmse_mean: 0.6652 val_rmse_std: 1.039\n","New best_val_rmse: 0.6652\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","64 steps took 81.5 seconds\n","Epoch: 0 batch_num: 128\n","train_kldiv: 1.014\n","val_rmse_mean: 0.8185 val_rmse_std: 0.9571\n","Still best_val_rmse: 0.6652 (from epoch 0)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","64 steps took 81.6 seconds\n","Epoch: 1 batch_num: 4\n","train_kldiv: 0.4597\n","val_rmse_mean: 0.5841 val_rmse_std: 0.988\n","New best_val_rmse: 0.5841\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","64 steps took 81.5 seconds\n","Epoch: 1 batch_num: 68\n","train_kldiv: 0.4165\n","val_rmse_mean: 0.5315 val_rmse_std: 0.9609\n","New best_val_rmse: 0.5315\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 40.9 seconds\n","Epoch: 1 batch_num: 100\n","train_kldiv: 0.5293\n","val_rmse_mean: 0.5254 val_rmse_std: 0.9698\n","New best_val_rmse: 0.5254\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 40.9 seconds\n","Epoch: 1 batch_num: 132\n","train_kldiv: 0.3329\n","val_rmse_mean: 0.5189 val_rmse_std: 0.9609\n","New best_val_rmse: 0.5189\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 1 batch_num: 164\n","train_kldiv: 0.319\n","val_rmse_mean: 0.5303 val_rmse_std: 0.9962\n","Still best_val_rmse: 0.5189 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.1 seconds\n","Epoch: 2 batch_num: 8\n","train_kldiv: 0.09586\n","val_rmse_mean: 0.5165 val_rmse_std: 0.9806\n","New best_val_rmse: 0.5165\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 2 batch_num: 40\n","train_kldiv: 0.1593\n","val_rmse_mean: 0.5232 val_rmse_std: 0.9459\n","Still best_val_rmse: 0.5165 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 2 batch_num: 72\n","train_kldiv: 0.09823\n","val_rmse_mean: 0.5022 val_rmse_std: 0.9698\n","New best_val_rmse: 0.5022\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 2 batch_num: 104\n","train_kldiv: 0.1739\n","val_rmse_mean: 0.4901 val_rmse_std: 1.002\n","New best_val_rmse: 0.4901\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 40.9 seconds\n","Epoch: 2 batch_num: 136\n","train_kldiv: 0.09404\n","val_rmse_mean: 0.5059 val_rmse_std: 0.9809\n","Still best_val_rmse: 0.4901 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 2 batch_num: 168\n","train_kldiv: 0.1419\n","val_rmse_mean: 0.4949 val_rmse_std: 0.9861\n","Still best_val_rmse: 0.4901 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.2 seconds\n","Epoch: 3 batch_num: 12\n","train_kldiv: 0.0855\n","val_rmse_mean: 0.5113 val_rmse_std: 0.9855\n","Still best_val_rmse: 0.4901 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 3 batch_num: 44\n","train_kldiv: 0.0484\n","val_rmse_mean: 0.5026 val_rmse_std: 0.9828\n","Still best_val_rmse: 0.4901 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 3 batch_num: 76\n","train_kldiv: 0.06555\n","val_rmse_mean: 0.5102 val_rmse_std: 0.9854\n","Still best_val_rmse: 0.4901 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 3 batch_num: 108\n","train_kldiv: 0.133\n","val_rmse_mean: 0.5022 val_rmse_std: 0.9762\n","Still best_val_rmse: 0.4901 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 3 batch_num: 140\n","train_kldiv: 0.03566\n","val_rmse_mean: 0.5057 val_rmse_std: 0.9964\n","Still best_val_rmse: 0.4901 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 3 batch_num: 172\n","train_kldiv: 0.0597\n","val_rmse_mean: 0.5002 val_rmse_std: 0.9827\n","Still best_val_rmse: 0.4901 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.1 seconds\n","Epoch: 4 batch_num: 16\n","train_kldiv: 0.03776\n","val_rmse_mean: 0.5 val_rmse_std: 0.9729\n","Still best_val_rmse: 0.4901 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 40.9 seconds\n","Epoch: 4 batch_num: 48\n","train_kldiv: 0.04865\n","val_rmse_mean: 0.4969 val_rmse_std: 0.9913\n","Still best_val_rmse: 0.4901 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 40.9 seconds\n","Epoch: 4 batch_num: 80\n","train_kldiv: 0.03462\n","val_rmse_mean: 0.4974 val_rmse_std: 0.9787\n","Still best_val_rmse: 0.4901 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 4 batch_num: 112\n","train_kldiv: 0.05354\n","val_rmse_mean: 0.4991 val_rmse_std: 0.985\n","Still best_val_rmse: 0.4901 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 40.9 seconds\n","Epoch: 4 batch_num: 144\n","train_kldiv: 0.04568\n","val_rmse_mean: 0.4988 val_rmse_std: 0.9851\n","Still best_val_rmse: 0.4901 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 40.9 seconds\n","Epoch: 4 batch_num: 176\n","train_kldiv: 0.07511\n","val_rmse_mean: 0.4987 val_rmse_std: 0.9849\n","Still best_val_rmse: 0.4901 (from epoch 2)\n","\n","Performance estimates:\n","[0.4900590584773388]\n","Mean: 0.4900590584773388\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 2/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","64 steps took 82.8 seconds\n","Epoch: 0 batch_num: 64\n","train_kldiv: 1.168\n","val_rmse_mean: 0.7856 val_rmse_std: 0.08857\n","New best_val_rmse: 0.7856\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","64 steps took 81.5 seconds\n","Epoch: 0 batch_num: 128\n","train_kldiv: 0.7047\n","val_rmse_mean: 0.6084 val_rmse_std: 0.07649\n","New best_val_rmse: 0.6084\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","64 steps took 81.7 seconds\n","Epoch: 1 batch_num: 4\n","train_kldiv: 0.4985\n","val_rmse_mean: 0.5507 val_rmse_std: 0.06987\n","New best_val_rmse: 0.5507\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","64 steps took 81.6 seconds\n","Epoch: 1 batch_num: 68\n","train_kldiv: 0.6909\n","val_rmse_mean: 0.5406 val_rmse_std: 0.07082\n","New best_val_rmse: 0.5406\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 1 batch_num: 100\n","train_kldiv: 0.6593\n","val_rmse_mean: 0.4985 val_rmse_std: 0.06988\n","New best_val_rmse: 0.4985\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 1 batch_num: 132\n","train_kldiv: 0.4498\n","val_rmse_mean: 0.5702 val_rmse_std: 0.06528\n","Still best_val_rmse: 0.4985 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","64 steps took 81.8 seconds\n","Epoch: 2 batch_num: 8\n","train_kldiv: 0.2671\n","val_rmse_mean: 0.4958 val_rmse_std: 0.06337\n","New best_val_rmse: 0.4958\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 2 batch_num: 40\n","train_kldiv: 0.2266\n","val_rmse_mean: 0.4961 val_rmse_std: 0.06401\n","Still best_val_rmse: 0.4958 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 2 batch_num: 72\n","train_kldiv: 0.3397\n","val_rmse_mean: 0.4929 val_rmse_std: 0.06447\n","New best_val_rmse: 0.4929\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 2 batch_num: 104\n","train_kldiv: 0.1694\n","val_rmse_mean: 0.4912 val_rmse_std: 0.07228\n","New best_val_rmse: 0.4912\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 2 batch_num: 136\n","train_kldiv: 0.293\n","val_rmse_mean: 0.4849 val_rmse_std: 0.06245\n","New best_val_rmse: 0.4849\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 2 batch_num: 168\n","train_kldiv: 0.1722\n","val_rmse_mean: 0.4828 val_rmse_std: 0.0674\n","New best_val_rmse: 0.4828\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.1 seconds\n","Epoch: 3 batch_num: 12\n","train_kldiv: 0.148\n","val_rmse_mean: 0.5042 val_rmse_std: 0.07165\n","Still best_val_rmse: 0.4828 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 40.9 seconds\n","Epoch: 3 batch_num: 44\n","train_kldiv: 0.1964\n","val_rmse_mean: 0.4992 val_rmse_std: 0.07331\n","Still best_val_rmse: 0.4828 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 40.9 seconds\n","Epoch: 3 batch_num: 76\n","train_kldiv: 0.1096\n","val_rmse_mean: 0.492 val_rmse_std: 0.06924\n","Still best_val_rmse: 0.4828 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 40.9 seconds\n","Epoch: 3 batch_num: 108\n","train_kldiv: 0.1434\n","val_rmse_mean: 0.4838 val_rmse_std: 0.0649\n","Still best_val_rmse: 0.4828 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 40.9 seconds\n","Epoch: 3 batch_num: 140\n","train_kldiv: 0.0743\n","val_rmse_mean: 0.483 val_rmse_std: 0.06108\n","Still best_val_rmse: 0.4828 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 40.9 seconds\n","Epoch: 3 batch_num: 172\n","train_kldiv: 0.1579\n","val_rmse_mean: 0.4863 val_rmse_std: 0.06428\n","Still best_val_rmse: 0.4828 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 4 batch_num: 16\n","train_kldiv: 0.05985\n","val_rmse_mean: 0.4802 val_rmse_std: 0.05938\n","New best_val_rmse: 0.4802\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 40.9 seconds\n","Epoch: 4 batch_num: 48\n","train_kldiv: 0.08931\n","val_rmse_mean: 0.4843 val_rmse_std: 0.06281\n","Still best_val_rmse: 0.4802 (from epoch 4)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 40.9 seconds\n","Epoch: 4 batch_num: 80\n","train_kldiv: 0.1423\n","val_rmse_mean: 0.4827 val_rmse_std: 0.06204\n","Still best_val_rmse: 0.4802 (from epoch 4)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 40.9 seconds\n","Epoch: 4 batch_num: 112\n","train_kldiv: 0.1055\n","val_rmse_mean: 0.4803 val_rmse_std: 0.06139\n","Still best_val_rmse: 0.4802 (from epoch 4)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 40.9 seconds\n","Epoch: 4 batch_num: 144\n","train_kldiv: 0.06767\n","val_rmse_mean: 0.4815 val_rmse_std: 0.05894\n","Still best_val_rmse: 0.4802 (from epoch 4)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 40.9 seconds\n","Epoch: 4 batch_num: 176\n","train_kldiv: 0.1391\n","val_rmse_mean: 0.4824 val_rmse_std: 0.06491\n","Still best_val_rmse: 0.4802 (from epoch 4)\n","\n","Performance estimates:\n","[0.4900590584773388, 0.48023838745387815]\n","Mean: 0.4851487229656085\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 3/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","64 steps took 83.0 seconds\n","Epoch: 0 batch_num: 64\n","train_kldiv: 8.382\n","val_rmse_mean: 1.012 val_rmse_std: 1.129\n","New best_val_rmse: 1.012\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","64 steps took 81.6 seconds\n","Epoch: 0 batch_num: 128\n","train_kldiv: 0.9865\n","val_rmse_mean: 0.8413 val_rmse_std: 1.034\n","New best_val_rmse: 0.8413\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","64 steps took 81.8 seconds\n","Epoch: 1 batch_num: 4\n","train_kldiv: 1.018\n","val_rmse_mean: 0.6386 val_rmse_std: 0.9513\n","New best_val_rmse: 0.6386\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","64 steps took 81.6 seconds\n","Epoch: 1 batch_num: 68\n","train_kldiv: 0.8366\n","val_rmse_mean: 0.5922 val_rmse_std: 0.9549\n","New best_val_rmse: 0.5922\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","64 steps took 81.6 seconds\n","Epoch: 1 batch_num: 132\n","train_kldiv: 0.5789\n","val_rmse_mean: 0.5528 val_rmse_std: 0.9915\n","New best_val_rmse: 0.5528\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","64 steps took 81.8 seconds\n","Epoch: 2 batch_num: 8\n","train_kldiv: 0.8075\n","val_rmse_mean: 0.5266 val_rmse_std: 0.9571\n","New best_val_rmse: 0.5266\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 2 batch_num: 40\n","train_kldiv: 0.529\n","val_rmse_mean: 0.5283 val_rmse_std: 0.9858\n","Still best_val_rmse: 0.5266 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 2 batch_num: 72\n","train_kldiv: 0.5155\n","val_rmse_mean: 0.5463 val_rmse_std: 0.975\n","Still best_val_rmse: 0.5266 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 2 batch_num: 104\n","train_kldiv: 0.2166\n","val_rmse_mean: 0.5148 val_rmse_std: 0.9617\n","New best_val_rmse: 0.5148\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 2 batch_num: 136\n","train_kldiv: 0.4818\n","val_rmse_mean: 0.5745 val_rmse_std: 0.9683\n","Still best_val_rmse: 0.5148 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","64 steps took 81.7 seconds\n","Epoch: 3 batch_num: 12\n","train_kldiv: 0.4701\n","val_rmse_mean: 0.5011 val_rmse_std: 0.9995\n","New best_val_rmse: 0.5011\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.1 seconds\n","Epoch: 3 batch_num: 44\n","train_kldiv: 0.3065\n","val_rmse_mean: 0.5511 val_rmse_std: 0.9536\n","Still best_val_rmse: 0.5011 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","64 steps took 81.5 seconds\n","Epoch: 3 batch_num: 108\n","train_kldiv: 0.4799\n","val_rmse_mean: 0.5143 val_rmse_std: 0.9834\n","Still best_val_rmse: 0.5011 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 3 batch_num: 140\n","train_kldiv: 0.4995\n","val_rmse_mean: 0.5033 val_rmse_std: 0.9903\n","Still best_val_rmse: 0.5011 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 3 batch_num: 172\n","train_kldiv: 0.3234\n","val_rmse_mean: 0.4972 val_rmse_std: 0.9768\n","New best_val_rmse: 0.4972\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.2 seconds\n","Epoch: 4 batch_num: 16\n","train_kldiv: 0.1645\n","val_rmse_mean: 0.4925 val_rmse_std: 0.9847\n","New best_val_rmse: 0.4925\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 4 batch_num: 48\n","train_kldiv: 0.2321\n","val_rmse_mean: 0.4975 val_rmse_std: 0.9789\n","Still best_val_rmse: 0.4925 (from epoch 4)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 4 batch_num: 80\n","train_kldiv: 0.317\n","val_rmse_mean: 0.5044 val_rmse_std: 0.9926\n","Still best_val_rmse: 0.4925 (from epoch 4)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 4 batch_num: 112\n","train_kldiv: 0.2171\n","val_rmse_mean: 0.5078 val_rmse_std: 0.9817\n","Still best_val_rmse: 0.4925 (from epoch 4)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 4 batch_num: 144\n","train_kldiv: 0.2294\n","val_rmse_mean: 0.4956 val_rmse_std: 0.9744\n","Still best_val_rmse: 0.4925 (from epoch 4)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 4 batch_num: 176\n","train_kldiv: 0.2036\n","val_rmse_mean: 0.4951 val_rmse_std: 0.9714\n","Still best_val_rmse: 0.4925 (from epoch 4)\n","\n","Performance estimates:\n","[0.4900590584773388, 0.48023838745387815, 0.49249132763242986]\n","Mean: 0.48759625785454896\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 4/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","64 steps took 82.9 seconds\n","Epoch: 0 batch_num: 64\n","train_kldiv: 1.149\n","val_rmse_mean: 0.6783 val_rmse_std: 0.999\n","New best_val_rmse: 0.6783\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","64 steps took 81.6 seconds\n","Epoch: 0 batch_num: 128\n","train_kldiv: 1.1\n","val_rmse_mean: 0.6162 val_rmse_std: 0.9855\n","New best_val_rmse: 0.6162\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","64 steps took 81.8 seconds\n","Epoch: 1 batch_num: 4\n","train_kldiv: 0.5188\n","val_rmse_mean: 0.538 val_rmse_std: 0.9797\n","New best_val_rmse: 0.538\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 1 batch_num: 36\n","train_kldiv: 0.5056\n","val_rmse_mean: 0.5234 val_rmse_std: 0.9954\n","New best_val_rmse: 0.5234\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 1 batch_num: 68\n","train_kldiv: 0.3751\n","val_rmse_mean: 0.4961 val_rmse_std: 1.011\n","New best_val_rmse: 0.4961\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 40.9 seconds\n","Epoch: 1 batch_num: 100\n","train_kldiv: 0.2855\n","val_rmse_mean: 0.4974 val_rmse_std: 0.9887\n","Still best_val_rmse: 0.4961 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 40.9 seconds\n","Epoch: 1 batch_num: 132\n","train_kldiv: 0.2166\n","val_rmse_mean: 0.5024 val_rmse_std: 0.9736\n","Still best_val_rmse: 0.4961 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 40.9 seconds\n","Epoch: 1 batch_num: 164\n","train_kldiv: 0.6364\n","val_rmse_mean: 0.4914 val_rmse_std: 0.9904\n","New best_val_rmse: 0.4914\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.1 seconds\n","Epoch: 2 batch_num: 8\n","train_kldiv: 0.1889\n","val_rmse_mean: 0.5139 val_rmse_std: 1.03\n","Still best_val_rmse: 0.4914 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 2 batch_num: 40\n","train_kldiv: 0.5227\n","val_rmse_mean: 0.4899 val_rmse_std: 0.9677\n","New best_val_rmse: 0.4899\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 2 batch_num: 72\n","train_kldiv: 0.1782\n","val_rmse_mean: 0.5052 val_rmse_std: 0.9422\n","Still best_val_rmse: 0.4899 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 40.9 seconds\n","Epoch: 2 batch_num: 104\n","train_kldiv: 0.1012\n","val_rmse_mean: 0.4733 val_rmse_std: 0.9852\n","New best_val_rmse: 0.4733\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 40.9 seconds\n","Epoch: 2 batch_num: 136\n","train_kldiv: 0.3293\n","val_rmse_mean: 0.4729 val_rmse_std: 1.016\n","New best_val_rmse: 0.4729\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 40.9 seconds\n","Epoch: 2 batch_num: 168\n","train_kldiv: 0.1515\n","val_rmse_mean: 0.4709 val_rmse_std: 0.9863\n","New best_val_rmse: 0.4709\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.1 seconds\n","Epoch: 3 batch_num: 12\n","train_kldiv: 0.1805\n","val_rmse_mean: 0.4768 val_rmse_std: 0.9949\n","Still best_val_rmse: 0.4709 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 3 batch_num: 44\n","train_kldiv: 0.07917\n","val_rmse_mean: 0.4686 val_rmse_std: 0.9856\n","New best_val_rmse: 0.4686\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 40.9 seconds\n","Epoch: 3 batch_num: 76\n","train_kldiv: 0.1032\n","val_rmse_mean: 0.4656 val_rmse_std: 0.985\n","New best_val_rmse: 0.4656\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 40.9 seconds\n","Epoch: 3 batch_num: 108\n","train_kldiv: 0.06244\n","val_rmse_mean: 0.4655 val_rmse_std: 0.9825\n","New best_val_rmse: 0.4655\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 40.9 seconds\n","Epoch: 3 batch_num: 140\n","train_kldiv: 0.09682\n","val_rmse_mean: 0.4719 val_rmse_std: 0.9838\n","Still best_val_rmse: 0.4655 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 40.9 seconds\n","Epoch: 3 batch_num: 172\n","train_kldiv: 0.04843\n","val_rmse_mean: 0.4689 val_rmse_std: 0.9841\n","Still best_val_rmse: 0.4655 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.1 seconds\n","Epoch: 4 batch_num: 16\n","train_kldiv: 0.09294\n","val_rmse_mean: 0.4675 val_rmse_std: 0.9967\n","Still best_val_rmse: 0.4655 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 40.9 seconds\n","Epoch: 4 batch_num: 48\n","train_kldiv: 0.04023\n","val_rmse_mean: 0.467 val_rmse_std: 0.9979\n","Still best_val_rmse: 0.4655 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 40.9 seconds\n","Epoch: 4 batch_num: 80\n","train_kldiv: 0.06876\n","val_rmse_mean: 0.4662 val_rmse_std: 0.9907\n","Still best_val_rmse: 0.4655 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 40.9 seconds\n","Epoch: 4 batch_num: 112\n","train_kldiv: 0.1146\n","val_rmse_mean: 0.4663 val_rmse_std: 0.9822\n","Still best_val_rmse: 0.4655 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 40.9 seconds\n","Epoch: 4 batch_num: 144\n","train_kldiv: 0.1204\n","val_rmse_mean: 0.4689 val_rmse_std: 0.9916\n","Still best_val_rmse: 0.4655 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 40.9 seconds\n","Epoch: 4 batch_num: 176\n","train_kldiv: 0.04924\n","val_rmse_mean: 0.4692 val_rmse_std: 1.007\n","Still best_val_rmse: 0.4655 (from epoch 3)\n","\n","Performance estimates:\n","[0.4900590584773388, 0.48023838745387815, 0.49249132763242986, 0.46549496634707227]\n","Mean: 0.4820709349776798\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 5/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","64 steps took 82.7 seconds\n","Epoch: 0 batch_num: 64\n","train_kldiv: 0.5788\n","val_rmse_mean: 0.7457 val_rmse_std: 0.9497\n","New best_val_rmse: 0.7457\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","64 steps took 81.7 seconds\n","Epoch: 0 batch_num: 128\n","train_kldiv: 0.472\n","val_rmse_mean: 0.5593 val_rmse_std: 0.9349\n","New best_val_rmse: 0.5593\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","64 steps took 81.9 seconds\n","Epoch: 1 batch_num: 4\n","train_kldiv: 0.4155\n","val_rmse_mean: 0.5835 val_rmse_std: 1.003\n","Still best_val_rmse: 0.5593 (from epoch 0)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","64 steps took 81.7 seconds\n","Epoch: 1 batch_num: 68\n","train_kldiv: 0.5476\n","val_rmse_mean: 0.5288 val_rmse_std: 0.9818\n","New best_val_rmse: 0.5288\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.1 seconds\n","Epoch: 1 batch_num: 100\n","train_kldiv: 0.8962\n","val_rmse_mean: 0.5461 val_rmse_std: 0.9981\n","Still best_val_rmse: 0.5288 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.2 seconds\n","Epoch: 1 batch_num: 132\n","train_kldiv: 0.4392\n","val_rmse_mean: 0.496 val_rmse_std: 1.003\n","New best_val_rmse: 0.496\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.2 seconds\n","Epoch: 1 batch_num: 164\n","train_kldiv: 0.8106\n","val_rmse_mean: 0.5926 val_rmse_std: 1.002\n","Still best_val_rmse: 0.496 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","64 steps took 81.9 seconds\n","Epoch: 2 batch_num: 40\n","train_kldiv: 0.2358\n","val_rmse_mean: 0.4927 val_rmse_std: 0.9837\n","New best_val_rmse: 0.4927\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.1 seconds\n","Epoch: 2 batch_num: 72\n","train_kldiv: 0.4256\n","val_rmse_mean: 0.5077 val_rmse_std: 1.019\n","Still best_val_rmse: 0.4927 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 2 batch_num: 104\n","train_kldiv: 0.2349\n","val_rmse_mean: 0.4849 val_rmse_std: 1.005\n","New best_val_rmse: 0.4849\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 2 batch_num: 136\n","train_kldiv: 0.1542\n","val_rmse_mean: 0.4888 val_rmse_std: 0.9913\n","Still best_val_rmse: 0.4849 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 2 batch_num: 168\n","train_kldiv: 0.1943\n","val_rmse_mean: 0.4902 val_rmse_std: 0.9898\n","Still best_val_rmse: 0.4849 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.3 seconds\n","Epoch: 3 batch_num: 12\n","train_kldiv: 0.1731\n","val_rmse_mean: 0.4965 val_rmse_std: 0.9945\n","Still best_val_rmse: 0.4849 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 3 batch_num: 44\n","train_kldiv: 0.1892\n","val_rmse_mean: 0.4876 val_rmse_std: 0.9738\n","Still best_val_rmse: 0.4849 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 3 batch_num: 76\n","train_kldiv: 0.196\n","val_rmse_mean: 0.481 val_rmse_std: 0.9572\n","New best_val_rmse: 0.481\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 3 batch_num: 108\n","train_kldiv: 0.162\n","val_rmse_mean: 0.4829 val_rmse_std: 0.991\n","Still best_val_rmse: 0.481 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 3 batch_num: 140\n","train_kldiv: 0.08218\n","val_rmse_mean: 0.4865 val_rmse_std: 0.9795\n","Still best_val_rmse: 0.481 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 3 batch_num: 172\n","train_kldiv: 0.1299\n","val_rmse_mean: 0.4863 val_rmse_std: 0.9751\n","Still best_val_rmse: 0.481 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.2 seconds\n","Epoch: 4 batch_num: 16\n","train_kldiv: 0.1245\n","val_rmse_mean: 0.4853 val_rmse_std: 0.9806\n","Still best_val_rmse: 0.481 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 4 batch_num: 48\n","train_kldiv: 0.06038\n","val_rmse_mean: 0.4845 val_rmse_std: 0.9796\n","Still best_val_rmse: 0.481 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 4 batch_num: 80\n","train_kldiv: 0.06938\n","val_rmse_mean: 0.4887 val_rmse_std: 0.9829\n","Still best_val_rmse: 0.481 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 4 batch_num: 112\n","train_kldiv: 0.06239\n","val_rmse_mean: 0.484 val_rmse_std: 0.9797\n","Still best_val_rmse: 0.481 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 4 batch_num: 144\n","train_kldiv: 0.09756\n","val_rmse_mean: 0.4815 val_rmse_std: 0.9916\n","Still best_val_rmse: 0.481 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.0 seconds\n","Epoch: 4 batch_num: 176\n","train_kldiv: 0.05223\n","val_rmse_mean: 0.4835 val_rmse_std: 0.9865\n","Still best_val_rmse: 0.481 (from epoch 3)\n","\n","Performance estimates:\n","[0.4900590584773388, 0.48023838745387815, 0.49249132763242986, 0.46549496634707227, 0.4809808676078318]\n","Mean: 0.4818529215037102\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"YSFnleU5vZS8","executionInfo":{"status":"ok","timestamp":1627892112993,"user_tz":-540,"elapsed":33,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"407a2230-8ede-49c8-d9af-31359d33889f"},"source":["\"\"\"desc_block = TextDescriptionBlock('excerpt')\n","desc_feats = desc_block.fit(train_kf_df.loc[train_indices])\n","desc_block_src = TextDescriptionBlock('excerpt')\n","desc_feats_src = desc_block_src.fit(train_kf_df.head(10))\"\"\""],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"desc_block = TextDescriptionBlock('excerpt')\\ndesc_feats = desc_block.fit(train_kf_df.loc[train_indices])\\ndesc_block_src = TextDescriptionBlock('excerpt')\\ndesc_feats_src = desc_block_src.fit(train_kf_df.head(10))\""]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":69},"id":"D0biwiMjq5KP","executionInfo":{"status":"ok","timestamp":1627892112994,"user_tz":-540,"elapsed":25,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"955898f2-f171-4fca-d6fd-9c146092afbc"},"source":["\"\"\"train_dataset = LitDataset(train_kf_df.loc[train_indices]) # train, validのDataset\n","val_dataset = LitDataset(train_kf_df.loc[val_indices])\n","    \n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n","                          drop_last=True, shuffle=True, num_workers=2) # train, validのDataLoader\n","val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n","                        drop_last=False, shuffle=False, num_workers=2)    \n","\"\"\""],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'train_dataset = LitDataset(train_kf_df.loc[train_indices]) # train, validのDataset\\nval_dataset = LitDataset(train_kf_df.loc[val_indices])\\n    \\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\\n                          drop_last=True, shuffle=True, num_workers=2) # train, validのDataLoader\\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\\n                        drop_last=False, shuffle=False, num_workers=2)    \\n'"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"m4v-cGx-Mv7S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627892112995,"user_tz":-540,"elapsed":24,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"6688d95c-2d16-46ee-b04b-be9fda87c33a"},"source":["print(list_val_rmse)"],"execution_count":30,"outputs":[{"output_type":"stream","text":["[0.4900590584773388, 0.48023838745387815, 0.49249132763242986, 0.46549496634707227, 0.4809808676078318]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XU4gRXHCBEpC","executionInfo":{"status":"ok","timestamp":1627892112995,"user_tz":-540,"elapsed":16,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"iAb99KSKBEmd","executionInfo":{"status":"ok","timestamp":1627892112996,"user_tz":-540,"elapsed":16,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"jH0aFzWxBEkG","executionInfo":{"status":"ok","timestamp":1627892112996,"user_tz":-540,"elapsed":16,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"q2CdCMuIKDMP","executionInfo":{"status":"ok","timestamp":1627892113467,"user_tz":-540,"elapsed":487,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#rep = MemReporter(model)\n","#rep.report()"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"eLl1yDOOKIe7","executionInfo":{"status":"ok","timestamp":1627892113468,"user_tz":-540,"elapsed":17,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#rep = MemReporter(model.roberta)\n","#rep.report()"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"7qkqnknA_m9D","executionInfo":{"status":"ok","timestamp":1627892113468,"user_tz":-540,"elapsed":16,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#gpuinfo()"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"PwrqSMdYA6Pu","executionInfo":{"status":"ok","timestamp":1627892113469,"user_tz":-540,"elapsed":16,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#del model\n","#del optimizer \n","#del train_loader\n","#del val_loader\n","#del scheduler \n","#del list_val_rmse\n","#del train_indices\n","#del val_indices\n","#del tokenizer\n","#torch.cuda.empty_cache()\n","#gpuinfo()"],"execution_count":34,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wXcHyUSJXecL"},"source":["# upload models"]},{"cell_type":"code","metadata":{"id":"YIV6UllSIGoa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627892225424,"user_tz":-540,"elapsed":111970,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"c79b7cb3-0706-4ebe-967f-04629576ea86"},"source":["%cd\n","!mkdir .kaggle\n","!mkdir /content/model\n","!cp /content/drive/MyDrive/Colab_Files/kaggle-api/kaggle.json .kaggle/\n","\n","!cp -r /content/model_1.pth /content/model/model_1.pth\n","!cp -r /content/model_2.pth /content/model/model_2.pth\n","!cp -r /content/model_3.pth /content/model/model_3.pth\n","!cp -r /content/model_4.pth /content/model/model_4.pth\n","!cp -r /content/model_5.pth /content/model/model_5.pth\n","!cp -r /content/CntVec_1.pkl /content/model/CntVec_1.pkl\n","!cp -r /content/CntVec_2.pkl /content/model/CntVec_2.pkl\n","!cp -r /content/CntVec_3.pkl /content/model/CntVec_3.pkl\n","!cp -r /content/CntVec_4.pkl /content/model/CntVec_4.pkl\n","!cp -r /content/CntVec_5.pkl /content/model/CntVec_5.pkl"],"execution_count":35,"outputs":[{"output_type":"stream","text":["/root\n","cp: cannot stat '/content/CntVec_1.pkl': No such file or directory\n","cp: cannot stat '/content/CntVec_2.pkl': No such file or directory\n","cp: cannot stat '/content/CntVec_3.pkl': No such file or directory\n","cp: cannot stat '/content/CntVec_4.pkl': No such file or directory\n","cp: cannot stat '/content/CntVec_5.pkl': No such file or directory\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xT_hwyuO_3dj","executionInfo":{"status":"ok","timestamp":1627893248994,"user_tz":-540,"elapsed":985,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["!cp -r /content/TFIDF_CntVec_1.pkl /content/model/CntVec_1.pkl\n","!cp -r /content/TFIDF_CntVec_2.pkl /content/model/CntVec_2.pkl\n","!cp -r /content/TFIDF_CntVec_3.pkl /content/model/CntVec_3.pkl\n","!cp -r /content/TFIDF_CntVec_4.pkl /content/model/CntVec_4.pkl\n","!cp -r /content/TFIDF_CntVec_5.pkl /content/model/CntVec_5.pkl"],"execution_count":39,"outputs":[]},{"cell_type":"code","metadata":{"id":"y9OpHdmWTPLE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627893334651,"user_tz":-540,"elapsed":77419,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"2589942d-9a32-4013-9250-68c6aa7c0b53"},"source":["import shutil\n","model_path_out = Path('/content/model/')\n","dir_ = f'/content/drive/MyDrive/Colab_Files/kaggle/commonlit/98_model_inf/{EX_NO}'\n","!mkdir {dir_}\n","tgdir = Path(dir_)\n","\n","for file_ in list(model_path_out.iterdir()):\n","  shutil.copy(file_, tgdir)"],"execution_count":40,"outputs":[{"output_type":"stream","text":["mkdir: cannot create directory ‘/content/drive/MyDrive/Colab_Files/kaggle/commonlit/98_model_inf/060-train-02’: File exists\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"14ddOZH4IMam","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627893800612,"user_tz":-540,"elapsed":465968,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"c8d22ddf-0794-4c6a-b92c-e0b1e64b1bf8"},"source":["def dataset_upload():\n","    import json\n","    from kaggle.api.kaggle_api_extended import KaggleApi\n","\n","    id = f'{USERID}/{EX_NO}'\n","    print(id)\n","\n","    dataset_metadata = {}\n","    dataset_metadata['id'] = id\n","    dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n","    dataset_metadata['title'] = f'{EX_NO}'\n","\n","    with open(UPLOAD_DIR / 'dataset-metadata.json', 'w') as f:\n","        json.dump(dataset_metadata, f, indent=4)\n","\n","    api = KaggleApi()\n","    api.authenticate()\n","\n","    # データセットがない場合\n","    if f'{USERID}/{EX_NO}' not in [str(d) for d in api.dataset_list(user=USERID, search=f'\"{EX_NO}\"')]:\n","        api.dataset_create_new(folder=UPLOAD_DIR,\n","                               convert_to_csv=False,\n","                               dir_mode='skip')\n","    # データセットがある場合\n","    else:\n","        api.dataset_create_version(folder=UPLOAD_DIR,\n","                                   version_notes='update',\n","                                   convert_to_csv=False,\n","                                   delete_old_versions=True,\n","                                   dir_mode='skip')\n","dataset_upload()\n","\n"],"execution_count":41,"outputs":[{"output_type":"stream","text":["calpis10000/060-train-02\n","Starting upload for file CntVec_2.pkl\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 544k/544k [00:05<00:00, 107kB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: CntVec_2.pkl (544KB)\n","Starting upload for file model_4.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [01:24<00:00, 16.9MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_4.pth (1GB)\n","Starting upload for file CntVec_4.pkl\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 543k/543k [00:09<00:00, 56.1kB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: CntVec_4.pkl (543KB)\n","Starting upload for file CntVec_5.pkl\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 546k/546k [00:06<00:00, 85.7kB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: CntVec_5.pkl (546KB)\n","Starting upload for file CntVec_1.pkl\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 542k/542k [00:05<00:00, 103kB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: CntVec_1.pkl (542KB)\n","Starting upload for file CntVec_3.pkl\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 543k/543k [00:05<00:00, 103kB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: CntVec_3.pkl (543KB)\n","Starting upload for file model_1.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [01:22<00:00, 17.2MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_1.pth (1GB)\n","Starting upload for file model_5.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [01:27<00:00, 16.3MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_5.pth (1GB)\n","Starting upload for file model_3.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [01:27<00:00, 16.4MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_3.pth (1GB)\n","Starting upload for file model_2.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [01:24<00:00, 16.9MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_2.pth (1GB)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"huJwVMSAPuDO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627893978291,"user_tz":-540,"elapsed":177686,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"34a20dc9-29fc-43aa-a078-1e417c526813"},"source":["# validation再実行_予測結果取得\n","all_predictions = np.zeros(len(train_kf_df)) # 推論結果について、「fold　× 推論df」のzero行列で枠を作る\n","\n","for fold_ in sorted(train_kf_df['kfold'].unique()):\n","    model_path = UPLOAD_DIR/f\"model_{fold_ + 1}.pth\" # 対応するモデルを読む\n","    feat_path = UPLOAD_DIR/f\"CntVec_{fold_ + 1}.pkl\" # 対応するモデルを読む\n","    print(f\"\\nUsing {model_path}\")\n","\n","    with open(feat_path, 'rb') as f:\n","      tfidf = pickle.load(f)\n","\n","    val_idx = train_kf_df['kfold'] == fold_\n","    val_df = train_kf_df[val_idx]\n","    val_dataset = LitDataset(val_df, tfidf, inference_only=True) # TestのDataset(何で、もう一回作るのだろう？)\n","    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n","                          drop_last=False, shuffle=False, num_workers=2) # TestのDataLoader\n","\n","    model = LitModel()\n","    model.load_state_dict(torch.load(model_path))    # 対応するモデルから、重みを読み込む\n","    model.to(DEVICE) # モデルをDEVICEへぶち込む\n","\n","    all_predictions[val_idx] = predict(model, val_loader) # 推論結果行列の対象列に、推論結果を入力(以後、繰り返し)\n","\n","    del model\n","    gc.collect()\n"],"execution_count":42,"outputs":[{"output_type":"stream","text":["\n","Using /content/model/model_1.pth\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Using /content/model/model_2.pth\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Using /content/model/model_3.pth\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Using /content/model/model_4.pth\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Using /content/model/model_5.pth\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"0zzuBPobmLFu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627893978292,"user_tz":-540,"elapsed":39,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"8e73f887-08f8-4627-f0e9-5d9759d18f5f"},"source":["from sklearn.metrics import mean_squared_error\n","import math\n","np.sqrt(mean_squared_error(train_kf_df.target.values, all_predictions))"],"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.4819526558517509"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"code","metadata":{"id":"Wpc8ro9hmNci","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627893978293,"user_tz":-540,"elapsed":26,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"3fe076e6-97e8-4cc4-9358-624f38214a95"},"source":["train_kf_df['pred'] = all_predictions\n","fold = 1\n","tg_true = train_kf_df[train_kf_df['kfold']==fold]['target'].values\n","tg_pred = train_kf_df[train_kf_df['kfold']==fold]['pred'].values\n","np.sqrt(mean_squared_error(tg_true, tg_pred))"],"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.48023838839276795"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"code","metadata":{"id":"ceDI72NumT5-","colab":{"base_uri":"https://localhost:8080/","height":296},"executionInfo":{"status":"ok","timestamp":1627893978294,"user_tz":-540,"elapsed":22,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"e05f94fd-e317-4c44-fc57-153a1f4643c3"},"source":["train_kf_df['pred'] = all_predictions\n","train_kf_df['diff_sq'] = (train_kf_df['target'] - train_kf_df['pred'])**2\n","train_kf_df.plot(kind='scatter', x='target', y='diff_sq')"],"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f0ad0a41850>"]},"metadata":{"tags":[]},"execution_count":45},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYMAAAEGCAYAAACHGfl5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO29e5wU1Zn//3mq+jLDDDcZvHATDaIBFjDOShT1p7gmRhF3I5JETb65GL/JV0x2vSYxxqCbbJQkv2gwybLGb+KGJCquARFzE41CBB3NQBhEHa8wqMAIAwMzfavn+0d19VRXn6quvlRfZp7368WL6e7qqlPV55znnOdKzAxBEARhaKNVuwGCIAhC9RFhIAiCIIgwEARBEEQYCIIgCBBhIAiCIAAIVbsBxdDS0sKTJ0+udjMEQRDqihdeeGEvM49VfVaXwmDy5Mloa2urdjMEQRDqCiJ6y+0zURMJgiAIIgwEQRAEEQaCIAgCRBgIgiAIEGEgCIIgQISBIAhDmO7eGDbv2I/u3li1m1J1AnUtJaIGAE8DiKavtZKZb3Uc81kASwF0pd9axsz3BtkuQRCEVe1duOnhLQhrGhKGgTsvmYkFs8dXu1lVI+g4gxiAeczcS0RhAOuJ6HFm3ug47gFmXhxwWwRBEACYO4KbHt6C/oSBfhgAgBsf3oK5U1owpjla5dZVh0DVRGzSm34ZTv+TAgqCIFSVnfv6ENayp7+wpmHnvr4qtaj6BG4zICKdiNoB7AbwJ2bepDjsEiLaQkQriWiiy3muIqI2Imrbs2dPoG0WBGFwM2F0IxKGkfVewjAwYXRjlVpUfQIXBsycYubZACYAOJWIZjgOeRTAZGaeCeBPAH7pcp7lzNzKzK1jxypTawiCIPhiTHMUd14yEw1hDcOjITSENdx5ycwhqyICKpibiJn3E9GTAM4HsNX2frftsHsB3FmpNgmCMHRZMHs85k5pwc59fZgwunFICwIg4J0BEY0lolHpvxsBnAdgu+OYY2wvFwB4Kcg2CYIgWIxpjmLWxFFDXhAAwe8MjgHwSyLSYQqeB5l5DRHdBqCNmVcD+AoRLQCQBPA+gM8G3CZBEATBATHXn3NPa2srSwprQRCEwiCiF5i5VfWZRCALgiAIIgwEQRAEEQaCIAgCRBgIgiAIEGEgCIIgQISBIAiCABEGgiAIAkQYCIIgCBBhIAiCIECEgSAIggARBoIgCAJEGAiCIAgQYSAIgiBAhIEgCIIAEQaCIAgCRBgIgiAIEGEgCIIgQISBIAiCABEGgiAIAgIWBkTUQETPEdFmIuogoiWKY6JE9AARdRLRJiKaHGSbBEEQapXu3hg279iP7t5Yxa8dCvj8MQDzmLmXiMIA1hPR48y80XbMFwDsY+YpRPRJAHcA+ETA7RIEQagpVrV34aaHtyCsaUgYBu68ZCYWzB5fsesHujNgk970y3D6HzsOuxjAL9N/rwRwLhFRkO0SBEGoJbp7Y7jp4S3oTxg4GEuiP2Hgxoe3VHSHELjNgIh0ImoHsBvAn5h5k+OQ8QB2AAAzJwH0ABijOM9VRNRGRG179uwJutmCIAgVY+e+PoS17Ok4rGnYua+vYm0IXBgwc4qZZwOYAOBUIppR5HmWM3MrM7eOHTu2vI0UBEGoIhNGNyJhGFnvJQwDE0Y3VqwNFfMmYub9AJ4EcL7joy4AEwGAiEIARgLorlS7BEEQqs2Y5ijuvGQmGsIahkdDaAhruPOSmRjTHK1YGwI1IBPRWAAJZt5PRI0AzoNpILazGsD/AvAsgIUA1jGz064gCIIwqFkwezzmTmnBzn19mDC6saKCAAjem+gYAL8kIh3mLuRBZl5DRLcBaGPm1QB+DuC/iagTwPsAPhlwmwRBEGqSMc3RigsBi0CFATNvAXCy4v1v2f7uB3BpkO0QBEEQvJEIZEEQBEGEgSAIgiDCQBAEQYAIA0EQBAEiDARBEASIMBAEQRAgwqBuqWaqW0EQBh9BB50JAVDtVLeCIAw+ZGdQZ9RCqltBEAYfIgzqjFpIdSsIwuBDhEGdUQupbgVBGHyIMKgzaiHVrSAIgw8xIJdId2/MV8pZv8f5odqpbgVBGHyIMCgBv149QXj/VDPVrSAIgw9RExWJX68e8f4RBKEeEGFQJH69esT7RxCEekCEQZH49eoR7x9BEOoBEQZF4terR7x/BEGoB6gea8+3trZyW1tbtZsBoDreRMLgQfqFUEmI6AVmblV9Fqg3ERFNBHA/gKMAMIDlzHyX45izAawC8Eb6rf9h5tuCbFc58evVI94/ghPJMSXUEkG7liYBXMfMLxLRcAAvENGfmHmb47hnmHl+wG0RhJrB7mXWD9OmdOPDWzB3SossGoSqEKjNgJnfYeYX038fBPASAFn6CEMe8TITao2KGZCJaDKAkwFsUnx8GhFtJqLHiWi6y/evIqI2Imrbs2dPgC0VhOARLzOh1qiIMCCiZgAPA/hXZj7g+PhFAMcy8ywAPwbwO9U5mHk5M7cyc+vYsWODbbAgBIx4mQm1RuDpKIgoDFMQrGDm/3F+bhcOzLyWiH5CRC3MvDfotglCNZEcU0ItEbQ3EQH4OYCXmPmHLsccDeA9ZmYiOhXmbqU7yHYJQq0gXmZCrRD0zmAugE8D+DsRtaff+waASQDAzD8DsBDAl4koCaAPwCe5HoMfBEEQ6phAhQEzrwdAeY5ZBmBZkO0QBEEQvJF0FIIgCIIIA0EQBEGEgSAIggARBoIgCAJEGAiCIHjS3RvD5h37B311QqmBLAiC4MJQyiwrOwOhrAyVVZQw+Blq9ctlZyCUjaG0ihIGP1ZmWSvFODCQWbbUqPFaLGokwkAoC5KfXxhsBJVZtlYXTaImKgOiGpH8/ELh1Nq4cbYniMyyne8dxA0Pba5J1ZPsDEqkVqV8pZH8/NWnFlUPbtTauHFrTzkzy65q78INK7cgnspOvVYu1VOpyM6gBIaagckLyc9fXVa1d2HuHetwxb2bMPeOdVjd3lXtJrlSa+MmX3vGNEcxa+KokvqydY140sj5rFYWTbIzKIEgDUz1iOTnrw71Zq+ptXFTifaorgEAEZ1qZtEkwqAERDWSi+Tnrzy1Nrnmo9bGTSXao7pGJKRh7TVnYMpRw8t2nVIQNVEJiGpEqAVqbXLNR62Nm0q0R3WN7y+cWTOCAACoHuvItLa2cltbW9nPW6wBrp4Md8LgZHV7F26sIYOsH+zjBkDVx1AlxnG15woieoGZW5WfiTAwqTXvBiE/1R5YtUa9Pg8Ze5XDSxiIzQD1Z4ATZAJRUY/2Ghl7tYPYDCABU/VGrbkmCsUjY692CFQYENFEInqSiLYRUQcRfVVxDBHR3UTUSURbiOhDQbZJRb0Z4IY6MoEMHmTs1Q5B7wySAK5j5mkAPgzgaiKa5jjmYwBOSP+7CsBPA25TDrXm3SB4IxPI4EHGXu0QqM2Amd8B8E7674NE9BKA8QC22Q67GMD9bFqyNxLRKCI6Jv3diiEBU/WDNYE4vWfkN6tPZOzVBr6FQT71DTO/mOf7kwGcDGCT46PxAHbYXu9Mv5clDIjoKpg7B0yaNMlPkwumHg1wQxWZQAYXMvaqTyE7g58A+BCALQAIwD8AeAFAPwAGMM/ti0TUDOBhAP/KzAeKaSgzLwewHDBdS4s5h1ActeqyKBOIIJSPQoTBLgBfZOa/AwARzQDwbWZe6PUlIgrDFAQrmPl/FId0AZhoez0h/Z5QA5TiwlmrQkQQhFwKEQYnWoIAAJh5KxF90OsLREQAfg7gJWb+octhqwEsJqLfApgDoKfS9gJBTSk+4BIHIAj1RSHCYAsR3QvgV+nXl8NUGXkxF8CnAfydiNrT730DwCQAYOafAVgL4AIAnQAOA/hcAW0SAqTYBGgSSCQI9UchwuBzAL4MwIoVeBp53ECZeT1M+4LXMQzg6gLaIVSIYl046y2LpiAIBcQZMHM/M///zPwvAL4A4Alm7g+uaUK1KdYHXOIABKH+KMS19CkAC9LfeQHAbiL6KzP/W0BtE2qAYlw4JQ5AEOqPQtREI5n5ABFdCTNI7FYiymczEAYBxbhwShyAINQXhQiDEBEdA2ARgJsDao8wiJA4AEGoHwrJTXQbgD8A6GTm54noeACvBtMsQRAEoZIUYkB+iJlnMvP/Sb9+nZkvsT4noq8H0UBBEAQheMqZtfTSMp5LEAQhL929MWzesV9qWZSBcmYt9YwnEIRyIqkuBIlyLy/lFAaSPE6oyCQtk4AgUe7lR3YGQtmoxCQtk4AAAB27eqBR9pQjUe6lkddmQER3pP/PZxN4qCwtqhNEV5lNpeoSS8lLYVV7F754fxsOx1NZ70uUe2n4MSBfkM4+6uktxMzfLU+Tap9V7V2Ye8c6XHHvJsy9Yx1Wt0vG7UpN0kMh1YUsNNyxFh2xZLZWOhqScpml4kdN9HsA+wA0E5G9MA3BzDM3IpCW1SiiplBTqUl6sKe6GOz2kO7eGDp29QAgTB83ouDfTZUEcVhYx88+fQrOmjq2zK0dWvgRBt9k5huIaBUzXxx4i2ocycipppKT9GBNdTHYFxqr2rtw/UObkUiZq/qQBvxw0eyChJ1q0WGAMX3ckFqTBoIfYfAszHKXRZWrHGz4WQEPVbfHck3Sfp5fPaW68NsfBvNCo7s3hhtXbskIAgBIGsANKzcXJOwG+86wmvgRBhEiugzA6UT0ceeHLqUsBy35OuNg3+bno9RJerA9v0LuZzDbQ3bu64Ou5Toc6lS4sKvkznAoLez8CIMvwaxqNgrARY7PGMCQEgaAe2cc7Nv8oBlsz6/Q+xnMq94JoxuRMnJDkVJcnLCrxM5wsC1M8pFXGKSrla0nojZm/nkF2lQXqDrjYN7mqyj3qsnt+XXs6sHIxkjdrc6K6Q/lXPXm+30queod0xzF0oUzcZ3DZrB04aya/E2DWpjU8k4jrzAgonnMvA7APlETeTOYt/lOglg1qZ5ffzKFL97fhoiu193qrNj+UI5Vb77fpxqrXkvQleJN5CSIybW7N4Ynt+9GSCtvUFut7zT8xBmclf7/IgDzFf+7QkT3EdFuItrq8vnZRNRDRO3pf98qoO01R7FlIuuNoALMnM8vGtLAzIglOdBAtqCoVn/I9/tUKkBQxZjmKM6aeiTOmjq2LAKv3PE+1jlvXd2B3lj5gtqq+cz94sdmcJCIrgWwFaaNwBKXfnIR/QLAMgD3exzzDDN7CpV6YrC6PdoJUh1mf349fQlcveJFHIwly36dSlGN/pDv9xkM6swg1Dj2c9ppiupIGVySIK+HZ+5HGDSn/z8RwD8CWAVTIFwE4DmvLzLz00Q0uYT21SWVMG5VU/cYtDrMen7dvbFBoXartBtsvt+nHL9ftXXfQUyuqnM2RXQsuWg6zjnpyJLusx5UyHnVRMy8hJmXAJgA4EPMfD0zXwfgFACTytCG04hoMxE9TkTT3Q4ioquIqI2I2vbs2VOGy9Yv1U6HUSn1x1BRu5WbfM+t1Oda7f4HBDO5qs6ZYi5ZEAD10ZeJ2V/maSJ6GcBMZo6lX0cBbGHmE/N8bzKANcw8Q/HZCAAGM/cS0QUA7mLmE/K1pbW1ldva2ny1e7DR3RvD3DvWZW1lG8IaNtw0r+Idq1KrwyCvU+0VbpAE4U1US/1vdXtXjhtuqQbZIM5pp9r9jYheYOZW1WeFpLC+H8BzRPRI+vU/w7QJFA0zH7D9vZaIfkJELcy8t5TzDmZqSfdYKfVHUNepde+OUsn33Ip5rqr+p4HQsetAxXMDBWGPKeWcfiPnAWQSOBba5iCFiW9hwMzfIaLHAZyZfutzzPy3Ui5OREcDeI+ZmYhOham26i7lnEFSbakO1IfusR4YbAFulULV/w4nTPffpQsrL0yLXSh4jeVizul3YVHKAiToxUtBNZCZ+UVmviv9L68gIKLfwMxtdCIR7SSiLxDRl4joS+lDFgLYSkSbAdwN4JPsV29VYaqlJ3WmM64H3WM9IHURisPqf9FQtg9+LFl7rpJulHss+3UbLcW9tBKuqeWsdJYDM38qz+fLYLqe1jTVWkW6rQT8bmWdq59a2NnUCrLDKp4Fs8dj1LAwvvSrF7MKzNSaq6SKQsZyuRMMlqLirYR6OFBhMFiohp4+X6fNt5V1CpJFrRPwYNvOoraYg8FQ7GQw5wEKCvvvM33cSBiOTXw9CFO/YzmIBIOlLEAqsXgRYeCDaqwiSxFAKkFy/7NvA0DBO5tS9JSFTO7VTI8gu6X8qH6fehSmflPQB5FgsJQFSCUWLyIMfFCNVWQpAkglSJz4ESx+B4Vq0l+x8S0sWbMNEZ2QTEdvuk3u1TTmVjogrB5x+3023DQPG26aV1fC1M9YDjLBYCkLkKAXL0NWGBSqkijkhyiHuqMUAaQSJE78CBY/g0K1YjzYn8TNvzPTUcXTmSS8Jnc/1xF7hz+CeE5ev8+siaPq7vfIN5aDTjBYygIkyMXLkBQGXiqJUl3OyqnuKHYloBIkKptBvvPlGxSqFeMNK7fAUAgiXSPXlVW+6wz2eIByEdRzGkzGdvv4njVxlPKYoWpP8h2BXEuUEoHsFUG5vnNvSYOplqIzrfaU6k3kFZG5ecd+XHHvpqxEcsMiOgyD0Z/MnjwiIQ3Pfs39Obhdp9rPtF52JEE/p6AjcytBocKyXn77QihXBPKgoGPXAWjI9pHWQHj2tW7cuHILYsni9da1FB0M5O5kitlieu1OlLlcDIYqoe2tF03zvLbbdXbu6yt7Xnm/VHNHUuhEFHTfq3djezF2qaFmTxpSwmBVe1dmwrdzOJHCVx9ozynLV+hgGkzbaTtug8JtOw2YA00nQiJl4NaLpuPyOccWdZ2tXT1lzSvvl2oatYsRQpXoe/U8OdbaQq0WGTLCwBrcTkFgoarPGk8VNpick2M8lcLVZ08pus21TndvDMeOacKaxWfgUDyVtWIsxyqyuzeG2x/blvP+LfO9dxnlIMjJw2vVX6wQGqp6br/U00KtWuqpISMM/LhbOll8zpSi1SorNr2Ne57sxPKnX8c9T3XWpY7VC9Xq1W6QK0fOGLf88jPGjSyp7X4GW1CTR75Vf6FCyH4v5VblDCadeb0Iy2qqJoeMMPDjbmknGiJcNqf4cg0/eaoTsaSR2YkMpiRoQalQnAPh2n+ailgyW0WUYi5pQvY72OyTh64REikueUfi57m5CaGmiI7NO/ZnTcxu91KOPjYYPbhq3e5R7eSJBSWqq2eswW1P8PaZ0yZlXod1QkhD5rOlC2cV/QMM9iRoQdyfKhHXdx/fDkrbjqM6lZyUr9BkXwtmj8ctF05DImkgrBFuX7OtpKRmfp6bqp8uOmUC5i9bn5VYLcjEZW7n7nzvYFbSxHpkTHO0ZmMjqj1vDJmdAaBeGXz13KmZ1wBKWjVY2+qmiF43+sliCEKF4qbGiyVNWw4T4bHFZ2DKUcPLeo18KpjbH9uGeIoRT5k7FGulZp2vkL7i97nZ+2lTRMf8ZetzVovLP90amE3D7be44O5nEA3piKdSWHzOCbhszqSCrjWY1E5BUG27xpASBkB+d8tiO6mfxHD1MAD8Fujwo38tZPDnU+NFdQ2H4inXz/1Q6GBzEx4rNr2NnzzVWbAKpRC9tdUvN+/Yr2wDwIFNHKrnZMUvxFNmTMkP/vQKlj3Z6buGwWBUO5Wbats1hlzQWbHk8wBRBfyovGxqmWKCcjp2HQDAmD5uZNY9up3L6zlagU26RjjkcCctRwBVd28Mv970NpY9+Soiup73HlW/q5nHn7K80gptWyFC0iuYbEPn3sACwexBZrGUAWJGLJU7V/i592oHDpZKpXc0QV5Pgs5KpFgPkEPxlGvIe61RjPHKLWLb7VwH+5O4/bFtrs/Rrh7Z2tWTc2y+CcdrANl/Q4Bw1VnH+1JzXH32lCzhcfXZU7D86dezhEGh6plCPK28VotBGkRVqioohIGfe69nH/9q7GiqFc8hwiAPfibJpoiOWKq+bQTF6NPdnovqXLpGWPJoB+Ip9hQ21kCYNXEUzp9xtK+JLt+AVbX1nqc6Pb3F3ISH9V07Qf/WXpN+KRNHPgFqP/edl8zEDSs3Z2w4Fn7uvdq68GKptndPpRky3kTFks/Cv6q9C/OXrQel1W0NYa0uS1EWq0+3Yz0X5blSjLBemKeEH8+PfF413b0xPLl9t2tKCz/njCWNjABQeftU4rcutxdMoaUfF8wej79+7Vxcd95UREOF3Xu1nlkhOMvLAtX37qk0sjPIg9ckaZ80LAyDsfYrZyq9XmrNm8LZnkKMV17PRXWuW+ZPw+1rtimP99M2N7x2NJYaSyfKMT4XYzi2dkm17q+ej1KinK851/QiKvTeK/HMih1fbjvLet3RFEugwoCI7gMwH8BuZp6h+JwA3AXgAgCHAXyWmV8Msk2F4jVJqjw9oiEdh+KpnI7p16BaKYHh1h6/Azaf8FCda3g05EvYlKPkYFNEzxHUANAU1ZFKF9spJfq4WnrdclCqDr/Yew/ymRWr288nGOsharlcBL0z+AXMgvf3u3z+MQAnpP/NAfDT9P81hWpi6+6NoacvnvE/t0gYBrZ29eATy5/NWRXnM6iWUqe4EPzUV/ZDPuHhPJcfYeNn1epnR3MonlKmslhy0XScc9KReQXdolMm4P6Nb2feW9Q6YdBMAoNtxVuKbr+cu8Ba2/kXSqDCgJmfJqLJHodcDOB+Nv1bNxLRKCI6hpnfCbJdxWCf2OyrEIOBkAY0hkPmxH/hNNz+WPbEv+TRbQg7dNY6EZas2Ya4LWV2sXWKC6Wc3h2FrvbcjrcGUk9fwrNtfnc03b2x3PTazHkFgdWWB1/YmfXeg2078dVzp1Z1kBfqkuolpKu94i3nxNmxqwcaFZfmvFy7wMEQR1Ftm8F4ADtsr3em36s5YWChWoVEQxruufxDmD5uhHqi1QmJpNOgaiAS0jJlIVUE5X5X7MowqJWPfSDFUwZSPmw0+XY0bhMegJwcP05q0RWykMnGz7HVtHuUs8iMmZa+OC8noDyCcbB4HVVbGPiGiK4CcBUATJpUfAK5QlB1QtVEEdE1jGwMZ46JO9xMUwbj1oumZ6mErB2EF0Ft3e0DwG8StqBWPqqBFNYJ0RCyAsPcbDRek7RzwlvfuRenf+8J6KQhxQaWLpylvIeg1SiFCtVCJhvVsdc/tBnTjhmR49RQDbtHoRNnvhK1Zlr6bEEQDRXmreTsJ0D+BYOdWlw8FEO1hUEXgIm21xPS7+XAzMsBLAfMCOSgG1ash8H6zr1ZK9uwTpnvOv3mhzdkG1QrkcLCmojmTmnBLRdOw5JHOxDWNdy+ZhuGR0PKydFtAE87ZkTJEdaqgdQQ0nHP5SdjZGMk69zFTNLWhNfdG8N1D7bD3KCZdp5rH2xXTkJBqlGKEaqFTDaqY+MpxgU/Xo/v+0wdESSF3Es+waE617Cwjp99+hScNXVsQe2y+kmtFhaqBNUWBqsBLCai38I0HPfUgr2gWA8D63t2jZBGyCQ282NQtSfO87tqzGeQta+MneqYpIGcJGx+JhhgIHFZKVt9t4HkTG8BlDZJd+w6AGddo6Rhvq+aOIJQoxSrTmiK6DmpvN0mG7ccT/GkUROqi0ImznyCQ3UuA4zp40YU1bahXlgoaNfS3wA4G0ALEe0EcCuAMAAw888ArIXpVtoJ07X0c0G2xy/FehioVUi653ZRpev224nyrWKydfEpGGwGf7kV+HFboflJXOaltrAK/UT03HYWOpCKnaQP9MU931cJq3KrUYpRJ1i/oaYRkGJEdQJp5JkY0NrxxR3pI3SN8OT23b6M6EFgb59bqhH775BPcBTSd/yo5kpR99R77AkQvDfRp/J8zgCuDrINxVCsh0Elt4v5VDd2P3u/1d1Ubc0M4LR7rFviMtWgcRr37IV+7CqmQgeS/dn71b+PaAy7vl8pT5BC+oeVBNBZs9stlbfzHq7/yIn4/p9eQdz23UOxFG5d3YFvrtqqvMdyOwi47Uotd+sZ40ZmXUv1O+Sb7L36jnV9VZ6rIGxF1bDBlBPJWuqCPWtjIRNEsd8rlM079uOKezfhYGzAHakhrMEwGNGQqVbQNMoJurIT1gkawTWDpzU4QxohnmJc/5GpmHPcmKwc+/Zr27NQqjJVqtpZyjMqZBLv7o3hw//xBBJ2AaYTHv/KmXnvxXmeUiZMP/0jsxsA4XAiWz00PBrCr66ck5UA0S0rqLUC14hwOO6dBda5iyymXoHzHm5cuRk6aUgaKTAo69n76S/WMUDhtSOs+1FFn3v9vpUav9VCspYWQTHbPq8C8eXGj+rGmWUypAG6pkHXCCmDsXThTM9VlTOC97trt+M7/zwDl3/42LwrNjc7g6qdxeiyC9XvjmmO4geXzsINK7dk3b8qOM1NNVCOHUS+fqV67nZUK1U39caM8SNxy4XTcOvqrTnnsd+j6lmq6hX4FYQqYz2Q3Redz9hLRVNoTqZ8z7AQD7R6XukXiggDG87OXqr+XpW+ulxbcae+VKW6ieoEJkI0ratfdMoEPNC2A2CCNTjd7nHnvr6c5G4AsOTRDpw/4+i8g8bNkBnRNRCy26mBXA25bhSj3/UbnOamLiuXL7nbM3dLqgcAwyI6DFan0fBKyXH7Y9tyDOfOe3QT3DGb0dktXbkKlbHe6/pe91CMitVrIeLnvPnGfb1HGrshwiBNKas+vxNFqddwdsB8OedJM/XLlg1h/rL1af29t/cQYA5OpwESAML6wITrNWicwspSPZx2/BG47N5NWcceTqTwxfvbfFfNAgrzsHG2y2mw92OEDNqX3EutEQ0RfnbFh5QeVl73oNr1AEDE4YfvJrite+zYdaBAQahWPUd0ylINFvM7WHhNyGbfzb0fP3mp8uFnDNersBBhgNJXfX4milKu4dUB7ZObajBZhsZCA7bGNEdx/XlT8d3Ht2e9n2JGU0T3FZSjCvq64r7nMp4xdmIFuD4W4mFjx22Q+lENBOkc0N0bU0bR2ievs6Ye6XkOv7ueiE5Ye022AXpMcxS3zJ+Gmx/JVSeZkyoX1HemjxtpRt077DNrv3Kmq/q0EBVrvglZFevz7YumY8b4kSVN0H7GcD2npRBhgOIKu9ijFd0S1tknimJXloUIEa9JrergCWUAACAASURBVNDJbFV7F37451cQDRFiSUZEAzRdw6JTJmD+svWuEaFuE+q+Q3FPPW4xz8PCzcPGzoqNb+Hbj25FiDQY4Jzo43yqgXwrVz+rQbdjVmx6O1cQeCTVczuP312P6jnNGDcSTRE9Z1ey+JwpmD5uZEF9x80+45bWXeV67FYhMN94cIv1OX/G0QXbHfy4juezvdRCbIdfRBigsInSLvn7EkkQERpCek7COucqtVC3Qqsjlks9UahPds7ErWn41edPxRX3PadMddDxzoGcFREDmfcsm4YX9hxEHbt6AFAmgMjreUR1LWcSs7Ni41u4+XfmqjeR/p5b9LEXbsLWz2rQ7ZjO9w5i2brOnGvFkynMThtOvVw08608F8wej2nHjED7jv2YPXGUq8CcMLoRKXamdaCMR1GhQVV+dltersduv83OfX3QHSYV+3goJtZH1a5isg+orl3t2I5CGPLCwE8gjP3YXN99RiLtFWNPWOf8rt8B5eyIt8yfVpSgUk0Ufj0l3CbcN7sPK1MdfOyupwGirIC2G1ZuAcCIJd2D3CzvJvuKcH3nXlz/0OaMioEAhHRT4Fo5nQr11f/2ox05nyUN4NnXujF/1jhl29xwrr79ptx2qwmtCg4DACLC/GXrseiUCXjwhZ05UeN+03ur+pPTv9+6r0LqUwD58/d4GcoHYijUdZU7dvXkpCMBgBWb3sKhuPr390or71edly+3k1f2gZ6+RI6tIl9sRy0xpIWBaqBMHD0MAGP6uJE5x+fzUnAmrHOSb0CpOuLta7YVLai8agxbZf7s184X+Tl74iilodHcQORGu5peSwMDUxVf4Hwep39vXZaumWFGTVsC9/bHtmUFwOUTqprDv93Ovz3Yjp6+REm6ZD/pk91WjG6CADCFLFKcqangJ2o8Jy7kvKn44Z9fyeoTNz+yFY2hXFWZH5291XeK0Ys7A8A0UFYwnZ3+pOlQ4Ix/6XzvIB5s25lz/LXnTc3aMbnt0ouNQnbmdnIuqOzPI2UYCOuESEjDoZjZ961da62rjIasMFBNnreu2pq1UnWuory8LgD/3iwAlHrSY8c0ufqLb7hpnmdHLkSd5AwwOvekI/HE9t1Zg89N13znJTNxnW3l7kbKYKi8SlRGROv/zTv2m0LEg7CmYcY47+eRz8/cIpFi3Py7rWiO6kga7LpqdsNv+mSlcE3XhHauYgvFulbnewdxw0Obs4TLdx/fjmgo93n2JbNVZSrVU7E6exV2IdUb877faMicUGMpIJbMjkNp37Ff+Z2ITsq08v/x8RkY0RjB9HEjfFca9Jvbyb4Ts/rAwLWBGz4yFUv/8EqW+lInyrIv1JrH0ZAVBqrJM2kAScPIrFhufmQrmiI6Umn/7gWzx2dNknabgd/kVF560jWLz3BVgeQzcKrc6VTCyT5pWPe+dut76bYMDL4NN81TTrhzp7TgX889AUv/+EpOGyK6hmgou3aAU6CMborgUFxdUHzC6Ma0EHEnnkqhpy+OCaMbXeM4nty+Gzp5CxU71gR18yNbMSyswQB8Jd7zmz5ZpYJR1YQO6wCBXHcLgGkMDeuUJbjXd+7FDSu3KL+nUsNYWKqyQiZ31bjRiNCxq0fp8eRXMANASCN8fu5k/Grj21mR9ZbeffKYYcrvtTQ3KHbsjGsf3IxoSFfm5VJVGrSP8esdghVQL65Uxn+dNHP361QZxVPYuqsHb3Yfwo0O43otqI+GrDDIt8q3cG7xVKoerxWq09VPNYEAZkc7FE85fPMNXH32FF/345Y6296mVe1drpOGsy2qyE+7L7yTkAas/UquisHpWjr3jnWu6oUxzVEsXei+89AIMBi4esXf8qbP8DIoe3E4PWld51IDwEI1KXqlT1b1m/d741j25KtZEztg9jVVKgrAtKGs+MIcvNl9GLMnjsLopgjm3rEuKweRnYgGQNOgE9CnmJD39vYX5KCgGjeH41acSG59iHyqVTtJg3Hfhjfh3FFaevcUM86cMgbPdHZnPvvMaZNw2gfG5LTJGmOZaHwHGg2o6ZxC0DK6X/Dj9VnP1bm46u6N4Z4nc43/hxMpfP2RrTmGbgC47dGOjGCyuO6hzTWhPhqywsC5WrOvHlTYo2RVLnxOVNvSUcMi0KBesVodbdbEUZg7pSWtRnoVy59+Hfc81Zk3745X6mz7MW6Thqotqms4V3gNYQ3Mpv5ZNXHabRR+VqDWpPnsa934twfbs34PgwHDZj9QuRQ629cU0ZEwOCc6O+8zSDHOv+sZ/HCR/wI4KTay0ie7RbTb+wZAuGjWMfj83OMyz2/ulBZ07DqAK3/5fI7gDumEy+7dlLG7XH32FGXEsoWma1iz+Axsf/cgvvrbv2WFd4R1Qktzg68dpYUVk7Bkdba9I5Zk5e+Zb9EVDWlZtoOIruGqs47HPU91QtcoR+++6Y338fPPnIJ9hxNZ3lG3XDgt4zHmh8PxVI4KzS4Epxw1HN9fmD/lSkTXXG0fqu5GoJwdQyLFrjurSqJV9epVZsHs8dhw0zz86so5+OvXzsUPLp2FhrCGpqiec6wVJbu63ay9Yxlgu3tjOcfaJ6aDsST6EwaufbAdX7y/TbnaU6kWfvJUJ2JJznz/xoe3KK8FDKy+7FjudF7HqIiG1MFbqu83RXT8+8Uz8NevnYu5U1qynofz+ai+bw0+J2Oao5h4xDA0hHJ/B7fvq84T1gk3fHQq1l5zBiiPLUJF0mDcsFL93K3FRMh2SwYDGzr3AjAXA6d/bx0+9V8bcfr31mX1G3vfiCUN/Pq5HfjY3c9gxaa3Muc+a+pY3Lpges51Y0lGPDXQL5Y9+ar7riC9O+x45wCuX7k5IzQiuoawTmBmfP1//p4xeg6PhtAQdq8S1t0bw91PvIrbHu1Q2nZUv6f1nCKh3L43LKLlWJUShoHL5kzChpvmYclF0zEsnP29eIrx5RV/Qyxl4FA8hc73DmLzjv2YeMQwNCvGrYVqle7cocdSZgoPC/v8sOGmeTmLgqaIjv6ER91aBc6SrgMU3j/LzZDdGVjYV/n2rfzWrh7ctqYjq8NYUbJuukYLL3uEnYgOXDNvak52yEJjC/zEMKiOCWlm1lJTr2pg8TlTXDNVqlfCZoF5pwFSVbFt7pQW9DkGTl8i6boCnTC6Ef1Jb1WP/R7NgZm74lry6Ev493/WcfXZU3D3ulfglMUNYQ2JlAFF9gIAQDJluD73uVNa0p5EnLmelZ77eoeqy1IFqISW9d2bH9kKMHD5h48FAFw+51iAkalGl0gxmBkJm10louu44sOT8NO/vJ51vkhIw9przsD+w3F88r82Zu0aGQwCI2Ego5uPhoB7Lj/ZNeWFaeuyp9POXfbaXTztOyJL7fLRHz2dtVqOJQxcddbxuG/Dmxn9uV0QxZJGRm1nJ54ycPMjWxHWTE+2aFrQqCZay3Nq8Tkn4Gd/eS1LfWjl7tLITJ5IzJi/bL0v76hV7V22ZHz5saLJrcSB9u+FNBRdkKecDHlh4MQSDrMmjsLEIxrxpV+9mJX+VyfCkjXbEE+6qzv82COiIQ0/uHSW0s+90GhhNx9xwPTQsSJLVS6Z+eIO7APbqVa7+uwpWZHF1vO4/9lsd8gbVm7BY9ecAbJNnADSr91xS6+uSj9xKJ5CVKccVRADGY8hAiGkmSt+i/6E4bk9TjGQUAil7t4YfvDHl5UFZNZ37slRNyZSjEc3d2HGuJGextRvrdqaFS17+YePxfkzjsaKTW9j2bpXswQBYBrUrzzzeEwYPSwjNCyHh/uffTPjmmonrGsAI8uTKaLrGNkY8QxCdFOHDAvrMMAZY7bKa2d0UwQgAmy/aYqBnz/zOuKGuYuxd4fu3piPGuHm/1a7QhohopuLm/5kCobB5o7QAA7HkzmLMdIIKz5/aiZXViztzpsvOZ/lQeR8HDoBIV0DpYWL1U9vuXBalvvy8IYQbkin97ZqcVfbXgCIMPBk+riRMNg5qA1EQhritkWuMyR9577sYjAqe0QsaeC6h9phMOesQvIFAOVLWmc31gK5HXPiEY2wonu9vJRUdo8NN83LuMUuf/p1/Hjdq2aOIA9iSQP/d8ObpqeRbQJqCLlHhu7c14fGcCjLq8QiycADnz8VrceNybw3YXSjS3o0E8tjKKSZahK7njzf4u7N7sNZ13JzKQVMY+fv/rZLeZ47fv8yUmxOGm7mixSrg+F+8lSn0vBvMPDrTW/jsjmTsmps7zsUx1d+266+hsLt121VD1hRv+rfOKITfvbpUzIrW6smgXOh1LGrR+kpZsWPWfdmHV+I4dkiaTDCOnDFhyfhvg1vIMHILOR++pfXEdJy4w/CIT29Mx7oZ/mS85nPQ4M9hgYAomEdP7viFIxsDGcWYKpFVq2myRZh4IHSJTAdAGbHGkg5QWy2FcGGtPuffXXlZnQDikt9oDLWZq6VXvV8+9EOz4I2Fir/acv91bRnDLjgus5sNn7z3Ns5w9prt+O1u0oZjE/duwk/uHRW1r2feUILnti+x7MdROSht1Uz21FIxs0jzKJ9Z4/yfZU3j4prH8xeJLilEwfMBYZZe+DVLG+eJ7fvVh6vE7B0odrt120lPGF0Y47R0+KaeSdkvKeefmW3awCeX524dbxfbz8niRTw8/VvIBLScrLaJo3cLAHdvbEc9eXheBKv7znomvbCTN2R27aUwcrsAyryuYpXgyFtQPaD04hkFXaxDM2RkIZb5k8DgByj8e2PbcvSm/7XZ1oxLJxt5HIzogLIqKtUaQ3cDMteOfEBc/KwG6ZvWLkZT7+yO2OI6+6Nobs3hu+ufSlnwgtrGtrT2U/tRHVCRPfuSqph/bnTJ2e1225wVhlonfdhv/fu3hjWp423XiRS7Ed2ZbjgH47K8pLya4j3QhUIZifuuLetXT15g7WshYX1O44epi7zqRHwVvdhzJ3SktWv505pce1bY5qjuP4jJ+acK6ITPjbjaADmIuWL97flVFSzBP6O9w97tt95vPX7N4Q1DI+G8gYj2jGD+dzSaOdmCXCqK1MMfOexl1zTXpgu0LOy+mZYp4yQdXMsqXVkZ+ADpxRfMHt8Jq9MWNdw+5pteL83ntfoO33cCBgu23M/5DMse+XEdyOWZFz5yzbEU5zp3G5GsXgqpUxJQRrhBwtn4saVf1d6S7nxy7++hfs2vIFzP3gknnhpd85uZcHs8dAIWPwbtbrD7u5rrp41xFBaRK+daEjD7Rf/Q+a1W+6bQmGGMkOoHUtVATCWPOrPZZINM22C5UZrxWXYSRjqKmZeKc7Xd+5NZ7A13SgtNRcBmL9sfUYl6haAB0Cp/9dgTqKxFKMh7TWkyofUsasHX7y/LcvIr5Npn9E1ytlxpZhx60XTcNuj23LsHKpswg0hPeOubH9OTm65cJqibeZvNH3cyLxxNF7UQkRy4MKAiM4HcBcAHcC9zPw9x+efBbAUQFf6rWXMfG/Q7fKD2w9kGbfiKc5MDMue7ISbHtZCFdugCipzu66XYbmQSE8n1ioqn2fEGSe0mIZoRa6k0z7QkiPo8mEJjrV/z42AtlRnp32gJW30VX/fKorzbk9/UYFmYc2cMJ0LyWhIw9KFM5XquXxR0nZ0AkCU+U5IA269aDpuW+NtHO1LJPHF+9ugawS/t2Uaz7PjMlyPTXvGTTtmRKb4kVPIxVMpJJIpM1DR9gNYz8pSPS55dBucmx17AJ5K0ACArhMWzzsBH5txtGc+pJGNkRxBPywSwj2XfwgjG8OuBe/Pn340fr3p7Uxgn328WZlxD/QllYVwnDRFdcwYn52vzHIBts4XRL2SShKoMCAiHcA9AM4DsBPA80S0mpmdI+EBZl4cZFsKxesHUqfJHQiW8UqgZq0o7EbYe57qzOTFsTq2lWzs1oummS6G8DYsuw24cvLES3uw6fX3XfP4uBVIAbLrLztVCU7su50xzVH8cNFs/NsD7Ur1Tixp4NoHN2d5CA1c0/RQSdhWnpbbq66ZCeyu/8hULP3Dy0jZTq5rwGO2AjDqbLX50WDes32y0TUNO/YdRtJjAtLJVF24ee84aYqYqQ80jQpeDFxw9zOIhnT0JZI5wiOeYiz6z43575gZh50++8kUxo1sAOBu/0mkGPc81ZlRNQHqhdDWrp4cQZ8wjIx+ftbEUVnGc3vOq2vOPQGXzZmU8cb66VOv4Ud/fiVLQBPSnkghzbVvpgz23MGr7DqF1ueodg2EoHcGpwLoZObXAYCIfgvgYgDey6KAKKSgt9cP5LZCv2zOJFw2Z5KvaziNsFZeHKdf9c2PbMXunn7M++BRmDC60dWwXKzBrVAs3fXta7Zhw03zsu7RzPiqZsmCGTh/xtGZLb+XATaWMpBIpjJZVedOaUFI15BymRxVgsB6P6yZ8RxXnz0QQ3HiUSMyKr7v/+FlONXRKQN4fOu7uCYtDNxsOvnQdSASyl7Zx5IGfuaICXCSYmQJp3zc8NETccaUFrPsaQFYgsMtZQOzWwHLbFT6+RQDF/54fUYV5Zbvx0irtqK6OtfX3CktShWTXWUD5DfI3v3EK0gaNndam5cgw+wrlDKwYNbR+H06V1fcRX2lQmXX8aMCLle9knIQtAF5PIAdttc70+85uYSIthDRSiKaqDoREV1FRG1E1LZnj7fHiIpV7V2Ye8c6XHHvJsy9YyAiVEW+aFmnccsetek0+vo9PwBlgA0A3LWuE4v+86+ZdlvXAAaMVVab8hkny4XK8L3upfeUx0ZDZuZVc1t9JJYunOXZzmTSwML/3IhPLH8Wc+9Yh19vetsz5YIXCQOIp4B7njJzyHS+dzCTk+ZQPIV42qDu5O4nXskYAVUBbUB2VCsBWUZOAnD5qcfmze5aDlqaoxjdFMHnTp9coKE12L5iqaI63zuIN7sPK+NG4ilGPGkarZOGuVuwG7A7dh3IjXxXqGy86Nh1wFdwWCLFWL35XbOvEeEbF5yEB646TRl9bMctJuKW+dPyTuiFxhQFSS0YkB8F8BtmjhHR/wbwSwDznAcx83IAywGgtbW1oBFW6FbMzw9Uiq9wU0TH4XhhYezmhJU/IGbulJa0nnQgPbYzInhR6wQ88PxOTzVERCdTLcOMSEjLMdIlDCOrFvLvt76LXzz7lsvZBrbYVt78x645Ew+/uDMnchYY8DyyJuAf/fmVgjyAVOhE+MEfX8bKF7ryJuoDTCHy5V+1YfG8qQAYET03m2gkpCNpGFgwaxwumHE01m59B7/72ztIMYMB/OLZt0AwJ92w7q6CyIcjViuHjl09OXmc/FCA6QOA2Seu/8iJ+L4i2M71GikDF9z9jO/j7ZhCgHPGYjJloKcvnlkE5adQW5Z5vR/+6ZWc3a8K1eq+KaJjhqImipN8MUWVJGhh0AXAvtKfgAFDMQCAmbttL+8FcGe5G1HoVszvD1SMr7AVsFTs5GZVgfISbpfNmYRZE0fCHlj21XOnZgmuz3x4ck56ACc3ffRE/OBPL4NA0AnQtIEt/KLWgVrI8VTKc+V13UdOxM59ffj91nez7CFfOGNyXq8awFcYQ14OxVP49XM78h9o47k39+Mz9z2H7LjpAfrSBvCHX+zCwy+qd5oMc8V52vGj8PSr3cpj8uElCEIa4efr3yhqB1KIIRwwDd+Xf/hYzDvpyJyMnm6Y3pnF/YCmXWBkTtp4r8y1KlXw9HEjM+kuCsFef8ALt1QtqmSPqsVjrQShBS0MngdwAhEdB1MIfBLAZfYDiOgYZn4n/XIBgJfK3YhitmKF/kB+C6J7BSxZYf0fmXYUVm9+R3mMeR/k6Qao2jE4BdeheAohjVx102Fdw9I/vpyeZNLRu2Tmrxk3shHzl633ZVANEfD9P76CiJ5b2OSnT72uTCBWa5RD0VOsIPAirBO+Mu8E/PQvr5Xs7pqPxrCOkY2hzE7w+wvVNgAnXtHWblh5fKwFmJXbaH3nXvzH49sRSxrKzLVeTh/krMRHwF2fPBkdu3pwr4swTaT8qWv8LB7zeQzVQhBaoMKAmZNEtBjAH2C6lt7HzB1EdBuANmZeDeArRLQAQBLA+wA+W+52FLsV8/sDef3Q+YrbW0RDWiasf0xzFHOOewtLHu0AmBE3kDFkmQFunDP4LbWNX3VYU0T3TOncF0/ltDKka9h9wNSj+85Rb1rn4KYVq4BKfVCy7FMn47QPmCkylily6pebvkQKi3/TnuWVxT7EZMGCIKJjyUXTswrI20uYOlWbdtuVqu9PO2YE2nfsh65pWbmJwiENE48YhvmzxuGSD01Q7nRuvWi67wnaa/FYSx5DXgRuM2DmtQDWOt77lu3vrwP4etDtCGorpvqhb1i5WanXVxVzBwZ82u1FUawEZTv39WVUKVu7ejL5jox0jptoSEeKTQF0KJ7yrQ47FE+hIazlGEaHhXX0J3IFATBQZCRpGL71zc48QEER1sl0EdQ1s/2DXMg8tmUXJh4xDBNGN3oWBCo3Vn+xkhGWm6TBWYIgX/xMPJVyXWhZQXghQo4Q6U8MpKu21y6wXI7tLt1+cVs81pLHkBe1YECuGOXcilkr/p6+RM4PHUsy7n3mdfzfv76ZXdzeUcw9lkzi0lMm4XNzJ2f5tDsLoljvf2L5szmqmQFP6cLUYU0RPWfCjIY0XNo6Ab90NQQPFBkJaaYrmtc0H9bga/VYKiGN8INLZ2WK4vzrb/+mbJeV8rganPvBsXjipcK94Nx4vOM9PLH9PWia6cm28evnomNXD7r29SGWNLDvUBx3rQt+x2AnpJGrm69fUoaB3299FxOPGAazd+eqRLOPB37f8S7On350brWzdBBeXPG9qJ4dpZ9vsVhKhHAteQx5QW5pgmuZ1tZWbmtrq9r1swvKG0imjJztsK4RGkJaVocbHg3hV1fOwYTRjZmgM8vj585LZoIBV3XT06/swZf++wXXdA/RkIb/+kwrtr9zAN//4yvQ05G137ooNzjMaj8bZtqCaMgsMnL9eVN9e4oMS+8qVEO0KaqjP54CYAZ9lTpB5COsEx7/yplYu/VdLFvX6boT0TUgqufGcgx8TjCM8ouvaEjDdedNxXcf317mM5s0hDVsuGke1nfuxY3p1MgJIwXm0idnv0R0wq+vnJNTO8GLYWGzvrhq/FiEddPwm+82vnHBSYgljIwXXSyZ8gzCC2nApm/8k3JiN6OTs9NMlBohvLq9K0dNXY0oYyJ6gZlblZ+JMCiM7t5YJk2vhZunQlhHVjEVa9ACyDmH6XefrRPNHuTu+eQtnLloNELatVFDyjBww0dPwknHDFcGfTVFzOIpKaOwRG5Ovvz/HY9X3juYN3toOdHSeWryqUkiOiGZ4gBjtLPb1BQxUyWrykSWk+HREO65/GR8/hfP+56IS8XsV4CWTs/x7QXTcfmcY7G6vQvX+ij6EtII37zwg2hpjuK6B9sLKknqxrCwOdFeecbxuORDEzJODirCOmHj188FkF3D3Fm0xqoIZ78fa1wWunuohfxDXsJgSKmJyoFbKoo+I3fFfuUZx+O+DW9kiljccuG0tGopN6mdTlpOll97XnU/qQmc8sh6bUXufvfx7Up/eQA5GRrdUEVJD7QXOPekI5WxA0Fi1UbOR1CTsQqDgUtOGY9r5p2Ajl09ZjBYQNdPGAa69vWVLAgWtY7HI3/b5cv2kPYLgJHehX0rXX+4ORrKMdaqSBqMO3+/3dxZl0mAWf3yp395HROOGJZxGkmlsqvDAaaKc8Wmt/ETW/qYa/9pKpb+cXtWe1TPQqXv95NfqBY8hrwYksKg3Po/gznHhS6kARNGDwNgLs8NA7h19VY0hkOZYjd2UmwAnC0NzOtw0dG3KkqZEIdFdHzw6Ga88LY6X7/BZt0CweQXf30L7/fG8Idt73mm3ygWqzrYglnj8M0CisGraAzrmHbMCKxsc4/Md2Lvwyk2U6eE9dwdWlgnaEDO6t9tUVEOljy6Dc9+bR7WLD4DH7vrmZzPYynGsnWvIp4aqNfhV43nDLgE1J5MteYtlI8hJwxKzRDo5qYKIKuU3bfmT8ftj+Wm0LUqd4U0U5dstxkAuQVHdrzflzeXfaU4HE+5CgLAnBAecanyNVRZveXdQM5rpb9IpBgPtu0s+Xx9iRT+4/HtJavQnIJgWEQ38xKt3Fz0zujDx43Gxjf2FfSdkGYW+DlyRANCOuXsDAAg6bM9YZ2yCkItOmUg4DJhGLj67Ck5leBq0VsoH0PKZqDS97vp//ycy7m7cMYUXHHvJmXZRsDS85opeN3OAQCnf2+d7+yV9UiYANLgO02zUF9Y48uq9KcRZSK3CznH/z7z+IK9o5qjerqYU/HjJ6wPeKpZbt5OW4RqN1TsvBI0YjNIU05/X5X+z/meVxZRewpet3Ns3rG/oMRjFgTTgFkuFXU0pAHpgillRyPMnjgSz725v/znFqpGQ1gDs1nNrmPXARzsTwJgECivS7KTsKZhdFME0XQhHL+UsqPWNcJdn5iF0z4woOpxSxWvsis4s6rWA0NKGFTS39epTupPpsDMWcW4VbsBZzGbQvOpAGZ0JZgLSoPshcEcWEBTIsUiCAYh/QmzItpP//K6w6Gg8Am6P5nCvz+2rWKeUoCZvsIuCCz8pIovNKtqrTCkhEG+tBR+8wv5NT47A1kA5Hw3X4H7pQtnuhZvcWLldLn2vKn47trSfdqtIKJKRLYKg49Su000pFWt/0VDulJjMKY5ikWtE7IisJ0u3fkK4dQqQ0oYAO6RhvkMy929sXSgmFVCz8DicwYKprhhfWZdz6pDYJ0znxfC3Ckt+NEnZudNUTwsrGVyuqzYVLpHjwYzdbIgVJovn308RjdG8L0yGLQBMylaofsRK0md04bXsasHDzyfnf1WIzOWx+4MUm8qImAICgMgV7efb1I2004P+PpbtXrNwuKvYunCWVgwe7xy1+AUMvZykW42jI5dB3Jqu+bzfEgxcM5JRwIA7vrzKyU/owtmHIUnXt4juwKhIoTSKdJvvWg6wGcmqQAADKhJREFUzp9xNE7/3hNlEQSN4XRurAJPdutF0zORx6F0JDMzIxrWc9yEG8NqZ5B6Y0gKAydehmUAnkFfsaRZcOZgfzKrKPct86dh4uhhGSFinfvmR7aiKWIWRfn8GcflZB+1CqGHbSmf/WQH/fzcydi5rw873j9cFsNxy/CGnII2ghAYBHz29GMRDWl49rVuFFLB1SuNSF/CQFjz3hnoZKYqsUdTnz/96BzPQwDKAkVuziD1hggDeBuWvdJOW+hEWLJmG+KOSb8hpCmFiJWv6KdPvY6wTghpyApGM2sj+2+/BuC+DW/iVxvfRn+ydB9NDcAKCR4TKkjSAJY/82ZR36U86RDzrWnCIVMIaESZuM8nt+/OiR1wYtUfqVe1kBMRBshvWM7nPZBIGYiEtJyc/f0+3B8S6URx91z+IRzoS+DGh7cgUWChEgOWACnPSt6Av/QOglALlNrtrdW/Ne5ufmQrGkOEPo+ocWf9EYtayD9ULCIM0rgZlu2CQtcIiSTjrKlj8MyrezMRibdcOE1ZENtOY1h3DbYJaYRnX9vrWnFJEITgUFVjyycInPVHgNKzG1SbIRWBXAorNpqVx8K6hhQzbrlwGmaMH0gNbaWo1TXCIUewSzRE+K/PtGLH+324bU1HIHlqBGGoE05npS3n6AprABMhqpvJ9xafcwIumzMJQLabeDmzGwSJRCCXSHdvDLc/tg3x1EC5ydsf25b1Q1s7ixWb3sbdT7yaiQsIacDShbNw1lTT0+f8GUfj3mecgTjlIaypc7AIwlDA1PuXNzksA/jRotkY0RjOqIRUO4BjxzTVRTUzL7RqN6AadPfGsHnHfnT3xnwdbxmR7di9jSz2HYrjrideyQoQIyLMndKSeT2mOYrzZxyD5qhewh2oqVQhE0GoRQzOLwga9JxM8Z4kDeD6lZtx1X+3YUPn3iw39IOxJPoTBm58eAuaInpdVDPzInBhQETnE9HLRNRJRF9TfB4logfSn28ioslBtmdVexfm3rEOV9y7CXPvWIfV7flT9rp5G1lpbLt7Y1jV3oUL7n4GziJbiRSjY1d2ps+miB5Ibn0RBYLgTX8KaAgVFk3ZnzAyk37HrgPKheGheAp3XjITDWENw6MhNIS1uvMyClRNREQ6gHsAnAdgJ4DniWg1M9utrV8AsI+ZpxDRJwHcAeATQbTHT8SvCpW3kT2NreUS6mb8ffa17oyayNpiGoU4UguCUDa8jMNemEKAXXcAsyaO8qyjXOsEbTM4FUAnM78OAET0WwAXA7ALg4sBfDv990oAy4iIOADLdilZS+3eRvY0tn4Cwu7b8AauPPN4AANFMARBqC/M4LKRnm7otV7NzIughcF4APZEHjsBzHE7hpmTRNQDYAyAvfaDiOgqAFcBwKRJk4pqTKlZS60fWpXG1ouIrmfsC4V8TxCE6hMNaSBCZtJ3c0Ovd+rGm4iZlwNYDpiupcWcI19wmV9UQiWkAbqmIaTnupbaBU6+ADZBEGqDsAbccP5JmHPcmJxJv553AG4ELQy6AEy0vZ6Qfk91zE4iCgEYCaA7qAaVQ6q7CRXrvPYEc06BY30PMA1TUZ1gAJlaB32JJIgIDSE9k+Po/d44lj3ZiYhu1kVIpRi6DuQrGEUAomENi1onYMXGHUjVYUyJMHQZNzKKfzl5HLp7E3joha6c/hvSCB//0Hg88rcuMHNOJHJIA5YsmAGNgD9uew8bOrsRDhFiCQMGcybtNMHM0Gu9DuuEr8w7IW9G4sFGoEFn6cn9FQDnwpz0nwdwGTN32I65GsA/MPOX0gbkjzPzIq/zViPoTIVX6Lmfz5oiOg7FUzm1Dux/u5XDtL6/q6cfB/oSAIARjSEkkgY27+zBrAkj0TK8ISso5tnXurG3N4YZ40bgcCKFA33Z+TMO9iewY99h9MdTYADDIhoiuo49vXE0RXQYAI4d3YjdvXEc3zIM+/uSeGd/H17dfRBHjWjA8IYwOtN/z50yFkePiGLdy7vxdvchHDm8AVOPGo7mhnDmeiMaQxg3shHb3z2At7oPY/eBfrzRfQgfP3k8hjeE8eiWd3Dk8CiSKQM79x1GJKRj/KhGdB+KY9/hGPYejOGD40biyjNMe8yvN72FV987iJbhUYweFslcZ0xzFB+dfjT2H47jt8/vwIG+BKYc1Yx5Jx6JV3f3YkPnXvT2m8+iuSGEuVNa8I+Tj8D2dw/gzy/txku7ehAJ6Rg1LIT3DyXQFNHBDBxOpHBEUwTMjOGNYTRFdBAIW3buR9JgHDOqAcSE4Y06DscNdPfG0NOfwKFYCkcMC6N18hEIaxpe3dOLqWObETcM7Hi/DyMadew/nMCu/f2IJw00RnWMG9mAeJLRGNZw9KhGHOxLYOe+Phw/tgnHjmnC3t44YokU3tjbi8aIDmbCxCMacfzYZryzvw97DsYQSgdlNTeYa8De/iRSbKA/wRgR1bF55wH09McwbuQwtAyPgJjQ3BDCrImjwABefvcAUgajN5YCARjTHMGE0Y2Yc9wYvHsghre6DyGRMrC3N46W5ghGDQtj4uhh2P7uQQDAnOOOQDikI5FM4bG/v4NX3zuIiUcMwwfGNqNrfx8SKcZJRzVjd28cZ53QgtbjxmSNmY5dPem+ThjRGML0cSMzfXtgPPThQF8CIxojnqkiAKS9/AjTx41Ivz4AgDPnHYx4BZ0FHoFMRBcA+BHMtOL3MfN3iOg2AG3MvJqIGgD8N4CTAbwP4JOWwdmNWhEGgiAI9URVI5CZeS2AtY73vmX7ux/ApUG3QxAEQXBnSEYgC4IgCNmIMBAEQRBEGAiCIAgiDARBEATUaT0DItoD4K1qtyMAWuCIvB5kDPb7Awb/Pcr91TfHMvNY1Qd1KQwGK0TU5ub2NRgY7PcHDP57lPsbvIiaSBAEQRBhIAiCIIgwqDWWV7sBATPY7w8Y/Pco9zdIEZuBIAiCIDsDQRAEQYSBIAiCABEGNQUR3U5EW4ionYj+SETjqt2mckNES4loe/o+HyGiUdVuUzkhokuJqIOIDCIaVC6KRHQ+Eb1MRJ1E9LVqt6ecENF9RLSbiLZWuy3VQoRBbbGUmWcy82wAawB8K98X6pA/AZjBzDNh1rr4epXbU262Avg4gKer3ZByQkQ6gHsAfAzANACfIqJp1W1VWfkFgPOr3YhqIsKghmDmA7aXTQAGnXWfmf/IzFZVnY0wq98NGpj5JWZ+udrtCIBTAXQy8+vMHAfwWwAXV7lNZYOZn4ZZT2XIUjc1kIcKRPQdAJ8B0APgnCo3J2g+D+CBajdC8MV4ADtsr3cCmFOltggBIMKgwhDRnwEcrfjoZmZexcw3A7iZiL4OYDGAWyvawDKQ7x7Tx9wMIAlgRSXbVg783J8g1BsiDCoMM/+Tz0NXwKwQV3fCIN89EtFnAcwHcC7XYaBLAb/hYKILwETb6wnp94RBgtgMaggiOsH28mIA26vVlqAgovMB3AhgATMfrnZ7BN88D+AEIjqOiCIAPglgdZXbJJQRiUCuIYjoYQAnAjBgpuj+EjMPqtUXEXUCiALoTr+1kZm/VMUmlRUi+hcAPwYwFsB+AO3M/NHqtqo8ENEFAH4EQAdwHzN/p8pNKhtE9BsAZ8NMYf0egFuZ+edVbVSFEWEgCIIgiJpIEARBEGEgCIIgQISBIAiCABEGgiAIAkQYCIIgCBBhIAhKiGgUEf2fClznnwdZwjehThFhIAhqRgHwLQzIpJjx9M8ws4AKQlWROANBUEBEVlbOlwE8CWAmgNEAwgC+ycyriGgygD8A2ATgFAAXwEwyeAWAPTATu73AzN8nog/ATAE9FsBhAF8EcATMVOU96X+XMPNrFbpFQchCchMJgpqvway7MJuIQgCGMfMBImoBsJGIrFQMJwD4X8y8kYj+EcAlAGbBFBovAnghfdxymBHlrxLRHAA/YeZ56fOsYeaVlbw5QXAiwkAQ8kMAvktEZ8FMFTIewFHpz95i5o3pv+cCWMXM/QD6iehRACCiZgCnA3iIiKxzRivVeEHwgwgDQcjP5TDVO6cwc4KI3gTQkP7skI/vawD2pyvYCUJNIgZkQVBzEMDw9N8jAexOC4JzABzr8p0NAC4ioob0bmA+kKlg9wYRXQpkjM2zFNcRhKohwkAQFDBzN4AN6QLpswG0EtHfYRqIlanFmfl5mGmdtwB4HMDfYRqGAXN38QUi2gygAwMlI38L4AYi+lvayCwIVUG8iQShjBBRMzP3EtEwAE8DuIqZX6x2uwQhH2IzEITysjwdRNYA4JciCIR6QXYGgiAIgtgMBEEQBBEGgiAIAkQYCIIgCBBhIAiCIECEgSAIggDg/wH5erJt+pASAgAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"PvRi_JQgwcKI","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1627893978295,"user_tz":-540,"elapsed":15,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"11619466-c957-4942-9474-338fde28bb01"},"source":["# 二乗誤差が2.0を超える列\n","thr_ = 2.0 \n","train_kf_df[train_kf_df['diff_sq'] > thr_]"],"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>url_legal</th>\n","      <th>license</th>\n","      <th>excerpt</th>\n","      <th>target</th>\n","      <th>standard_error</th>\n","      <th>kfold</th>\n","      <th>bins_tg</th>\n","      <th>bins_std</th>\n","      <th>bins</th>\n","      <th>pred</th>\n","      <th>diff_sq</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>59</th>\n","      <td>9ea0d2788</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>The most important bee in the hive is naturall...</td>\n","      <td>0.987862</td>\n","      <td>0.594408</td>\n","      <td>2</td>\n","      <td>10</td>\n","      <td>9</td>\n","      <td>109</td>\n","      <td>-0.490408</td>\n","      <td>2.185281</td>\n","    </tr>\n","    <tr>\n","      <th>141</th>\n","      <td>bcd734621</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Midas was enjoying himself in his treasure-roo...</td>\n","      <td>0.943021</td>\n","      <td>0.537713</td>\n","      <td>0</td>\n","      <td>10</td>\n","      <td>5</td>\n","      <td>105</td>\n","      <td>-0.930454</td>\n","      <td>3.509907</td>\n","    </tr>\n","    <tr>\n","      <th>162</th>\n","      <td>060fc57c6</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>The owner of the island and sheep, A.P. Moore,...</td>\n","      <td>-2.099605</td>\n","      <td>0.472377</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>32</td>\n","      <td>-0.605813</td>\n","      <td>2.231414</td>\n","    </tr>\n","    <tr>\n","      <th>674</th>\n","      <td>09c41e31e</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>There was once a young man who spent all his t...</td>\n","      <td>1.465592</td>\n","      <td>0.639018</td>\n","      <td>2</td>\n","      <td>11</td>\n","      <td>11</td>\n","      <td>1111</td>\n","      <td>-0.023194</td>\n","      <td>2.216485</td>\n","    </tr>\n","    <tr>\n","      <th>695</th>\n","      <td>e26914a57</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Seedlings from the same fruit, and the young o...</td>\n","      <td>-0.769207</td>\n","      <td>0.469529</td>\n","      <td>2</td>\n","      <td>6</td>\n","      <td>2</td>\n","      <td>62</td>\n","      <td>-2.355489</td>\n","      <td>2.516288</td>\n","    </tr>\n","    <tr>\n","      <th>990</th>\n","      <td>afeb324bd</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>On the morning of the 20th of March, a long se...</td>\n","      <td>0.401053</td>\n","      <td>0.481889</td>\n","      <td>0</td>\n","      <td>9</td>\n","      <td>2</td>\n","      <td>92</td>\n","      <td>-1.041513</td>\n","      <td>2.080996</td>\n","    </tr>\n","    <tr>\n","      <th>1152</th>\n","      <td>03b761fd9</td>\n","      <td>https://simple.wikipedia.org/wiki/Larva</td>\n","      <td>CC BY-SA 3.0 and GFDL</td>\n","      <td>Probably the most widely accepted theory expla...</td>\n","      <td>-2.778515</td>\n","      <td>0.533111</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>15</td>\n","      <td>-1.123507</td>\n","      <td>2.739051</td>\n","    </tr>\n","    <tr>\n","      <th>1314</th>\n","      <td>85b41606e</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>As soon as the plate is dry, a positive cliché...</td>\n","      <td>-3.543987</td>\n","      <td>0.609348</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>-2.105827</td>\n","      <td>2.068306</td>\n","    </tr>\n","    <tr>\n","      <th>1347</th>\n","      <td>bae209b89</td>\n","      <td>https://www.africanstorybook.org/</td>\n","      <td>CC BY 4.0</td>\n","      <td>After a night of heavy rain, a group of friend...</td>\n","      <td>1.432604</td>\n","      <td>0.615058</td>\n","      <td>4</td>\n","      <td>11</td>\n","      <td>10</td>\n","      <td>1110</td>\n","      <td>-0.046176</td>\n","      <td>2.186791</td>\n","    </tr>\n","    <tr>\n","      <th>1412</th>\n","      <td>8f35441e3</td>\n","      <td>https://www.africanstorybook.org/#</td>\n","      <td>CC BY 4.0</td>\n","      <td>Every day, Emeka's father took him to school i...</td>\n","      <td>1.583847</td>\n","      <td>0.624776</td>\n","      <td>1</td>\n","      <td>11</td>\n","      <td>10</td>\n","      <td>1110</td>\n","      <td>-0.147679</td>\n","      <td>2.998183</td>\n","    </tr>\n","    <tr>\n","      <th>1538</th>\n","      <td>e9a3ac07b</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Everybody who has moved about the world at all...</td>\n","      <td>-0.416552</td>\n","      <td>0.488732</td>\n","      <td>2</td>\n","      <td>7</td>\n","      <td>3</td>\n","      <td>73</td>\n","      <td>-1.889223</td>\n","      <td>2.168759</td>\n","    </tr>\n","    <tr>\n","      <th>1821</th>\n","      <td>0c101f2db</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>The \"Legend of Sleepy Hollow\" is a genuine gho...</td>\n","      <td>0.356843</td>\n","      <td>0.481520</td>\n","      <td>3</td>\n","      <td>8</td>\n","      <td>2</td>\n","      <td>82</td>\n","      <td>-1.120605</td>\n","      <td>2.182854</td>\n","    </tr>\n","    <tr>\n","      <th>1944</th>\n","      <td>04ade0eb2</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>While I was hailing the brig, I spied a tract ...</td>\n","      <td>-3.315282</td>\n","      <td>0.544735</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>-1.696163</td>\n","      <td>2.621546</td>\n","    </tr>\n","    <tr>\n","      <th>1997</th>\n","      <td>bf3ea5462</td>\n","      <td>https://en.wikipedia.org/wiki/Machine_learning</td>\n","      <td>CC BY-SA 3.0</td>\n","      <td>Machine learning is a subfield of computer sci...</td>\n","      <td>-3.295576</td>\n","      <td>0.614204</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>10</td>\n","      <td>10</td>\n","      <td>-1.817943</td>\n","      <td>2.183398</td>\n","    </tr>\n","    <tr>\n","      <th>2124</th>\n","      <td>76f92b721</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>The biggest desert in the world is in Africa, ...</td>\n","      <td>1.103341</td>\n","      <td>0.553751</td>\n","      <td>2</td>\n","      <td>10</td>\n","      <td>6</td>\n","      <td>106</td>\n","      <td>-0.402802</td>\n","      <td>2.268467</td>\n","    </tr>\n","    <tr>\n","      <th>2277</th>\n","      <td>7c732b8bb</td>\n","      <td>https://en.wikipedia.org/wiki/Environmental_sc...</td>\n","      <td>CC BY-SA 3.0</td>\n","      <td>Environmental science is an interdisciplinary ...</td>\n","      <td>-3.137143</td>\n","      <td>0.555843</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>16</td>\n","      <td>-1.516155</td>\n","      <td>2.627603</td>\n","    </tr>\n","    <tr>\n","      <th>2611</th>\n","      <td>034bfda3f</td>\n","      <td>https://www.commonlit.org/texts/everyday-life-...</td>\n","      <td>CC BY-NC-SA 2.0</td>\n","      <td>Even the clothes we wear every day are scrupul...</td>\n","      <td>-1.624428</td>\n","      <td>0.484176</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>43</td>\n","      <td>-0.192856</td>\n","      <td>2.049400</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             id  ...   diff_sq\n","59    9ea0d2788  ...  2.185281\n","141   bcd734621  ...  3.509907\n","162   060fc57c6  ...  2.231414\n","674   09c41e31e  ...  2.216485\n","695   e26914a57  ...  2.516288\n","990   afeb324bd  ...  2.080996\n","1152  03b761fd9  ...  2.739051\n","1314  85b41606e  ...  2.068306\n","1347  bae209b89  ...  2.186791\n","1412  8f35441e3  ...  2.998183\n","1538  e9a3ac07b  ...  2.168759\n","1821  0c101f2db  ...  2.182854\n","1944  04ade0eb2  ...  2.621546\n","1997  bf3ea5462  ...  2.183398\n","2124  76f92b721  ...  2.268467\n","2277  7c732b8bb  ...  2.627603\n","2611  034bfda3f  ...  2.049400\n","\n","[17 rows x 12 columns]"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"code","metadata":{"id":"cL4lTGKjSAA5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627893978791,"user_tz":-540,"elapsed":509,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"ce677709-317a-46be-cb26-ade95d481765"},"source":["# 二乗誤差が2.0を超える文章\n","thr_ = 2.0 \n","tmp_df = train_kf_df[train_kf_df['diff_sq'] > thr_].copy()\n","for i in tmp_df.index:\n","  print(tmp_df.loc[i].target)\n","  #print(tmp_df.loc[i].standard_error)\n","  print(tmp_df.loc[i].pred)\n","  print(tmp_df.loc[i].excerpt)\n","  print('--------------------------')"],"execution_count":47,"outputs":[{"output_type":"stream","text":["0.987861812\n","-0.4904078543186188\n","The most important bee in the hive is naturally the queen. She is longer and sleeker than the others, and has a crooked sting, of which, however, she seldom makes use. Similar in form, but smaller, are the working-bees, whose sting is straight. The male bee, or drone, is thicker than the others, and stingless.\n","\"What has the queen to do in the hive?\" I asked. The old gentleman replied, \"She is the mother-bee, lays all the eggs, and is so diligent that she often lays twelve hundred in a day, having a separate cell for each egg. That is her only work; for she leaves the whole care of her children to the industrious working-bees, who have various labors to perform. Some of them build cells of wax; others bring in honey on the dust of flowers, called pollen; yet others feed and take care of the young; and a small number act as body-guard to the queen.\"\n","--------------------------\n","0.943020903\n","-0.9304537177085876\n","Midas was enjoying himself in his treasure-room, one day, as usual, when he perceived a shadow fall over the heaps of gold; and, looking suddenly up, what should he behold but the figure of a stranger, standing in the bright and narrow sunbeam! It was a young man, with a cheerful and ruddy face. Whether it was that the imagination of King Midas threw a yellow tinge over everything, or whatever the cause might be, he could not help fancying that the smile with which the stranger regarded him had a kind of golden radiance in it. Certainly, although his figure intercepted the sunshine, there was now a brighter gleam upon all the piled-up treasures than before. Even the remotest corners had their share of it, and were lighted up, when the stranger smiled, as with tips of flame and sparkles of fire.\n","--------------------------\n","-2.099604652\n","-0.6058127284049988\n","The owner of the island and sheep, A.P. Moore, a few years ago purchased the property from the widow of his deceased brother Henry, for $600,000. Owing to ill health, he has rented it to his brother Lawrence for $140,000 a year, and soon starts for Boston, where he will settle down for the rest of his life. He still retains an interest in the Santa Cruz Island ranch, which is about 25 miles southeast of Santa Barbara. This island contains about 64,000 acres, and on it are 25,000 sheep. On Catalina Island, 60 miles east of Santa Barbara, are 15,000 sheep, and on Clementa Island, 80 miles east of that city, are 10,000 sheep. Forty miles west of the same city is San Miguel, on which are 2,000 sheep. Each one of these ranches has a sailing vessel to carry freight, etc., to and fro between the islands and the mainland, and they are kept busy the greater part of the time.\n","--------------------------\n","1.465592368\n","-0.02319405972957611\n","There was once a young man who spent all his time in traveling. One day, as he was walking along, he picked up a snuffbox. He opened it, and the snuffbox said to him in the Spanish language: \"What do you want?\" He was very much frightened, but, luckily, instead of throwing the box away he only shut it tight and put it in his pocket. Then he went on, away, away, away, and as he went he said to himself, \"if it says to me again, 'What do you want?' I shall know better what to say this time.\" So he took out the snuffbox and opened it, and again it asked: \"What do you want?\" \"My hat full of gold,\" answered the youth, and immediately it was full.\n","Our young man was enchanted. Henceforth he should never be in need of anything. So on he traveled, away, away, away, through thick forests, till at last he came to a beautiful castle.\n","--------------------------\n","-0.7692072529999999\n","-2.3554885387420654\n","Seedlings from the same fruit, and the young of the same litter, sometimes differ considerably from each other, though both the young and the parents, as Muller has remarked, have apparently been exposed to exactly the same conditions of life; and this shows how unimportant the direct effects of the conditions of life are in comparison with the laws of reproduction, and of growth, and of inheritance; for had the action of the conditions been direct, if any of the young had varied, all would probably have varied in the same manner. To judge how much, in the case of any variation, we should attribute to the direct action of heat, moisture, light, food, etc., is most difficult: my impression is, that with animals such agencies have produced very little direct effect, though apparently more in the case of plants.\n","--------------------------\n","0.401052549\n","-1.0415133237838745\n","On the morning of the 20th of March, a long series of earthquakes spread alarm throughout all the cities and numerous villages that are scattered over the sides of Mt. Etna. The shocks followed each other at intervals of a few minutes; dull subterranean rumblings were heard; and a catastrophe was seen to be impending. Toward evening the ground cracked at the lower part of the south side of the mountain, at the limit of the cultivated zone, and at four kilometers to the north of the village of Nicolosi. There formed on the earth a large number of very wide fissures, through which escaped great volumes of steam and gases which enveloped the mountain in a thick haze; and toward night, a very bright red light, which, seen from Catania, seemed to come out in great waves from the foot of the mountain, announced the coming of the lava.\n","--------------------------\n","-2.778515087\n","-1.1235073804855347\n","Probably the most widely accepted theory explaining the evolution of larval stages is the need for dispersal. Sessile organisms such as barnacles and tunicates, and sea-floor groups like mussels and crabs, need some way to move their young into new territory, since they cannot move long distances as adults. Many species have relatively long pelagic larval stages (how long a larva is in the water column). During this time, larvae feed and grow, and many species move through several stages of development. For example, most barnacles molt through six nauplius larva stages before molting to a cipris, when they look to settle. The larvae eat different food from the adults, and disperse.\n","The other consideration is the small size of the eggs. If animals lay many small eggs (and most do), then the young stages cannot live the life the adults lead. They must live a separate life until they have the size and capability to live as an adult. This is what the larvae do.\n","--------------------------\n","-3.5439874060000003\n","-2.1058268547058105\n","As soon as the plate is dry, a positive cliché of the drawing to be reproduced is laid upon it, and the whole exposed to the sun for a minute, or to the electric light for three minutes. The reaction produced is the same as with the citrate of iron, but much quicker; the exposed parts are no longer hygroscopic, but in the parts protected by the lines of the drawing the sensitive coating has retained its stickiness, and will hold any powder that may be passed over it, thus producing a very clear image of the drawing. The coating being excessively thin, the little moisture it holds and the powder applied suffice to break its continuity, especially if the powder be slightly alkaline. If the rest of the surface were sufficiently resisting, the plate might be bitten at once; but light alone is not enough to produce complete impermeability: the action of heat must be combined with it. The plate is, therefore, placed on a grating, with wide openings, a large flame is applied underneath, and it is heated till the borders where the copper is bare show iridescent colors.\n","--------------------------\n","1.432603719\n","-0.046176400035619736\n","After a night of heavy rain, a group of friends were on their way to school. \n","They came to the river they had to cross every day. \"Yoh! It's stopped raining, but look how full and fast the river is,\" said Siya. \n","\"Oh no,\" groaned Linda. \"Do you think teacher will be angry if we miss our classes today?\" \n","Linda remembered what the Sea Rescue instructor had taught them in water safety lessons. \n","\"Never cross a flooded river. Even if you can't get to school,\" the instructor had said. \n","Meanwhile, Lungi stepped straight into the river! \"I know where the stepping stones are!\" he yelled. \n","But he soon fell into the water and the strong river began pulling him away. \n","\"Run and get help!\" shouted Linda. \"Tell them to call the free emergency number, like the Sea Rescue lady told us.\" \n","\"Help, help!\" shouted Lungi as he struggled to keep his head above the water. \n","\"Hold on, Lungi!\" shouted Phelelani, as he grabbed a branch that he could use to help his friend. \n","Phelelani's class had been taught that they should never go into the water to help someone as they might also be washed away.\n","--------------------------\n","1.583846826\n","-0.14767934381961823\n","Every day, Emeka's father took him to school in his car. He also brought Emeka home after school. One afternoon on their way home, Emeka's father stopped to buy something at a big shop. From the car, Emeka looked across the road and saw an old man. He was carrying a big load on his head. He was tired and walked slowly. Emeka kept looking at him. The old man sat under the shade of a tree on the walkway and opened his bag. He had two flat plastic water bottles, which he was making into shoes. Emeka thought about that old man for a long time. He felt sad. When he got home, he could not eat. He thought about what he could do. He got up and took some money from his money bag. He called Chita and jumped on his bicycle. Emeka rode to the shop where his father had shopped. The boy ran into the shop and came out with a bag. He went to where the old man was resting against a tree. Emeka called out, \"Good afternoon, sir.\" The man answered, \"Peace to you, my child.\"\n","--------------------------\n","-0.416552018\n","-1.8892228603363037\n","Everybody who has moved about the world at all knows Ring's Come-one Come-all Up-to-date Stores. The main office is in New York. Broadway, to be exact, on the left as you go down, just before you get to Park Row, where the newspapers come from. There is another office in Chicago. Others in St. Louis, St. Paul, and across the seas in London, Paris, Berlin, and, in short, everywhere. The peculiar advantage about Ring's Stores is that you can get anything you happen to want there, from a motor to a macaroon, and rather cheaper than you could get it anywhere else. England had up to the present been ill-supplied with these handy paradises, the one in Piccadilly being the only extant specimen. But now Mr. Ring in person had crossed the Atlantic on a tour of inspection, and things were shortly to be so brisk that you would be able to hear them whizz.\n","--------------------------\n","0.356843257\n","-1.1206051111221313\n","The \"Legend of Sleepy Hollow\" is a genuine ghost story. It is not very startling, but very, very funny, when you know what scared poor Ichabod Crane on his midnight ride that last time he went courting Governor Wouter Van Twiller's only daughter.\n","You must read for yourselves the famous story of Rip Van Winkle and the nap he took. It is too long for me to give in Irving's words, and \"Rip Van Winkle\" is just such a story as no one but Irving knows how to tell.\n","In another of his interesting stories in the \"Sketch Book,\" told, he says, by a strange old traveler to as strange a company gathered in a great inn-kitchen, Irving describes the busy making-ready for a wedding. The bride's father, he says, \"had in truth nothing exactly to do.\"\n","Do you suppose he was content to do nothing \"when all the world was in a hurry?\"\n","--------------------------\n","-3.31528229\n","-1.6961634159088135\n","While I was hailing the brig, I spied a tract of water lying between us, where no great waves came, but which yet boiled white all over and bristled in the moon with rings and bubbles. Sometimes the whole tract swung to one side, like the tail of a live serpent; sometimes, for a glimpse, it would all disappear and then boil up again. What it was I had no guess, which for the time increased my fear of it; but I now know it must have been the roost or tide-race, which had carried me away so fast and tumbled me about so cruelly, and at last, as if tired of that play, had flung out me and the spare yard upon its landward margin.\n","I now lay quite becalmed, and began to feel that a man can die of cold as well as of drowning. The shores of Earraid were close in; I could see in the moonlight the dots of heather and the sparkling of the mica in the rocks.\n","--------------------------\n","-3.2955761010000004\n","-1.8179434537887573\n","Machine learning is a subfield of computer science that evolved from the study of pattern recognition and computational learning theory in artificial intelligence. In 1959, Arthur Samuel defined machine learning as a \"Field of study that gives computers the ability to learn without being explicitly programmed\". Machine learning explores the study and construction of algorithms that can learn from and make predictions on data. Such algorithms operate by building a model from example inputs in order to make data-driven predictions or decisions,:2 rather than following strictly static program instructions.\n","Machine learning is closely related to (and often overlaps with) computational statistics; a discipline which also focuses in prediction-making through the use of computers. It has strong ties to mathematical optimization, which delivers methods, theory and application domains to the field. Machine learning is employed in a range of computing tasks where designing and programming explicit algorithms is unfeasible. Example applications include spam filtering, optical character recognition (OCR), search engines and computer vision.\n","--------------------------\n","1.103341259\n","-0.40280184149742126\n","The biggest desert in the world is in Africa, and is called the Sahara. It is almost as large as the Atlantic Ocean, but instead of water it is all sands and rocks. Like the ocean, it is visited with storms; dreadful gales, when the wind scoops up thousands of tons of sand and drives them forward, burying and crushing all they meet. And it has islands, too—small green patches, where springs bubble through the ground, and ferns and acacias and palm-trees grow. When a traveler sees one of these fertile spots afar off, he feels as a tempest-tossed sailor does at sight of land. It is delightful to quit the hot, baking sun, sit in shadow under the trees, and rest the eyes, long wearied with dazzling sands, on the sweet green and the clear spring. Oases, these islands are called. Long distances divide them. It is often a race for life to get across from one to the other.\n","--------------------------\n","-3.1371432610000003\n","-1.5161550045013428\n","Environmental science is an interdisciplinary academic field that integrates physical, biological and information sciences (including ecology, biology, physics, chemistry, zoology, mineralogy, oceanology, limnology, soil science, geology, atmospheric science, and geodesy) to the study of the environment, and the solution of environmental problems. Environmental science emerged from the fields of natural history and medicine during the Enlightenment. Today it provides an integrated, quantitative, and interdisciplinary approach to the study of environmental systems.\n","Related areas of study include environmental studies and environmental engineering. Environmental studies incorporate more of the social sciences for understanding human relationships, perceptions and policies towards the environment. Environmental engineering focuses on design and technology for improving environmental quality in every aspect. Environmental scientists work on subjects like the understanding of earth processes, evaluating alternative energy systems, pollution control and mitigation, natural resource management, and the effects of global climate change. Environmental issues almost always include an interaction of physical, chemical, and biological processes.\n","--------------------------\n","-1.624428478\n","-0.1928558200597763\n","Even the clothes we wear every day are scrupulously patterned after Victorian antiques and nineteenth-century fashion plates. Clothes are incredibly intimate. They influence how we move, and at the same time record tiny details about us that seem too mundane to write down — things like whether the items in our pockets are light or heavy, or what we do with our hands when we don't have pockets at all. I sew all my own clothes by hand, and Gabriel's are made for him by a seamstress in Seattle.\n","I'm an author; as with any true writer it's not just my profession but how I experience the world. I keep a diary every day, using an antique mother-of-pearl fountain pen I bought with part of my first book advance. I draft a lot of my manuscripts the same way: I enjoy this tangible connection to my words. (There have been some really interesting studies done showing the human brain processes information more thoroughly when it's written by hand as opposed to typed.) When I take notes from antique books and magazines I use a pencil to avoid dribbling ink on irreplaceable antique volumes.\n","--------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"d89ElwoOUPDx","executionInfo":{"status":"ok","timestamp":1627893978792,"user_tz":-540,"elapsed":5,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":47,"outputs":[]}]}