{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"039-train-01.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":86},"id":"Z6yRwt-PXtbP","executionInfo":{"status":"ok","timestamp":1625805333200,"user_tz":-540,"elapsed":370,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"33ef242c-81c2-4e6e-a989-061007fc6383"},"source":["\"\"\"\n","if 'google.colab' in sys.modules:  # colab環境特有の処理_初回のみ\n","  # Google Driveのマウント\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","\n","  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules' \\\n","   -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/requirements.txt' \\\n","   --ignore-installed\n","\n","  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules' \\\n","   transformers -U\n","  !pip install gensim==4.0.1 --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\n","  !pip install pytorch_memlab --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\n","\"\"\""],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\nif 'google.colab' in sys.modules:  # colab環境特有の処理_初回のみ\\n  # Google Driveのマウント\\n  from google.colab import drive\\n  drive.mount('/content/drive')\\n\\n  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'    -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/requirements.txt'    --ignore-installed\\n\\n  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'    transformers -U\\n  !pip install gensim==4.0.1 --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\\n  !pip install pytorch_memlab --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\\n\""]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kA8loJjZHY2-","executionInfo":{"status":"ok","timestamp":1625805336365,"user_tz":-540,"elapsed":2578,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"a38b04fb-22dd-4833-dc10-1a9669bfc70a"},"source":["!pip install pytorch_memlab"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pytorch_memlab in /usr/local/lib/python3.7/dist-packages (0.2.3)\n","Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch_memlab) (1.9.0+cu102)\n","Requirement already satisfied: pandas>=0.18 in /usr/local/lib/python3.7/dist-packages (from pytorch_memlab) (1.1.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytorch_memlab) (57.0.0)\n","Requirement already satisfied: calmsize in /usr/local/lib/python3.7/dist-packages (from pytorch_memlab) (0.1.3)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->pytorch_memlab) (3.7.4.3)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18->pytorch_memlab) (2.8.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18->pytorch_memlab) (2018.9)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18->pytorch_memlab) (1.19.5)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.18->pytorch_memlab) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ucCbvGD1XvG7","executionInfo":{"status":"ok","timestamp":1625805336366,"user_tz":-540,"elapsed":11,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"95752947-1202-4175-d758-3e468b5fc134"},"source":["import sys\n","if 'google.colab' in sys.modules:  # colab特有の処理_2回目以降\n","  # Google Driveのマウント\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","\n","  # データセットをDriveから取得\n","  !mkdir -p 'input'\n","  !cp -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/00_input' '/content/input'\n","\n","  # ライブラリのパス指定\n","  sys.path.append('/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules')\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RV9-VwbpZLZ9","executionInfo":{"status":"ok","timestamp":1625805337000,"user_tz":-540,"elapsed":638,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["from pathlib import Path\n","\n","# input\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    DATA_DIR = Path('../input/commonlitreadabilityprize/')\n","\n","elif 'google.colab' in sys.modules: # Colab環境\n","    !mkdir 'input' -p\n","    !cp '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/00_input/commonlitreadabilityprize/' './input' -r\n","    DATA_DIR = Path('/content/input/commonlitreadabilityprize')\n","\n","else:\n","    DATA_DIR = Path('../00_input/commonlitreadabilityprize/')"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"8tMampUSaDo5","executionInfo":{"status":"ok","timestamp":1625805337001,"user_tz":-540,"elapsed":7,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["from pathlib import Path\n","\n","# pre-trained model\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    PRE_TRAINED_MODEL_DIR = '../input/roberta-transformers-pytorch/roberta-large'\n","elif 'google.colab' in sys.modules: # Colab環境\n","    PRE_TRAINED_MODEL_DIR = 'roberta-base' # 仮で、毎回DLする想定のモデル名を指定。あとで変更予定。\n","else:\n","    PRE_TRAINED_MODEL_DIR = 'roberta-base'"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"tKjsUxnOeDYl","executionInfo":{"status":"ok","timestamp":1625805337002,"user_tz":-540,"elapsed":7,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["from pathlib import Path\n","\n","# pre-trained model\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    PRE_TRAINED_MODEL_DIR = '../input/roberta-transformers-pytorch/roberta-large'\n","elif 'google.colab' in sys.modules: # Colab環境\n","    PRE_TRAINED_MODEL_DIR = 'roberta-base' # 仮で、毎回DLする想定のモデル名を指定。あとで変更予定。\n","else:\n","    PRE_TRAINED_MODEL_DIR = 'roberta-base'"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZLaT2V0ReoAZ","executionInfo":{"status":"ok","timestamp":1625805337002,"user_tz":-540,"elapsed":7,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["UPLOAD_DIR = Path('/content/model')\n","EX_NO = '039-train-01'  # 実験番号などを入れる、folderのpathにする\n","USERID = 'calpis10000'"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"hOGjAb4pAJ0F","executionInfo":{"status":"ok","timestamp":1625805337004,"user_tz":-540,"elapsed":8,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["import subprocess\n","import shlex\n","\n","def gpuinfo():\n","    \"\"\"\n","    Returns size of total GPU RAM and used GPU RAM.\n","\n","    Parameters\n","    ----------\n","    None\n","\n","    Returns\n","    -------\n","    info : dict\n","        Total GPU RAM in integer for key 'total_MiB'.\n","        Used GPU RAM in integer for key 'used_MiB'.\n","    \"\"\"\n","\n","    command = 'nvidia-smi -q -d MEMORY | sed -n \"/FB Memory Usage/,/Free/p\" | sed -e \"1d\" -e \"4d\" -e \"s/ MiB//g\" | cut -d \":\" -f 2 | cut -c2-'\n","    commands = [shlex.split(part) for part in command.split(' | ')]\n","    for i, cmd in enumerate(commands):\n","        if i==0:\n","            res = subprocess.Popen(cmd, stdout=subprocess.PIPE)\n","        else:\n","            res = subprocess.Popen(cmd, stdin=res.stdout, stdout=subprocess.PIPE)\n","    total, used = map(int, res.communicate()[0].decode('utf-8').strip().split('\\n'))\n","    info = {'total_MiB':total, 'used_MiB':used}\n","    return info\n"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g3-6m5MKXecB"},"source":["# Overview\n","This nb is based on copy from https://www.kaggle.com/andretugan/lightweight-roberta-solution-in-pytorch .\n","\n","Acknowledgments(from base nb): \n","some ideas were taken from kernels by [Torch](https://www.kaggle.com/rhtsingh) and [Maunish](https://www.kaggle.com/maunish)."]},{"cell_type":"code","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-04T06:26:32.834365Z","iopub.execute_input":"2021-07-04T06:26:32.834903Z","iopub.status.idle":"2021-07-04T06:26:40.143740Z","shell.execute_reply.started":"2021-07-04T06:26:32.834785Z","shell.execute_reply":"2021-07-04T06:26:40.142864Z"},"trusted":true,"id":"HRsRZ06WXecD","executionInfo":{"status":"ok","timestamp":1625805340119,"user_tz":-540,"elapsed":3123,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["import os\n","import math\n","import random\n","import time\n","\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","\n","from transformers import AdamW # optimizer\n","from transformers import AutoTokenizer\n","from transformers import AutoModel\n","from transformers import AutoConfig\n","from transformers import get_cosine_schedule_with_warmup # scheduler\n","from pytorch_memlab import profile\n","import pytorch_memlab\n","from pytorch_memlab import MemReporter\n","\n","from sklearn.model_selection import KFold\n","\n","import gc\n","gc.enable()"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.145217Z","iopub.execute_input":"2021-07-04T06:26:40.145539Z","iopub.status.idle":"2021-07-04T06:26:40.201326Z","shell.execute_reply.started":"2021-07-04T06:26:40.145504Z","shell.execute_reply":"2021-07-04T06:26:40.200136Z"},"trusted":true,"id":"omBfwshTXecE","executionInfo":{"status":"ok","timestamp":1625805340123,"user_tz":-540,"elapsed":8,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["NUM_FOLDS = 5 # K Fold\n","NUM_EPOCHS = 5 # Epochs\n","BATCH_SIZE = 32 # Batch Size\n","MAX_LEN = 248 # ベクトル長\n","EVAL_SCHEDULE = [(0.50, 16), (0.49, 8), (0.48, 4), (0.47, 2), (-1., 1)] # schedulerの何らかの設定？\n","ROBERTA_PATH = PRE_TRAINED_MODEL_DIR # roberta pre-trainedモデル(モデルとして指定)\n","TOKENIZER_PATH = PRE_TRAINED_MODEL_DIR # roberta pre-trainedモデル(Tokenizerとして指定)\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\" # cudaがなければcpuを使えばいいじゃない"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.203398Z","iopub.execute_input":"2021-07-04T06:26:40.204055Z","iopub.status.idle":"2021-07-04T06:26:40.211572Z","shell.execute_reply.started":"2021-07-04T06:26:40.204015Z","shell.execute_reply":"2021-07-04T06:26:40.210762Z"},"trusted":true,"id":"4qcuXqwtXecF","executionInfo":{"status":"ok","timestamp":1625805340124,"user_tz":-540,"elapsed":8,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["def set_random_seed(random_seed):\n","    random.seed(random_seed)\n","    np.random.seed(random_seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(random_seed)\n","\n","    torch.manual_seed(random_seed)\n","    torch.cuda.manual_seed(random_seed)\n","    torch.cuda.manual_seed_all(random_seed)\n","\n","    torch.backends.cudnn.deterministic = True# cudnnによる最適化で結果が変わらないためのおまじない "],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.214188Z","iopub.execute_input":"2021-07-04T06:26:40.214809Z","iopub.status.idle":"2021-07-04T06:26:40.309744Z","shell.execute_reply.started":"2021-07-04T06:26:40.214769Z","shell.execute_reply":"2021-07-04T06:26:40.308926Z"},"trusted":true,"id":"70PyLsJTXecF","executionInfo":{"status":"ok","timestamp":1625805340124,"user_tz":-540,"elapsed":7,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# train, testを読む\n","train_df = pd.read_csv(DATA_DIR/\"train.csv\")\n","\n","# Remove incomplete entries if any.\n","train_df.drop(train_df[(train_df.target == 0) & (train_df.standard_error == 0)].index,\n","              inplace=True)\n","train_df.reset_index(drop=True, inplace=True)\n","\n","test_df = pd.read_csv(DATA_DIR/\"test.csv\")\n","submission_df = pd.read_csv(DATA_DIR/\"sample_submission.csv\")"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.311021Z","iopub.execute_input":"2021-07-04T06:26:40.311347Z","iopub.status.idle":"2021-07-04T06:26:40.624393Z","shell.execute_reply.started":"2021-07-04T06:26:40.311314Z","shell.execute_reply":"2021-07-04T06:26:40.623347Z"},"trusted":true,"id":"xf0662k4XecF","executionInfo":{"status":"ok","timestamp":1625805344953,"user_tz":-540,"elapsed":4836,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# tokenizerを指定\n","tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N6aaghNkXecG"},"source":["# Dataset"]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.628883Z","iopub.execute_input":"2021-07-04T06:26:40.629347Z","iopub.status.idle":"2021-07-04T06:26:40.644338Z","shell.execute_reply.started":"2021-07-04T06:26:40.629309Z","shell.execute_reply":"2021-07-04T06:26:40.643336Z"},"trusted":true,"id":"zkopT0U1XecG","executionInfo":{"status":"ok","timestamp":1625805344959,"user_tz":-540,"elapsed":19,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# Dataset用のClass。おそらく、trainとtestでインスタンスを生成し、DataFrameと同じように扱えるような思想。\n","class LitDataset(Dataset):\n","    def __init__(self, df, inference_only=False):\n","        super().__init__()\n","\n","        self.df = df        \n","        self.inference_only = inference_only # Testデータ用フラグ\n","        self.text = df.excerpt.tolist() # 分析対象カラムをlistにする。(分かち書きではなく、Seriesをlistへ変換するような処理)\n","        #self.text = [text.replace(\"\\n\", \" \") for text in self.text] # 単語単位で分かち書きする場合\n","        \n","        if not self.inference_only:\n","            self.target = torch.tensor(df.target.values, dtype=torch.float32) # trainのみ、targetをtensorに変換\n","    \n","        self.encoded = tokenizer.batch_encode_plus( # textをtokenize\n","            self.text,\n","            padding = 'max_length',            \n","            max_length = MAX_LEN,\n","            truncation = True, # 最大長を超える文字は切り捨て\n","            return_attention_mask=True\n","        )        \n"," \n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    \n","    def __getitem__(self, index): # 変換結果を返す\n","        input_ids = torch.tensor(self.encoded['input_ids'][index])\n","        attention_mask = torch.tensor(self.encoded['attention_mask'][index])\n","        \n","        if self.inference_only:\n","            return (input_ids, attention_mask)            \n","        else:\n","            target = self.target[index]\n","            return (input_ids, attention_mask, target)"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KKtdy32wXecG"},"source":["# Model\n","The model is inspired by the one from [Maunish](https://www.kaggle.com/maunish/clrp-roberta-svm)."]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.649629Z","iopub.execute_input":"2021-07-04T06:26:40.650066Z","iopub.status.idle":"2021-07-04T06:26:40.666374Z","shell.execute_reply.started":"2021-07-04T06:26:40.650002Z","shell.execute_reply":"2021-07-04T06:26:40.665211Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"BpkxjXEUXecH","executionInfo":{"status":"ok","timestamp":1625805344960,"user_tz":-540,"elapsed":18,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"585416e4-1f77-4925-8d89-962ad975b30b"},"source":["class LitModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        config = AutoConfig.from_pretrained(ROBERTA_PATH) # pretrainedからconfigを読み込み\n","        config.update({\"output_hidden_states\":True, # config更新: embedding層を抽出\n","                       \"hidden_dropout_prob\": 0.0, # config更新: dropoutしない\n","                       \"layer_norm_eps\": 1e-7}) # config更新: layer normalizationのepsilon                      \n","        \n","        self.roberta = AutoModel.from_pretrained(ROBERTA_PATH, config=config) # cpuで処理する\n","            \n","        self.attention = nn.Sequential(# attentionレイヤー            \n","            nn.Linear(768, 512), # 1024(元は768)は、ベースとなる学習済みモデルの重みをハードコードしてる。イケてないので、configから取得する感じにしたい。     \n","            nn.Tanh(),                       \n","            nn.Linear(512, 1),\n","            nn.Softmax(dim=1)\n","        )\n","\n","        self.regressor = nn.Sequential( # 出力レイヤー                    \n","            nn.Linear(768, 1)                        \n","        )\n","        \n","    %profile\n","    def forward(self, input_ids, attention_mask):\n","        #print('model: get_roberta_out: Start', gpuinfo())                 \n","        roberta_output = self.roberta(input_ids=input_ids, # robertaに入力データを流し、出力としてrobertaモデル(layerの複合体)を得る\n","                                      attention_mask=attention_mask)     \n","        #print('model: get_roberta_out: Done', gpuinfo())                 \n","\n","        # There are a total of 13 layers of hidden states.\n","        # 1 for the embedding layer, and 12 for the 12 Roberta layers.\n","        # We take the hidden states from the last Roberta layer.\n","        last_layer_hidden_states = roberta_output.hidden_states[-1] # robertaモデルの最後のlayerを得る\n","\n","        # The number of cells is MAX_LEN.\n","        # The size of the hidden state of each cell is 768 (for roberta-base). # \n","        # In order to condense hidden states of all cells to a context vector,\n","        # we compute a weighted average of the hidden states of all cells.\n","        # We compute the weight of each cell, using the attention neural network.\n","        weights = self.attention(last_layer_hidden_states) # robertaの最後のlayerをattentionへ入力し、出力として重みを得る\n","                \n","        # weights.shape is BATCH_SIZE x MAX_LEN x 1\n","        # last_layer_hidden_states.shape is BATCH_SIZE x MAX_LEN x 768        \n","        # Now we compute context_vector as the weighted average.\n","        # context_vector.shape is BATCH_SIZE x 768\n","        context_vector = torch.sum(weights * last_layer_hidden_states, dim=1) # 重み×最後の層を足し合わせて文書ベクトルとする。\n","        \n","        # Now we reduce the context vector to the prediction score.\n","        return self.regressor(context_vector) # 文書ベクトルを線形層に入力し、targetを出力する"],"execution_count":15,"outputs":[{"output_type":"stream","text":["default\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/IPython/core/magics/basic.py:300: UserWarning: %profile is now deprecated. Please use get_ipython().profile instead.\n","  warn(\"%profile is now deprecated. Please use get_ipython().profile instead.\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.672515Z","iopub.execute_input":"2021-07-04T06:26:40.672944Z","iopub.status.idle":"2021-07-04T06:26:40.684593Z","shell.execute_reply.started":"2021-07-04T06:26:40.672908Z","shell.execute_reply":"2021-07-04T06:26:40.683569Z"},"trusted":true,"id":"bB4jvQTxXecH","executionInfo":{"status":"ok","timestamp":1625805344960,"user_tz":-540,"elapsed":15,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 評価指標(MSE)の計算。最終的に、ルートしてRMSEにすると思われる。\n","def eval_mse(model, data_loader):\n","    \"\"\"Evaluates the mean squared error of the |model| on |data_loader|\"\"\"\n","    model.eval() # evalモードを選択。Batch Normとかdropoutをしなくなる           \n","    mse_sum = 0\n","\n","    with torch.no_grad(): # 勾配の計算をしないBlock\n","        for batch_num, (input_ids, attention_mask, target) in enumerate(data_loader): # data_loaderからinput, attentin_mask, targetをbatchごとに取り出す\n","            input_ids = input_ids.to(DEVICE)   \n","            attention_mask = attention_mask.to(DEVICE)   \n","            target = target.to(DEVICE)           \n","            \n","            pred = model(input_ids, attention_mask) # 取得した値をモデルへ入力し、出力として予測値を得る。\n","\n","            mse_sum += nn.MSELoss(reduction=\"sum\")(pred.flatten(), target).item() # 誤差の合計を得る(Batchごとに計算した誤差を足し上げる)\n","    del input_ids\n","    del attention_mask\n","    del target\n","  \n","    return mse_sum / len(data_loader.dataset) # 誤差の合計をdataset長で除し、mseを取得＆返す"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.690155Z","iopub.execute_input":"2021-07-04T06:26:40.692530Z","iopub.status.idle":"2021-07-04T06:26:40.703425Z","shell.execute_reply.started":"2021-07-04T06:26:40.692488Z","shell.execute_reply":"2021-07-04T06:26:40.702366Z"},"trusted":true,"id":"47bDno_LXecI","executionInfo":{"status":"ok","timestamp":1625805344960,"user_tz":-540,"elapsed":14,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 推論結果を返す\n","def predict(model, data_loader):\n","    \"\"\"Returns an np.array with predictions of the |model| on |data_loader|\"\"\"\n","    model.eval() # evalモード(dropout, batch_normしない)\n","\n","    result = np.zeros(len(data_loader.dataset)) # 結果をdataset長のzero配列として用意\n","    index = 0\n","    \n","    with torch.no_grad(): # 勾配の計算をしないblock(inputすると、現状の重みによる推論結果を返す)\n","        for batch_num, (input_ids, attention_mask) in enumerate(data_loader): # data_loaderからbatchごとにinputを得る\n","            input_ids = input_ids.to(DEVICE)\n","            attention_mask = attention_mask.to(DEVICE)\n","                        \n","            pred = model(input_ids, attention_mask) # modelにinputを入力し、予測結果を得る。\n","\n","            result[index : index + pred.shape[0]] = pred.flatten().to(\"cpu\") # result[index ~ predの長さ]へ、予測結果を格納\n","            index += pred.shape[0] # indexを更新\n","\n","    return result # 全batchで推論が終わったら、結果を返す"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.708605Z","iopub.execute_input":"2021-07-04T06:26:40.709024Z","iopub.status.idle":"2021-07-04T06:26:40.730675Z","shell.execute_reply.started":"2021-07-04T06:26:40.708983Z","shell.execute_reply":"2021-07-04T06:26:40.729705Z"},"trusted":true,"id":"oInneuAmXecI","executionInfo":{"status":"ok","timestamp":1625805344961,"user_tz":-540,"elapsed":15,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 学習\n","def train(model, # モデル\n","          model_path, # モデルのアウトプット先\n","          train_loader, # train-setのdata_loader\n","          val_loader, # valid-setのdata_loader\n","          optimizer, # optimizer\n","          scheduler=None, # scheduler, デフォルトはNone\n","          num_epochs=NUM_EPOCHS # epoch数、notebook冒頭で指定した値\n","         ):    \n","    \n","    best_val_rmse = None\n","    best_epoch = 0\n","    step = 0\n","    last_eval_step = 0\n","    eval_period = EVAL_SCHEDULE[0][1] # eval期間(って何？) 冒頭で決めたEVAL_SCHEDULEの最初のtupleの[1]を取得\n","\n","    start = time.time() # 時間計測用\n","\n","    for epoch in range(num_epochs): # 指定したEpoch数だけ繰り返し\n","        val_rmse = None         \n","\n","        for batch_num, (input_ids, attention_mask, target) in enumerate(train_loader): # train_loaderからinput, targetを取得\n","            input_ids = input_ids.to(DEVICE) # inputをDEVICEへ突っ込む\n","            attention_mask = attention_mask.to(DEVICE)       \n","            target = target.to(DEVICE)   \n","            #print(f'train_{epoch}_{batch_num}: get_input: Done', gpuinfo())                 \n","\n","            optimizer.zero_grad() # 勾配を初期化\n","            \n","            model.train() # 学習モード開始\n","\n","            #print(f'train_{epoch}_{batch_num}: get_pred: Start', gpuinfo())                 \n","            pred = model(input_ids, attention_mask) # input,attention_maskを入力し、予測結果を得る\n","            #print(f'train_{epoch}_{batch_num}: get_pred: Done', gpuinfo())  \n","\n","            #print(f'train_{epoch}_{batch_num}: get_loss: Start', gpuinfo())                 \n","            mse = nn.MSELoss(reduction=\"mean\")(pred.flatten(), target) # 予測結果からMSEを得る(これが損失関数となる?)\n","            #print(f'train_{epoch}_{batch_num}: get_loss: Done', gpuinfo())                 \n","\n","            mse.backward() # 誤差逆伝播法により勾配を得る\n","            optimizer.step() # 重みを更新する\n","\n","            if scheduler:\n","                scheduler.step() # schedulerが与えられた場合は、schedulerの学習率更新\n","            \n","            if step >= last_eval_step + eval_period: # batchを回すごとにstepを増やしていって、「前回evalしたstep + eval_period(16)」を超えたら実行。\n","                # Evaluate the model on val_loader.\n","                elapsed_seconds = time.time() - start # 経過時間\n","                num_steps = step - last_eval_step # 経過ステップ数\n","                print(f\"\\n{num_steps} steps took {elapsed_seconds:0.3} seconds\")\n","                last_eval_step = step # 前回stepの更新\n","                \n","                val_rmse = math.sqrt(eval_mse(model, val_loader)) # valid-setによるrmse計算                           \n","\n","                print(f\"Epoch: {epoch} batch_num: {batch_num}\", \n","                      f\"val_rmse: {val_rmse:0.4}\") # epoch, batch, score\n","\n","                for rmse, period in EVAL_SCHEDULE: # eval_periodをvalid-rmseで切り替える処理\n","                    if val_rmse >= rmse: # valid rmseをEVAL_SCHEDULEと比較し、0項 > valid rmseとなるまで回す : EVAL_SCHEDULE = [(0.50, 16), (0.49, 8), (0.48, 4), (0.47, 2), (-1., 1)]\n","                        eval_period = period # eval_periodを更新\n","                        break                               \n","\n","                if not best_val_rmse or val_rmse < best_val_rmse: # 初回(best_val_rmse==None), またはbest_val_rmseを更新したらモデルを保存する\n","                    best_val_rmse = val_rmse\n","                    best_epoch = epoch\n","                    torch.save(model.state_dict(), model_path) # 最高の自分を保存\n","                    print(f\"New best_val_rmse: {best_val_rmse:0.4}\")\n","                else:       \n","                    print(f\"Still best_val_rmse: {best_val_rmse:0.4}\", # 更新されない場合は、元のスコアを表示\n","                          f\"(from epoch {best_epoch})\")      \n","                                                  \n","                start = time.time()\n","            \n","            # batchごとにメモリ解放\n","            #print(f'train_{epoch}_{batch_num}: free_memory: Start', gpuinfo())                  \n","            del input_ids\n","            del attention_mask\n","            del target\n","            del pred\n","            del mse\n","            torch.cuda.empty_cache()\n","            #print(f'train_{epoch}_{batch_num}: free_memory: Done', gpuinfo())  \n","                                            \n","            step += 1\n","    \n","    return best_val_rmse"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.735798Z","iopub.execute_input":"2021-07-04T06:26:40.738398Z","iopub.status.idle":"2021-07-04T06:26:40.750876Z","shell.execute_reply.started":"2021-07-04T06:26:40.738356Z","shell.execute_reply":"2021-07-04T06:26:40.749635Z"},"trusted":true,"id":"rMY0fjXwXecJ","executionInfo":{"status":"ok","timestamp":1625805344961,"user_tz":-540,"elapsed":14,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# optimizerの作成\n","def create_optimizer(model):\n","    named_parameters = list(model.named_parameters()) # モデルパラメータの取得\n","    \n","    roberta_parameters = list(model.roberta.named_parameters())[:-2] # パラメータをroberta用、attention用、regressor用に格納。(直接引っ張ってくる形式に変更)\n","    attention_parameters = list(model.attention.named_parameters())\n","    regressor_parameters = list(model.regressor.named_parameters())\n","        \n","    attention_group = [params for (name, params) in attention_parameters] # attention用パラメータをリストとして取得\n","    regressor_group = [params for (name, params) in regressor_parameters] # reg用パラメータをリストとして取得\n","\n","    parameters = []\n","    parameters.append({\"params\": attention_group}) # パラメータをリストに辞書として格納していく\n","    parameters.append({\"params\": regressor_group})\n","\n","    for layer_num, (name, params) in enumerate(roberta_parameters): # レイヤーごとにname, paramsを取得していろんな処理\n","        weight_decay = 0.0 if \"bias\" in name else 0.01\n","        lr = 2e-5\n","\n","        if layer_num >= 69:        \n","            lr = 5e-5\n","\n","        if layer_num >= 133:\n","            lr = 1e-4\n","            \n","        parameters.append({\"params\": params,\n","                           \"weight_decay\": weight_decay,\n","                           \"lr\": lr})\n","\n","    return AdamW(parameters) # 最終的に、AdamWにパラメータを入力する。"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.755813Z","iopub.execute_input":"2021-07-04T06:26:40.758373Z","iopub.status.idle":"2021-07-04T06:27:12.493221Z","shell.execute_reply.started":"2021-07-04T06:26:40.758265Z","shell.execute_reply":"2021-07-04T06:27:12.490139Z"},"trusted":true,"id":"k2LGJD3XXecK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625808669306,"user_tz":-540,"elapsed":3248101,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"c2b658bc-db3f-48aa-a2f4-84167c06b7ed"},"source":["# 実行処理。 KFold & 学習\n","gc.collect()\n","\n","SEED = 1000\n","list_val_rmse = []\n","\n","kfold = KFold(n_splits=NUM_FOLDS, random_state=SEED, shuffle=True)\n","\n","for fold, (train_indices, val_indices) in enumerate(kfold.split(train_df)):    \n","    print(f\"\\nFold {fold + 1}/{NUM_FOLDS}\")\n","    model_path = f\"model_{fold + 1}.pth\" # model_fold数_.pth\n","        \n","    set_random_seed(SEED + fold) # SEEDはfold別に変わるようにする\n","    \n","    train_dataset = LitDataset(train_df.loc[train_indices]) # train, validのDataset\n","    val_dataset = LitDataset(train_df.loc[val_indices])\n","        \n","    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n","                              drop_last=True, shuffle=True, num_workers=2) # train, validのDataLoader\n","    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n","                            drop_last=False, shuffle=False, num_workers=2)    \n","        \n","    set_random_seed(SEED + fold) # なんで二回SEEDをセットするのだろう？\n","\n","    #print('getmodel: Start', gpuinfo())                 \n","    model = LitModel().to(DEVICE) # modelをDEVICEへぶち込む\n","    #print('getmodel: Done', gpuinfo())                 \n","\n","    #print('get_optim_sched: Start', gpuinfo())                 \n","    optimizer = create_optimizer(model) # optimizerをモデルから作成\n","    scheduler = get_cosine_schedule_with_warmup( # schedulerを作成\n","        optimizer,\n","        num_training_steps=NUM_EPOCHS * len(train_loader),\n","        num_warmup_steps=50)    \n","    #print('get_optim_sched: Done', gpuinfo())                 \n","\n","    list_val_rmse.append(train(model, model_path, train_loader,\n","                               val_loader, optimizer, scheduler=scheduler)) # 学習開始し、val_rmseのリストを格納\n","\n","    del model # モデルは保存したので、消す\n","    gc.collect() \n","    \n","    print(\"\\nPerformance estimates:\")\n","    print(list_val_rmse)\n","    print(\"Mean:\", np.array(list_val_rmse).mean())\n","    "],"execution_count":21,"outputs":[{"output_type":"stream","text":["\n","Fold 1/5\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"stream","text":["\n","16 steps took 17.3 seconds\n","Epoch: 0 batch_num: 16 val_rmse: 0.9292\n","New best_val_rmse: 0.9292\n","\n","16 steps took 16.5 seconds\n","Epoch: 0 batch_num: 32 val_rmse: 0.7068\n","New best_val_rmse: 0.7068\n","\n","16 steps took 16.5 seconds\n","Epoch: 0 batch_num: 48 val_rmse: 0.6034\n","New best_val_rmse: 0.6034\n","\n","16 steps took 16.5 seconds\n","Epoch: 0 batch_num: 64 val_rmse: 0.6094\n","Still best_val_rmse: 0.6034 (from epoch 0)\n","\n","16 steps took 16.6 seconds\n","Epoch: 1 batch_num: 10 val_rmse: 0.5499\n","New best_val_rmse: 0.5499\n","\n","16 steps took 16.5 seconds\n","Epoch: 1 batch_num: 26 val_rmse: 0.5425\n","New best_val_rmse: 0.5425\n","\n","16 steps took 16.5 seconds\n","Epoch: 1 batch_num: 42 val_rmse: 0.504\n","New best_val_rmse: 0.504\n","\n","16 steps took 16.5 seconds\n","Epoch: 1 batch_num: 58 val_rmse: 0.5036\n","New best_val_rmse: 0.5036\n","\n","16 steps took 16.6 seconds\n","Epoch: 2 batch_num: 4 val_rmse: 0.5147\n","Still best_val_rmse: 0.5036 (from epoch 1)\n","\n","16 steps took 16.5 seconds\n","Epoch: 2 batch_num: 20 val_rmse: 0.4905\n","New best_val_rmse: 0.4905\n","\n","8 steps took 8.24 seconds\n","Epoch: 2 batch_num: 28 val_rmse: 0.5044\n","Still best_val_rmse: 0.4905 (from epoch 2)\n","\n","16 steps took 16.5 seconds\n","Epoch: 2 batch_num: 44 val_rmse: 0.4855\n","New best_val_rmse: 0.4855\n","\n","4 steps took 4.13 seconds\n","Epoch: 2 batch_num: 48 val_rmse: 0.4971\n","Still best_val_rmse: 0.4855 (from epoch 2)\n","\n","8 steps took 8.24 seconds\n","Epoch: 2 batch_num: 56 val_rmse: 0.5061\n","Still best_val_rmse: 0.4855 (from epoch 2)\n","\n","16 steps took 16.6 seconds\n","Epoch: 3 batch_num: 2 val_rmse: 0.4957\n","Still best_val_rmse: 0.4855 (from epoch 2)\n","\n","8 steps took 8.24 seconds\n","Epoch: 3 batch_num: 10 val_rmse: 0.5064\n","Still best_val_rmse: 0.4855 (from epoch 2)\n","\n","16 steps took 16.5 seconds\n","Epoch: 3 batch_num: 26 val_rmse: 0.4931\n","Still best_val_rmse: 0.4855 (from epoch 2)\n","\n","8 steps took 8.23 seconds\n","Epoch: 3 batch_num: 34 val_rmse: 0.491\n","Still best_val_rmse: 0.4855 (from epoch 2)\n","\n","8 steps took 8.23 seconds\n","Epoch: 3 batch_num: 42 val_rmse: 0.4956\n","Still best_val_rmse: 0.4855 (from epoch 2)\n","\n","8 steps took 8.24 seconds\n","Epoch: 3 batch_num: 50 val_rmse: 0.4959\n","Still best_val_rmse: 0.4855 (from epoch 2)\n","\n","8 steps took 8.27 seconds\n","Epoch: 3 batch_num: 58 val_rmse: 0.5045\n","Still best_val_rmse: 0.4855 (from epoch 2)\n","\n","16 steps took 16.6 seconds\n","Epoch: 4 batch_num: 4 val_rmse: 0.4865\n","Still best_val_rmse: 0.4855 (from epoch 2)\n","\n","4 steps took 4.12 seconds\n","Epoch: 4 batch_num: 8 val_rmse: 0.4868\n","Still best_val_rmse: 0.4855 (from epoch 2)\n","\n","4 steps took 4.12 seconds\n","Epoch: 4 batch_num: 12 val_rmse: 0.4936\n","Still best_val_rmse: 0.4855 (from epoch 2)\n","\n","8 steps took 8.23 seconds\n","Epoch: 4 batch_num: 20 val_rmse: 0.4989\n","Still best_val_rmse: 0.4855 (from epoch 2)\n","\n","8 steps took 8.24 seconds\n","Epoch: 4 batch_num: 28 val_rmse: 0.4931\n","Still best_val_rmse: 0.4855 (from epoch 2)\n","\n","8 steps took 8.26 seconds\n","Epoch: 4 batch_num: 36 val_rmse: 0.4962\n","Still best_val_rmse: 0.4855 (from epoch 2)\n","\n","8 steps took 8.24 seconds\n","Epoch: 4 batch_num: 44 val_rmse: 0.4981\n","Still best_val_rmse: 0.4855 (from epoch 2)\n","\n","8 steps took 8.23 seconds\n","Epoch: 4 batch_num: 52 val_rmse: 0.4955\n","Still best_val_rmse: 0.4855 (from epoch 2)\n","\n","8 steps took 8.24 seconds\n","Epoch: 4 batch_num: 60 val_rmse: 0.4942\n","Still best_val_rmse: 0.4855 (from epoch 2)\n","\n","8 steps took 8.24 seconds\n","Epoch: 4 batch_num: 68 val_rmse: 0.4939\n","Still best_val_rmse: 0.4855 (from epoch 2)\n","\n","Performance estimates:\n","[0.48547078039400055]\n","Mean: 0.48547078039400055\n","\n","Fold 2/5\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"stream","text":["\n","16 steps took 17.2 seconds\n","Epoch: 0 batch_num: 16 val_rmse: 0.9467\n","New best_val_rmse: 0.9467\n","\n","16 steps took 16.3 seconds\n","Epoch: 0 batch_num: 32 val_rmse: 0.6654\n","New best_val_rmse: 0.6654\n","\n","16 steps took 16.3 seconds\n","Epoch: 0 batch_num: 48 val_rmse: 0.578\n","New best_val_rmse: 0.578\n","\n","16 steps took 16.3 seconds\n","Epoch: 0 batch_num: 64 val_rmse: 0.532\n","New best_val_rmse: 0.532\n","\n","16 steps took 16.5 seconds\n","Epoch: 1 batch_num: 10 val_rmse: 0.6136\n","Still best_val_rmse: 0.532 (from epoch 0)\n","\n","16 steps took 16.3 seconds\n","Epoch: 1 batch_num: 26 val_rmse: 0.5058\n","New best_val_rmse: 0.5058\n","\n","16 steps took 16.3 seconds\n","Epoch: 1 batch_num: 42 val_rmse: 0.5855\n","Still best_val_rmse: 0.5058 (from epoch 1)\n","\n","16 steps took 16.3 seconds\n","Epoch: 1 batch_num: 58 val_rmse: 0.4976\n","New best_val_rmse: 0.4976\n","\n","8 steps took 8.13 seconds\n","Epoch: 1 batch_num: 66 val_rmse: 0.5303\n","Still best_val_rmse: 0.4976 (from epoch 1)\n","\n","16 steps took 16.4 seconds\n","Epoch: 2 batch_num: 12 val_rmse: 0.4995\n","Still best_val_rmse: 0.4976 (from epoch 1)\n","\n","8 steps took 8.15 seconds\n","Epoch: 2 batch_num: 20 val_rmse: 0.537\n","Still best_val_rmse: 0.4976 (from epoch 1)\n","\n","16 steps took 16.3 seconds\n","Epoch: 2 batch_num: 36 val_rmse: 0.4731\n","New best_val_rmse: 0.4731\n","\n","2 steps took 2.03 seconds\n","Epoch: 2 batch_num: 38 val_rmse: 0.4774\n","Still best_val_rmse: 0.4731 (from epoch 2)\n","\n","2 steps took 2.03 seconds\n","Epoch: 2 batch_num: 40 val_rmse: 0.4792\n","Still best_val_rmse: 0.4731 (from epoch 2)\n","\n","2 steps took 2.03 seconds\n","Epoch: 2 batch_num: 42 val_rmse: 0.4739\n","Still best_val_rmse: 0.4731 (from epoch 2)\n","\n","2 steps took 2.04 seconds\n","Epoch: 2 batch_num: 44 val_rmse: 0.4738\n","Still best_val_rmse: 0.4731 (from epoch 2)\n","\n","2 steps took 2.03 seconds\n","Epoch: 2 batch_num: 46 val_rmse: 0.5031\n","Still best_val_rmse: 0.4731 (from epoch 2)\n","\n","16 steps took 16.3 seconds\n","Epoch: 2 batch_num: 62 val_rmse: 0.4643\n","New best_val_rmse: 0.4643\n","\n","1 steps took 1.02 seconds\n","Epoch: 2 batch_num: 63 val_rmse: 0.4625\n","New best_val_rmse: 0.4625\n","\n","1 steps took 1.02 seconds\n","Epoch: 2 batch_num: 64 val_rmse: 0.4616\n","New best_val_rmse: 0.4616\n","\n","1 steps took 1.01 seconds\n","Epoch: 2 batch_num: 65 val_rmse: 0.4635\n","Still best_val_rmse: 0.4616 (from epoch 2)\n","\n","1 steps took 1.01 seconds\n","Epoch: 2 batch_num: 66 val_rmse: 0.4668\n","Still best_val_rmse: 0.4616 (from epoch 2)\n","\n","1 steps took 1.01 seconds\n","Epoch: 2 batch_num: 67 val_rmse: 0.4693\n","Still best_val_rmse: 0.4616 (from epoch 2)\n","\n","1 steps took 1.01 seconds\n","Epoch: 2 batch_num: 68 val_rmse: 0.4702\n","Still best_val_rmse: 0.4616 (from epoch 2)\n","\n","2 steps took 2.17 seconds\n","Epoch: 3 batch_num: 0 val_rmse: 0.4693\n","Still best_val_rmse: 0.4616 (from epoch 2)\n","\n","1 steps took 1.02 seconds\n","Epoch: 3 batch_num: 1 val_rmse: 0.4629\n","Still best_val_rmse: 0.4616 (from epoch 2)\n","\n","1 steps took 1.01 seconds\n","Epoch: 3 batch_num: 2 val_rmse: 0.4587\n","New best_val_rmse: 0.4587\n","\n","1 steps took 1.02 seconds\n","Epoch: 3 batch_num: 3 val_rmse: 0.4599\n","Still best_val_rmse: 0.4587 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 3 batch_num: 4 val_rmse: 0.4621\n","Still best_val_rmse: 0.4587 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 3 batch_num: 5 val_rmse: 0.4602\n","Still best_val_rmse: 0.4587 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 3 batch_num: 6 val_rmse: 0.4613\n","Still best_val_rmse: 0.4587 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 3 batch_num: 7 val_rmse: 0.4693\n","Still best_val_rmse: 0.4587 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 3 batch_num: 8 val_rmse: 0.4782\n","Still best_val_rmse: 0.4587 (from epoch 3)\n","\n","2 steps took 2.04 seconds\n","Epoch: 3 batch_num: 10 val_rmse: 0.4726\n","Still best_val_rmse: 0.4587 (from epoch 3)\n","\n","2 steps took 2.04 seconds\n","Epoch: 3 batch_num: 12 val_rmse: 0.4618\n","Still best_val_rmse: 0.4587 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 3 batch_num: 13 val_rmse: 0.4601\n","Still best_val_rmse: 0.4587 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 3 batch_num: 14 val_rmse: 0.4602\n","Still best_val_rmse: 0.4587 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 3 batch_num: 15 val_rmse: 0.4624\n","Still best_val_rmse: 0.4587 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 3 batch_num: 16 val_rmse: 0.4663\n","Still best_val_rmse: 0.4587 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 3 batch_num: 17 val_rmse: 0.469\n","Still best_val_rmse: 0.4587 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 3 batch_num: 18 val_rmse: 0.4685\n","Still best_val_rmse: 0.4587 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 3 batch_num: 19 val_rmse: 0.466\n","Still best_val_rmse: 0.4587 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 3 batch_num: 20 val_rmse: 0.4638\n","Still best_val_rmse: 0.4587 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 3 batch_num: 21 val_rmse: 0.4616\n","Still best_val_rmse: 0.4587 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 3 batch_num: 22 val_rmse: 0.4613\n","Still best_val_rmse: 0.4587 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 3 batch_num: 23 val_rmse: 0.4632\n","Still best_val_rmse: 0.4587 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 3 batch_num: 24 val_rmse: 0.467\n","Still best_val_rmse: 0.4587 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 3 batch_num: 25 val_rmse: 0.4729\n","Still best_val_rmse: 0.4587 (from epoch 3)\n","\n","2 steps took 2.03 seconds\n","Epoch: 3 batch_num: 27 val_rmse: 0.4707\n","Still best_val_rmse: 0.4587 (from epoch 3)\n","\n","2 steps took 2.03 seconds\n","Epoch: 3 batch_num: 29 val_rmse: 0.4652\n","Still best_val_rmse: 0.4587 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 3 batch_num: 30 val_rmse: 0.4652\n","Still best_val_rmse: 0.4587 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 3 batch_num: 31 val_rmse: 0.4635\n","Still best_val_rmse: 0.4587 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 3 batch_num: 32 val_rmse: 0.4624\n","Still best_val_rmse: 0.4587 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 3 batch_num: 33 val_rmse: 0.4625\n","Still best_val_rmse: 0.4587 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 3 batch_num: 34 val_rmse: 0.4651\n","Still best_val_rmse: 0.4587 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 3 batch_num: 35 val_rmse: 0.4682\n","Still best_val_rmse: 0.4587 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 3 batch_num: 36 val_rmse: 0.4701\n","Still best_val_rmse: 0.4587 (from epoch 3)\n","\n","2 steps took 2.03 seconds\n","Epoch: 3 batch_num: 38 val_rmse: 0.4654\n","Still best_val_rmse: 0.4587 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 3 batch_num: 39 val_rmse: 0.4638\n","Still best_val_rmse: 0.4587 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 3 batch_num: 40 val_rmse: 0.4638\n","Still best_val_rmse: 0.4587 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 3 batch_num: 41 val_rmse: 0.4634\n","Still best_val_rmse: 0.4587 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 3 batch_num: 42 val_rmse: 0.4632\n","Still best_val_rmse: 0.4587 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 3 batch_num: 43 val_rmse: 0.4646\n","Still best_val_rmse: 0.4587 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 3 batch_num: 44 val_rmse: 0.4671\n","Still best_val_rmse: 0.4587 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 3 batch_num: 45 val_rmse: 0.472\n","Still best_val_rmse: 0.4587 (from epoch 3)\n","\n","2 steps took 2.03 seconds\n","Epoch: 3 batch_num: 47 val_rmse: 0.4822\n","Still best_val_rmse: 0.4587 (from epoch 3)\n","\n","4 steps took 4.06 seconds\n","Epoch: 3 batch_num: 51 val_rmse: 0.4634\n","Still best_val_rmse: 0.4587 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 3 batch_num: 52 val_rmse: 0.4586\n","New best_val_rmse: 0.4586\n","\n","1 steps took 1.01 seconds\n","Epoch: 3 batch_num: 53 val_rmse: 0.4589\n","Still best_val_rmse: 0.4586 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 3 batch_num: 54 val_rmse: 0.4597\n","Still best_val_rmse: 0.4586 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 3 batch_num: 55 val_rmse: 0.4595\n","Still best_val_rmse: 0.4586 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 3 batch_num: 56 val_rmse: 0.4583\n","New best_val_rmse: 0.4583\n","\n","1 steps took 1.01 seconds\n","Epoch: 3 batch_num: 57 val_rmse: 0.4586\n","Still best_val_rmse: 0.4583 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 3 batch_num: 58 val_rmse: 0.4617\n","Still best_val_rmse: 0.4583 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 3 batch_num: 59 val_rmse: 0.4691\n","Still best_val_rmse: 0.4583 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 3 batch_num: 60 val_rmse: 0.4761\n","Still best_val_rmse: 0.4583 (from epoch 3)\n","\n","2 steps took 2.03 seconds\n","Epoch: 3 batch_num: 62 val_rmse: 0.4797\n","Still best_val_rmse: 0.4583 (from epoch 3)\n","\n","2 steps took 2.03 seconds\n","Epoch: 3 batch_num: 64 val_rmse: 0.4742\n","Still best_val_rmse: 0.4583 (from epoch 3)\n","\n","2 steps took 2.04 seconds\n","Epoch: 3 batch_num: 66 val_rmse: 0.4642\n","Still best_val_rmse: 0.4583 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 3 batch_num: 67 val_rmse: 0.46\n","Still best_val_rmse: 0.4583 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 3 batch_num: 68 val_rmse: 0.4581\n","New best_val_rmse: 0.4581\n","\n","1 steps took 1.02 seconds\n","Epoch: 3 batch_num: 69 val_rmse: 0.4578\n","New best_val_rmse: 0.4578\n","\n","1 steps took 1.17 seconds\n","Epoch: 4 batch_num: 0 val_rmse: 0.4581\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 4 batch_num: 1 val_rmse: 0.4585\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 4 batch_num: 2 val_rmse: 0.4587\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.03 seconds\n","Epoch: 4 batch_num: 3 val_rmse: 0.4588\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 4 batch_num: 4 val_rmse: 0.4589\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 4 batch_num: 5 val_rmse: 0.4593\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 4 batch_num: 6 val_rmse: 0.46\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 4 batch_num: 7 val_rmse: 0.461\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 4 batch_num: 8 val_rmse: 0.4622\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 4 batch_num: 9 val_rmse: 0.4637\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 4 batch_num: 10 val_rmse: 0.4643\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 4 batch_num: 11 val_rmse: 0.465\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 4 batch_num: 12 val_rmse: 0.4656\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 4 batch_num: 13 val_rmse: 0.4658\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 4 batch_num: 14 val_rmse: 0.4655\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 4 batch_num: 15 val_rmse: 0.4652\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 4 batch_num: 16 val_rmse: 0.4651\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 4 batch_num: 17 val_rmse: 0.4652\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 4 batch_num: 18 val_rmse: 0.4643\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 4 batch_num: 19 val_rmse: 0.4641\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 4 batch_num: 20 val_rmse: 0.4635\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 4 batch_num: 21 val_rmse: 0.4633\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 4 batch_num: 22 val_rmse: 0.4624\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 4 batch_num: 23 val_rmse: 0.4619\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 4 batch_num: 24 val_rmse: 0.4619\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 4 batch_num: 25 val_rmse: 0.4622\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 4 batch_num: 26 val_rmse: 0.4623\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 4 batch_num: 27 val_rmse: 0.4624\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 4 batch_num: 28 val_rmse: 0.4625\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 4 batch_num: 29 val_rmse: 0.4627\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 4 batch_num: 30 val_rmse: 0.4629\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 4 batch_num: 31 val_rmse: 0.4631\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 4 batch_num: 32 val_rmse: 0.4634\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 4 batch_num: 33 val_rmse: 0.4636\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 4 batch_num: 34 val_rmse: 0.4635\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 4 batch_num: 35 val_rmse: 0.4636\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 4 batch_num: 36 val_rmse: 0.4638\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 4 batch_num: 37 val_rmse: 0.4639\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 4 batch_num: 38 val_rmse: 0.4639\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 4 batch_num: 39 val_rmse: 0.4638\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 4 batch_num: 40 val_rmse: 0.4636\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 4 batch_num: 41 val_rmse: 0.4634\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 4 batch_num: 42 val_rmse: 0.4632\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 4 batch_num: 43 val_rmse: 0.463\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 4 batch_num: 44 val_rmse: 0.4629\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 4 batch_num: 45 val_rmse: 0.4627\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 4 batch_num: 46 val_rmse: 0.4627\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 4 batch_num: 47 val_rmse: 0.4626\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 4 batch_num: 48 val_rmse: 0.4626\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 4 batch_num: 49 val_rmse: 0.4626\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 4 batch_num: 50 val_rmse: 0.4627\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 4 batch_num: 51 val_rmse: 0.4628\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 4 batch_num: 52 val_rmse: 0.4628\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 4 batch_num: 53 val_rmse: 0.4629\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 4 batch_num: 54 val_rmse: 0.4629\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 4 batch_num: 55 val_rmse: 0.4629\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 4 batch_num: 56 val_rmse: 0.4628\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 4 batch_num: 57 val_rmse: 0.4628\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 4 batch_num: 58 val_rmse: 0.4628\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 4 batch_num: 59 val_rmse: 0.4628\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 4 batch_num: 60 val_rmse: 0.4629\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 4 batch_num: 61 val_rmse: 0.4629\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 4 batch_num: 62 val_rmse: 0.4629\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 4 batch_num: 63 val_rmse: 0.4629\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 4 batch_num: 64 val_rmse: 0.4629\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 4 batch_num: 65 val_rmse: 0.4629\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 4 batch_num: 66 val_rmse: 0.4629\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.01 seconds\n","Epoch: 4 batch_num: 67 val_rmse: 0.4629\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 4 batch_num: 68 val_rmse: 0.4629\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","1 steps took 1.02 seconds\n","Epoch: 4 batch_num: 69 val_rmse: 0.4629\n","Still best_val_rmse: 0.4578 (from epoch 3)\n","\n","Performance estimates:\n","[0.48547078039400055, 0.45781590850086784]\n","Mean: 0.47164334444743417\n","\n","Fold 3/5\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"stream","text":["\n","16 steps took 16.9 seconds\n","Epoch: 0 batch_num: 16 val_rmse: 1.036\n","New best_val_rmse: 1.036\n","\n","16 steps took 16.1 seconds\n","Epoch: 0 batch_num: 32 val_rmse: 0.9044\n","New best_val_rmse: 0.9044\n","\n","16 steps took 16.1 seconds\n","Epoch: 0 batch_num: 48 val_rmse: 0.6576\n","New best_val_rmse: 0.6576\n","\n","16 steps took 16.1 seconds\n","Epoch: 0 batch_num: 64 val_rmse: 0.6554\n","New best_val_rmse: 0.6554\n","\n","16 steps took 16.2 seconds\n","Epoch: 1 batch_num: 10 val_rmse: 0.6122\n","New best_val_rmse: 0.6122\n","\n","16 steps took 16.1 seconds\n","Epoch: 1 batch_num: 26 val_rmse: 0.5941\n","New best_val_rmse: 0.5941\n","\n","16 steps took 16.1 seconds\n","Epoch: 1 batch_num: 42 val_rmse: 0.5393\n","New best_val_rmse: 0.5393\n","\n","16 steps took 16.1 seconds\n","Epoch: 1 batch_num: 58 val_rmse: 0.5178\n","New best_val_rmse: 0.5178\n","\n","16 steps took 16.2 seconds\n","Epoch: 2 batch_num: 4 val_rmse: 0.5241\n","Still best_val_rmse: 0.5178 (from epoch 1)\n","\n","16 steps took 16.1 seconds\n","Epoch: 2 batch_num: 20 val_rmse: 0.5028\n","New best_val_rmse: 0.5028\n","\n","16 steps took 16.1 seconds\n","Epoch: 2 batch_num: 36 val_rmse: 0.5016\n","New best_val_rmse: 0.5016\n","\n","16 steps took 16.1 seconds\n","Epoch: 2 batch_num: 52 val_rmse: 0.4899\n","New best_val_rmse: 0.4899\n","\n","4 steps took 4.04 seconds\n","Epoch: 2 batch_num: 56 val_rmse: 0.495\n","Still best_val_rmse: 0.4899 (from epoch 2)\n","\n","8 steps took 8.03 seconds\n","Epoch: 2 batch_num: 64 val_rmse: 0.4982\n","Still best_val_rmse: 0.4899 (from epoch 2)\n","\n","8 steps took 8.19 seconds\n","Epoch: 3 batch_num: 2 val_rmse: 0.4883\n","New best_val_rmse: 0.4883\n","\n","4 steps took 4.02 seconds\n","Epoch: 3 batch_num: 6 val_rmse: 0.4984\n","Still best_val_rmse: 0.4883 (from epoch 3)\n","\n","8 steps took 8.04 seconds\n","Epoch: 3 batch_num: 14 val_rmse: 0.5255\n","Still best_val_rmse: 0.4883 (from epoch 3)\n","\n","16 steps took 16.1 seconds\n","Epoch: 3 batch_num: 30 val_rmse: 0.4877\n","New best_val_rmse: 0.4877\n","\n","4 steps took 4.01 seconds\n","Epoch: 3 batch_num: 34 val_rmse: 0.4811\n","New best_val_rmse: 0.4811\n","\n","4 steps took 4.04 seconds\n","Epoch: 3 batch_num: 38 val_rmse: 0.4793\n","New best_val_rmse: 0.4793\n","\n","2 steps took 2.01 seconds\n","Epoch: 3 batch_num: 40 val_rmse: 0.4906\n","Still best_val_rmse: 0.4793 (from epoch 3)\n","\n","8 steps took 8.05 seconds\n","Epoch: 3 batch_num: 48 val_rmse: 0.4949\n","Still best_val_rmse: 0.4793 (from epoch 3)\n","\n","8 steps took 8.03 seconds\n","Epoch: 3 batch_num: 56 val_rmse: 0.4963\n","Still best_val_rmse: 0.4793 (from epoch 3)\n","\n","8 steps took 8.05 seconds\n","Epoch: 3 batch_num: 64 val_rmse: 0.4861\n","Still best_val_rmse: 0.4793 (from epoch 3)\n","\n","4 steps took 4.0 seconds\n","Epoch: 3 batch_num: 68 val_rmse: 0.4853\n","Still best_val_rmse: 0.4793 (from epoch 3)\n","\n","4 steps took 4.15 seconds\n","Epoch: 4 batch_num: 2 val_rmse: 0.5076\n","Still best_val_rmse: 0.4793 (from epoch 3)\n","\n","16 steps took 16.1 seconds\n","Epoch: 4 batch_num: 18 val_rmse: 0.4805\n","Still best_val_rmse: 0.4793 (from epoch 3)\n","\n","4 steps took 4.02 seconds\n","Epoch: 4 batch_num: 22 val_rmse: 0.4817\n","Still best_val_rmse: 0.4793 (from epoch 3)\n","\n","4 steps took 4.02 seconds\n","Epoch: 4 batch_num: 26 val_rmse: 0.4802\n","Still best_val_rmse: 0.4793 (from epoch 3)\n","\n","4 steps took 4.01 seconds\n","Epoch: 4 batch_num: 30 val_rmse: 0.4787\n","New best_val_rmse: 0.4787\n","\n","2 steps took 2.01 seconds\n","Epoch: 4 batch_num: 32 val_rmse: 0.4784\n","New best_val_rmse: 0.4784\n","\n","2 steps took 2.01 seconds\n","Epoch: 4 batch_num: 34 val_rmse: 0.4782\n","New best_val_rmse: 0.4782\n","\n","2 steps took 2.01 seconds\n","Epoch: 4 batch_num: 36 val_rmse: 0.4781\n","New best_val_rmse: 0.4781\n","\n","2 steps took 2.01 seconds\n","Epoch: 4 batch_num: 38 val_rmse: 0.4781\n","New best_val_rmse: 0.4781\n","\n","2 steps took 2.01 seconds\n","Epoch: 4 batch_num: 40 val_rmse: 0.4781\n","New best_val_rmse: 0.4781\n","\n","2 steps took 2.01 seconds\n","Epoch: 4 batch_num: 42 val_rmse: 0.4781\n","New best_val_rmse: 0.4781\n","\n","2 steps took 2.01 seconds\n","Epoch: 4 batch_num: 44 val_rmse: 0.4782\n","Still best_val_rmse: 0.4781 (from epoch 4)\n","\n","2 steps took 2.01 seconds\n","Epoch: 4 batch_num: 46 val_rmse: 0.4784\n","Still best_val_rmse: 0.4781 (from epoch 4)\n","\n","2 steps took 2.01 seconds\n","Epoch: 4 batch_num: 48 val_rmse: 0.4787\n","Still best_val_rmse: 0.4781 (from epoch 4)\n","\n","2 steps took 2.01 seconds\n","Epoch: 4 batch_num: 50 val_rmse: 0.4789\n","Still best_val_rmse: 0.4781 (from epoch 4)\n","\n","2 steps took 2.0 seconds\n","Epoch: 4 batch_num: 52 val_rmse: 0.4789\n","Still best_val_rmse: 0.4781 (from epoch 4)\n","\n","2 steps took 2.01 seconds\n","Epoch: 4 batch_num: 54 val_rmse: 0.479\n","Still best_val_rmse: 0.4781 (from epoch 4)\n","\n","2 steps took 2.01 seconds\n","Epoch: 4 batch_num: 56 val_rmse: 0.4791\n","Still best_val_rmse: 0.4781 (from epoch 4)\n","\n","2 steps took 2.01 seconds\n","Epoch: 4 batch_num: 58 val_rmse: 0.4792\n","Still best_val_rmse: 0.4781 (from epoch 4)\n","\n","2 steps took 2.0 seconds\n","Epoch: 4 batch_num: 60 val_rmse: 0.4792\n","Still best_val_rmse: 0.4781 (from epoch 4)\n","\n","2 steps took 2.01 seconds\n","Epoch: 4 batch_num: 62 val_rmse: 0.4793\n","Still best_val_rmse: 0.4781 (from epoch 4)\n","\n","2 steps took 2.0 seconds\n","Epoch: 4 batch_num: 64 val_rmse: 0.4793\n","Still best_val_rmse: 0.4781 (from epoch 4)\n","\n","2 steps took 2.02 seconds\n","Epoch: 4 batch_num: 66 val_rmse: 0.4793\n","Still best_val_rmse: 0.4781 (from epoch 4)\n","\n","2 steps took 2.0 seconds\n","Epoch: 4 batch_num: 68 val_rmse: 0.4793\n","Still best_val_rmse: 0.4781 (from epoch 4)\n","\n","Performance estimates:\n","[0.48547078039400055, 0.45781590850086784, 0.47805608112029807]\n","Mean: 0.4737809233383888\n","\n","Fold 4/5\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"stream","text":["\n","16 steps took 16.6 seconds\n","Epoch: 0 batch_num: 16 val_rmse: 0.965\n","New best_val_rmse: 0.965\n","\n","16 steps took 15.7 seconds\n","Epoch: 0 batch_num: 32 val_rmse: 0.7128\n","New best_val_rmse: 0.7128\n","\n","16 steps took 15.8 seconds\n","Epoch: 0 batch_num: 48 val_rmse: 0.6773\n","New best_val_rmse: 0.6773\n","\n","16 steps took 15.7 seconds\n","Epoch: 0 batch_num: 64 val_rmse: 0.5547\n","New best_val_rmse: 0.5547\n","\n","16 steps took 15.9 seconds\n","Epoch: 1 batch_num: 10 val_rmse: 0.6796\n","Still best_val_rmse: 0.5547 (from epoch 0)\n","\n","16 steps took 15.8 seconds\n","Epoch: 1 batch_num: 26 val_rmse: 0.5401\n","New best_val_rmse: 0.5401\n","\n","16 steps took 15.8 seconds\n","Epoch: 1 batch_num: 42 val_rmse: 0.555\n","Still best_val_rmse: 0.5401 (from epoch 1)\n","\n","16 steps took 15.8 seconds\n","Epoch: 1 batch_num: 58 val_rmse: 0.5235\n","New best_val_rmse: 0.5235\n","\n","16 steps took 15.9 seconds\n","Epoch: 2 batch_num: 4 val_rmse: 0.5304\n","Still best_val_rmse: 0.5235 (from epoch 1)\n","\n","16 steps took 15.8 seconds\n","Epoch: 2 batch_num: 20 val_rmse: 0.5048\n","New best_val_rmse: 0.5048\n","\n","16 steps took 15.8 seconds\n","Epoch: 2 batch_num: 36 val_rmse: 0.551\n","Still best_val_rmse: 0.5048 (from epoch 2)\n","\n","16 steps took 15.8 seconds\n","Epoch: 2 batch_num: 52 val_rmse: 0.526\n","Still best_val_rmse: 0.5048 (from epoch 2)\n","\n","16 steps took 15.8 seconds\n","Epoch: 2 batch_num: 68 val_rmse: 0.5001\n","New best_val_rmse: 0.5001\n","\n","16 steps took 15.9 seconds\n","Epoch: 3 batch_num: 14 val_rmse: 0.5071\n","Still best_val_rmse: 0.5001 (from epoch 2)\n","\n","16 steps took 15.8 seconds\n","Epoch: 3 batch_num: 30 val_rmse: 0.5062\n","Still best_val_rmse: 0.5001 (from epoch 2)\n","\n","16 steps took 15.8 seconds\n","Epoch: 3 batch_num: 46 val_rmse: 0.49\n","New best_val_rmse: 0.49\n","\n","4 steps took 3.93 seconds\n","Epoch: 3 batch_num: 50 val_rmse: 0.4921\n","Still best_val_rmse: 0.49 (from epoch 3)\n","\n","8 steps took 7.87 seconds\n","Epoch: 3 batch_num: 58 val_rmse: 0.4993\n","Still best_val_rmse: 0.49 (from epoch 3)\n","\n","8 steps took 7.88 seconds\n","Epoch: 3 batch_num: 66 val_rmse: 0.4899\n","New best_val_rmse: 0.4899\n","\n","4 steps took 4.07 seconds\n","Epoch: 4 batch_num: 0 val_rmse: 0.4931\n","Still best_val_rmse: 0.4899 (from epoch 3)\n","\n","8 steps took 7.87 seconds\n","Epoch: 4 batch_num: 8 val_rmse: 0.4918\n","Still best_val_rmse: 0.4899 (from epoch 3)\n","\n","8 steps took 7.86 seconds\n","Epoch: 4 batch_num: 16 val_rmse: 0.4981\n","Still best_val_rmse: 0.4899 (from epoch 3)\n","\n","8 steps took 7.87 seconds\n","Epoch: 4 batch_num: 24 val_rmse: 0.4926\n","Still best_val_rmse: 0.4899 (from epoch 3)\n","\n","8 steps took 7.91 seconds\n","Epoch: 4 batch_num: 32 val_rmse: 0.4956\n","Still best_val_rmse: 0.4899 (from epoch 3)\n","\n","8 steps took 7.87 seconds\n","Epoch: 4 batch_num: 40 val_rmse: 0.4985\n","Still best_val_rmse: 0.4899 (from epoch 3)\n","\n","8 steps took 7.86 seconds\n","Epoch: 4 batch_num: 48 val_rmse: 0.4977\n","Still best_val_rmse: 0.4899 (from epoch 3)\n","\n","8 steps took 7.88 seconds\n","Epoch: 4 batch_num: 56 val_rmse: 0.4971\n","Still best_val_rmse: 0.4899 (from epoch 3)\n","\n","8 steps took 7.86 seconds\n","Epoch: 4 batch_num: 64 val_rmse: 0.4969\n","Still best_val_rmse: 0.4899 (from epoch 3)\n","\n","Performance estimates:\n","[0.48547078039400055, 0.45781590850086784, 0.47805608112029807, 0.48990617485954707]\n","Mean: 0.47781223621867835\n","\n","Fold 5/5\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"stream","text":["\n","16 steps took 16.4 seconds\n","Epoch: 0 batch_num: 16 val_rmse: 0.9054\n","New best_val_rmse: 0.9054\n","\n","16 steps took 15.5 seconds\n","Epoch: 0 batch_num: 32 val_rmse: 0.7605\n","New best_val_rmse: 0.7605\n","\n","16 steps took 15.5 seconds\n","Epoch: 0 batch_num: 48 val_rmse: 0.7615\n","Still best_val_rmse: 0.7605 (from epoch 0)\n","\n","16 steps took 15.5 seconds\n","Epoch: 0 batch_num: 64 val_rmse: 0.6967\n","New best_val_rmse: 0.6967\n","\n","16 steps took 15.7 seconds\n","Epoch: 1 batch_num: 10 val_rmse: 0.5662\n","New best_val_rmse: 0.5662\n","\n","16 steps took 15.5 seconds\n","Epoch: 1 batch_num: 26 val_rmse: 0.5163\n","New best_val_rmse: 0.5163\n","\n","16 steps took 15.6 seconds\n","Epoch: 1 batch_num: 42 val_rmse: 0.5026\n","New best_val_rmse: 0.5026\n","\n","16 steps took 15.5 seconds\n","Epoch: 1 batch_num: 58 val_rmse: 0.5721\n","Still best_val_rmse: 0.5026 (from epoch 1)\n","\n","16 steps took 15.6 seconds\n","Epoch: 2 batch_num: 4 val_rmse: 0.5071\n","Still best_val_rmse: 0.5026 (from epoch 1)\n","\n","16 steps took 15.5 seconds\n","Epoch: 2 batch_num: 20 val_rmse: 0.5068\n","Still best_val_rmse: 0.5026 (from epoch 1)\n","\n","16 steps took 15.5 seconds\n","Epoch: 2 batch_num: 36 val_rmse: 0.5131\n","Still best_val_rmse: 0.5026 (from epoch 1)\n","\n","16 steps took 15.6 seconds\n","Epoch: 2 batch_num: 52 val_rmse: 0.4855\n","New best_val_rmse: 0.4855\n","\n","4 steps took 3.88 seconds\n","Epoch: 2 batch_num: 56 val_rmse: 0.4821\n","New best_val_rmse: 0.4821\n","\n","4 steps took 3.88 seconds\n","Epoch: 2 batch_num: 60 val_rmse: 0.4795\n","New best_val_rmse: 0.4795\n","\n","2 steps took 1.95 seconds\n","Epoch: 2 batch_num: 62 val_rmse: 0.4743\n","New best_val_rmse: 0.4743\n","\n","2 steps took 1.94 seconds\n","Epoch: 2 batch_num: 64 val_rmse: 0.4729\n","New best_val_rmse: 0.4729\n","\n","2 steps took 1.93 seconds\n","Epoch: 2 batch_num: 66 val_rmse: 0.4906\n","Still best_val_rmse: 0.4729 (from epoch 2)\n","\n","8 steps took 7.91 seconds\n","Epoch: 3 batch_num: 4 val_rmse: 0.4732\n","Still best_val_rmse: 0.4729 (from epoch 2)\n","\n","2 steps took 1.94 seconds\n","Epoch: 3 batch_num: 6 val_rmse: 0.485\n","Still best_val_rmse: 0.4729 (from epoch 2)\n","\n","4 steps took 3.88 seconds\n","Epoch: 3 batch_num: 10 val_rmse: 0.4807\n","Still best_val_rmse: 0.4729 (from epoch 2)\n","\n","4 steps took 3.88 seconds\n","Epoch: 3 batch_num: 14 val_rmse: 0.4865\n","Still best_val_rmse: 0.4729 (from epoch 2)\n","\n","4 steps took 3.87 seconds\n","Epoch: 3 batch_num: 18 val_rmse: 0.4955\n","Still best_val_rmse: 0.4729 (from epoch 2)\n","\n","8 steps took 7.76 seconds\n","Epoch: 3 batch_num: 26 val_rmse: 0.4741\n","Still best_val_rmse: 0.4729 (from epoch 2)\n","\n","2 steps took 1.94 seconds\n","Epoch: 3 batch_num: 28 val_rmse: 0.4795\n","Still best_val_rmse: 0.4729 (from epoch 2)\n","\n","2 steps took 1.94 seconds\n","Epoch: 3 batch_num: 30 val_rmse: 0.5055\n","Still best_val_rmse: 0.4729 (from epoch 2)\n","\n","16 steps took 15.6 seconds\n","Epoch: 3 batch_num: 46 val_rmse: 0.4733\n","Still best_val_rmse: 0.4729 (from epoch 2)\n","\n","2 steps took 1.94 seconds\n","Epoch: 3 batch_num: 48 val_rmse: 0.4756\n","Still best_val_rmse: 0.4729 (from epoch 2)\n","\n","2 steps took 1.93 seconds\n","Epoch: 3 batch_num: 50 val_rmse: 0.4876\n","Still best_val_rmse: 0.4729 (from epoch 2)\n","\n","4 steps took 3.89 seconds\n","Epoch: 3 batch_num: 54 val_rmse: 0.4803\n","Still best_val_rmse: 0.4729 (from epoch 2)\n","\n","4 steps took 3.87 seconds\n","Epoch: 3 batch_num: 58 val_rmse: 0.4822\n","Still best_val_rmse: 0.4729 (from epoch 2)\n","\n","4 steps took 3.87 seconds\n","Epoch: 3 batch_num: 62 val_rmse: 0.4822\n","Still best_val_rmse: 0.4729 (from epoch 2)\n","\n","4 steps took 3.89 seconds\n","Epoch: 3 batch_num: 66 val_rmse: 0.4773\n","Still best_val_rmse: 0.4729 (from epoch 2)\n","\n","2 steps took 1.94 seconds\n","Epoch: 3 batch_num: 68 val_rmse: 0.4775\n","Still best_val_rmse: 0.4729 (from epoch 2)\n","\n","2 steps took 2.07 seconds\n","Epoch: 4 batch_num: 0 val_rmse: 0.4831\n","Still best_val_rmse: 0.4729 (from epoch 2)\n","\n","4 steps took 3.88 seconds\n","Epoch: 4 batch_num: 4 val_rmse: 0.493\n","Still best_val_rmse: 0.4729 (from epoch 2)\n","\n","8 steps took 7.76 seconds\n","Epoch: 4 batch_num: 12 val_rmse: 0.4783\n","Still best_val_rmse: 0.4729 (from epoch 2)\n","\n","2 steps took 1.94 seconds\n","Epoch: 4 batch_num: 14 val_rmse: 0.4784\n","Still best_val_rmse: 0.4729 (from epoch 2)\n","\n","2 steps took 1.93 seconds\n","Epoch: 4 batch_num: 16 val_rmse: 0.4811\n","Still best_val_rmse: 0.4729 (from epoch 2)\n","\n","4 steps took 3.87 seconds\n","Epoch: 4 batch_num: 20 val_rmse: 0.4877\n","Still best_val_rmse: 0.4729 (from epoch 2)\n","\n","4 steps took 3.88 seconds\n","Epoch: 4 batch_num: 24 val_rmse: 0.4866\n","Still best_val_rmse: 0.4729 (from epoch 2)\n","\n","4 steps took 3.9 seconds\n","Epoch: 4 batch_num: 28 val_rmse: 0.4792\n","Still best_val_rmse: 0.4729 (from epoch 2)\n","\n","2 steps took 1.94 seconds\n","Epoch: 4 batch_num: 30 val_rmse: 0.4785\n","Still best_val_rmse: 0.4729 (from epoch 2)\n","\n","2 steps took 1.93 seconds\n","Epoch: 4 batch_num: 32 val_rmse: 0.4791\n","Still best_val_rmse: 0.4729 (from epoch 2)\n","\n","2 steps took 1.93 seconds\n","Epoch: 4 batch_num: 34 val_rmse: 0.4803\n","Still best_val_rmse: 0.4729 (from epoch 2)\n","\n","4 steps took 3.89 seconds\n","Epoch: 4 batch_num: 38 val_rmse: 0.4806\n","Still best_val_rmse: 0.4729 (from epoch 2)\n","\n","4 steps took 3.88 seconds\n","Epoch: 4 batch_num: 42 val_rmse: 0.4801\n","Still best_val_rmse: 0.4729 (from epoch 2)\n","\n","4 steps took 3.89 seconds\n","Epoch: 4 batch_num: 46 val_rmse: 0.4801\n","Still best_val_rmse: 0.4729 (from epoch 2)\n","\n","4 steps took 3.88 seconds\n","Epoch: 4 batch_num: 50 val_rmse: 0.4801\n","Still best_val_rmse: 0.4729 (from epoch 2)\n","\n","4 steps took 3.87 seconds\n","Epoch: 4 batch_num: 54 val_rmse: 0.4807\n","Still best_val_rmse: 0.4729 (from epoch 2)\n","\n","4 steps took 3.88 seconds\n","Epoch: 4 batch_num: 58 val_rmse: 0.481\n","Still best_val_rmse: 0.4729 (from epoch 2)\n","\n","4 steps took 3.88 seconds\n","Epoch: 4 batch_num: 62 val_rmse: 0.4808\n","Still best_val_rmse: 0.4729 (from epoch 2)\n","\n","4 steps took 3.87 seconds\n","Epoch: 4 batch_num: 66 val_rmse: 0.4808\n","Still best_val_rmse: 0.4729 (from epoch 2)\n","\n","Performance estimates:\n","[0.48547078039400055, 0.45781590850086784, 0.47805608112029807, 0.48990617485954707, 0.47288673818319515]\n","Mean: 0.4768271366115817\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"m4v-cGx-Mv7S","executionInfo":{"status":"aborted","timestamp":1625805374392,"user_tz":-540,"elapsed":16,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["print(list_val_rmse)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q2CdCMuIKDMP","executionInfo":{"status":"aborted","timestamp":1625805374393,"user_tz":-540,"elapsed":17,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#rep = MemReporter(model)\n","#rep.report()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eLl1yDOOKIe7","executionInfo":{"status":"aborted","timestamp":1625805374394,"user_tz":-540,"elapsed":18,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#rep = MemReporter(model.roberta)\n","#rep.report()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7qkqnknA_m9D","executionInfo":{"status":"aborted","timestamp":1625805374395,"user_tz":-540,"elapsed":19,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#gpuinfo()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PwrqSMdYA6Pu","executionInfo":{"status":"aborted","timestamp":1625805374395,"user_tz":-540,"elapsed":18,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#del model\n","#del optimizer \n","#del train_loader\n","#del val_loader\n","#del scheduler \n","#del list_val_rmse\n","#del train_indices\n","#del val_indices\n","#del tokenizer\n","#torch.cuda.empty_cache()\n","#gpuinfo()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wXcHyUSJXecL"},"source":["# Inference"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YIV6UllSIGoa","executionInfo":{"status":"ok","timestamp":1625808874702,"user_tz":-540,"elapsed":2772,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"2f680e42-30e8-426b-db79-8c860b9be1c3"},"source":["%cd\n","!mkdir .kaggle\n","!cp /content/drive/MyDrive/Colab_Files/kaggle-api/kaggle.json .kaggle/"],"execution_count":22,"outputs":[{"output_type":"stream","text":["/root\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"14ddOZH4IMam","executionInfo":{"status":"ok","timestamp":1625809056043,"user_tz":-540,"elapsed":176942,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"20d88849-7a1b-49ee-81e4-57ae856d807d"},"source":["\n","\n","def dataset_upload():\n","    import json\n","    from kaggle.api.kaggle_api_extended import KaggleApi\n","\n","    id = f'{USERID}/{EX_NO}'\n","\n","    dataset_metadata = {}\n","    dataset_metadata['id'] = id\n","    dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n","    dataset_metadata['title'] = f'{EX_NO}'\n","\n","    with open(UPLOAD_DIR / 'dataset-metadata.json', 'w') as f:\n","        json.dump(dataset_metadata, f, indent=4)\n","\n","    api = KaggleApi()\n","    api.authenticate()\n","\n","    # データセットがない場合\n","    if f'{USERID}/{EX_NO}' not in [str(d) for d in api.dataset_list(user=USERID, search=f'\"{EX_NO}\"')]:\n","        api.dataset_create_new(folder=UPLOAD_DIR,\n","                               convert_to_csv=False,\n","                               dir_mode='skip')\n","    # データセットがある場合\n","    else:\n","        api.dataset_create_version(folder=UPLOAD_DIR,\n","                                   version_notes='update',\n","                                   convert_to_csv=False,\n","                                   delete_old_versions=True,\n","                                   dir_mode='skip')\n","dataset_upload()\n","\n"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Starting upload for file model_3.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 477M/477M [00:32<00:00, 15.3MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_3.pth (477MB)\n","Starting upload for file model_2.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 477M/477M [00:34<00:00, 14.3MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_2.pth (477MB)\n","Starting upload for file model_5.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 477M/477M [00:34<00:00, 14.4MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_5.pth (477MB)\n","Starting upload for file model_1.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 477M/477M [00:35<00:00, 14.1MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_1.pth (477MB)\n","Starting upload for file model_4.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 477M/477M [00:32<00:00, 15.2MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_4.pth (477MB)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_D-0XGBIHEFw","executionInfo":{"status":"aborted","timestamp":1625805374396,"user_tz":-540,"elapsed":19,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["for index in range(len(list_val_rmse)): # Fold数ごとに推論する\n","    model_path = f\"model_{index + 1}.pth\" # 対応するモデルを読む\n","    print(f\"\\nUsing {model_path}\")\n","                        \n","    model = LitModel()\n","    model.load_state_dict(torch.load(model_path))    # 対応するモデルから、重みを読み込む\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:27:12.494216Z","iopub.status.idle":"2021-07-04T06:27:12.494593Z"},"trusted":true,"id":"3sfvgD1AXecL","executionInfo":{"status":"aborted","timestamp":1625805374397,"user_tz":-540,"elapsed":20,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["test_dataset = LitDataset(test_df, inference_only=True) # TestのDataset作成"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:27:12.495644Z","iopub.status.idle":"2021-07-04T06:27:12.496188Z"},"trusted":true,"id":"ZaUqUGzwXecL","executionInfo":{"status":"aborted","timestamp":1625805374397,"user_tz":-540,"elapsed":20,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 推論実行\n","all_predictions = np.zeros((len(list_val_rmse), len(test_df))) # 推論結果について、「fold　× 推論df」のzero行列で枠を作る\n","\n","test_dataset = LitDataset(test_df, inference_only=True) # TestのDataset(何で、もう一回作るのだろう？)\n","test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n","                         drop_last=False, shuffle=False, num_workers=2) # TestのDataLoader\n","\n","for index in range(len(list_val_rmse)): # Fold数ごとに推論する\n","    model_path = f\"model_{index + 1}.pth\" # 対応するモデルを読む\n","    print(f\"\\nUsing {model_path}\")\n","                        \n","    model = LitModel()\n","    model.load_state_dict(torch.load(model_path))    # 対応するモデルから、重みを読み込む\n","    model.to(DEVICE) # モデルをDEVICEへぶち込む\n","    \n","    all_predictions[index] = predict(model, test_loader) # 推論結果行列の対象列に、推論結果を入力(以後、繰り返し)\n","    \n","    del model\n","    gc.collect()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:27:12.497445Z","iopub.status.idle":"2021-07-04T06:27:12.498075Z"},"trusted":true,"id":"Cbi42hQ-XecL","executionInfo":{"status":"aborted","timestamp":1625805374398,"user_tz":-540,"elapsed":20,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["predictions = all_predictions.mean(axis=0) # 全FOLDの推論の平均を最終結果とする。\n","submission_df.target = predictions # 予測結果をsub用dfと結合\n","print(submission_df) # 結果表示\n","submission_df.to_csv(\"submission.csv\", index=False) # sub用csv出力"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oE9yE3moXecL","executionInfo":{"status":"aborted","timestamp":1625805374398,"user_tz":-540,"elapsed":20,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b8e_n0e4XecM","executionInfo":{"status":"aborted","timestamp":1625805374398,"user_tz":-540,"elapsed":20,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gtOQkIUcXecM","executionInfo":{"status":"aborted","timestamp":1625805374401,"user_tz":-540,"elapsed":23,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sR5_O4qcXecM","executionInfo":{"status":"aborted","timestamp":1625805374401,"user_tz":-540,"elapsed":23,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DLE4ivbJXecM","executionInfo":{"status":"aborted","timestamp":1625805374402,"user_tz":-540,"elapsed":24,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zVG72uNhXecM","executionInfo":{"status":"aborted","timestamp":1625805374402,"user_tz":-540,"elapsed":23,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eHRLBazYptD1","executionInfo":{"status":"aborted","timestamp":1625805374403,"user_tz":-540,"elapsed":24,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aH82HhNupvFT","executionInfo":{"status":"aborted","timestamp":1625805374403,"user_tz":-540,"elapsed":24,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lUVgPYDM30_q","executionInfo":{"status":"aborted","timestamp":1625805374404,"user_tz":-540,"elapsed":25,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QdUmUFWt34Yy","executionInfo":{"status":"aborted","timestamp":1625805374404,"user_tz":-540,"elapsed":24,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1u9Qt5_BBlJf","executionInfo":{"status":"aborted","timestamp":1625805374404,"user_tz":-540,"elapsed":24,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uCLuffFwHBsf","executionInfo":{"status":"aborted","timestamp":1625805374405,"user_tz":-540,"elapsed":25,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XRsRswU3HC1H","executionInfo":{"status":"aborted","timestamp":1625805374405,"user_tz":-540,"elapsed":25,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":null,"outputs":[]}]}