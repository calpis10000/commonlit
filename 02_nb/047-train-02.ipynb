{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"047-train-02.ipynb","provenance":[{"file_id":"17V-_oEoc7G-20Mk78qNMJWU1Of9PfFTH","timestamp":1626791764319},{"file_id":"17a4F4aC9L0QBqU8BRTrdqPn0WwJ0b08b","timestamp":1626746992716},{"file_id":"1G_W9irFTrEmDeHR0S6_u0bjpk8nxipXW","timestamp":1626689695352},{"file_id":"1bhhkorT--y8XXaVLM8hibVgC-tLqZ16P","timestamp":1626358153868},{"file_id":"1WtT2hX6O9Qbt_hb9sF50nM2QmDXFi-XA","timestamp":1626338366006},{"file_id":"1k_p5wftcUeo711Xho1-T5an2Xkneau-J","timestamp":1626323813472},{"file_id":"1Vz2GB2BNTWuefEFkCSh3TBPEIel7KG1t","timestamp":1626317426487},{"file_id":"1djoMWojeaIPopG5tS1jNMohn8ineblRh","timestamp":1626306831897},{"file_id":"1-6tlDO8158Pi6TpptIF884oFaEiT4Uxb","timestamp":1626276420047},{"file_id":"1js8eA3mDNS8mwSpCiHuzPeARFlUPAVrg","timestamp":1626272452526},{"file_id":"1yhcPgulwJtjJKUK9IuRKmNMhJ-4YXGol","timestamp":1626267205517},{"file_id":"1mnnSv0Pofn1QxArywV81VYqnZPB8uUWN","timestamp":1626180468522},{"file_id":"1RRdjt_UAeHmr5QQBAMyC82Fq1s31OWdK","timestamp":1625833136005},{"file_id":"1JPgg44HFemzwk8VSCXih3PejL0idy-C4","timestamp":1625825483466},{"file_id":"1Ye6wqVX71xAAAhmjXkw9IpRvTqeUyJDA","timestamp":1625812137500}],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":86},"id":"Z6yRwt-PXtbP","executionInfo":{"status":"ok","timestamp":1626792072467,"user_tz":-540,"elapsed":427,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"35cd1efa-70a7-43fc-c623-95d3362d073e"},"source":["\"\"\"\n","if 'google.colab' in sys.modules:  # colab環境特有の処理_初回のみ\n","  # Google Driveのマウント\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","\n","  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules' \\\n","   -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/requirements.txt' \\\n","   --ignore-installed\n","\n","  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules' \\\n","   transformers -U\n","  !pip install gensim==4.0.1 --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\n","  !pip install pytorch_memlab --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\n","\"\"\""],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\nif 'google.colab' in sys.modules:  # colab環境特有の処理_初回のみ\\n  # Google Driveのマウント\\n  from google.colab import drive\\n  drive.mount('/content/drive')\\n\\n  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'    -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/requirements.txt'    --ignore-installed\\n\\n  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'    transformers -U\\n  !pip install gensim==4.0.1 --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\\n  !pip install pytorch_memlab --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\\n\""]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ucCbvGD1XvG7","executionInfo":{"status":"ok","timestamp":1626792268483,"user_tz":-540,"elapsed":195668,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"e87b26f6-a447-4b64-8ec5-ba2737584632"},"source":["import sys\n","if 'google.colab' in sys.modules:  # colab特有の処理_2回目以降\n","  # Google Driveのマウント\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","\n","  # データセットをDriveから取得\n","  !mkdir -p 'input'\n","  !cp -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/00_input/commonlitreadabilityprize/' '/content/input'\n","  !cp -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/97_pre_trained/clrp_pretrained_manish_epoch5' '/content/clrp-roberta-large'\n","  # ライブラリのパス指定\n","  sys.path.append('/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules')\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"N6kqvVoPrnpj","executionInfo":{"status":"ok","timestamp":1626792268484,"user_tz":-540,"elapsed":36,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"11edd743-a25f-4c1f-9e70-472d1cb03cc3"},"source":["\"\"\"\n","%cd\n","!mkdir .kaggle\n","!mkdir /content/model\n","!cp /content/drive/MyDrive/Colab_Files/kaggle-api/kaggle.json .kaggle/\n","\"\"\""],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\n%cd\\n!mkdir .kaggle\\n!mkdir /content/model\\n!cp /content/drive/MyDrive/Colab_Files/kaggle-api/kaggle.json .kaggle/\\n'"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"Axihy1acGjie","executionInfo":{"status":"ok","timestamp":1626792268485,"user_tz":-540,"elapsed":30,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"8986e2ff-f424-4e9f-fdc1-d34845400fe8"},"source":["\"\"\"\n","!mkdir /content/pre-trained-roberta\n","!kaggle datasets download -p /content/pre-trained-roberta clrprobertalarge --unzip\n","!cp -r /content/pre-trained-roberta/ /content/drive/MyDrive/Colab_Files/kaggle/commonlit/97_pre_trained/clrp_pretrained_manish_epoch5\n","\"\"\""],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\n!mkdir /content/pre-trained-roberta\\n!kaggle datasets download -p /content/pre-trained-roberta clrprobertalarge --unzip\\n!cp -r /content/pre-trained-roberta/ /content/drive/MyDrive/Colab_Files/kaggle/commonlit/97_pre_trained/clrp_pretrained_manish_epoch5\\n'"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"GpYkj74lHeU_","executionInfo":{"status":"ok","timestamp":1626792268485,"user_tz":-540,"elapsed":28,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"RV9-VwbpZLZ9","executionInfo":{"status":"ok","timestamp":1626792268486,"user_tz":-540,"elapsed":28,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["from pathlib import Path\n","\n","# input\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    DATA_DIR = Path('../input/commonlitreadabilityprize/')\n","\n","elif 'google.colab' in sys.modules: # Colab環境\n","    DATA_DIR = Path('/content/input/commonlitreadabilityprize')\n","\n","else:\n","    DATA_DIR = Path('../00_input/commonlitreadabilityprize/')"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"x5difyXe00UV","executionInfo":{"status":"ok","timestamp":1626792268487,"user_tz":-540,"elapsed":28,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["from pathlib import Path\n","\n","# tokenizer\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    TOKENIZER_DIR = '../input/roberta-transformers-pytorch/roberta-large'\n","elif 'google.colab' in sys.modules: # Colab環境\n","    TOKENIZER_DIR = '/content/clrp-roberta-large/pre-trained-roberta/clrp_roberta_large' # 仮で、毎回DLする想定のモデル名を指定。あとで変更予定。\n","else:\n","    TOKENIZER_DIR = 'roberta-large'"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"tKjsUxnOeDYl","executionInfo":{"status":"ok","timestamp":1626792268488,"user_tz":-540,"elapsed":29,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["from pathlib import Path\n","\n","# pre-trained model\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    PRE_TRAINED_MODEL_DIR = '../input/roberta-transformers-pytorch/roberta-large'\n","elif 'google.colab' in sys.modules: # Colab環境\n","    PRE_TRAINED_MODEL_DIR = '/content/clrp-roberta-large/pre-trained-roberta/clrp_roberta_large' # 仮で、毎回DLする想定のモデル名を指定。あとで変更予定。\n","else:\n","    PRE_TRAINED_MODEL_DIR = 'roberta-large'"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZLaT2V0ReoAZ","executionInfo":{"status":"ok","timestamp":1626792268488,"user_tz":-540,"elapsed":28,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["UPLOAD_DIR = Path('/content/model')\n","EX_NO = '047-train-02'  # 実験番号などを入れる、folderのpathにする\n","USERID = 'calpis10000'"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"hOGjAb4pAJ0F","executionInfo":{"status":"ok","timestamp":1626792268489,"user_tz":-540,"elapsed":28,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["import subprocess\n","import shlex\n","\n","def gpuinfo():\n","    \"\"\"\n","    Returns size of total GPU RAM and used GPU RAM.\n","\n","    Parameters\n","    ----------\n","    None\n","\n","    Returns\n","    -------\n","    info : dict\n","        Total GPU RAM in integer for key 'total_MiB'.\n","        Used GPU RAM in integer for key 'used_MiB'.\n","    \"\"\"\n","\n","    command = 'nvidia-smi -q -d MEMORY | sed -n \"/FB Memory Usage/,/Free/p\" | sed -e \"1d\" -e \"4d\" -e \"s/ MiB//g\" | cut -d \":\" -f 2 | cut -c2-'\n","    commands = [shlex.split(part) for part in command.split(' | ')]\n","    for i, cmd in enumerate(commands):\n","        if i==0:\n","            res = subprocess.Popen(cmd, stdout=subprocess.PIPE)\n","        else:\n","            res = subprocess.Popen(cmd, stdin=res.stdout, stdout=subprocess.PIPE)\n","    total, used = map(int, res.communicate()[0].decode('utf-8').strip().split('\\n'))\n","    info = {'total_MiB':total, 'used_MiB':used}\n","    return info\n"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g3-6m5MKXecB"},"source":["# Overview\n","This nb is based on copy from https://www.kaggle.com/andretugan/lightweight-roberta-solution-in-pytorch .\n","\n","Acknowledgments(from base nb): \n","some ideas were taken from kernels by [Torch](https://www.kaggle.com/rhtsingh) and [Maunish](https://www.kaggle.com/maunish)."]},{"cell_type":"code","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-04T06:26:32.834365Z","iopub.execute_input":"2021-07-04T06:26:32.834903Z","iopub.status.idle":"2021-07-04T06:26:40.143740Z","shell.execute_reply.started":"2021-07-04T06:26:32.834785Z","shell.execute_reply":"2021-07-04T06:26:40.142864Z"},"trusted":true,"id":"HRsRZ06WXecD","executionInfo":{"status":"ok","timestamp":1626792439401,"user_tz":-540,"elapsed":170941,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["import os\n","import math\n","import random\n","import time\n","\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","\n","from transformers import AdamW # optimizer\n","from transformers import AutoTokenizer\n","from transformers import AutoModel\n","from transformers import AutoConfig\n","from transformers import get_cosine_schedule_with_warmup # scheduler\n","from pytorch_memlab import profile\n","import pytorch_memlab\n","from pytorch_memlab import MemReporter\n","\n","from sklearn.model_selection import KFold, StratifiedKFold\n","\n","import gc\n","gc.enable()"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.145217Z","iopub.execute_input":"2021-07-04T06:26:40.145539Z","iopub.status.idle":"2021-07-04T06:26:40.201326Z","shell.execute_reply.started":"2021-07-04T06:26:40.145504Z","shell.execute_reply":"2021-07-04T06:26:40.200136Z"},"trusted":true,"id":"omBfwshTXecE","executionInfo":{"status":"ok","timestamp":1626792439408,"user_tz":-540,"elapsed":23,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["NUM_FOLDS = 5 # K Fold\n","NUM_EPOCHS = 5 # Epochs\n","BATCH_SIZE = 12 # Batch Size\n","MAX_LEN = 248 # ベクトル長\n","EVAL_SCHEDULE = [(0.55, 64), (0.50, 32), (0.49, 16), (0.48, 8), (0.47, 4), (0.46, 2), (-1., 1)] # schedulerの何らかの設定？\n","ROBERTA_PATH = PRE_TRAINED_MODEL_DIR # roberta pre-trainedモデル(モデルとして指定)\n","TOKENIZER_PATH = TOKENIZER_DIR # roberta pre-trainedモデル(Tokenizerとして指定)\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\" # cudaがなければcpuを使えばいいじゃない"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.203398Z","iopub.execute_input":"2021-07-04T06:26:40.204055Z","iopub.status.idle":"2021-07-04T06:26:40.211572Z","shell.execute_reply.started":"2021-07-04T06:26:40.204015Z","shell.execute_reply":"2021-07-04T06:26:40.210762Z"},"trusted":true,"id":"4qcuXqwtXecF","executionInfo":{"status":"ok","timestamp":1626792439409,"user_tz":-540,"elapsed":22,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["def set_random_seed(random_seed):\n","    random.seed(random_seed)\n","    np.random.seed(random_seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(random_seed)\n","\n","    torch.manual_seed(random_seed)\n","    torch.cuda.manual_seed(random_seed)\n","    torch.cuda.manual_seed_all(random_seed)\n","\n","    torch.backends.cudnn.deterministic = True# cudnnによる最適化で結果が変わらないためのおまじない "],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.214188Z","iopub.execute_input":"2021-07-04T06:26:40.214809Z","iopub.status.idle":"2021-07-04T06:26:40.309744Z","shell.execute_reply.started":"2021-07-04T06:26:40.214769Z","shell.execute_reply":"2021-07-04T06:26:40.308926Z"},"trusted":true,"id":"70PyLsJTXecF","executionInfo":{"status":"ok","timestamp":1626792439410,"user_tz":-540,"elapsed":22,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# train, testを読む\n","train_df = pd.read_csv(DATA_DIR/\"train.csv\")\n","\n","# Remove incomplete entries if any.\n","train_df.drop(train_df[(train_df.target == 0) & (train_df.standard_error == 0)].index,\n","              inplace=True)\n","train_df.reset_index(drop=True, inplace=True)\n","\n","test_df = pd.read_csv(DATA_DIR/\"test.csv\")\n","submission_df = pd.read_csv(DATA_DIR/\"sample_submission.csv\")"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"9ZYOB59L8qtA","executionInfo":{"status":"ok","timestamp":1626792439411,"user_tz":-540,"elapsed":23,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"0901a280-b5bb-4ff0-abcc-993e63188534"},"source":["train_df.head()\n"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>url_legal</th>\n","      <th>license</th>\n","      <th>excerpt</th>\n","      <th>target</th>\n","      <th>standard_error</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>c12129c31</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>When the young people returned to the ballroom...</td>\n","      <td>-0.340259</td>\n","      <td>0.464009</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>85aa80a4c</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>All through dinner time, Mrs. Fayre was somewh...</td>\n","      <td>-0.315372</td>\n","      <td>0.480805</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>b69ac6792</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>As Roger had predicted, the snow departed as q...</td>\n","      <td>-0.580118</td>\n","      <td>0.476676</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>dd1000b26</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>And outside before the palace a great garden w...</td>\n","      <td>-1.054013</td>\n","      <td>0.450007</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>37c1b32fb</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Once upon a time there were Three Bears who li...</td>\n","      <td>0.247197</td>\n","      <td>0.510845</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          id url_legal  ...    target standard_error\n","0  c12129c31       NaN  ... -0.340259       0.464009\n","1  85aa80a4c       NaN  ... -0.315372       0.480805\n","2  b69ac6792       NaN  ... -0.580118       0.476676\n","3  dd1000b26       NaN  ... -1.054013       0.450007\n","4  37c1b32fb       NaN  ...  0.247197       0.510845\n","\n","[5 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.311021Z","iopub.execute_input":"2021-07-04T06:26:40.311347Z","iopub.status.idle":"2021-07-04T06:26:40.624393Z","shell.execute_reply.started":"2021-07-04T06:26:40.311314Z","shell.execute_reply":"2021-07-04T06:26:40.623347Z"},"trusted":true,"id":"xf0662k4XecF","executionInfo":{"status":"ok","timestamp":1626792441741,"user_tz":-540,"elapsed":2351,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# tokenizerを指定\n","tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N6aaghNkXecG"},"source":["# Dataset"]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.628883Z","iopub.execute_input":"2021-07-04T06:26:40.629347Z","iopub.status.idle":"2021-07-04T06:26:40.644338Z","shell.execute_reply.started":"2021-07-04T06:26:40.629309Z","shell.execute_reply":"2021-07-04T06:26:40.643336Z"},"trusted":true,"id":"zkopT0U1XecG","executionInfo":{"status":"ok","timestamp":1626792441747,"user_tz":-540,"elapsed":25,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# Dataset用のClass。おそらく、trainとtestでインスタンスを生成し、DataFrameと同じように扱えるような思想。\n","class LitDataset(Dataset):\n","    def __init__(self, df, inference_only=False):\n","        super().__init__()\n","\n","        self.df = df        \n","        self.inference_only = inference_only # Testデータ用フラグ\n","        self.text = df.excerpt.tolist() # 分析対象カラムをlistにする。(分かち書きではなく、Seriesをlistへ変換するような処理)\n","        #self.text = [text.replace(\"\\n\", \" \") for text in self.text] # 単語単位で分かち書きする場合\n","        \n","        if not self.inference_only:\n","            self.target = torch.tensor(df.target.values, dtype=torch.float32) # trainのみ、targetをtensorに変換\n","            self.standard_error = torch.tensor(df.standard_error.values, dtype=torch.float32) \n","\n","        self.encoded = tokenizer.batch_encode_plus( # textをtokenize\n","            self.text,\n","            padding = 'max_length',            \n","            max_length = MAX_LEN,\n","            truncation = True, # 最大長を超える文字は切り捨て\n","            return_attention_mask=True\n","        )        \n"," \n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    \n","    def __getitem__(self, index): # 変換結果を返す\n","        input_ids = torch.tensor(self.encoded['input_ids'][index])\n","        attention_mask = torch.tensor(self.encoded['attention_mask'][index])\n","        \n","        if self.inference_only:\n","            return (input_ids, attention_mask)            \n","        else:\n","            target = self.target[index]\n","            standard_error = self.standard_error[index]\n","            return (input_ids, attention_mask, target, standard_error)"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KKtdy32wXecG"},"source":["# Model\n","The model is inspired by the one from [Maunish](https://www.kaggle.com/maunish/clrp-roberta-svm)."]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.649629Z","iopub.execute_input":"2021-07-04T06:26:40.650066Z","iopub.status.idle":"2021-07-04T06:26:40.666374Z","shell.execute_reply.started":"2021-07-04T06:26:40.650002Z","shell.execute_reply":"2021-07-04T06:26:40.665211Z"},"trusted":true,"id":"BpkxjXEUXecH","executionInfo":{"status":"ok","timestamp":1626792441748,"user_tz":-540,"elapsed":24,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["class LitModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        config = AutoConfig.from_pretrained(ROBERTA_PATH) # pretrainedからconfigを読み込み\n","        config.update({\"output_hidden_states\":True, # config更新: embedding層を抽出\n","                       \"hidden_dropout_prob\": 0.0, # config更新: dropoutしない\n","                       \"layer_norm_eps\": 1e-7}) # config更新: layer normalizationのepsilon                      \n","        \n","        self.roberta = AutoModel.from_pretrained(ROBERTA_PATH, config=config) # cpuで処理する\n","            \n","        self.attention = nn.Sequential(# attentionレイヤー            \n","            nn.Linear(config.hidden_size, 512),      \n","            nn.Tanh(),                       \n","            nn.Linear(512, 1),\n","            nn.Softmax(dim=1)\n","        )\n","\n","        self.regressor = nn.Sequential( # 出力レイヤー                    \n","            nn.Linear(config.hidden_size, 2)                        \n","        )\n","\n","    def forward(self, input_ids, attention_mask):\n","        roberta_output = self.roberta(input_ids=input_ids, # robertaに入力データを流し、出力としてrobertaモデル(layerの複合体)を得る\n","                                      attention_mask=attention_mask)     \n","\n","        last_hidden_state = roberta_output.hidden_states[-1] # robertaモデルの最後のlayerを得る\n","        weights = self.attention(last_hidden_state) # robertaの最後のlayerをattentionへ入力し、出力として重みを得る                \n","        context_vector = torch.sum(weights * last_hidden_state, dim=1) # 重み×最後の層を足し合わせて文書ベクトルとする。\n","        return self.regressor(context_vector) # 文書ベクトルを線形層に入力し、targetを出力する\n","\n","        # https://www.kaggle.com/rhtsingh/utilizing-transformer-representations-efficiently\n","        #last_hidden_state = roberta_output[0]\n","        #input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        #sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        #sum_mask = input_mask_expanded.sum(1)\n","        #sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        #mean_embeddings = sum_embeddings / sum_mask\n","\n","        \n","        # Now we reduce the context vector to the prediction score.\n","        #return self.regressor(mean_embeddings) # 文書ベクトルを線形層に入力し、targetを出力する"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.672515Z","iopub.execute_input":"2021-07-04T06:26:40.672944Z","iopub.status.idle":"2021-07-04T06:26:40.684593Z","shell.execute_reply.started":"2021-07-04T06:26:40.672908Z","shell.execute_reply":"2021-07-04T06:26:40.683569Z"},"trusted":true,"id":"bB4jvQTxXecH","executionInfo":{"status":"ok","timestamp":1626792441748,"user_tz":-540,"elapsed":23,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 評価指標(MSE)の計算。最終的に、ルートしてRMSEにすると思われる。\n","def eval_mse(model, data_loader):\n","    \"\"\"Evaluates the mean squared error of the |model| on |data_loader|\"\"\"\n","    model.eval() # evalモードを選択。Batch Normとかdropoutをしなくなる           \n","    mse_mean_sum = 0\n","    mse_std_sum = 0\n","\n","    with torch.no_grad(): # 勾配の計算をしないBlock\n","        for batch_num, (input_ids, attention_mask, target, standard_error) in enumerate(data_loader): # data_loaderからinput, attentin_mask, targetをbatchごとに取り出す\n","            input_ids = input_ids.to(DEVICE)   \n","            attention_mask = attention_mask.to(DEVICE)   \n","            target = target.to(DEVICE)      \n","            standard_error = standard_error.to(DEVICE) \n","            \n","            output = model(input_ids, attention_mask) # 取得した値をモデルへ入力し、出力として予測値を得る。\n","\n","            mse_mean_sum += nn.MSELoss(reduction=\"sum\")(output[:,0].flatten(), target).item() # 誤差の合計を得る(Batchごとに計算した誤差を足し上げる)\n","            mse_std_sum += nn.MSELoss(reduction=\"sum\")(output[:,1].flatten(), target).item() # 誤差の合計を得る(Batchごとに計算した誤差を足し上げる)\n","\n","    del input_ids\n","    del attention_mask\n","    del target\n","\n","    mse_mean_result = mse_mean_sum / len(data_loader.dataset)\n","    mse_std_result = mse_std_sum / len(data_loader.dataset)\n","  \n","    return mse_mean_result, mse_std_result # 誤差の合計をdataset長で除し、mseを取得＆返す"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.690155Z","iopub.execute_input":"2021-07-04T06:26:40.692530Z","iopub.status.idle":"2021-07-04T06:26:40.703425Z","shell.execute_reply.started":"2021-07-04T06:26:40.692488Z","shell.execute_reply":"2021-07-04T06:26:40.702366Z"},"trusted":true,"id":"47bDno_LXecI","executionInfo":{"status":"ok","timestamp":1626792441749,"user_tz":-540,"elapsed":21,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 推論結果を返す\n","def predict(model, data_loader):\n","    \"\"\"Returns an np.array with predictions of the |model| on |data_loader|\"\"\"\n","    model.eval() # evalモード(dropout, batch_normしない)\n","\n","    result = np.zeros(len(data_loader.dataset)) # 結果をdataset長のzero配列として用意\n","    index = 0\n","    \n","    with torch.no_grad(): # 勾配の計算をしないblock(inputすると、現状の重みによる推論結果を返す)\n","        for batch_num, (input_ids, attention_mask) in enumerate(data_loader): # data_loaderからbatchごとにinputを得る\n","            input_ids = input_ids.to(DEVICE)\n","            attention_mask = attention_mask.to(DEVICE)\n","                        \n","            output = model(input_ids, attention_mask) # modelにinputを入力し、予測結果を得る。\n","\n","            result[index : index + output[:,0].shape[0]] = output[:,0].flatten().to(\"cpu\") # result[index ~ predの長さ]へ、予測結果を格納\n","            index += pred.shape[0] # indexを更新\n","\n","    return result # 全batchで推論が終わったら、結果を返す"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.708605Z","iopub.execute_input":"2021-07-04T06:26:40.709024Z","iopub.status.idle":"2021-07-04T06:26:40.730675Z","shell.execute_reply.started":"2021-07-04T06:26:40.708983Z","shell.execute_reply":"2021-07-04T06:26:40.729705Z"},"trusted":true,"id":"oInneuAmXecI","executionInfo":{"status":"ok","timestamp":1626792441750,"user_tz":-540,"elapsed":21,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 学習\n","def train(model, # モデル\n","          model_path, # モデルのアウトプット先\n","          train_loader, # train-setのdata_loader\n","          val_loader, # valid-setのdata_loader\n","          optimizer, # optimizer\n","          scheduler=None, # scheduler, デフォルトはNone\n","          num_epochs=NUM_EPOCHS # epoch数、notebook冒頭で指定した値\n","         ):    \n","    \n","    best_val_rmse = None\n","    best_epoch = 0\n","    step = 0\n","    last_eval_step = 0\n","    eval_period = EVAL_SCHEDULE[0][1] # eval期間(って何？) 冒頭で決めたEVAL_SCHEDULEの最初のtupleの[1]を取得\n","\n","    start = time.time() # 時間計測用\n","\n","    for epoch in range(num_epochs): # 指定したEpoch数だけ繰り返し\n","        val_rmse = None         \n","\n","        for batch_num, (input_ids, attention_mask, target, standard_error) in enumerate(train_loader): # train_loaderからinput, targetを取得\n","            input_ids = input_ids.to(DEVICE) # inputをDEVICEへ突っ込む\n","            attention_mask = attention_mask.to(DEVICE)       \n","            target = target.to(DEVICE)\n","            standard_error = standard_error.to(DEVICE)  \n","\n","            optimizer.zero_grad() # 勾配を初期化            \n","            model.train() # 学習モード開始\n","\n","            # https://www.kaggle.com/c/commonlitreadabilityprize/discussion/239421\n","            output = model(input_ids, attention_mask) # input,attention_maskを入力し、予測結果を得る\n","            p = torch.distributions.Normal(output[:,0], torch.sqrt(output[:,1]**2))\n","            q = torch.distributions.Normal(target, standard_error)\n","            kl_vector = torch.distributions.kl_divergence(p, q)\n","            loss = kl_vector.mean()\n","\n","            loss.backward() # 誤差逆伝播法により勾配を得る\n","            optimizer.step() # 重みを更新する\n","\n","            if scheduler:\n","                scheduler.step() # schedulerが与えられた場合は、schedulerの学習率更新\n","            \n","            if step >= last_eval_step + eval_period: # batchを回すごとにstepを増やしていって、「前回evalしたstep + eval_period(16)」を超えたら実行。\n","                # Evaluate the model on val_loader.\n","                elapsed_seconds = time.time() - start # 経過時間\n","                num_steps = step - last_eval_step # 経過ステップ数\n","                print(f\"\\n{num_steps} steps took {elapsed_seconds:0.3} seconds\")\n","                last_eval_step = step # 前回stepの更新\n","                \n","                # valid-setによるrmse計算\n","                train_mean_mse = nn.MSELoss(reduction=\"mean\")(output[:,0].flatten(), target) \n","                train_std_mse = nn.MSELoss(reduction=\"mean\")(torch.sqrt(output[:,1]**2).flatten(), standard_error) \n","\n","                train_mean_rmse = math.sqrt(train_mean_mse)\n","                train_std_rmse = math.sqrt(train_std_mse)\n","\n","                val_mean_mse, val_std_mse = eval_mse(model, val_loader)\n","                val_mean_rmse = math.sqrt(val_mean_mse)                            \n","                val_std_rmse = math.sqrt(val_std_mse)                            \n","\n","                print(f\"Epoch: {epoch} batch_num: {batch_num}\")\n","                print(f\"train_rmse_target: {train_mean_rmse:0.4}\",\n","                      f\"train_rmse_stderror: {train_std_rmse:0.4}\",\n","                      f\"train_kl_div: {loss:0.4}\",\n","                      )\n","                print(f\"val_rmse_target: {val_mean_rmse:0.4}\",\n","                      f\"val_rmse_stderror: {val_std_rmse:0.4}\"\n","                      )\n","\n","                for rmse, period in EVAL_SCHEDULE: # eval_periodをvalid-rmseで切り替える処理\n","                    if val_mean_rmse >= rmse: # valid rmseをEVAL_SCHEDULEと比較し、0項 > valid rmseとなるまで回す : EVAL_SCHEDULE = [(0.50, 16), (0.49, 8), (0.48, 4), (0.47, 2), (-1., 1)]\n","                        eval_period = period # eval_periodを更新\n","                        break                               \n","\n","                if not best_val_rmse or val_mean_rmse < best_val_rmse: # 初回(best_val_rmse==None), またはbest_val_rmseを更新したらモデルを保存する\n","                    best_val_rmse = val_mean_rmse\n","                    best_epoch = epoch\n","                    torch.save(model.state_dict(), model_path) # 最高の自分を保存\n","                    print(f\"New best_val_rmse: {best_val_rmse:0.4}\")\n","                else:       \n","                    print(f\"Still best_val_rmse: {best_val_rmse:0.4}\", # 更新されない場合は、元のスコアを表示\n","                          f\"(from epoch {best_epoch})\")      \n","                                                  \n","                start = time.time()\n","            \n","            # batchごとにメモリ解放\n","            del input_ids\n","            del attention_mask\n","            del target\n","            torch.cuda.empty_cache()                                            \n","            step += 1\n","    \n","    return best_val_rmse"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.735798Z","iopub.execute_input":"2021-07-04T06:26:40.738398Z","iopub.status.idle":"2021-07-04T06:26:40.750876Z","shell.execute_reply.started":"2021-07-04T06:26:40.738356Z","shell.execute_reply":"2021-07-04T06:26:40.749635Z"},"trusted":true,"id":"rMY0fjXwXecJ","executionInfo":{"status":"ok","timestamp":1626792441750,"user_tz":-540,"elapsed":21,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# optimizerの作成\n","def create_optimizer(model):\n","    named_parameters = list(model.named_parameters()) # モデルパラメータの取得\n","    \n","    roberta_parameters = list(model.roberta.named_parameters())[:-2] # パラメータをroberta用、attention用、regressor用に格納。(直接引っ張ってくる形式に変更)\n","    attention_parameters = list(model.attention.named_parameters())\n","    regressor_parameters = list(model.regressor.named_parameters())\n","        \n","    attention_group = [params for (name, params) in attention_parameters] # attention用パラメータをリストとして取得\n","    regressor_group = [params for (name, params) in regressor_parameters] # reg用パラメータをリストとして取得\n","\n","    parameters = []\n","    parameters.append({\"params\": attention_group}) # パラメータをリストに辞書として格納していく\n","    parameters.append({\"params\": regressor_group})\n","\n","    for layer_num, (name, params) in enumerate(roberta_parameters): # レイヤーごとにname, paramsを取得していろんな処理\n","        weight_decay = 0.0 if \"bias\" in name else 0.01\n","\n","        lr = 2e-6\n","\n","        if layer_num >= 69:        \n","            lr = 5e-6\n","\n","        if layer_num >= 133:\n","            lr = 1e-5\n","\n","        parameters.append({\"params\": params,\n","                           \"weight_decay\": weight_decay,\n","                           \"lr\": lr})\n","\n","    return AdamW(parameters) # 最終的に、AdamWにパラメータを入力する。\n"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"EbaJojz0Zjif","executionInfo":{"status":"ok","timestamp":1626792441750,"user_tz":-540,"elapsed":21,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# https://www.kaggle.com/abhishek/step-1-create-folds\n","def create_folds(data, num_splits, SEED, return_df=False):\n","    # we create a new column called kfold and fill it with -1\n","    data[\"kfold\"] = -1\n","    \n","    # the next step is to randomize the rows of the data\n","    data = data.sample(frac=1).reset_index(drop=True)\n","\n","    # calculate number of bins by Sturge's rule\n","    # I take the floor of the value, you can also\n","    # just round it\n","    num_bins = int(np.floor(1 + np.log2(len(data))))\n","    \n","    # bin targets\n","    data.loc[:, \"bins_tg\"] = pd.cut(\n","        data[\"target\"], bins=num_bins, labels=False\n","    ).map(lambda x: str(x))\n","\n","    # bin standard_error\n","    data.loc[:, \"bins_std\"] = pd.cut(\n","        data[\"standard_error\"], bins=num_bins, labels=False\n","    )\n","\n","    # bins\n","    data.loc[:, \"bins\"] = data['bins_tg'].map(lambda x: str(x)) + data['bins_std'].map(lambda x: str(x))\n","\n","    # initiate the kfold class from model_selection module\n","    kf = StratifiedKFold(n_splits=5, random_state=SEED, shuffle=True)\n","\n","    # note that, instead of targets, we use bins!\n","    if return_df:\n","      for f, (t_, v_) in enumerate(kf.split(X=data, y=data.bins.values)):\n","        data.loc[v_, 'kfold'] = f\n","      return data\n","    else:\n","      return kf.split(X=data, y=data.bins.values)"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"id":"vAmhaYaylMk5","executionInfo":{"status":"ok","timestamp":1626792441751,"user_tz":-540,"elapsed":20,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"eddc1bbb-d65b-4a76-b119-400b8b847fd5"},"source":["# 検証用\n","SEED = 1000\n","st_kfold_bins_df = create_folds(train_df, num_splits=5, SEED=SEED, return_df=True)\n","st_kfold_bins_df['bins_tg'] = st_kfold_bins_df['bins_tg'].map(lambda x: float(x))\n","st_kfold_bins_df['bins_std'] = st_kfold_bins_df['bins_std'].map(lambda x: float(x))\n","st_kfold_bins_df.groupby('kfold').agg({'bins_tg': ['min', 'max', 'mean'],\n","                                    'bins_std': ['min', 'max', 'mean']})"],"execution_count":23,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  % (min_groups, self.n_splits)), UserWarning)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","\n","    .dataframe thead tr:last-of-type th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th></th>\n","      <th colspan=\"3\" halign=\"left\">bins_tg</th>\n","      <th colspan=\"3\" halign=\"left\">bins_std</th>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <th>min</th>\n","      <th>max</th>\n","      <th>mean</th>\n","      <th>min</th>\n","      <th>max</th>\n","      <th>mean</th>\n","    </tr>\n","    <tr>\n","      <th>kfold</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>5.566138</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>2.917108</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>5.560847</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>2.971781</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>5.513228</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>2.947090</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>5.538869</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>2.885159</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>5.570671</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>2.924028</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      bins_tg                 bins_std                \n","          min   max      mean      min   max      mean\n","kfold                                                 \n","0         0.0  11.0  5.566138      0.0  11.0  2.917108\n","1         0.0  11.0  5.560847      0.0  11.0  2.971781\n","2         0.0  11.0  5.513228      0.0  11.0  2.947090\n","3         0.0  11.0  5.538869      0.0  11.0  2.885159\n","4         0.0  11.0  5.570671      0.0  11.0  2.924028"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"TyjgRCu3mmqG","executionInfo":{"status":"ok","timestamp":1626792441752,"user_tz":-540,"elapsed":14,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"4PLKHwvKtNBn","executionInfo":{"status":"ok","timestamp":1626792441752,"user_tz":-540,"elapsed":13,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["def train_and_save_model(train_indices, val_indices, model_path):\n","    train_dataset = LitDataset(train_df.loc[train_indices]) # train, validのDataset\n","    val_dataset = LitDataset(train_df.loc[val_indices])\n","        \n","    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n","                              drop_last=True, shuffle=True, num_workers=2) # train, validのDataLoader\n","    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n","                            drop_last=False, shuffle=False, num_workers=2)    \n","\n","    model = LitModel().to(DEVICE) # modelをDEVICEへぶち込む\n","    optimizer = create_optimizer(model) # optimizerをモデルから作成\n","    scheduler = get_cosine_schedule_with_warmup( # schedulerを作成\n","        optimizer,\n","        num_training_steps=NUM_EPOCHS * len(train_loader),\n","        num_warmup_steps=50)    \n","    rmse = train(model, model_path, train_loader, val_loader, optimizer, scheduler=scheduler)\n","\n","    del train_dataset\n","    del val_dataset\n","    del train_loader\n","    del val_loader\n","    del model\n","    del optimizer\n","    del scheduler\n","    gc.collect() \n","    torch.cuda.empty_cache()\n","    return rmse"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.755813Z","iopub.execute_input":"2021-07-04T06:26:40.758373Z","iopub.status.idle":"2021-07-04T06:27:12.493221Z","shell.execute_reply.started":"2021-07-04T06:26:40.758265Z","shell.execute_reply":"2021-07-04T06:27:12.490139Z"},"trusted":true,"id":"k2LGJD3XXecK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626803219385,"user_tz":-540,"elapsed":10777646,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"bf2049c3-6784-4e2c-be79-2185ece614b5"},"source":["# 実行処理。 KFold & 学習\n","SEED = 1000\n","list_val_rmse = []\n","\n","#kfold = KFold(n_splits=NUM_FOLDS, random_state=SEED, shuffle=True)\n","kfold = create_folds(train_df, 5, SEED=SEED, return_df=False) # binsで切る場合\n","\n","for fold, (train_indices, val_indices) in enumerate(kfold):    \n","    print(f\"\\nFold {fold + 1}/{NUM_FOLDS}\")\n","    print(gpuinfo())\n","    model_path = f\"model_{fold + 1}.pth\" # model_fold数_.pth\n","    set_random_seed(SEED + fold) # SEEDはfold別に変わるようにする\n","    list_val_rmse.append(train_and_save_model(train_indices, val_indices, model_path))\n","\n","    print(\"\\nPerformance estimates:\")\n","    print(list_val_rmse)\n","    print(\"Mean:\", np.array(list_val_rmse).mean())\n","    print(gpuinfo())"],"execution_count":25,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  % (min_groups, self.n_splits)), UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Fold 1/5\n","{'total_MiB': 16280, 'used_MiB': 2}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-roberta-large/pre-trained-roberta/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-roberta-large/pre-trained-roberta/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 82.5 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.6724 train_rmse_stderror: 0.0472 train_kl_div: 0.8846\n","val_rmse_target: 0.7004 val_rmse_stderror: 1.794\n","New best_val_rmse: 0.7004\n","\n","64 steps took 81.4 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.7106 train_rmse_stderror: 0.07257 train_kl_div: 0.9228\n","val_rmse_target: 0.6347 val_rmse_stderror: 1.776\n","New best_val_rmse: 0.6347\n","\n","64 steps took 81.7 seconds\n","Epoch: 1 batch_num: 4\n","train_rmse_target: 0.4768 train_rmse_stderror: 0.0354 train_kl_div: 0.5137\n","val_rmse_target: 0.5711 val_rmse_stderror: 1.786\n","New best_val_rmse: 0.5711\n","\n","64 steps took 81.5 seconds\n","Epoch: 1 batch_num: 68\n","train_rmse_target: 0.3608 train_rmse_stderror: 0.03184 train_kl_div: 0.2764\n","val_rmse_target: 0.5543 val_rmse_stderror: 1.774\n","New best_val_rmse: 0.5543\n","\n","64 steps took 81.5 seconds\n","Epoch: 1 batch_num: 132\n","train_rmse_target: 0.4022 train_rmse_stderror: 0.04962 train_kl_div: 0.3531\n","val_rmse_target: 0.568 val_rmse_stderror: 1.806\n","Still best_val_rmse: 0.5543 (from epoch 1)\n","\n","64 steps took 81.7 seconds\n","Epoch: 2 batch_num: 8\n","train_rmse_target: 0.2713 train_rmse_stderror: 0.04618 train_kl_div: 0.1523\n","val_rmse_target: 0.5335 val_rmse_stderror: 1.779\n","New best_val_rmse: 0.5335\n","\n","32 steps took 40.7 seconds\n","Epoch: 2 batch_num: 40\n","train_rmse_target: 0.3775 train_rmse_stderror: 0.02649 train_kl_div: 0.2963\n","val_rmse_target: 0.5326 val_rmse_stderror: 1.785\n","New best_val_rmse: 0.5326\n","\n","32 steps took 40.7 seconds\n","Epoch: 2 batch_num: 72\n","train_rmse_target: 0.3535 train_rmse_stderror: 0.02849 train_kl_div: 0.2576\n","val_rmse_target: 0.5317 val_rmse_stderror: 1.787\n","New best_val_rmse: 0.5317\n","\n","32 steps took 40.7 seconds\n","Epoch: 2 batch_num: 104\n","train_rmse_target: 0.4032 train_rmse_stderror: 0.04133 train_kl_div: 0.3652\n","val_rmse_target: 0.5326 val_rmse_stderror: 1.774\n","Still best_val_rmse: 0.5317 (from epoch 2)\n","\n","32 steps took 40.7 seconds\n","Epoch: 2 batch_num: 136\n","train_rmse_target: 0.5557 train_rmse_stderror: 0.04128 train_kl_div: 0.6629\n","val_rmse_target: 0.5197 val_rmse_stderror: 1.793\n","New best_val_rmse: 0.5197\n","\n","32 steps took 40.7 seconds\n","Epoch: 2 batch_num: 168\n","train_rmse_target: 0.2789 train_rmse_stderror: 0.04956 train_kl_div: 0.1722\n","val_rmse_target: 0.5435 val_rmse_stderror: 1.777\n","Still best_val_rmse: 0.5197 (from epoch 2)\n","\n","32 steps took 41.0 seconds\n","Epoch: 3 batch_num: 12\n","train_rmse_target: 0.2741 train_rmse_stderror: 0.04851 train_kl_div: 0.1532\n","val_rmse_target: 0.5142 val_rmse_stderror: 1.789\n","New best_val_rmse: 0.5142\n","\n","32 steps took 40.7 seconds\n","Epoch: 3 batch_num: 44\n","train_rmse_target: 0.2762 train_rmse_stderror: 0.04228 train_kl_div: 0.1583\n","val_rmse_target: 0.5202 val_rmse_stderror: 1.779\n","Still best_val_rmse: 0.5142 (from epoch 3)\n","\n","32 steps took 40.7 seconds\n","Epoch: 3 batch_num: 76\n","train_rmse_target: 0.2997 train_rmse_stderror: 0.03419 train_kl_div: 0.1811\n","val_rmse_target: 0.5306 val_rmse_stderror: 1.786\n","Still best_val_rmse: 0.5142 (from epoch 3)\n","\n","32 steps took 40.7 seconds\n","Epoch: 3 batch_num: 108\n","train_rmse_target: 0.2616 train_rmse_stderror: 0.04143 train_kl_div: 0.1424\n","val_rmse_target: 0.5239 val_rmse_stderror: 1.788\n","Still best_val_rmse: 0.5142 (from epoch 3)\n","\n","32 steps took 40.7 seconds\n","Epoch: 3 batch_num: 140\n","train_rmse_target: 0.2469 train_rmse_stderror: 0.03617 train_kl_div: 0.1232\n","val_rmse_target: 0.5233 val_rmse_stderror: 1.777\n","Still best_val_rmse: 0.5142 (from epoch 3)\n","\n","32 steps took 40.7 seconds\n","Epoch: 3 batch_num: 172\n","train_rmse_target: 0.281 train_rmse_stderror: 0.03225 train_kl_div: 0.1476\n","val_rmse_target: 0.5222 val_rmse_stderror: 1.786\n","Still best_val_rmse: 0.5142 (from epoch 3)\n","\n","32 steps took 40.9 seconds\n","Epoch: 4 batch_num: 16\n","train_rmse_target: 0.2507 train_rmse_stderror: 0.02821 train_kl_div: 0.1409\n","val_rmse_target: 0.5255 val_rmse_stderror: 1.783\n","Still best_val_rmse: 0.5142 (from epoch 3)\n","\n","32 steps took 40.7 seconds\n","Epoch: 4 batch_num: 48\n","train_rmse_target: 0.3608 train_rmse_stderror: 0.04485 train_kl_div: 0.2513\n","val_rmse_target: 0.5327 val_rmse_stderror: 1.779\n","Still best_val_rmse: 0.5142 (from epoch 3)\n","\n","32 steps took 40.7 seconds\n","Epoch: 4 batch_num: 80\n","train_rmse_target: 0.3103 train_rmse_stderror: 0.03177 train_kl_div: 0.1941\n","val_rmse_target: 0.5243 val_rmse_stderror: 1.785\n","Still best_val_rmse: 0.5142 (from epoch 3)\n","\n","32 steps took 40.7 seconds\n","Epoch: 4 batch_num: 112\n","train_rmse_target: 0.1753 train_rmse_stderror: 0.04087 train_kl_div: 0.07051\n","val_rmse_target: 0.5281 val_rmse_stderror: 1.788\n","Still best_val_rmse: 0.5142 (from epoch 3)\n","\n","32 steps took 40.7 seconds\n","Epoch: 4 batch_num: 144\n","train_rmse_target: 0.1758 train_rmse_stderror: 0.0342 train_kl_div: 0.06788\n","val_rmse_target: 0.5286 val_rmse_stderror: 1.787\n","Still best_val_rmse: 0.5142 (from epoch 3)\n","\n","32 steps took 40.7 seconds\n","Epoch: 4 batch_num: 176\n","train_rmse_target: 0.2152 train_rmse_stderror: 0.02662 train_kl_div: 0.09971\n","val_rmse_target: 0.5284 val_rmse_stderror: 1.787\n","Still best_val_rmse: 0.5142 (from epoch 3)\n","\n","Performance estimates:\n","[0.5141760121366414]\n","Mean: 0.5141760121366414\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 2/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-roberta-large/pre-trained-roberta/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-roberta-large/pre-trained-roberta/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 82.5 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.4834 train_rmse_stderror: 0.1438 train_kl_div: 0.5888\n","val_rmse_target: 0.6659 val_rmse_stderror: 1.15\n","New best_val_rmse: 0.6659\n","\n","64 steps took 81.5 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.5651 train_rmse_stderror: 0.08243 train_kl_div: 0.6339\n","val_rmse_target: 0.6756 val_rmse_stderror: 1.21\n","Still best_val_rmse: 0.6659 (from epoch 0)\n","\n","64 steps took 82.6 seconds\n","Epoch: 1 batch_num: 4\n","train_rmse_target: 0.3893 train_rmse_stderror: 0.06368 train_kl_div: 0.3437\n","val_rmse_target: 0.6357 val_rmse_stderror: 1.143\n","New best_val_rmse: 0.6357\n","\n","64 steps took 81.5 seconds\n","Epoch: 1 batch_num: 68\n","train_rmse_target: 0.4309 train_rmse_stderror: 0.04227 train_kl_div: 0.4151\n","val_rmse_target: 0.644 val_rmse_stderror: 1.153\n","Still best_val_rmse: 0.6357 (from epoch 1)\n","\n","64 steps took 81.5 seconds\n","Epoch: 1 batch_num: 132\n","train_rmse_target: 0.5255 train_rmse_stderror: 0.0605 train_kl_div: 0.523\n","val_rmse_target: 0.5597 val_rmse_stderror: 1.16\n","New best_val_rmse: 0.5597\n","\n","64 steps took 81.7 seconds\n","Epoch: 2 batch_num: 8\n","train_rmse_target: 0.666 train_rmse_stderror: 0.05173 train_kl_div: 0.8422\n","val_rmse_target: 0.5349 val_rmse_stderror: 1.169\n","New best_val_rmse: 0.5349\n","\n","32 steps took 40.8 seconds\n","Epoch: 2 batch_num: 40\n","train_rmse_target: 0.5248 train_rmse_stderror: 0.0502 train_kl_div: 0.6101\n","val_rmse_target: 0.5382 val_rmse_stderror: 1.172\n","Still best_val_rmse: 0.5349 (from epoch 2)\n","\n","32 steps took 40.7 seconds\n","Epoch: 2 batch_num: 72\n","train_rmse_target: 0.2908 train_rmse_stderror: 0.05938 train_kl_div: 0.1716\n","val_rmse_target: 0.5329 val_rmse_stderror: 1.158\n","New best_val_rmse: 0.5329\n","\n","32 steps took 40.7 seconds\n","Epoch: 2 batch_num: 104\n","train_rmse_target: 0.321 train_rmse_stderror: 0.04172 train_kl_div: 0.2251\n","val_rmse_target: 0.5244 val_rmse_stderror: 1.165\n","New best_val_rmse: 0.5244\n","\n","32 steps took 40.7 seconds\n","Epoch: 2 batch_num: 136\n","train_rmse_target: 0.4562 train_rmse_stderror: 0.02489 train_kl_div: 0.3898\n","val_rmse_target: 0.5213 val_rmse_stderror: 1.171\n","New best_val_rmse: 0.5213\n","\n","32 steps took 40.8 seconds\n","Epoch: 2 batch_num: 168\n","train_rmse_target: 0.3884 train_rmse_stderror: 0.03477 train_kl_div: 0.3171\n","val_rmse_target: 0.5458 val_rmse_stderror: 1.173\n","Still best_val_rmse: 0.5213 (from epoch 2)\n","\n","32 steps took 41.0 seconds\n","Epoch: 3 batch_num: 12\n","train_rmse_target: 0.2542 train_rmse_stderror: 0.04178 train_kl_div: 0.1273\n","val_rmse_target: 0.5325 val_rmse_stderror: 1.164\n","Still best_val_rmse: 0.5213 (from epoch 2)\n","\n","32 steps took 40.7 seconds\n","Epoch: 3 batch_num: 44\n","train_rmse_target: 0.2851 train_rmse_stderror: 0.04611 train_kl_div: 0.1648\n","val_rmse_target: 0.518 val_rmse_stderror: 1.167\n","New best_val_rmse: 0.518\n","\n","32 steps took 40.7 seconds\n","Epoch: 3 batch_num: 76\n","train_rmse_target: 0.4182 train_rmse_stderror: 0.04249 train_kl_div: 0.3619\n","val_rmse_target: 0.5267 val_rmse_stderror: 1.171\n","Still best_val_rmse: 0.518 (from epoch 3)\n","\n","32 steps took 40.7 seconds\n","Epoch: 3 batch_num: 108\n","train_rmse_target: 0.4149 train_rmse_stderror: 0.0561 train_kl_div: 0.3623\n","val_rmse_target: 0.5316 val_rmse_stderror: 1.169\n","Still best_val_rmse: 0.518 (from epoch 3)\n","\n","32 steps took 40.7 seconds\n","Epoch: 3 batch_num: 140\n","train_rmse_target: 0.5042 train_rmse_stderror: 0.05546 train_kl_div: 0.5146\n","val_rmse_target: 0.5212 val_rmse_stderror: 1.168\n","Still best_val_rmse: 0.518 (from epoch 3)\n","\n","32 steps took 40.7 seconds\n","Epoch: 3 batch_num: 172\n","train_rmse_target: 0.3005 train_rmse_stderror: 0.04277 train_kl_div: 0.1956\n","val_rmse_target: 0.5278 val_rmse_stderror: 1.171\n","Still best_val_rmse: 0.518 (from epoch 3)\n","\n","32 steps took 40.9 seconds\n","Epoch: 4 batch_num: 16\n","train_rmse_target: 0.2693 train_rmse_stderror: 0.03357 train_kl_div: 0.1468\n","val_rmse_target: 0.5202 val_rmse_stderror: 1.165\n","Still best_val_rmse: 0.518 (from epoch 3)\n","\n","32 steps took 40.7 seconds\n","Epoch: 4 batch_num: 48\n","train_rmse_target: 0.3518 train_rmse_stderror: 0.04632 train_kl_div: 0.2661\n","val_rmse_target: 0.5206 val_rmse_stderror: 1.16\n","Still best_val_rmse: 0.518 (from epoch 3)\n","\n","32 steps took 40.7 seconds\n","Epoch: 4 batch_num: 80\n","train_rmse_target: 0.2976 train_rmse_stderror: 0.02763 train_kl_div: 0.1892\n","val_rmse_target: 0.5261 val_rmse_stderror: 1.165\n","Still best_val_rmse: 0.518 (from epoch 3)\n","\n","32 steps took 40.7 seconds\n","Epoch: 4 batch_num: 112\n","train_rmse_target: 0.2399 train_rmse_stderror: 0.05319 train_kl_div: 0.116\n","val_rmse_target: 0.5324 val_rmse_stderror: 1.166\n","Still best_val_rmse: 0.518 (from epoch 3)\n","\n","32 steps took 40.7 seconds\n","Epoch: 4 batch_num: 144\n","train_rmse_target: 0.4188 train_rmse_stderror: 0.0357 train_kl_div: 0.3454\n","val_rmse_target: 0.5269 val_rmse_stderror: 1.164\n","Still best_val_rmse: 0.518 (from epoch 3)\n","\n","32 steps took 40.7 seconds\n","Epoch: 4 batch_num: 176\n","train_rmse_target: 0.3211 train_rmse_stderror: 0.03805 train_kl_div: 0.2234\n","val_rmse_target: 0.5268 val_rmse_stderror: 1.165\n","Still best_val_rmse: 0.518 (from epoch 3)\n","\n","Performance estimates:\n","[0.5141760121366414, 0.5180231677731012]\n","Mean: 0.5160995899548713\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 3/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-roberta-large/pre-trained-roberta/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-roberta-large/pre-trained-roberta/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 82.4 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.6184 train_rmse_stderror: 0.04489 train_kl_div: 0.824\n","val_rmse_target: 0.6773 val_rmse_stderror: 1.691\n","New best_val_rmse: 0.6773\n","\n","64 steps took 81.5 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.9195 train_rmse_stderror: 0.04367 train_kl_div: 1.544\n","val_rmse_target: 0.6107 val_rmse_stderror: 1.751\n","New best_val_rmse: 0.6107\n","\n","64 steps took 81.7 seconds\n","Epoch: 1 batch_num: 4\n","train_rmse_target: 0.4101 train_rmse_stderror: 0.07935 train_kl_div: 0.3928\n","val_rmse_target: 0.7179 val_rmse_stderror: 1.759\n","Still best_val_rmse: 0.6107 (from epoch 0)\n","\n","64 steps took 81.4 seconds\n","Epoch: 1 batch_num: 68\n","train_rmse_target: 0.7746 train_rmse_stderror: 0.07281 train_kl_div: 0.9997\n","val_rmse_target: 0.5894 val_rmse_stderror: 1.734\n","New best_val_rmse: 0.5894\n","\n","64 steps took 81.6 seconds\n","Epoch: 1 batch_num: 132\n","train_rmse_target: 0.4252 train_rmse_stderror: 0.02246 train_kl_div: 0.3584\n","val_rmse_target: 0.5374 val_rmse_stderror: 1.727\n","New best_val_rmse: 0.5374\n","\n","32 steps took 40.7 seconds\n","Epoch: 1 batch_num: 164\n","train_rmse_target: 0.3943 train_rmse_stderror: 0.03069 train_kl_div: 0.3276\n","val_rmse_target: 0.5977 val_rmse_stderror: 1.724\n","Still best_val_rmse: 0.5374 (from epoch 1)\n","\n","64 steps took 81.7 seconds\n","Epoch: 2 batch_num: 40\n","train_rmse_target: 0.2381 train_rmse_stderror: 0.03929 train_kl_div: 0.1186\n","val_rmse_target: 0.5098 val_rmse_stderror: 1.743\n","New best_val_rmse: 0.5098\n","\n","32 steps took 40.7 seconds\n","Epoch: 2 batch_num: 72\n","train_rmse_target: 0.364 train_rmse_stderror: 0.0289 train_kl_div: 0.2994\n","val_rmse_target: 0.5107 val_rmse_stderror: 1.726\n","Still best_val_rmse: 0.5098 (from epoch 2)\n","\n","32 steps took 40.7 seconds\n","Epoch: 2 batch_num: 104\n","train_rmse_target: 0.3197 train_rmse_stderror: 0.03021 train_kl_div: 0.2203\n","val_rmse_target: 0.5103 val_rmse_stderror: 1.712\n","Still best_val_rmse: 0.5098 (from epoch 2)\n","\n","32 steps took 40.7 seconds\n","Epoch: 2 batch_num: 136\n","train_rmse_target: 0.4628 train_rmse_stderror: 0.06433 train_kl_div: 0.4457\n","val_rmse_target: 0.5083 val_rmse_stderror: 1.716\n","New best_val_rmse: 0.5083\n","\n","32 steps took 40.7 seconds\n","Epoch: 2 batch_num: 168\n","train_rmse_target: 0.3593 train_rmse_stderror: 0.04378 train_kl_div: 0.2791\n","val_rmse_target: 0.5074 val_rmse_stderror: 1.729\n","New best_val_rmse: 0.5074\n","\n","32 steps took 41.0 seconds\n","Epoch: 3 batch_num: 12\n","train_rmse_target: 0.2486 train_rmse_stderror: 0.0239 train_kl_div: 0.1265\n","val_rmse_target: 0.5295 val_rmse_stderror: 1.725\n","Still best_val_rmse: 0.5074 (from epoch 2)\n","\n","32 steps took 40.7 seconds\n","Epoch: 3 batch_num: 44\n","train_rmse_target: 0.3022 train_rmse_stderror: 0.04646 train_kl_div: 0.1517\n","val_rmse_target: 0.525 val_rmse_stderror: 1.722\n","Still best_val_rmse: 0.5074 (from epoch 2)\n","\n","32 steps took 40.7 seconds\n","Epoch: 3 batch_num: 76\n","train_rmse_target: 0.2051 train_rmse_stderror: 0.05789 train_kl_div: 0.08749\n","val_rmse_target: 0.509 val_rmse_stderror: 1.748\n","Still best_val_rmse: 0.5074 (from epoch 2)\n","\n","32 steps took 40.7 seconds\n","Epoch: 3 batch_num: 108\n","train_rmse_target: 0.2908 train_rmse_stderror: 0.05248 train_kl_div: 0.1674\n","val_rmse_target: 0.5298 val_rmse_stderror: 1.73\n","Still best_val_rmse: 0.5074 (from epoch 2)\n","\n","32 steps took 40.7 seconds\n","Epoch: 3 batch_num: 140\n","train_rmse_target: 0.4818 train_rmse_stderror: 0.03935 train_kl_div: 0.3812\n","val_rmse_target: 0.5213 val_rmse_stderror: 1.734\n","Still best_val_rmse: 0.5074 (from epoch 2)\n","\n","32 steps took 40.7 seconds\n","Epoch: 3 batch_num: 172\n","train_rmse_target: 0.3655 train_rmse_stderror: 0.04621 train_kl_div: 0.2811\n","val_rmse_target: 0.5255 val_rmse_stderror: 1.73\n","Still best_val_rmse: 0.5074 (from epoch 2)\n","\n","32 steps took 41.0 seconds\n","Epoch: 4 batch_num: 16\n","train_rmse_target: 0.2153 train_rmse_stderror: 0.04069 train_kl_div: 0.1017\n","val_rmse_target: 0.519 val_rmse_stderror: 1.726\n","Still best_val_rmse: 0.5074 (from epoch 2)\n","\n","32 steps took 40.7 seconds\n","Epoch: 4 batch_num: 48\n","train_rmse_target: 0.2913 train_rmse_stderror: 0.03321 train_kl_div: 0.1682\n","val_rmse_target: 0.5296 val_rmse_stderror: 1.727\n","Still best_val_rmse: 0.5074 (from epoch 2)\n","\n","32 steps took 40.7 seconds\n","Epoch: 4 batch_num: 80\n","train_rmse_target: 0.2855 train_rmse_stderror: 0.04517 train_kl_div: 0.1464\n","val_rmse_target: 0.5222 val_rmse_stderror: 1.73\n","Still best_val_rmse: 0.5074 (from epoch 2)\n","\n","32 steps took 40.7 seconds\n","Epoch: 4 batch_num: 112\n","train_rmse_target: 0.2206 train_rmse_stderror: 0.03152 train_kl_div: 0.1134\n","val_rmse_target: 0.5221 val_rmse_stderror: 1.729\n","Still best_val_rmse: 0.5074 (from epoch 2)\n","\n","32 steps took 40.7 seconds\n","Epoch: 4 batch_num: 144\n","train_rmse_target: 0.2813 train_rmse_stderror: 0.03633 train_kl_div: 0.1653\n","val_rmse_target: 0.5237 val_rmse_stderror: 1.731\n","Still best_val_rmse: 0.5074 (from epoch 2)\n","\n","32 steps took 40.7 seconds\n","Epoch: 4 batch_num: 176\n","train_rmse_target: 0.1825 train_rmse_stderror: 0.03703 train_kl_div: 0.05957\n","val_rmse_target: 0.5233 val_rmse_stderror: 1.73\n","Still best_val_rmse: 0.5074 (from epoch 2)\n","\n","Performance estimates:\n","[0.5141760121366414, 0.5180231677731012, 0.5073765523091726]\n","Mean: 0.5131919107396383\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 4/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-roberta-large/pre-trained-roberta/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-roberta-large/pre-trained-roberta/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 82.5 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.5026 train_rmse_stderror: 0.15 train_kl_div: 0.6232\n","val_rmse_target: 0.6076 val_rmse_stderror: 1.731\n","New best_val_rmse: 0.6076\n","\n","64 steps took 81.5 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.4531 train_rmse_stderror: 0.05676 train_kl_div: 0.4598\n","val_rmse_target: 0.5415 val_rmse_stderror: 1.728\n","New best_val_rmse: 0.5415\n","\n","32 steps took 40.7 seconds\n","Epoch: 0 batch_num: 160\n","train_rmse_target: 0.8846 train_rmse_stderror: 0.07209 train_kl_div: 1.616\n","val_rmse_target: 0.5549 val_rmse_stderror: 1.686\n","Still best_val_rmse: 0.5415 (from epoch 0)\n","\n","64 steps took 81.7 seconds\n","Epoch: 1 batch_num: 36\n","train_rmse_target: 0.4674 train_rmse_stderror: 0.03265 train_kl_div: 0.4882\n","val_rmse_target: 0.5147 val_rmse_stderror: 1.742\n","New best_val_rmse: 0.5147\n","\n","32 steps took 40.7 seconds\n","Epoch: 1 batch_num: 68\n","train_rmse_target: 0.3931 train_rmse_stderror: 0.06931 train_kl_div: 0.2643\n","val_rmse_target: 0.4915 val_rmse_stderror: 1.756\n","New best_val_rmse: 0.4915\n","\n","16 steps took 20.4 seconds\n","Epoch: 1 batch_num: 84\n","train_rmse_target: 0.4163 train_rmse_stderror: 0.0543 train_kl_div: 0.3536\n","val_rmse_target: 0.5364 val_rmse_stderror: 1.745\n","Still best_val_rmse: 0.4915 (from epoch 1)\n","\n","32 steps took 40.7 seconds\n","Epoch: 1 batch_num: 116\n","train_rmse_target: 0.4902 train_rmse_stderror: 0.04506 train_kl_div: 0.4336\n","val_rmse_target: 0.5179 val_rmse_stderror: 1.71\n","Still best_val_rmse: 0.4915 (from epoch 1)\n","\n","32 steps took 40.7 seconds\n","Epoch: 1 batch_num: 148\n","train_rmse_target: 0.5904 train_rmse_stderror: 0.05174 train_kl_div: 0.6419\n","val_rmse_target: 0.4995 val_rmse_stderror: 1.757\n","Still best_val_rmse: 0.4915 (from epoch 1)\n","\n","16 steps took 20.4 seconds\n","Epoch: 1 batch_num: 164\n","train_rmse_target: 0.356 train_rmse_stderror: 0.03786 train_kl_div: 0.226\n","val_rmse_target: 0.5054 val_rmse_stderror: 1.737\n","Still best_val_rmse: 0.4915 (from epoch 1)\n","\n","32 steps took 41.0 seconds\n","Epoch: 2 batch_num: 8\n","train_rmse_target: 0.4543 train_rmse_stderror: 0.03701 train_kl_div: 0.3819\n","val_rmse_target: 0.4754 val_rmse_stderror: 1.747\n","New best_val_rmse: 0.4754\n","\n","4 steps took 5.11 seconds\n","Epoch: 2 batch_num: 12\n","train_rmse_target: 0.2908 train_rmse_stderror: 0.04437 train_kl_div: 0.1934\n","val_rmse_target: 0.5052 val_rmse_stderror: 1.74\n","Still best_val_rmse: 0.4754 (from epoch 2)\n","\n","32 steps took 40.7 seconds\n","Epoch: 2 batch_num: 44\n","train_rmse_target: 0.3084 train_rmse_stderror: 0.03016 train_kl_div: 0.1877\n","val_rmse_target: 0.4727 val_rmse_stderror: 1.746\n","New best_val_rmse: 0.4727\n","\n","4 steps took 5.11 seconds\n","Epoch: 2 batch_num: 48\n","train_rmse_target: 0.2417 train_rmse_stderror: 0.02883 train_kl_div: 0.14\n","val_rmse_target: 0.4736 val_rmse_stderror: 1.73\n","Still best_val_rmse: 0.4727 (from epoch 2)\n","\n","4 steps took 5.08 seconds\n","Epoch: 2 batch_num: 52\n","train_rmse_target: 0.3622 train_rmse_stderror: 0.03346 train_kl_div: 0.2685\n","val_rmse_target: 0.4665 val_rmse_stderror: 1.744\n","New best_val_rmse: 0.4665\n","\n","2 steps took 2.56 seconds\n","Epoch: 2 batch_num: 54\n","train_rmse_target: 0.3407 train_rmse_stderror: 0.04468 train_kl_div: 0.2357\n","val_rmse_target: 0.4697 val_rmse_stderror: 1.757\n","Still best_val_rmse: 0.4665 (from epoch 2)\n","\n","2 steps took 2.53 seconds\n","Epoch: 2 batch_num: 56\n","train_rmse_target: 0.4616 train_rmse_stderror: 0.04231 train_kl_div: 0.3577\n","val_rmse_target: 0.4686 val_rmse_stderror: 1.758\n","Still best_val_rmse: 0.4665 (from epoch 2)\n","\n","2 steps took 2.54 seconds\n","Epoch: 2 batch_num: 58\n","train_rmse_target: 0.2103 train_rmse_stderror: 0.04786 train_kl_div: 0.09309\n","val_rmse_target: 0.485 val_rmse_stderror: 1.748\n","Still best_val_rmse: 0.4665 (from epoch 2)\n","\n","8 steps took 10.2 seconds\n","Epoch: 2 batch_num: 66\n","train_rmse_target: 0.4229 train_rmse_stderror: 0.05511 train_kl_div: 0.3561\n","val_rmse_target: 0.4635 val_rmse_stderror: 1.737\n","New best_val_rmse: 0.4635\n","\n","2 steps took 2.56 seconds\n","Epoch: 2 batch_num: 68\n","train_rmse_target: 0.3373 train_rmse_stderror: 0.03881 train_kl_div: 0.2456\n","val_rmse_target: 0.4701 val_rmse_stderror: 1.758\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","4 steps took 5.08 seconds\n","Epoch: 2 batch_num: 72\n","train_rmse_target: 0.4591 train_rmse_stderror: 0.04568 train_kl_div: 0.4082\n","val_rmse_target: 0.4672 val_rmse_stderror: 1.751\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","2 steps took 2.54 seconds\n","Epoch: 2 batch_num: 74\n","train_rmse_target: 0.4904 train_rmse_stderror: 0.03344 train_kl_div: 0.4733\n","val_rmse_target: 0.4707 val_rmse_stderror: 1.736\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","4 steps took 5.07 seconds\n","Epoch: 2 batch_num: 78\n","train_rmse_target: 0.3169 train_rmse_stderror: 0.04423 train_kl_div: 0.2177\n","val_rmse_target: 0.4715 val_rmse_stderror: 1.746\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","4 steps took 5.08 seconds\n","Epoch: 2 batch_num: 82\n","train_rmse_target: 0.2375 train_rmse_stderror: 0.03269 train_kl_div: 0.1259\n","val_rmse_target: 0.4996 val_rmse_stderror: 1.743\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","16 steps took 20.4 seconds\n","Epoch: 2 batch_num: 98\n","train_rmse_target: 0.3371 train_rmse_stderror: 0.03825 train_kl_div: 0.251\n","val_rmse_target: 0.4671 val_rmse_stderror: 1.731\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","2 steps took 2.53 seconds\n","Epoch: 2 batch_num: 100\n","train_rmse_target: 0.3767 train_rmse_stderror: 0.0384 train_kl_div: 0.3106\n","val_rmse_target: 0.4715 val_rmse_stderror: 1.746\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","4 steps took 5.07 seconds\n","Epoch: 2 batch_num: 104\n","train_rmse_target: 0.2668 train_rmse_stderror: 0.0396 train_kl_div: 0.1661\n","val_rmse_target: 0.4808 val_rmse_stderror: 1.737\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","8 steps took 10.2 seconds\n","Epoch: 2 batch_num: 112\n","train_rmse_target: 0.2322 train_rmse_stderror: 0.03364 train_kl_div: 0.1063\n","val_rmse_target: 0.4921 val_rmse_stderror: 1.754\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","16 steps took 20.3 seconds\n","Epoch: 2 batch_num: 128\n","train_rmse_target: 0.2538 train_rmse_stderror: 0.04362 train_kl_div: 0.1415\n","val_rmse_target: 0.4667 val_rmse_stderror: 1.763\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","2 steps took 2.54 seconds\n","Epoch: 2 batch_num: 130\n","train_rmse_target: 0.219 train_rmse_stderror: 0.03025 train_kl_div: 0.1125\n","val_rmse_target: 0.4672 val_rmse_stderror: 1.745\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","2 steps took 2.54 seconds\n","Epoch: 2 batch_num: 132\n","train_rmse_target: 0.3838 train_rmse_stderror: 0.04621 train_kl_div: 0.2827\n","val_rmse_target: 0.486 val_rmse_stderror: 1.731\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","8 steps took 10.2 seconds\n","Epoch: 2 batch_num: 140\n","train_rmse_target: 0.2856 train_rmse_stderror: 0.03385 train_kl_div: 0.1562\n","val_rmse_target: 0.4699 val_rmse_stderror: 1.732\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","2 steps took 2.54 seconds\n","Epoch: 2 batch_num: 142\n","train_rmse_target: 0.2411 train_rmse_stderror: 0.04174 train_kl_div: 0.1195\n","val_rmse_target: 0.4713 val_rmse_stderror: 1.729\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","4 steps took 5.08 seconds\n","Epoch: 2 batch_num: 146\n","train_rmse_target: 0.2858 train_rmse_stderror: 0.04247 train_kl_div: 0.135\n","val_rmse_target: 0.4692 val_rmse_stderror: 1.74\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","2 steps took 2.54 seconds\n","Epoch: 2 batch_num: 148\n","train_rmse_target: 0.2582 train_rmse_stderror: 0.04141 train_kl_div: 0.1492\n","val_rmse_target: 0.4823 val_rmse_stderror: 1.734\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","8 steps took 10.2 seconds\n","Epoch: 2 batch_num: 156\n","train_rmse_target: 0.3474 train_rmse_stderror: 0.01837 train_kl_div: 0.2388\n","val_rmse_target: 0.47 val_rmse_stderror: 1.729\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","2 steps took 2.53 seconds\n","Epoch: 2 batch_num: 158\n","train_rmse_target: 0.3633 train_rmse_stderror: 0.03641 train_kl_div: 0.2389\n","val_rmse_target: 0.4733 val_rmse_stderror: 1.729\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","4 steps took 5.08 seconds\n","Epoch: 2 batch_num: 162\n","train_rmse_target: 0.4645 train_rmse_stderror: 0.04087 train_kl_div: 0.443\n","val_rmse_target: 0.487 val_rmse_stderror: 1.75\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","8 steps took 10.2 seconds\n","Epoch: 2 batch_num: 170\n","train_rmse_target: 0.3653 train_rmse_stderror: 0.03532 train_kl_div: 0.244\n","val_rmse_target: 0.467 val_rmse_stderror: 1.741\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","2 steps took 2.54 seconds\n","Epoch: 2 batch_num: 172\n","train_rmse_target: 0.3062 train_rmse_stderror: 0.03156 train_kl_div: 0.1944\n","val_rmse_target: 0.4788 val_rmse_stderror: 1.742\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","4 steps took 5.08 seconds\n","Epoch: 2 batch_num: 176\n","train_rmse_target: 0.2685 train_rmse_stderror: 0.05463 train_kl_div: 0.1669\n","val_rmse_target: 0.4689 val_rmse_stderror: 1.729\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","2 steps took 2.53 seconds\n","Epoch: 2 batch_num: 178\n","train_rmse_target: 0.3532 train_rmse_stderror: 0.04933 train_kl_div: 0.2514\n","val_rmse_target: 0.4831 val_rmse_stderror: 1.731\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","8 steps took 10.2 seconds\n","Epoch: 2 batch_num: 186\n","train_rmse_target: 0.2542 train_rmse_stderror: 0.03983 train_kl_div: 0.1473\n","val_rmse_target: 0.475 val_rmse_stderror: 1.742\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","4 steps took 5.34 seconds\n","Epoch: 3 batch_num: 2\n","train_rmse_target: 0.1855 train_rmse_stderror: 0.02984 train_kl_div: 0.07812\n","val_rmse_target: 0.4747 val_rmse_stderror: 1.737\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","4 steps took 5.08 seconds\n","Epoch: 3 batch_num: 6\n","train_rmse_target: 0.3667 train_rmse_stderror: 0.04611 train_kl_div: 0.2375\n","val_rmse_target: 0.4892 val_rmse_stderror: 1.747\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","8 steps took 10.2 seconds\n","Epoch: 3 batch_num: 14\n","train_rmse_target: 0.3001 train_rmse_stderror: 0.03493 train_kl_div: 0.1853\n","val_rmse_target: 0.4759 val_rmse_stderror: 1.722\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","4 steps took 5.08 seconds\n","Epoch: 3 batch_num: 18\n","train_rmse_target: 0.3068 train_rmse_stderror: 0.04434 train_kl_div: 0.2077\n","val_rmse_target: 0.4851 val_rmse_stderror: 1.727\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","8 steps took 10.2 seconds\n","Epoch: 3 batch_num: 26\n","train_rmse_target: 0.23 train_rmse_stderror: 0.03017 train_kl_div: 0.1008\n","val_rmse_target: 0.4679 val_rmse_stderror: 1.743\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","2 steps took 2.53 seconds\n","Epoch: 3 batch_num: 28\n","train_rmse_target: 0.1969 train_rmse_stderror: 0.03041 train_kl_div: 0.08655\n","val_rmse_target: 0.4699 val_rmse_stderror: 1.729\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","2 steps took 2.53 seconds\n","Epoch: 3 batch_num: 30\n","train_rmse_target: 0.2166 train_rmse_stderror: 0.03378 train_kl_div: 0.1014\n","val_rmse_target: 0.4754 val_rmse_stderror: 1.719\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","4 steps took 5.08 seconds\n","Epoch: 3 batch_num: 34\n","train_rmse_target: 0.2038 train_rmse_stderror: 0.03317 train_kl_div: 0.09134\n","val_rmse_target: 0.4692 val_rmse_stderror: 1.736\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","2 steps took 2.54 seconds\n","Epoch: 3 batch_num: 36\n","train_rmse_target: 0.2802 train_rmse_stderror: 0.02346 train_kl_div: 0.1386\n","val_rmse_target: 0.4685 val_rmse_stderror: 1.745\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","2 steps took 2.54 seconds\n","Epoch: 3 batch_num: 38\n","train_rmse_target: 0.1687 train_rmse_stderror: 0.02926 train_kl_div: 0.0642\n","val_rmse_target: 0.4737 val_rmse_stderror: 1.75\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","4 steps took 5.08 seconds\n","Epoch: 3 batch_num: 42\n","train_rmse_target: 0.2358 train_rmse_stderror: 0.03884 train_kl_div: 0.1283\n","val_rmse_target: 0.4692 val_rmse_stderror: 1.735\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","2 steps took 2.53 seconds\n","Epoch: 3 batch_num: 44\n","train_rmse_target: 0.1576 train_rmse_stderror: 0.03141 train_kl_div: 0.05568\n","val_rmse_target: 0.4753 val_rmse_stderror: 1.737\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","4 steps took 5.08 seconds\n","Epoch: 3 batch_num: 48\n","train_rmse_target: 0.2679 train_rmse_stderror: 0.02132 train_kl_div: 0.1473\n","val_rmse_target: 0.4697 val_rmse_stderror: 1.745\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","2 steps took 2.53 seconds\n","Epoch: 3 batch_num: 50\n","train_rmse_target: 0.2773 train_rmse_stderror: 0.03545 train_kl_div: 0.1577\n","val_rmse_target: 0.4665 val_rmse_stderror: 1.745\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","2 steps took 2.54 seconds\n","Epoch: 3 batch_num: 52\n","train_rmse_target: 0.2846 train_rmse_stderror: 0.04159 train_kl_div: 0.1882\n","val_rmse_target: 0.4665 val_rmse_stderror: 1.742\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","2 steps took 2.53 seconds\n","Epoch: 3 batch_num: 54\n","train_rmse_target: 0.2912 train_rmse_stderror: 0.03476 train_kl_div: 0.1736\n","val_rmse_target: 0.4665 val_rmse_stderror: 1.741\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","2 steps took 2.53 seconds\n","Epoch: 3 batch_num: 56\n","train_rmse_target: 0.2396 train_rmse_stderror: 0.0316 train_kl_div: 0.1228\n","val_rmse_target: 0.4674 val_rmse_stderror: 1.743\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","2 steps took 2.53 seconds\n","Epoch: 3 batch_num: 58\n","train_rmse_target: 0.2771 train_rmse_stderror: 0.04017 train_kl_div: 0.1511\n","val_rmse_target: 0.4683 val_rmse_stderror: 1.747\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","2 steps took 2.54 seconds\n","Epoch: 3 batch_num: 60\n","train_rmse_target: 0.1848 train_rmse_stderror: 0.02745 train_kl_div: 0.07561\n","val_rmse_target: 0.4693 val_rmse_stderror: 1.745\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","2 steps took 2.53 seconds\n","Epoch: 3 batch_num: 62\n","train_rmse_target: 0.1997 train_rmse_stderror: 0.02544 train_kl_div: 0.08013\n","val_rmse_target: 0.4695 val_rmse_stderror: 1.741\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","2 steps took 2.54 seconds\n","Epoch: 3 batch_num: 64\n","train_rmse_target: 0.1549 train_rmse_stderror: 0.03204 train_kl_div: 0.05376\n","val_rmse_target: 0.4737 val_rmse_stderror: 1.738\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","4 steps took 5.08 seconds\n","Epoch: 3 batch_num: 68\n","train_rmse_target: 0.2051 train_rmse_stderror: 0.03266 train_kl_div: 0.09451\n","val_rmse_target: 0.4818 val_rmse_stderror: 1.738\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","8 steps took 10.2 seconds\n","Epoch: 3 batch_num: 76\n","train_rmse_target: 0.2543 train_rmse_stderror: 0.02525 train_kl_div: 0.1333\n","val_rmse_target: 0.4697 val_rmse_stderror: 1.747\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","2 steps took 2.54 seconds\n","Epoch: 3 batch_num: 78\n","train_rmse_target: 0.2729 train_rmse_stderror: 0.02897 train_kl_div: 0.1627\n","val_rmse_target: 0.4732 val_rmse_stderror: 1.747\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","4 steps took 5.08 seconds\n","Epoch: 3 batch_num: 82\n","train_rmse_target: 0.2072 train_rmse_stderror: 0.03522 train_kl_div: 0.09396\n","val_rmse_target: 0.4694 val_rmse_stderror: 1.737\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","2 steps took 2.53 seconds\n","Epoch: 3 batch_num: 84\n","train_rmse_target: 0.1814 train_rmse_stderror: 0.03804 train_kl_div: 0.07469\n","val_rmse_target: 0.465 val_rmse_stderror: 1.732\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","2 steps took 2.54 seconds\n","Epoch: 3 batch_num: 86\n","train_rmse_target: 0.2213 train_rmse_stderror: 0.03258 train_kl_div: 0.1031\n","val_rmse_target: 0.4683 val_rmse_stderror: 1.733\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","2 steps took 2.54 seconds\n","Epoch: 3 batch_num: 88\n","train_rmse_target: 0.328 train_rmse_stderror: 0.03625 train_kl_div: 0.2073\n","val_rmse_target: 0.4706 val_rmse_stderror: 1.735\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","4 steps took 5.08 seconds\n","Epoch: 3 batch_num: 92\n","train_rmse_target: 0.3483 train_rmse_stderror: 0.04645 train_kl_div: 0.2128\n","val_rmse_target: 0.4641 val_rmse_stderror: 1.751\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","2 steps took 2.53 seconds\n","Epoch: 3 batch_num: 94\n","train_rmse_target: 0.1568 train_rmse_stderror: 0.03476 train_kl_div: 0.05843\n","val_rmse_target: 0.4722 val_rmse_stderror: 1.754\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","4 steps took 5.08 seconds\n","Epoch: 3 batch_num: 98\n","train_rmse_target: 0.3072 train_rmse_stderror: 0.04621 train_kl_div: 0.1994\n","val_rmse_target: 0.4869 val_rmse_stderror: 1.735\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","8 steps took 10.2 seconds\n","Epoch: 3 batch_num: 106\n","train_rmse_target: 0.2786 train_rmse_stderror: 0.02962 train_kl_div: 0.1643\n","val_rmse_target: 0.4672 val_rmse_stderror: 1.737\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","2 steps took 2.53 seconds\n","Epoch: 3 batch_num: 108\n","train_rmse_target: 0.1975 train_rmse_stderror: 0.02213 train_kl_div: 0.08091\n","val_rmse_target: 0.4695 val_rmse_stderror: 1.738\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","2 steps took 2.54 seconds\n","Epoch: 3 batch_num: 110\n","train_rmse_target: 0.2119 train_rmse_stderror: 0.0301 train_kl_div: 0.09654\n","val_rmse_target: 0.4706 val_rmse_stderror: 1.741\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","4 steps took 5.08 seconds\n","Epoch: 3 batch_num: 114\n","train_rmse_target: 0.2361 train_rmse_stderror: 0.02063 train_kl_div: 0.1201\n","val_rmse_target: 0.4722 val_rmse_stderror: 1.74\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","4 steps took 5.07 seconds\n","Epoch: 3 batch_num: 118\n","train_rmse_target: 0.1989 train_rmse_stderror: 0.03087 train_kl_div: 0.08518\n","val_rmse_target: 0.4697 val_rmse_stderror: 1.74\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","2 steps took 2.53 seconds\n","Epoch: 3 batch_num: 120\n","train_rmse_target: 0.2496 train_rmse_stderror: 0.0397 train_kl_div: 0.1329\n","val_rmse_target: 0.4681 val_rmse_stderror: 1.739\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","2 steps took 2.54 seconds\n","Epoch: 3 batch_num: 122\n","train_rmse_target: 0.2087 train_rmse_stderror: 0.02778 train_kl_div: 0.09668\n","val_rmse_target: 0.4679 val_rmse_stderror: 1.739\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","2 steps took 2.54 seconds\n","Epoch: 3 batch_num: 124\n","train_rmse_target: 0.1813 train_rmse_stderror: 0.04458 train_kl_div: 0.07304\n","val_rmse_target: 0.4669 val_rmse_stderror: 1.739\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","2 steps took 2.53 seconds\n","Epoch: 3 batch_num: 126\n","train_rmse_target: 0.231 train_rmse_stderror: 0.02733 train_kl_div: 0.1031\n","val_rmse_target: 0.4685 val_rmse_stderror: 1.741\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","2 steps took 2.53 seconds\n","Epoch: 3 batch_num: 128\n","train_rmse_target: 0.2847 train_rmse_stderror: 0.035 train_kl_div: 0.1781\n","val_rmse_target: 0.4676 val_rmse_stderror: 1.743\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","2 steps took 2.53 seconds\n","Epoch: 3 batch_num: 130\n","train_rmse_target: 0.2237 train_rmse_stderror: 0.03029 train_kl_div: 0.1053\n","val_rmse_target: 0.4657 val_rmse_stderror: 1.745\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","2 steps took 2.53 seconds\n","Epoch: 3 batch_num: 132\n","train_rmse_target: 0.1712 train_rmse_stderror: 0.03315 train_kl_div: 0.06292\n","val_rmse_target: 0.4649 val_rmse_stderror: 1.748\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","2 steps took 2.53 seconds\n","Epoch: 3 batch_num: 134\n","train_rmse_target: 0.2401 train_rmse_stderror: 0.02299 train_kl_div: 0.1127\n","val_rmse_target: 0.4659 val_rmse_stderror: 1.75\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","2 steps took 2.54 seconds\n","Epoch: 3 batch_num: 136\n","train_rmse_target: 0.2759 train_rmse_stderror: 0.03666 train_kl_div: 0.1552\n","val_rmse_target: 0.4662 val_rmse_stderror: 1.752\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","2 steps took 2.54 seconds\n","Epoch: 3 batch_num: 138\n","train_rmse_target: 0.3308 train_rmse_stderror: 0.03506 train_kl_div: 0.2208\n","val_rmse_target: 0.4661 val_rmse_stderror: 1.747\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","2 steps took 2.54 seconds\n","Epoch: 3 batch_num: 140\n","train_rmse_target: 0.2943 train_rmse_stderror: 0.03885 train_kl_div: 0.1636\n","val_rmse_target: 0.4655 val_rmse_stderror: 1.739\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","2 steps took 2.53 seconds\n","Epoch: 3 batch_num: 142\n","train_rmse_target: 0.2259 train_rmse_stderror: 0.03049 train_kl_div: 0.1135\n","val_rmse_target: 0.4651 val_rmse_stderror: 1.733\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","2 steps took 2.54 seconds\n","Epoch: 3 batch_num: 144\n","train_rmse_target: 0.2078 train_rmse_stderror: 0.03381 train_kl_div: 0.0952\n","val_rmse_target: 0.4639 val_rmse_stderror: 1.732\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","2 steps took 2.53 seconds\n","Epoch: 3 batch_num: 146\n","train_rmse_target: 0.266 train_rmse_stderror: 0.02256 train_kl_div: 0.1512\n","val_rmse_target: 0.4635 val_rmse_stderror: 1.733\n","Still best_val_rmse: 0.4635 (from epoch 2)\n","\n","2 steps took 2.54 seconds\n","Epoch: 3 batch_num: 148\n","train_rmse_target: 0.1975 train_rmse_stderror: 0.03225 train_kl_div: 0.08205\n","val_rmse_target: 0.463 val_rmse_stderror: 1.737\n","New best_val_rmse: 0.463\n","\n","2 steps took 2.56 seconds\n","Epoch: 3 batch_num: 150\n","train_rmse_target: 0.2951 train_rmse_stderror: 0.03877 train_kl_div: 0.1387\n","val_rmse_target: 0.4629 val_rmse_stderror: 1.742\n","New best_val_rmse: 0.4629\n","\n","2 steps took 2.54 seconds\n","Epoch: 3 batch_num: 152\n","train_rmse_target: 0.2894 train_rmse_stderror: 0.04471 train_kl_div: 0.1421\n","val_rmse_target: 0.463 val_rmse_stderror: 1.745\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 3 batch_num: 154\n","train_rmse_target: 0.3428 train_rmse_stderror: 0.0539 train_kl_div: 0.2349\n","val_rmse_target: 0.4635 val_rmse_stderror: 1.745\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 3 batch_num: 156\n","train_rmse_target: 0.2816 train_rmse_stderror: 0.04129 train_kl_div: 0.1478\n","val_rmse_target: 0.4645 val_rmse_stderror: 1.743\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 3 batch_num: 158\n","train_rmse_target: 0.2369 train_rmse_stderror: 0.02322 train_kl_div: 0.1074\n","val_rmse_target: 0.467 val_rmse_stderror: 1.742\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 3 batch_num: 160\n","train_rmse_target: 0.2239 train_rmse_stderror: 0.0387 train_kl_div: 0.1149\n","val_rmse_target: 0.4682 val_rmse_stderror: 1.743\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 3 batch_num: 162\n","train_rmse_target: 0.2436 train_rmse_stderror: 0.03073 train_kl_div: 0.1313\n","val_rmse_target: 0.4666 val_rmse_stderror: 1.744\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 3 batch_num: 164\n","train_rmse_target: 0.2249 train_rmse_stderror: 0.0303 train_kl_div: 0.1153\n","val_rmse_target: 0.4663 val_rmse_stderror: 1.743\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 3 batch_num: 166\n","train_rmse_target: 0.213 train_rmse_stderror: 0.02995 train_kl_div: 0.1048\n","val_rmse_target: 0.4676 val_rmse_stderror: 1.739\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 3 batch_num: 168\n","train_rmse_target: 0.2999 train_rmse_stderror: 0.02921 train_kl_div: 0.1817\n","val_rmse_target: 0.4701 val_rmse_stderror: 1.734\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","4 steps took 5.08 seconds\n","Epoch: 3 batch_num: 172\n","train_rmse_target: 0.186 train_rmse_stderror: 0.03326 train_kl_div: 0.0687\n","val_rmse_target: 0.4711 val_rmse_stderror: 1.73\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","4 steps took 5.08 seconds\n","Epoch: 3 batch_num: 176\n","train_rmse_target: 0.2628 train_rmse_stderror: 0.02161 train_kl_div: 0.1478\n","val_rmse_target: 0.4649 val_rmse_stderror: 1.737\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 3 batch_num: 178\n","train_rmse_target: 0.2907 train_rmse_stderror: 0.02578 train_kl_div: 0.1619\n","val_rmse_target: 0.464 val_rmse_stderror: 1.741\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 3 batch_num: 180\n","train_rmse_target: 0.3038 train_rmse_stderror: 0.03066 train_kl_div: 0.2005\n","val_rmse_target: 0.4649 val_rmse_stderror: 1.745\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 3 batch_num: 182\n","train_rmse_target: 0.1953 train_rmse_stderror: 0.04742 train_kl_div: 0.09106\n","val_rmse_target: 0.4651 val_rmse_stderror: 1.745\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 3 batch_num: 184\n","train_rmse_target: 0.5043 train_rmse_stderror: 0.05007 train_kl_div: 0.4235\n","val_rmse_target: 0.4636 val_rmse_stderror: 1.741\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 3 batch_num: 186\n","train_rmse_target: 0.2392 train_rmse_stderror: 0.02419 train_kl_div: 0.1282\n","val_rmse_target: 0.4637 val_rmse_stderror: 1.738\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.77 seconds\n","Epoch: 4 batch_num: 0\n","train_rmse_target: 0.1468 train_rmse_stderror: 0.01381 train_kl_div: 0.0448\n","val_rmse_target: 0.4656 val_rmse_stderror: 1.735\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 4 batch_num: 2\n","train_rmse_target: 0.1854 train_rmse_stderror: 0.03552 train_kl_div: 0.07596\n","val_rmse_target: 0.4693 val_rmse_stderror: 1.731\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 4 batch_num: 4\n","train_rmse_target: 0.1279 train_rmse_stderror: 0.05086 train_kl_div: 0.03948\n","val_rmse_target: 0.4713 val_rmse_stderror: 1.729\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","4 steps took 5.08 seconds\n","Epoch: 4 batch_num: 8\n","train_rmse_target: 0.1466 train_rmse_stderror: 0.03515 train_kl_div: 0.04745\n","val_rmse_target: 0.4672 val_rmse_stderror: 1.731\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 4 batch_num: 10\n","train_rmse_target: 0.2756 train_rmse_stderror: 0.03819 train_kl_div: 0.1606\n","val_rmse_target: 0.4661 val_rmse_stderror: 1.736\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 12\n","train_rmse_target: 0.2523 train_rmse_stderror: 0.04111 train_kl_div: 0.1069\n","val_rmse_target: 0.465 val_rmse_stderror: 1.738\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 4 batch_num: 14\n","train_rmse_target: 0.267 train_rmse_stderror: 0.04099 train_kl_div: 0.1367\n","val_rmse_target: 0.4646 val_rmse_stderror: 1.741\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 16\n","train_rmse_target: 0.2993 train_rmse_stderror: 0.03095 train_kl_div: 0.1772\n","val_rmse_target: 0.4644 val_rmse_stderror: 1.744\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 4 batch_num: 18\n","train_rmse_target: 0.1145 train_rmse_stderror: 0.02642 train_kl_div: 0.03013\n","val_rmse_target: 0.4645 val_rmse_stderror: 1.745\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 20\n","train_rmse_target: 0.2174 train_rmse_stderror: 0.03585 train_kl_div: 0.08705\n","val_rmse_target: 0.4657 val_rmse_stderror: 1.746\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 22\n","train_rmse_target: 0.3306 train_rmse_stderror: 0.03373 train_kl_div: 0.2058\n","val_rmse_target: 0.4662 val_rmse_stderror: 1.747\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 4 batch_num: 24\n","train_rmse_target: 0.2308 train_rmse_stderror: 0.02866 train_kl_div: 0.1071\n","val_rmse_target: 0.4667 val_rmse_stderror: 1.747\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 26\n","train_rmse_target: 0.2011 train_rmse_stderror: 0.02564 train_kl_div: 0.08821\n","val_rmse_target: 0.4676 val_rmse_stderror: 1.746\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 4 batch_num: 28\n","train_rmse_target: 0.1708 train_rmse_stderror: 0.02571 train_kl_div: 0.06733\n","val_rmse_target: 0.4664 val_rmse_stderror: 1.745\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 4 batch_num: 30\n","train_rmse_target: 0.1927 train_rmse_stderror: 0.02486 train_kl_div: 0.08606\n","val_rmse_target: 0.4652 val_rmse_stderror: 1.74\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 32\n","train_rmse_target: 0.1837 train_rmse_stderror: 0.01636 train_kl_div: 0.06996\n","val_rmse_target: 0.4642 val_rmse_stderror: 1.735\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 34\n","train_rmse_target: 0.2435 train_rmse_stderror: 0.03246 train_kl_div: 0.1287\n","val_rmse_target: 0.4634 val_rmse_stderror: 1.733\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 4 batch_num: 36\n","train_rmse_target: 0.201 train_rmse_stderror: 0.03854 train_kl_div: 0.08113\n","val_rmse_target: 0.4634 val_rmse_stderror: 1.731\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 38\n","train_rmse_target: 0.1563 train_rmse_stderror: 0.03747 train_kl_div: 0.05442\n","val_rmse_target: 0.4638 val_rmse_stderror: 1.73\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 40\n","train_rmse_target: 0.258 train_rmse_stderror: 0.0455 train_kl_div: 0.1301\n","val_rmse_target: 0.4638 val_rmse_stderror: 1.732\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 42\n","train_rmse_target: 0.2346 train_rmse_stderror: 0.03042 train_kl_div: 0.1068\n","val_rmse_target: 0.4638 val_rmse_stderror: 1.735\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 4 batch_num: 44\n","train_rmse_target: 0.2192 train_rmse_stderror: 0.0367 train_kl_div: 0.1066\n","val_rmse_target: 0.464 val_rmse_stderror: 1.74\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 46\n","train_rmse_target: 0.2357 train_rmse_stderror: 0.05909 train_kl_div: 0.09738\n","val_rmse_target: 0.4646 val_rmse_stderror: 1.743\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 48\n","train_rmse_target: 0.2148 train_rmse_stderror: 0.03158 train_kl_div: 0.09634\n","val_rmse_target: 0.4656 val_rmse_stderror: 1.744\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 4 batch_num: 50\n","train_rmse_target: 0.1281 train_rmse_stderror: 0.02922 train_kl_div: 0.0413\n","val_rmse_target: 0.4661 val_rmse_stderror: 1.744\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 52\n","train_rmse_target: 0.1452 train_rmse_stderror: 0.03068 train_kl_div: 0.04461\n","val_rmse_target: 0.4666 val_rmse_stderror: 1.745\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 4 batch_num: 54\n","train_rmse_target: 0.1716 train_rmse_stderror: 0.03017 train_kl_div: 0.0661\n","val_rmse_target: 0.4668 val_rmse_stderror: 1.745\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 4 batch_num: 56\n","train_rmse_target: 0.1638 train_rmse_stderror: 0.02799 train_kl_div: 0.05534\n","val_rmse_target: 0.4671 val_rmse_stderror: 1.745\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 4 batch_num: 58\n","train_rmse_target: 0.1958 train_rmse_stderror: 0.03467 train_kl_div: 0.08138\n","val_rmse_target: 0.4672 val_rmse_stderror: 1.743\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 4 batch_num: 60\n","train_rmse_target: 0.138 train_rmse_stderror: 0.029 train_kl_div: 0.04257\n","val_rmse_target: 0.4673 val_rmse_stderror: 1.741\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 62\n","train_rmse_target: 0.1799 train_rmse_stderror: 0.03807 train_kl_div: 0.06479\n","val_rmse_target: 0.468 val_rmse_stderror: 1.739\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 4 batch_num: 64\n","train_rmse_target: 0.1587 train_rmse_stderror: 0.02885 train_kl_div: 0.06274\n","val_rmse_target: 0.4686 val_rmse_stderror: 1.738\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 66\n","train_rmse_target: 0.1612 train_rmse_stderror: 0.02469 train_kl_div: 0.05847\n","val_rmse_target: 0.4685 val_rmse_stderror: 1.737\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 4 batch_num: 68\n","train_rmse_target: 0.2088 train_rmse_stderror: 0.03575 train_kl_div: 0.09202\n","val_rmse_target: 0.4685 val_rmse_stderror: 1.737\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 70\n","train_rmse_target: 0.1774 train_rmse_stderror: 0.02841 train_kl_div: 0.05855\n","val_rmse_target: 0.4683 val_rmse_stderror: 1.738\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 72\n","train_rmse_target: 0.2293 train_rmse_stderror: 0.02694 train_kl_div: 0.1138\n","val_rmse_target: 0.4686 val_rmse_stderror: 1.739\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 4 batch_num: 74\n","train_rmse_target: 0.1866 train_rmse_stderror: 0.03325 train_kl_div: 0.07032\n","val_rmse_target: 0.469 val_rmse_stderror: 1.74\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 4 batch_num: 76\n","train_rmse_target: 0.178 train_rmse_stderror: 0.02917 train_kl_div: 0.06668\n","val_rmse_target: 0.4691 val_rmse_stderror: 1.741\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 4 batch_num: 78\n","train_rmse_target: 0.2178 train_rmse_stderror: 0.02932 train_kl_div: 0.09694\n","val_rmse_target: 0.4689 val_rmse_stderror: 1.741\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 80\n","train_rmse_target: 0.2364 train_rmse_stderror: 0.02072 train_kl_div: 0.1312\n","val_rmse_target: 0.4689 val_rmse_stderror: 1.741\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 82\n","train_rmse_target: 0.1719 train_rmse_stderror: 0.03127 train_kl_div: 0.06544\n","val_rmse_target: 0.469 val_rmse_stderror: 1.741\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 4 batch_num: 84\n","train_rmse_target: 0.3207 train_rmse_stderror: 0.04486 train_kl_div: 0.1687\n","val_rmse_target: 0.469 val_rmse_stderror: 1.741\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 86\n","train_rmse_target: 0.175 train_rmse_stderror: 0.04445 train_kl_div: 0.07159\n","val_rmse_target: 0.4683 val_rmse_stderror: 1.741\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 4 batch_num: 88\n","train_rmse_target: 0.1832 train_rmse_stderror: 0.02793 train_kl_div: 0.07429\n","val_rmse_target: 0.468 val_rmse_stderror: 1.741\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 4 batch_num: 90\n","train_rmse_target: 0.1435 train_rmse_stderror: 0.03573 train_kl_div: 0.04763\n","val_rmse_target: 0.4674 val_rmse_stderror: 1.74\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 4 batch_num: 92\n","train_rmse_target: 0.1693 train_rmse_stderror: 0.03732 train_kl_div: 0.06111\n","val_rmse_target: 0.4669 val_rmse_stderror: 1.739\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 4 batch_num: 94\n","train_rmse_target: 0.2699 train_rmse_stderror: 0.03707 train_kl_div: 0.1546\n","val_rmse_target: 0.4666 val_rmse_stderror: 1.739\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 4 batch_num: 96\n","train_rmse_target: 0.2591 train_rmse_stderror: 0.02718 train_kl_div: 0.1502\n","val_rmse_target: 0.4665 val_rmse_stderror: 1.738\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 98\n","train_rmse_target: 0.1749 train_rmse_stderror: 0.02559 train_kl_div: 0.06419\n","val_rmse_target: 0.4666 val_rmse_stderror: 1.737\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 100\n","train_rmse_target: 0.2433 train_rmse_stderror: 0.03103 train_kl_div: 0.1211\n","val_rmse_target: 0.4664 val_rmse_stderror: 1.736\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 102\n","train_rmse_target: 0.2675 train_rmse_stderror: 0.02702 train_kl_div: 0.1457\n","val_rmse_target: 0.4664 val_rmse_stderror: 1.736\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 104\n","train_rmse_target: 0.2082 train_rmse_stderror: 0.04188 train_kl_div: 0.08693\n","val_rmse_target: 0.4665 val_rmse_stderror: 1.736\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 4 batch_num: 106\n","train_rmse_target: 0.1351 train_rmse_stderror: 0.02639 train_kl_div: 0.04369\n","val_rmse_target: 0.4667 val_rmse_stderror: 1.737\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 108\n","train_rmse_target: 0.1588 train_rmse_stderror: 0.02566 train_kl_div: 0.05577\n","val_rmse_target: 0.4669 val_rmse_stderror: 1.737\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 110\n","train_rmse_target: 0.1229 train_rmse_stderror: 0.01595 train_kl_div: 0.03448\n","val_rmse_target: 0.4671 val_rmse_stderror: 1.737\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 112\n","train_rmse_target: 0.1883 train_rmse_stderror: 0.03553 train_kl_div: 0.06769\n","val_rmse_target: 0.4671 val_rmse_stderror: 1.737\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 114\n","train_rmse_target: 0.1784 train_rmse_stderror: 0.02325 train_kl_div: 0.06672\n","val_rmse_target: 0.4671 val_rmse_stderror: 1.738\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 4 batch_num: 116\n","train_rmse_target: 0.1624 train_rmse_stderror: 0.02986 train_kl_div: 0.05019\n","val_rmse_target: 0.467 val_rmse_stderror: 1.739\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 4 batch_num: 118\n","train_rmse_target: 0.2208 train_rmse_stderror: 0.04173 train_kl_div: 0.09925\n","val_rmse_target: 0.4669 val_rmse_stderror: 1.739\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 120\n","train_rmse_target: 0.1974 train_rmse_stderror: 0.02605 train_kl_div: 0.08044\n","val_rmse_target: 0.4668 val_rmse_stderror: 1.74\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 122\n","train_rmse_target: 0.151 train_rmse_stderror: 0.03331 train_kl_div: 0.04943\n","val_rmse_target: 0.4669 val_rmse_stderror: 1.74\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 124\n","train_rmse_target: 0.11 train_rmse_stderror: 0.02326 train_kl_div: 0.02768\n","val_rmse_target: 0.4669 val_rmse_stderror: 1.74\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 4 batch_num: 126\n","train_rmse_target: 0.1784 train_rmse_stderror: 0.02763 train_kl_div: 0.06756\n","val_rmse_target: 0.4668 val_rmse_stderror: 1.74\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 128\n","train_rmse_target: 0.1979 train_rmse_stderror: 0.02725 train_kl_div: 0.08114\n","val_rmse_target: 0.4669 val_rmse_stderror: 1.74\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 130\n","train_rmse_target: 0.1699 train_rmse_stderror: 0.02059 train_kl_div: 0.06578\n","val_rmse_target: 0.4669 val_rmse_stderror: 1.74\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 132\n","train_rmse_target: 0.217 train_rmse_stderror: 0.03236 train_kl_div: 0.1008\n","val_rmse_target: 0.4669 val_rmse_stderror: 1.74\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 134\n","train_rmse_target: 0.1652 train_rmse_stderror: 0.0224 train_kl_div: 0.06317\n","val_rmse_target: 0.467 val_rmse_stderror: 1.74\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 4 batch_num: 136\n","train_rmse_target: 0.1649 train_rmse_stderror: 0.02953 train_kl_div: 0.06385\n","val_rmse_target: 0.4671 val_rmse_stderror: 1.74\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 4 batch_num: 138\n","train_rmse_target: 0.2252 train_rmse_stderror: 0.03105 train_kl_div: 0.1087\n","val_rmse_target: 0.4672 val_rmse_stderror: 1.74\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 140\n","train_rmse_target: 0.2064 train_rmse_stderror: 0.04007 train_kl_div: 0.1028\n","val_rmse_target: 0.4673 val_rmse_stderror: 1.739\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 4 batch_num: 142\n","train_rmse_target: 0.2438 train_rmse_stderror: 0.04037 train_kl_div: 0.1321\n","val_rmse_target: 0.4673 val_rmse_stderror: 1.739\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 4 batch_num: 144\n","train_rmse_target: 0.1972 train_rmse_stderror: 0.03137 train_kl_div: 0.07493\n","val_rmse_target: 0.4672 val_rmse_stderror: 1.739\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 4 batch_num: 146\n","train_rmse_target: 0.2561 train_rmse_stderror: 0.03276 train_kl_div: 0.1161\n","val_rmse_target: 0.4672 val_rmse_stderror: 1.739\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 148\n","train_rmse_target: 0.2367 train_rmse_stderror: 0.02468 train_kl_div: 0.1202\n","val_rmse_target: 0.4673 val_rmse_stderror: 1.739\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 150\n","train_rmse_target: 0.2014 train_rmse_stderror: 0.02408 train_kl_div: 0.09241\n","val_rmse_target: 0.4672 val_rmse_stderror: 1.739\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 4 batch_num: 152\n","train_rmse_target: 0.2192 train_rmse_stderror: 0.02917 train_kl_div: 0.1103\n","val_rmse_target: 0.4671 val_rmse_stderror: 1.739\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 154\n","train_rmse_target: 0.1476 train_rmse_stderror: 0.03805 train_kl_div: 0.05198\n","val_rmse_target: 0.4671 val_rmse_stderror: 1.739\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 156\n","train_rmse_target: 0.2309 train_rmse_stderror: 0.02926 train_kl_div: 0.1071\n","val_rmse_target: 0.4671 val_rmse_stderror: 1.739\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 158\n","train_rmse_target: 0.1194 train_rmse_stderror: 0.02695 train_kl_div: 0.03373\n","val_rmse_target: 0.4671 val_rmse_stderror: 1.739\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 160\n","train_rmse_target: 0.1747 train_rmse_stderror: 0.03004 train_kl_div: 0.07119\n","val_rmse_target: 0.4671 val_rmse_stderror: 1.739\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 4 batch_num: 162\n","train_rmse_target: 0.2285 train_rmse_stderror: 0.0343 train_kl_div: 0.09323\n","val_rmse_target: 0.4671 val_rmse_stderror: 1.739\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 164\n","train_rmse_target: 0.1734 train_rmse_stderror: 0.0492 train_kl_div: 0.06904\n","val_rmse_target: 0.4671 val_rmse_stderror: 1.739\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 4 batch_num: 166\n","train_rmse_target: 0.1482 train_rmse_stderror: 0.02773 train_kl_div: 0.04634\n","val_rmse_target: 0.4671 val_rmse_stderror: 1.739\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 4 batch_num: 168\n","train_rmse_target: 0.2032 train_rmse_stderror: 0.02796 train_kl_div: 0.09817\n","val_rmse_target: 0.4671 val_rmse_stderror: 1.739\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 4 batch_num: 170\n","train_rmse_target: 0.2967 train_rmse_stderror: 0.04336 train_kl_div: 0.1461\n","val_rmse_target: 0.4671 val_rmse_stderror: 1.739\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 172\n","train_rmse_target: 0.182 train_rmse_stderror: 0.03046 train_kl_div: 0.07035\n","val_rmse_target: 0.4671 val_rmse_stderror: 1.739\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 174\n","train_rmse_target: 0.1353 train_rmse_stderror: 0.02868 train_kl_div: 0.04174\n","val_rmse_target: 0.4671 val_rmse_stderror: 1.739\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 4 batch_num: 176\n","train_rmse_target: 0.1888 train_rmse_stderror: 0.02443 train_kl_div: 0.07853\n","val_rmse_target: 0.4671 val_rmse_stderror: 1.739\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 4 batch_num: 178\n","train_rmse_target: 0.1466 train_rmse_stderror: 0.02818 train_kl_div: 0.04932\n","val_rmse_target: 0.4671 val_rmse_stderror: 1.739\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 180\n","train_rmse_target: 0.2119 train_rmse_stderror: 0.03733 train_kl_div: 0.08017\n","val_rmse_target: 0.4671 val_rmse_stderror: 1.739\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 182\n","train_rmse_target: 0.23 train_rmse_stderror: 0.02742 train_kl_div: 0.1118\n","val_rmse_target: 0.4671 val_rmse_stderror: 1.739\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.54 seconds\n","Epoch: 4 batch_num: 184\n","train_rmse_target: 0.2304 train_rmse_stderror: 0.05732 train_kl_div: 0.1001\n","val_rmse_target: 0.4671 val_rmse_stderror: 1.739\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","2 steps took 2.53 seconds\n","Epoch: 4 batch_num: 186\n","train_rmse_target: 0.2479 train_rmse_stderror: 0.02501 train_kl_div: 0.1348\n","val_rmse_target: 0.4671 val_rmse_stderror: 1.739\n","Still best_val_rmse: 0.4629 (from epoch 3)\n","\n","Performance estimates:\n","[0.5141760121366414, 0.5180231677731012, 0.5073765523091726, 0.4629027952178399]\n","Mean: 0.5006196318591887\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 5/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-roberta-large/pre-trained-roberta/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-roberta-large/pre-trained-roberta/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 82.5 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.5798 train_rmse_stderror: 0.06208 train_kl_div: 0.6695\n","val_rmse_target: 0.62 val_rmse_stderror: 1.806\n","New best_val_rmse: 0.62\n","\n","64 steps took 81.5 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.6371 train_rmse_stderror: 0.04444 train_kl_div: 0.8197\n","val_rmse_target: 0.5722 val_rmse_stderror: 1.83\n","New best_val_rmse: 0.5722\n","\n","64 steps took 81.7 seconds\n","Epoch: 1 batch_num: 4\n","train_rmse_target: 0.4069 train_rmse_stderror: 0.04396 train_kl_div: 0.3319\n","val_rmse_target: 0.5587 val_rmse_stderror: 1.834\n","New best_val_rmse: 0.5587\n","\n","64 steps took 81.5 seconds\n","Epoch: 1 batch_num: 68\n","train_rmse_target: 0.515 train_rmse_stderror: 0.03385 train_kl_div: 0.5375\n","val_rmse_target: 0.5226 val_rmse_stderror: 1.836\n","New best_val_rmse: 0.5226\n","\n","32 steps took 40.7 seconds\n","Epoch: 1 batch_num: 100\n","train_rmse_target: 0.4201 train_rmse_stderror: 0.04047 train_kl_div: 0.366\n","val_rmse_target: 0.532 val_rmse_stderror: 1.816\n","Still best_val_rmse: 0.5226 (from epoch 1)\n","\n","32 steps took 40.7 seconds\n","Epoch: 1 batch_num: 132\n","train_rmse_target: 0.6441 train_rmse_stderror: 0.04161 train_kl_div: 0.8368\n","val_rmse_target: 0.5509 val_rmse_stderror: 1.849\n","Still best_val_rmse: 0.5226 (from epoch 1)\n","\n","64 steps took 81.7 seconds\n","Epoch: 2 batch_num: 8\n","train_rmse_target: 0.4001 train_rmse_stderror: 0.02195 train_kl_div: 0.3429\n","val_rmse_target: 0.5678 val_rmse_stderror: 1.848\n","Still best_val_rmse: 0.5226 (from epoch 1)\n","\n","64 steps took 81.4 seconds\n","Epoch: 2 batch_num: 72\n","train_rmse_target: 0.3564 train_rmse_stderror: 0.02985 train_kl_div: 0.26\n","val_rmse_target: 0.5255 val_rmse_stderror: 1.849\n","Still best_val_rmse: 0.5226 (from epoch 1)\n","\n","32 steps took 40.7 seconds\n","Epoch: 2 batch_num: 104\n","train_rmse_target: 0.4295 train_rmse_stderror: 0.03638 train_kl_div: 0.3903\n","val_rmse_target: 0.5143 val_rmse_stderror: 1.842\n","New best_val_rmse: 0.5143\n","\n","32 steps took 40.7 seconds\n","Epoch: 2 batch_num: 136\n","train_rmse_target: 0.2285 train_rmse_stderror: 0.03654 train_kl_div: 0.1102\n","val_rmse_target: 0.5287 val_rmse_stderror: 1.841\n","Still best_val_rmse: 0.5143 (from epoch 2)\n","\n","32 steps took 40.7 seconds\n","Epoch: 2 batch_num: 168\n","train_rmse_target: 0.3805 train_rmse_stderror: 0.03649 train_kl_div: 0.3059\n","val_rmse_target: 0.5233 val_rmse_stderror: 1.852\n","Still best_val_rmse: 0.5143 (from epoch 2)\n","\n","32 steps took 40.9 seconds\n","Epoch: 3 batch_num: 12\n","train_rmse_target: 0.2905 train_rmse_stderror: 0.04948 train_kl_div: 0.1601\n","val_rmse_target: 0.5295 val_rmse_stderror: 1.848\n","Still best_val_rmse: 0.5143 (from epoch 2)\n","\n","32 steps took 40.7 seconds\n","Epoch: 3 batch_num: 44\n","train_rmse_target: 0.3316 train_rmse_stderror: 0.0274 train_kl_div: 0.2231\n","val_rmse_target: 0.5443 val_rmse_stderror: 1.841\n","Still best_val_rmse: 0.5143 (from epoch 2)\n","\n","32 steps took 40.7 seconds\n","Epoch: 3 batch_num: 76\n","train_rmse_target: 0.4533 train_rmse_stderror: 0.05363 train_kl_div: 0.3539\n","val_rmse_target: 0.5314 val_rmse_stderror: 1.834\n","Still best_val_rmse: 0.5143 (from epoch 2)\n","\n","32 steps took 40.7 seconds\n","Epoch: 3 batch_num: 108\n","train_rmse_target: 0.268 train_rmse_stderror: 0.03688 train_kl_div: 0.1617\n","val_rmse_target: 0.5434 val_rmse_stderror: 1.853\n","Still best_val_rmse: 0.5143 (from epoch 2)\n","\n","32 steps took 40.7 seconds\n","Epoch: 3 batch_num: 140\n","train_rmse_target: 0.2128 train_rmse_stderror: 0.02243 train_kl_div: 0.09524\n","val_rmse_target: 0.526 val_rmse_stderror: 1.847\n","Still best_val_rmse: 0.5143 (from epoch 2)\n","\n","32 steps took 40.7 seconds\n","Epoch: 3 batch_num: 172\n","train_rmse_target: 0.2976 train_rmse_stderror: 0.03235 train_kl_div: 0.1805\n","val_rmse_target: 0.5296 val_rmse_stderror: 1.853\n","Still best_val_rmse: 0.5143 (from epoch 2)\n","\n","32 steps took 40.9 seconds\n","Epoch: 4 batch_num: 16\n","train_rmse_target: 0.1979 train_rmse_stderror: 0.04003 train_kl_div: 0.0813\n","val_rmse_target: 0.5327 val_rmse_stderror: 1.838\n","Still best_val_rmse: 0.5143 (from epoch 2)\n","\n","32 steps took 40.7 seconds\n","Epoch: 4 batch_num: 48\n","train_rmse_target: 0.2421 train_rmse_stderror: 0.03113 train_kl_div: 0.1345\n","val_rmse_target: 0.5323 val_rmse_stderror: 1.841\n","Still best_val_rmse: 0.5143 (from epoch 2)\n","\n","32 steps took 40.7 seconds\n","Epoch: 4 batch_num: 80\n","train_rmse_target: 0.1538 train_rmse_stderror: 0.02304 train_kl_div: 0.04987\n","val_rmse_target: 0.5359 val_rmse_stderror: 1.843\n","Still best_val_rmse: 0.5143 (from epoch 2)\n","\n","32 steps took 40.7 seconds\n","Epoch: 4 batch_num: 112\n","train_rmse_target: 0.1367 train_rmse_stderror: 0.03744 train_kl_div: 0.04618\n","val_rmse_target: 0.5349 val_rmse_stderror: 1.845\n","Still best_val_rmse: 0.5143 (from epoch 2)\n","\n","32 steps took 40.7 seconds\n","Epoch: 4 batch_num: 144\n","train_rmse_target: 0.1587 train_rmse_stderror: 0.0275 train_kl_div: 0.05662\n","val_rmse_target: 0.5364 val_rmse_stderror: 1.845\n","Still best_val_rmse: 0.5143 (from epoch 2)\n","\n","32 steps took 40.7 seconds\n","Epoch: 4 batch_num: 176\n","train_rmse_target: 0.186 train_rmse_stderror: 0.02586 train_kl_div: 0.07183\n","val_rmse_target: 0.5368 val_rmse_stderror: 1.845\n","Still best_val_rmse: 0.5143 (from epoch 2)\n","\n","Performance estimates:\n","[0.5141760121366414, 0.5180231677731012, 0.5073765523091726, 0.4629027952178399, 0.5143318729400304]\n","Mean: 0.503362080075357\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"m4v-cGx-Mv7S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626803219387,"user_tz":-540,"elapsed":20,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"2df96f1b-99ba-4ad5-ce83-80e39750ca6a"},"source":["print(list_val_rmse)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["[0.5141760121366414, 0.5180231677731012, 0.5073765523091726, 0.4629027952178399, 0.5143318729400304]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"q2CdCMuIKDMP","executionInfo":{"status":"ok","timestamp":1626803219809,"user_tz":-540,"elapsed":430,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#rep = MemReporter(model)\n","#rep.report()"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"eLl1yDOOKIe7","executionInfo":{"status":"ok","timestamp":1626803219810,"user_tz":-540,"elapsed":15,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#rep = MemReporter(model.roberta)\n","#rep.report()"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"7qkqnknA_m9D","executionInfo":{"status":"ok","timestamp":1626803219811,"user_tz":-540,"elapsed":15,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#gpuinfo()"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"PwrqSMdYA6Pu","executionInfo":{"status":"ok","timestamp":1626803219811,"user_tz":-540,"elapsed":14,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#del model\n","#del optimizer \n","#del train_loader\n","#del val_loader\n","#del scheduler \n","#del list_val_rmse\n","#del train_indices\n","#del val_indices\n","#del tokenizer\n","#torch.cuda.empty_cache()\n","#gpuinfo()"],"execution_count":30,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wXcHyUSJXecL"},"source":["# upload models"]},{"cell_type":"code","metadata":{"id":"YIV6UllSIGoa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626803340863,"user_tz":-540,"elapsed":121066,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"9382ec65-68fc-4e4a-b21e-1669b73288cd"},"source":["%cd\n","!mkdir .kaggle\n","!mkdir /content/model\n","!cp /content/drive/MyDrive/Colab_Files/kaggle-api/kaggle.json .kaggle/\n","\n","!cp -r /content/model_1.pth /content/model/model_1.pth\n","!cp -r /content/model_2.pth /content/model/model_2.pth\n","!cp -r /content/model_3.pth /content/model/model_3.pth\n","!cp -r /content/model_4.pth /content/model/model_4.pth\n","!cp -r /content/model_5.pth /content/model/model_5.pth"],"execution_count":31,"outputs":[{"output_type":"stream","text":["/root\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"14ddOZH4IMam","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626803584499,"user_tz":-540,"elapsed":243651,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"b777b089-1a63-4631-c7cc-96c865d0551b"},"source":["def dataset_upload():\n","    import json\n","    from kaggle.api.kaggle_api_extended import KaggleApi\n","\n","    id = f'{USERID}/{EX_NO}'\n","\n","    dataset_metadata = {}\n","    dataset_metadata['id'] = id\n","    dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n","    dataset_metadata['title'] = f'{EX_NO}'\n","\n","    with open(UPLOAD_DIR / 'dataset-metadata.json', 'w') as f:\n","        json.dump(dataset_metadata, f, indent=4)\n","\n","    api = KaggleApi()\n","    api.authenticate()\n","\n","    # データセットがない場合\n","    if f'{USERID}/{EX_NO}' not in [str(d) for d in api.dataset_list(user=USERID, search=f'\"{EX_NO}\"')]:\n","        api.dataset_create_new(folder=UPLOAD_DIR,\n","                               convert_to_csv=False,\n","                               dir_mode='skip')\n","    # データセットがある場合\n","    else:\n","        api.dataset_create_version(folder=UPLOAD_DIR,\n","                                   version_notes='update',\n","                                   convert_to_csv=False,\n","                                   delete_old_versions=True,\n","                                   dir_mode='skip')\n","dataset_upload()\n","\n"],"execution_count":32,"outputs":[{"output_type":"stream","text":["\r  0%|          | 0.00/1.33G [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Starting upload for file model_2.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [00:49<00:00, 28.7MB/s]\n","  0%|          | 0.00/1.33G [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_2.pth (1GB)\n","Starting upload for file model_4.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [00:48<00:00, 29.7MB/s]\n","  0%|          | 0.00/1.33G [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_4.pth (1GB)\n","Starting upload for file model_1.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [00:45<00:00, 31.0MB/s]\n","  0%|          | 0.00/1.33G [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_1.pth (1GB)\n","Starting upload for file model_5.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [00:47<00:00, 30.3MB/s]\n","  0%|          | 0.00/1.33G [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_5.pth (1GB)\n","Starting upload for file model_3.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [00:48<00:00, 29.5MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_3.pth (1GB)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"huJwVMSAPuDO","executionInfo":{"status":"ok","timestamp":1626803584502,"user_tz":-540,"elapsed":12,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"0zzuBPobmLFu","executionInfo":{"status":"ok","timestamp":1626803584503,"user_tz":-540,"elapsed":12,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wpc8ro9hmNci","executionInfo":{"status":"ok","timestamp":1626803584504,"user_tz":-540,"elapsed":12,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"ceDI72NumT5-","executionInfo":{"status":"ok","timestamp":1626803584504,"user_tz":-540,"elapsed":11,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"PvRi_JQgwcKI","executionInfo":{"status":"ok","timestamp":1626803584504,"user_tz":-540,"elapsed":11,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":32,"outputs":[]}]}