{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"055-054-train-05.ipynb","provenance":[{"file_id":"10ke_cv7Phs9nPIFwY0HsojNaHk9rq4Pw","timestamp":1627694048586},{"file_id":"1ANF2nhdHdZW664fcSoIBbMi92Gs0FBR5","timestamp":1627431232882},{"file_id":"17BUK8yRF7SDX0khlOXoHcFRTEFffkvRb","timestamp":1627395077423},{"file_id":"1wNpTEKAuuKP7ivTcm1f9j0sdmYU1RyzA","timestamp":1627306793279},{"file_id":"1uE__yBR1oxeYaUIrUTMEOffmeyuJBRAU","timestamp":1627305921964},{"file_id":"1PbEPh6kL5p5cdH5HC8iHoMVCIzA0MqvB","timestamp":1627284576770},{"file_id":"1TlxQ4e-ZX1Zy51dKLuhNdrBWg1qhojqP","timestamp":1627273765934},{"file_id":"17a4F4aC9L0QBqU8BRTrdqPn0WwJ0b08b","timestamp":1626746992716},{"file_id":"1G_W9irFTrEmDeHR0S6_u0bjpk8nxipXW","timestamp":1626689695352},{"file_id":"1bhhkorT--y8XXaVLM8hibVgC-tLqZ16P","timestamp":1626358153868},{"file_id":"1WtT2hX6O9Qbt_hb9sF50nM2QmDXFi-XA","timestamp":1626338366006},{"file_id":"1k_p5wftcUeo711Xho1-T5an2Xkneau-J","timestamp":1626323813472},{"file_id":"1Vz2GB2BNTWuefEFkCSh3TBPEIel7KG1t","timestamp":1626317426487},{"file_id":"1djoMWojeaIPopG5tS1jNMohn8ineblRh","timestamp":1626306831897},{"file_id":"1-6tlDO8158Pi6TpptIF884oFaEiT4Uxb","timestamp":1626276420047},{"file_id":"1js8eA3mDNS8mwSpCiHuzPeARFlUPAVrg","timestamp":1626272452526},{"file_id":"1yhcPgulwJtjJKUK9IuRKmNMhJ-4YXGol","timestamp":1626267205517},{"file_id":"1mnnSv0Pofn1QxArywV81VYqnZPB8uUWN","timestamp":1626180468522},{"file_id":"1RRdjt_UAeHmr5QQBAMyC82Fq1s31OWdK","timestamp":1625833136005},{"file_id":"1JPgg44HFemzwk8VSCXih3PejL0idy-C4","timestamp":1625825483466},{"file_id":"1Ye6wqVX71xAAAhmjXkw9IpRvTqeUyJDA","timestamp":1625812137500}],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ucCbvGD1XvG7","executionInfo":{"status":"ok","timestamp":1627834461122,"user_tz":-540,"elapsed":367,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"acc4e0d2-b463-4ea6-d0e8-29b55cc0594e"},"source":["import sys\n","if 'google.colab' in sys.modules:  # colab特有の処理_2回目以降\n","  # Google Driveのマウント\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","\n","  # ライブラリのパス指定\n","  sys.path.append('/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules')\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FACwJ6icpxrR","executionInfo":{"status":"ok","timestamp":1627834466644,"user_tz":-540,"elapsed":5223,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# データセットをDriveから取得\n","!mkdir -p 'input'\n","!mkdir -p 'clrp-pre-trained'\n","\n","!cp -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/00_input/commonlitreadabilityprize/' '/content/input'\n","!cp -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/97_pre_trained/clrp_pretrained_manish_epoch5/pre-trained-roberta/clrp_roberta_large/' '/content/clrp-pre-trained'"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"RV9-VwbpZLZ9","executionInfo":{"status":"ok","timestamp":1627834466645,"user_tz":-540,"elapsed":8,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["from pathlib import Path\n","\n","# input\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    DATA_DIR = Path('../input/commonlitreadabilityprize/')\n","\n","elif 'google.colab' in sys.modules: # Colab環境\n","    DATA_DIR = Path('/content/input/commonlitreadabilityprize')\n","\n","else:\n","    DATA_DIR = Path('../00_input/commonlitreadabilityprize/')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"x5difyXe00UV","executionInfo":{"status":"ok","timestamp":1627834466645,"user_tz":-540,"elapsed":6,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["from pathlib import Path\n","\n","# tokenizer\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    TOKENIZER_DIR = '../input/roberta-transformers-pytorch/roberta-large'\n","elif 'google.colab' in sys.modules: # Colab環境\n","    TOKENIZER_DIR = '/content/clrp-pre-trained/clrp_roberta_large' # 仮で、毎回DLする想定のモデル名を指定。あとで変更予定。\n","else:\n","    TOKENIZER_DIR = 'roberta-large'"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"tKjsUxnOeDYl","executionInfo":{"status":"ok","timestamp":1627834466646,"user_tz":-540,"elapsed":7,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["from pathlib import Path\n","\n","# pre-trained model\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    PRE_TRAINED_MODEL_DIR = '../input/roberta-transformers-pytorch/roberta-large'\n","elif 'google.colab' in sys.modules: # Colab環境\n","    PRE_TRAINED_MODEL_DIR = '/content/clrp-pre-trained/clrp_roberta_large' # 仮で、毎回DLする想定のモデル名を指定。あとで変更予定。\n","else:\n","    PRE_TRAINED_MODEL_DIR = 'roberta-large'"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZLaT2V0ReoAZ","executionInfo":{"status":"ok","timestamp":1627834466646,"user_tz":-540,"elapsed":6,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["UPLOAD_DIR = Path('/content/model')\n","EX_NO = '055-054-train-05'  # 実験番号などを入れる、folderのpathにする\n","USERID = 'calpis10000'"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"hOGjAb4pAJ0F","executionInfo":{"status":"ok","timestamp":1627834466647,"user_tz":-540,"elapsed":7,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["import subprocess\n","import shlex\n","\n","def gpuinfo():\n","    \"\"\"\n","    Returns size of total GPU RAM and used GPU RAM.\n","\n","    Parameters\n","    ----------\n","    None\n","\n","    Returns\n","    -------\n","    info : dict\n","        Total GPU RAM in integer for key 'total_MiB'.\n","        Used GPU RAM in integer for key 'used_MiB'.\n","    \"\"\"\n","\n","    command = 'nvidia-smi -q -d MEMORY | sed -n \"/FB Memory Usage/,/Free/p\" | sed -e \"1d\" -e \"4d\" -e \"s/ MiB//g\" | cut -d \":\" -f 2 | cut -c2-'\n","    commands = [shlex.split(part) for part in command.split(' | ')]\n","    for i, cmd in enumerate(commands):\n","        if i==0:\n","            res = subprocess.Popen(cmd, stdout=subprocess.PIPE)\n","        else:\n","            res = subprocess.Popen(cmd, stdin=res.stdout, stdout=subprocess.PIPE)\n","    total, used = map(int, res.communicate()[0].decode('utf-8').strip().split('\\n'))\n","    info = {'total_MiB':total, 'used_MiB':used}\n","    return info\n"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g3-6m5MKXecB"},"source":["# Overview\n","This nb is based on copy from https://www.kaggle.com/andretugan/lightweight-roberta-solution-in-pytorch .\n","\n","Acknowledgments(from base nb): \n","some ideas were taken from kernels by [Torch](https://www.kaggle.com/rhtsingh) and [Maunish](https://www.kaggle.com/maunish)."]},{"cell_type":"code","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-04T06:26:32.834365Z","iopub.execute_input":"2021-07-04T06:26:32.834903Z","iopub.status.idle":"2021-07-04T06:26:40.143740Z","shell.execute_reply.started":"2021-07-04T06:26:32.834785Z","shell.execute_reply":"2021-07-04T06:26:40.142864Z"},"trusted":true,"id":"HRsRZ06WXecD","executionInfo":{"status":"ok","timestamp":1627834470841,"user_tz":-540,"elapsed":4200,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["import os\n","import math\n","import random\n","import time\n","\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","\n","from transformers import AdamW # optimizer\n","from transformers import AutoTokenizer\n","from transformers import AutoModel\n","from transformers import AutoConfig\n","from transformers import get_cosine_schedule_with_warmup # scheduler\n","from pytorch_memlab import profile\n","import pytorch_memlab\n","from pytorch_memlab import MemReporter\n","\n","from sklearn.model_selection import KFold, StratifiedKFold\n","\n","import pickle\n","import gc\n","gc.enable()"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.145217Z","iopub.execute_input":"2021-07-04T06:26:40.145539Z","iopub.status.idle":"2021-07-04T06:26:40.201326Z","shell.execute_reply.started":"2021-07-04T06:26:40.145504Z","shell.execute_reply":"2021-07-04T06:26:40.200136Z"},"trusted":true,"id":"omBfwshTXecE","executionInfo":{"status":"ok","timestamp":1627834470844,"user_tz":-540,"elapsed":19,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["NUM_FOLDS = 5 # K Fold\n","NUM_EPOCHS = 5 # Epochs\n","BATCH_SIZE = 8 # Batch Size\n","MAX_LEN = 248 # ベクトル長\n","TFIDF_MAX_FEAT = 1024\n","\n","EVAL_SCHEDULE = [(0.55, 64), (-1., 32)] # schedulerの何らかの設定？\n","ROBERTA_PATH = PRE_TRAINED_MODEL_DIR # roberta pre-trainedモデル(モデルとして指定)\n","TOKENIZER_PATH = TOKENIZER_DIR # roberta pre-trainedモデル(Tokenizerとして指定)\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\" # cudaがなければcpuを使えばいいじゃない"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.203398Z","iopub.execute_input":"2021-07-04T06:26:40.204055Z","iopub.status.idle":"2021-07-04T06:26:40.211572Z","shell.execute_reply.started":"2021-07-04T06:26:40.204015Z","shell.execute_reply":"2021-07-04T06:26:40.210762Z"},"trusted":true,"id":"4qcuXqwtXecF","executionInfo":{"status":"ok","timestamp":1627834470844,"user_tz":-540,"elapsed":17,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["def set_random_seed(random_seed):\n","    random.seed(random_seed)\n","    np.random.seed(random_seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(random_seed)\n","\n","    torch.manual_seed(random_seed)\n","    torch.cuda.manual_seed(random_seed)\n","    torch.cuda.manual_seed_all(random_seed)\n","\n","    torch.backends.cudnn.deterministic = True# cudnnによる最適化で結果が変わらないためのおまじない "],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.214188Z","iopub.execute_input":"2021-07-04T06:26:40.214809Z","iopub.status.idle":"2021-07-04T06:26:40.309744Z","shell.execute_reply.started":"2021-07-04T06:26:40.214769Z","shell.execute_reply":"2021-07-04T06:26:40.308926Z"},"trusted":true,"id":"70PyLsJTXecF","executionInfo":{"status":"ok","timestamp":1627834470845,"user_tz":-540,"elapsed":17,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# read train_df(kfold)\n","train_kf_df = pd.read_csv(DATA_DIR/\"train_kfold.csv\")"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.311021Z","iopub.execute_input":"2021-07-04T06:26:40.311347Z","iopub.status.idle":"2021-07-04T06:26:40.624393Z","shell.execute_reply.started":"2021-07-04T06:26:40.311314Z","shell.execute_reply":"2021-07-04T06:26:40.623347Z"},"trusted":true,"id":"xf0662k4XecF","executionInfo":{"status":"ok","timestamp":1627834470845,"user_tz":-540,"elapsed":17,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# tokenizerを指定\n","tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N6aaghNkXecG"},"source":["# Dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UU5uZKIcDjkV","executionInfo":{"status":"ok","timestamp":1627834471304,"user_tz":-540,"elapsed":475,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"dc4e1f63-617d-40ba-ffcf-fc9d98593d50"},"source":["# 前処理用\n","import string\n","import re\n","# ローカルの場合、stopwordsをダウンロード\n","import nltk\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    pass\n","else:\n","    import nltk\n","    nltk.download('stopwords')\n","    nltk.download('averaged_perceptron_tagger')\n","    os.listdir(os.path.expanduser('~/nltk_data/corpora/stopwords/'))\n","\n","# テキスト前処理\n","# https://www.kaggle.com/alaasedeeq/commonlit-readability-eda\n","\n","#filtering the unwanted symbols, spaces, ....etc\n","to_replace_by_space = re.compile('[/(){}\\[\\]|@,;]')\n","punctuation = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n","bad_symbols = re.compile('[^0-9a-z #+_]')\n","stopwords = set(nltk.corpus.stopwords.words('english'))\n","\n","def text_prepare(text):\n","    '''\n","    text: a string\n","    returna modified version of the string\n","    '''\n","    text = text.lower() # lowercase text\n","    text = re.sub(punctuation, '',text)\n","    text = re.sub(to_replace_by_space, \" \", text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n","    text = re.sub(bad_symbols, \"\", text)         # delete symbols which are in BAD_SYMBOLS_RE from text\n","    text = \" \".join([word for word in text.split(\" \") if word not in stopwords]) # delete stopwords from text\n","    text = re.sub(' +', ' ', text)\n","    return text\n","\n","def text_normalization(s:pd.Series):\n","    x = s.apply(text_prepare)\n","    return x\n","\n","# Counterオブジェクトを取得\n","def get_counter(text:str):\n","    text_list = [wrd for wrd in text.split(\" \") if wrd not in ('', '\\n')]\n","    counter = collections.Counter(text_list)\n","    return counter\n"],"execution_count":13,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kqqJmgKBT6Xx","executionInfo":{"status":"ok","timestamp":1627834471305,"user_tz":-540,"elapsed":9,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["from sklearn.feature_extraction.text import CountVectorizer\n","\n","# ベースとなる継承元のクラス\n","class BaseBlock(object):\n","    def fit(self, input_df, y=None):\n","        return self.transform(input_df)\n","    def transform(self, input_df):\n","        raise NotImplementedError()\n","\n","class CountVectorizerSimpleBlock(BaseBlock):\n","    \"\"\"CountVectorizerのベクトルをそのまま返す block\"\"\"\n","    def __init__(self, column: str, master_df=None, max_features=50, ngram_range=(1,1)):\n","        \"\"\"\n","        args:\n","            column: str\n","                変換対象のカラム名\n","        \"\"\"\n","        self.column = column\n","        self.master_df=master_df\n","        self.max_features=max_features\n","        self.ngram_range=ngram_range\n","        self.param_prefix = f\"col={column}_feats={max_features}_ngram={''.join([str(i) for i in self.ngram_range])}\"\n","\n","    def preprocess(self, input_df):\n","        x = text_normalization(input_df[self.column])\n","        return x\n","\n","    def fit(self, \n","            input_df, \n","            y=None\n","           ):\n","        master_df = input_df if self.master_df is None else self.master_df\n","        text = self.preprocess(master_df)\n","        self.vectorizer_ = CountVectorizer(max_features=self.max_features, ngram_range=self.ngram_range)\n","\n","        self.vectorizer_.fit(text)\n","        self.prefix = 'countvec'\n","        return self.transform(input_df)\n","\n","    def transform(self, input_df):\n","        text = self.preprocess(input_df)\n","        z = self.vectorizer_.transform(text)\n","\n","        out_df = pd.DataFrame(z.toarray())\n","        out_df.columns = self.vectorizer_.get_feature_names()\n","        return out_df.add_prefix(f'{self.prefix}_')"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"iAse0IDWDjho","executionInfo":{"status":"ok","timestamp":1627834471305,"user_tz":-540,"elapsed":8,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["class LitDataset(Dataset):\n","    def __init__(self, df, vectorizer_, inference_only=False):\n","        super().__init__()\n","\n","        self.df = df        \n","        self.inference_only = inference_only # Testデータ用フラグ\n","        self.text = df.excerpt.tolist() # 分析対象カラムをlistにする。(分かち書きではなく、Seriesをlistへ変換するような処理)\n","        #self.text = [text.replace(\"\\n\", \" \") for text in self.text] # 単語単位で分かち書きする場合\n","        self.text_len = text_normalization(df.excerpt).map(lambda x: [0 if i >= len(x.split(' ')) else len(x.split(' ')[i]) for i in range(132)])\n","        self.vectorizer_ = vectorizer_ # fit済みのものを入力する。（クラス内ではtransformのみ行う）\n","        self.vectorizer_val = vectorizer_.transform(df).values\n","\n","        if not self.inference_only:\n","            self.target = torch.tensor(df.target.values, dtype=torch.float32) # trainのみ、targetをtensorに変換\n","            self.standard_error = torch.tensor(df.standard_error.values, dtype=torch.float32) \n","\n","        self.encoded = tokenizer.batch_encode_plus( # textをtokenize\n","            self.text,\n","            padding = 'max_length',            \n","            max_length = MAX_LEN,\n","            truncation = True, # 最大長を超える文字は切り捨て\n","            return_attention_mask=True\n","        )        \n"," \n","\n","    def __len__(self):\n","        return len(self.df)\n","    \n","    def __getitem__(self, index): # 変換結果を返す\n","        input_ids = torch.tensor(self.encoded['input_ids'][index])\n","        attention_mask = torch.tensor(self.encoded['attention_mask'][index])\n","        input_len = torch.tensor(self.text_len.iloc[index], dtype=torch.float32)\n","        input_bow = torch.tensor(self.vectorizer_val[index, :], dtype=torch.float32)\n","\n","        if self.inference_only:\n","            return (input_ids, attention_mask, input_len, input_tfidf)            \n","        else:\n","            target = self.target[index]\n","            standard_error = self.standard_error[index]\n","            return (input_ids, attention_mask, input_len, input_bow, target, standard_error)"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KKtdy32wXecG"},"source":["# Model\n","The model is inspired by the one from [Maunish](https://www.kaggle.com/maunish/clrp-roberta-svm)."]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.649629Z","iopub.execute_input":"2021-07-04T06:26:40.650066Z","iopub.status.idle":"2021-07-04T06:26:40.666374Z","shell.execute_reply.started":"2021-07-04T06:26:40.650002Z","shell.execute_reply":"2021-07-04T06:26:40.665211Z"},"trusted":true,"id":"BpkxjXEUXecH","executionInfo":{"status":"ok","timestamp":1627834471305,"user_tz":-540,"elapsed":8,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["class LitModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        config = AutoConfig.from_pretrained(ROBERTA_PATH) # pretrainedからconfigを読み込み\n","        config.update({\"output_hidden_states\":True, # config更新: embedding層を抽出\n","                       \"hidden_dropout_prob\": 0.0, # config更新: dropoutしない\n","                       \"layer_norm_eps\": 1e-7}) # config更新: layer normalizationのepsilon                      \n","        \n","        self.roberta = AutoModel.from_pretrained(ROBERTA_PATH, config=config) # cpuで処理する\n","            \n","        self.attention = nn.Sequential(# attentionレイヤー            \n","            nn.Linear(config.hidden_size, 512),      \n","            nn.Tanh(),                       \n","            nn.Linear(512, 1),\n","            nn.Softmax(dim=1)\n","        )\n","\n","        self.mlp_wordlen = nn.Sequential(\n","            nn.Linear(132, 64),\n","            nn.ReLU(),\n","            nn.Linear(64, 64)\n","        )\n","\n","        self.mlp_tfidf = nn.Sequential(\n","            nn.Linear(TFIDF_MAX_FEAT, 192),\n","            nn.ReLU(),\n","            nn.Linear(192, 192),\n","            nn.ReLU(),\n","            nn.Linear(192, 64)\n","        )\n","\n","        self.regressor = nn.Sequential( # 出力レイヤー                    \n","            nn.Linear(config.hidden_size + 64 + 64, 2)                        \n","        )\n","\n","    def forward(self, input_ids, attention_mask, input_len, input_tfidf):\n","        roberta_output = self.roberta(input_ids=input_ids, # robertaに入力データを流し、出力としてrobertaモデル(layerの複合体)を得る\n","                                      attention_mask=attention_mask)     \n","        # attention_pooling\n","        last_hidden_state = roberta_output.hidden_states[-1] # robertaモデルの最後のlayerを得る\n","        weights = self.attention(last_hidden_state) # robertaの最後のlayerをattentionへ入力し、出力として重みを得る                \n","        context_vector = torch.sum(weights * last_hidden_state, dim=1) # 重み×最後の層を足し合わせて文書ベクトルとする。\n","\n","        # word_length_conv1d\n","        #input_chnl = input_len.unsqueeze(1)\n","        #conv1_layers = self.conv1_layers(input_chnl)\n","        #conv1_layers_v = conv1_layers.view(conv1_layers.size(0),-1)\n","\n","        # mlm_layers\n","        mlp_wordlen = self.mlp_wordlen(input_len)\n","        mlp_tfidf = self.mlp_tfidf(input_tfidf)\n","\n","        # https://www.kaggle.com/rhtsingh/utilizing-transformer-representations-efficiently\n","        # last_hidden_state = roberta_output[0]\n","        # input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        # sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        # sum_mask = input_mask_expanded.sum(1)\n","        # sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        # mean_embeddings = sum_embeddings / sum_mask\n","\n","        # concat_embeddings\n","        cat_embeddings = torch.cat([context_vector, mlp_wordlen, mlp_tfidf], dim=1)        \n","        return self.regressor(cat_embeddings) # 文書ベクトルを線形層に入力し、targetを出力する\n","        \n","        # Now we reduce the context vector to the prediction score.\n","        #return self.regressor(mean_embeddings) # 文書ベクトルを線形層に入力し、targetを出力する"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.672515Z","iopub.execute_input":"2021-07-04T06:26:40.672944Z","iopub.status.idle":"2021-07-04T06:26:40.684593Z","shell.execute_reply.started":"2021-07-04T06:26:40.672908Z","shell.execute_reply":"2021-07-04T06:26:40.683569Z"},"trusted":true,"id":"bB4jvQTxXecH","executionInfo":{"status":"ok","timestamp":1627834471306,"user_tz":-540,"elapsed":8,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 評価指標(MSE)の計算。最終的に、ルートしてRMSEにすると思われる。\n","def eval_mse(model, data_loader):\n","    \"\"\"Evaluates the mean squared error of the |model| on |data_loader|\"\"\"\n","    model.eval() # evalモードを選択。Batch Normとかdropoutをしなくなる           \n","    mse_mean_sum = 0\n","    mse_std_sum = 0\n","\n","    with torch.no_grad(): # 勾配の計算をしないBlock\n","        for batch_num, (input_ids, attention_mask, input_len, input_tfidf, target, standard_error) in enumerate(data_loader): # data_loaderからinput, attentin_mask, targetをbatchごとに取り出す\n","            input_ids = input_ids.to(DEVICE)   \n","            attention_mask = attention_mask.to(DEVICE)  \n","            input_len = input_len.to(DEVICE) \n","            input_tfidf = input_tfidf.to(DEVICE)\n","            target = target.to(DEVICE)      \n","            standard_error = standard_error.to(DEVICE) \n","            \n","            output = model(input_ids, attention_mask, input_len, input_tfidf) # 取得した値をモデルへ入力し、出力として予測値を得る。\n","\n","            mse_mean_sum += nn.MSELoss(reduction=\"sum\")(output[:,0].flatten(), target).item() # 誤差の合計を得る(Batchごとに計算した誤差を足し上げる)\n","            mse_std_sum += nn.MSELoss(reduction=\"sum\")(output[:,1].flatten(), target).item() # 誤差の合計を得る(Batchごとに計算した誤差を足し上げる)\n","\n","    del input_ids\n","    del attention_mask\n","    del target\n","    del input_len\n","    del input_tfidf\n","\n","    mse_mean_result = mse_mean_sum / len(data_loader.dataset)\n","    mse_std_result = mse_std_sum / len(data_loader.dataset)\n","  \n","    return mse_mean_result, mse_std_result # 誤差の合計をdataset長で除し、mseを取得＆返す"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.690155Z","iopub.execute_input":"2021-07-04T06:26:40.692530Z","iopub.status.idle":"2021-07-04T06:26:40.703425Z","shell.execute_reply.started":"2021-07-04T06:26:40.692488Z","shell.execute_reply":"2021-07-04T06:26:40.702366Z"},"trusted":true,"id":"47bDno_LXecI","executionInfo":{"status":"ok","timestamp":1627834471306,"user_tz":-540,"elapsed":8,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 推論結果を返す\n","def predict(model, data_loader):\n","    \"\"\"Returns an np.array with predictions of the |model| on |data_loader|\"\"\"\n","    model.eval() # evalモード(dropout, batch_normしない)\n","\n","    result = np.zeros(len(data_loader.dataset)) # 結果をdataset長のzero配列として用意\n","    index = 0\n","    \n","    with torch.no_grad(): # 勾配の計算をしないblock(inputすると、現状の重みによる推論結果を返す)\n","        for batch_num, (input_ids, attention_mask, input_len, input_tfidf) in enumerate(data_loader): # data_loaderからbatchごとにinputを得る\n","            input_ids = input_ids.to(DEVICE)\n","            attention_mask = attention_mask.to(DEVICE)\n","            input_len = input_len.to(DEVICE)\n","            input_tfidf = input_tfidf.to(DEVICE)\n","                        \n","            output = model(input_ids, attention_mask, input_len, input_tfidf) # modelにinputを入力し、予測結果を得る。\n","\n","            result[index : index + output[:,0].shape[0]] = output[:,0].flatten().to(\"cpu\") # result[index ~ predの長さ]へ、予測結果を格納\n","            index += output.shape[0] # indexを更新\n","\n","    return result # 全batchで推論が終わったら、結果を返す"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.708605Z","iopub.execute_input":"2021-07-04T06:26:40.709024Z","iopub.status.idle":"2021-07-04T06:26:40.730675Z","shell.execute_reply.started":"2021-07-04T06:26:40.708983Z","shell.execute_reply":"2021-07-04T06:26:40.729705Z"},"trusted":true,"id":"oInneuAmXecI","executionInfo":{"status":"ok","timestamp":1627834471307,"user_tz":-540,"elapsed":8,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 学習\n","def train(model, # モデル\n","          model_path, # モデルのアウトプット先\n","          train_loader, # train-setのdata_loader\n","          val_loader, # valid-setのdata_loader\n","          optimizer, # optimizer\n","          scheduler=None, # scheduler, デフォルトはNone\n","          num_epochs=NUM_EPOCHS # epoch数、notebook冒頭で指定した値\n","         ):    \n","    \n","    best_val_rmse = None\n","    best_epoch = 0\n","    step = 0\n","    last_eval_step = 0\n","    eval_period = EVAL_SCHEDULE[0][1] # eval期間(って何？) 冒頭で決めたEVAL_SCHEDULEの最初のtupleの[1]を取得\n","\n","    start = time.time() # 時間計測用\n","\n","    for epoch in range(num_epochs): # 指定したEpoch数だけ繰り返し\n","        val_rmse = None         \n","\n","        for batch_num, (input_ids, attention_mask, input_len, input_tfidf, target, standard_error) in enumerate(train_loader): # train_loaderからinput, targetを取得\n","            input_ids = input_ids.to(DEVICE) # inputをDEVICEへ突っ込む\n","            attention_mask = attention_mask.to(DEVICE)   \n","            input_len = input_len.to(DEVICE)\n","            input_tfidf = input_tfidf.to(DEVICE)\n","            target = target.to(DEVICE)\n","            standard_error = standard_error.to(DEVICE)  \n","\n","            optimizer.zero_grad() # 勾配を初期化            \n","            model.train() # 学習モード開始\n","\n","            # https://www.kaggle.com/c/commonlitreadabilityprize/discussion/239421\n","            output = model(input_ids, attention_mask, input_len, input_tfidf) # input,attention_maskを入力し、予測結果を得る\n","            p = torch.distributions.Normal(output[:,0], torch.sqrt(output[:,1]**2))\n","            q = torch.distributions.Normal(target, standard_error)\n","            kl_vector = torch.distributions.kl_divergence(p, q)\n","            loss = kl_vector.mean()\n","\n","            loss.backward() # 誤差逆伝播法により勾配を得る\n","            optimizer.step() # 重みを更新する\n","\n","            if scheduler:\n","                scheduler.step() # schedulerが与えられた場合は、schedulerの学習率更新\n","            \n","            if step >= last_eval_step + eval_period: # batchを回すごとにstepを増やしていって、「前回evalしたstep + eval_period(16)」を超えたら実行。\n","                # Evaluate the model on val_loader.\n","                elapsed_seconds = time.time() - start # 経過時間\n","                num_steps = step - last_eval_step # 経過ステップ数\n","                print(f\"\\n{num_steps} steps took {elapsed_seconds:0.3} seconds\")\n","                last_eval_step = step # 前回stepの更新\n","                \n","                # valid-setによるrmse計算\n","                train_mean_mse = nn.MSELoss(reduction=\"mean\")(output[:,0].flatten(), target) \n","                train_std_mse = nn.MSELoss(reduction=\"mean\")(torch.sqrt(output[:,1]**2).flatten(), standard_error) \n","\n","                train_mean_rmse = math.sqrt(train_mean_mse)\n","                train_std_rmse = math.sqrt(train_std_mse)\n","\n","                val_mean_mse, val_std_mse = eval_mse(model, val_loader)\n","                val_mean_rmse = math.sqrt(val_mean_mse)                            \n","                val_std_rmse = math.sqrt(val_std_mse)                            \n","\n","                print(f\"Epoch: {epoch} batch_num: {batch_num}\")\n","                print(f\"train_rmse_target: {train_mean_rmse:0.4}\",\n","                      f\"train_rmse_stderror: {train_std_rmse:0.4}\",\n","                      f\"train_kl_div: {loss:0.4}\",\n","                      )\n","                print(f\"val_rmse_target: {val_mean_rmse:0.4}\",\n","                      f\"val_rmse_stderror: {val_std_rmse:0.4}\"\n","                      )\n","\n","                for rmse, period in EVAL_SCHEDULE: # eval_periodをvalid-rmseで切り替える処理\n","                    if val_mean_rmse >= rmse: # valid rmseをEVAL_SCHEDULEと比較し、0項 > valid rmseとなるまで回す : EVAL_SCHEDULE = [(0.50, 16), (0.49, 8), (0.48, 4), (0.47, 2), (-1., 1)]\n","                        eval_period = period # eval_periodを更新\n","                        break                               \n","\n","                if not best_val_rmse or val_mean_rmse < best_val_rmse: # 初回(best_val_rmse==None), またはbest_val_rmseを更新したらモデルを保存する\n","                    best_val_rmse = val_mean_rmse\n","                    best_epoch = epoch\n","                    torch.save(model.state_dict(), model_path) # 最高の自分を保存\n","                    print(f\"New best_val_rmse: {best_val_rmse:0.4}\")\n","                else:       \n","                    print(f\"Still best_val_rmse: {best_val_rmse:0.4}\", # 更新されない場合は、元のスコアを表示\n","                          f\"(from epoch {best_epoch})\")      \n","                                                  \n","                start = time.time()\n","            \n","            # batchごとにメモリ解放\n","            del input_ids\n","            del attention_mask\n","            del target\n","            torch.cuda.empty_cache()                                            \n","            step += 1\n","    \n","    return best_val_rmse"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.735798Z","iopub.execute_input":"2021-07-04T06:26:40.738398Z","iopub.status.idle":"2021-07-04T06:26:40.750876Z","shell.execute_reply.started":"2021-07-04T06:26:40.738356Z","shell.execute_reply":"2021-07-04T06:26:40.749635Z"},"trusted":true,"id":"rMY0fjXwXecJ","executionInfo":{"status":"ok","timestamp":1627834471307,"user_tz":-540,"elapsed":8,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# optimizerの作成\n","def create_optimizer(model):\n","    parameters = []\n","\n","    named_parameters = list(model.named_parameters()) # モデルパラメータの取得\n","    roberta_parameters = list(model.roberta.named_parameters())[:-2] # パラメータをroberta用、attention用、regressor用に格納。(直接引っ張ってくる形式に変更)\n","\n","    attention_parameters = list(model.attention.named_parameters())\n","    attention_group = [{'params': params, 'lr': 2e-5} for (name, params) in attention_parameters] # attention用パラメータをリストとして取得\n","    parameters += attention_group\n","\n","    #norm_parameters = list(model.layer_norm.named_parameters())\n","    #norm_group = [{'params': params, 'lr': 2e-5} for (name, params) in norm_parameters]\n","    #parameters += norm_group\n","\n","    mlp_wrd_parameters = list(model.mlp_wordlen.named_parameters())\n","    mlp_wrd_group = [{'params': params, 'lr': 2e-5} for (name, params) in mlp_wrd_parameters] # reg用パラメータをリストとして取得\n","    parameters += mlp_wrd_group\n","\n","    mlp_tfidf_parameters = list(model.mlp_tfidf.named_parameters())\n","    mlp_tfidf_group = [{'params': params, 'lr': 2e-5} for (name, params) in mlp_tfidf_parameters] # reg用パラメータをリストとして取得\n","    parameters += mlp_tfidf_group\n","\n","    regressor_parameters = list(model.regressor.named_parameters())\n","    regressor_group = [{'params': params, 'lr': 2e-5} for (name, params) in regressor_parameters] # reg用パラメータをリストとして取得\n","    parameters += regressor_group\n","\n","    for layer_num, (name, params) in enumerate(roberta_parameters): # レイヤーごとにname, paramsを取得していろんな処理\n","        weight_decay = 0.0 if \"bias\" in name else 0.01\n","\n","        lr = 8e-6\n","\n","        if layer_num >= 69:        \n","            lr = 2e-5\n","\n","        if layer_num >= 133:\n","            lr = 4e-5\n","\n","        parameters.append({\"params\": params,\n","                           \"weight_decay\": weight_decay,\n","                           \"lr\": lr})\n","\n","    return AdamW(parameters) # 最終的に、AdamWにパラメータを入力する。\n"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"EbaJojz0Zjif","executionInfo":{"status":"ok","timestamp":1627834471591,"user_tz":-540,"elapsed":5,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# https://www.kaggle.com/abhishek/step-1-create-folds\n","def create_folds(data, num_splits, SEED, return_df=False):\n","    # we create a new column called kfold and fill it with -1\n","    data[\"kfold\"] = -1\n","    \n","    # the next step is to randomize the rows of the data\n","    data = data.sample(frac=1).reset_index(drop=True)\n","\n","    # calculate number of bins by Sturge's rule\n","    # I take the floor of the value, you can also\n","    # just round it\n","    num_bins = int(np.floor(1 + np.log2(len(data))))\n","    \n","    # bin targets\n","    data.loc[:, \"bins_tg\"] = pd.cut(\n","        data[\"target\"], bins=num_bins, labels=False\n","    ).map(lambda x: str(x))\n","\n","    # bin standard_error\n","    data.loc[:, \"bins_std\"] = pd.cut(\n","        data[\"standard_error\"], bins=num_bins, labels=False\n","    )\n","\n","    # bins\n","    data.loc[:, \"bins\"] = data['bins_tg'].map(lambda x: str(x)) + data['bins_std'].map(lambda x: str(x))\n","\n","    # initiate the kfold class from model_selection module\n","    kf = StratifiedKFold(n_splits=5, random_state=SEED, shuffle=True)\n","\n","    # note that, instead of targets, we use bins!\n","    if return_df:\n","      for f, (t_, v_) in enumerate(kf.split(X=data, y=data.bins.values)):\n","        data.loc[v_, 'kfold'] = f\n","      return data\n","    else:\n","      return kf.split(X=data, y=data.bins.values)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"4PLKHwvKtNBn","executionInfo":{"status":"ok","timestamp":1627834471592,"user_tz":-540,"elapsed":5,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["def train_and_save_model(train_indices, val_indices, model_path, feat_suffix):\n","    tfidf = CountVectorizerSimpleBlock('excerpt', max_features=TFIDF_MAX_FEAT)\n","    df_tfidf = tfidf.fit(train_kf_df.loc[train_indices]) # TODO: fit_transformみたいなメソッド作って、fitではdfが返らないようにする。\n","\n","    with open(f'TFIDF_{feat_suffix}', 'wb') as f:\n","      pickle.dump(tfidf, f)\n","\n","    train_dataset = LitDataset(train_kf_df.loc[train_indices], tfidf) # train, validのDataset\n","    val_dataset = LitDataset(train_kf_df.loc[val_indices], tfidf)\n","        \n","    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n","                              drop_last=True, shuffle=True, num_workers=2) # train, validのDataLoader\n","    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n","                            drop_last=False, shuffle=False, num_workers=2)    \n","\n","    model = LitModel().to(DEVICE) # modelをDEVICEへぶち込む\n","    optimizer = create_optimizer(model) # optimizerをモデルから作成\n","    scheduler = get_cosine_schedule_with_warmup( # schedulerを作成\n","        optimizer,\n","        num_training_steps=NUM_EPOCHS * len(train_loader),\n","        num_warmup_steps=50)    \n","    rmse = train(model, model_path, train_loader, val_loader, optimizer, scheduler=scheduler)\n","\n","    del train_dataset\n","    del val_dataset\n","    del train_loader\n","    del val_loader\n","    del model\n","    del optimizer\n","    del scheduler\n","    gc.collect() \n","    torch.cuda.empty_cache()\n","    return rmse"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.755813Z","iopub.execute_input":"2021-07-04T06:26:40.758373Z","iopub.status.idle":"2021-07-04T06:27:12.493221Z","shell.execute_reply.started":"2021-07-04T06:26:40.758265Z","shell.execute_reply":"2021-07-04T06:27:12.490139Z"},"trusted":true,"id":"k2LGJD3XXecK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627844851683,"user_tz":-540,"elapsed":10380096,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"49f3a881-6af7-4e59-806a-183429f25050"},"source":["# 実行処理。 KFold & 学習\n","SEED = 1000\n","list_val_rmse = []\n","\n","for fold in sorted(train_kf_df['kfold'].unique()):\n","    print(f\"\\nFold {fold + 1}/{NUM_FOLDS}\")\n","    print(gpuinfo())\n","    model_path = f\"model_{fold + 1}.pth\" # model_fold数_.pth\n","    set_random_seed(SEED + fold) # SEEDはfold別に変わるようにする\n","    feat_suffix = f\"{fold + 1}.pkl\" \n","\n","    train_indices = (train_kf_df['kfold'] != fold)\n","    val_indices = (train_kf_df['kfold'] == fold)\n","    list_val_rmse.append(train_and_save_model(train_indices, val_indices, model_path, feat_suffix))\n","    print(\"\\nPerformance estimates:\")\n","    print(list_val_rmse)\n","    print(\"Mean:\", np.array(list_val_rmse).mean())\n","    print(gpuinfo())"],"execution_count":23,"outputs":[{"output_type":"stream","text":["\n","Fold 1/5\n","{'total_MiB': 16280, 'used_MiB': 2}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 64.1 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.5086 train_rmse_stderror: 0.06856 train_kl_div: 0.5348\n","val_rmse_target: 0.6894 val_rmse_stderror: 1.125\n","New best_val_rmse: 0.6894\n","\n","64 steps took 63.1 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.6224 train_rmse_stderror: 0.1118 train_kl_div: 0.8163\n","val_rmse_target: 0.62 val_rmse_stderror: 1.151\n","New best_val_rmse: 0.62\n","\n","64 steps took 63.1 seconds\n","Epoch: 0 batch_num: 192\n","train_rmse_target: 0.5837 train_rmse_stderror: 0.1028 train_kl_div: 0.5881\n","val_rmse_target: 0.6123 val_rmse_stderror: 1.138\n","New best_val_rmse: 0.6123\n","\n","64 steps took 63.1 seconds\n","Epoch: 0 batch_num: 256\n","train_rmse_target: 0.6882 train_rmse_stderror: 0.05332 train_kl_div: 1.07\n","val_rmse_target: 0.5763 val_rmse_stderror: 1.151\n","New best_val_rmse: 0.5763\n","\n","64 steps took 63.4 seconds\n","Epoch: 1 batch_num: 37\n","train_rmse_target: 0.732 train_rmse_stderror: 0.1026 train_kl_div: 0.9483\n","val_rmse_target: 0.5517 val_rmse_stderror: 1.137\n","New best_val_rmse: 0.5517\n","\n","64 steps took 63.2 seconds\n","Epoch: 1 batch_num: 101\n","train_rmse_target: 0.3735 train_rmse_stderror: 0.04347 train_kl_div: 0.2946\n","val_rmse_target: 0.5543 val_rmse_stderror: 1.137\n","Still best_val_rmse: 0.5517 (from epoch 1)\n","\n","64 steps took 63.1 seconds\n","Epoch: 1 batch_num: 165\n","train_rmse_target: 0.3832 train_rmse_stderror: 0.1046 train_kl_div: 0.3341\n","val_rmse_target: 0.5228 val_rmse_stderror: 1.148\n","New best_val_rmse: 0.5228\n","\n","32 steps took 31.5 seconds\n","Epoch: 1 batch_num: 197\n","train_rmse_target: 0.4365 train_rmse_stderror: 0.05378 train_kl_div: 0.3181\n","val_rmse_target: 0.5308 val_rmse_stderror: 1.139\n","Still best_val_rmse: 0.5228 (from epoch 1)\n","\n","32 steps took 31.5 seconds\n","Epoch: 1 batch_num: 229\n","train_rmse_target: 0.4599 train_rmse_stderror: 0.07101 train_kl_div: 0.4588\n","val_rmse_target: 0.5722 val_rmse_stderror: 1.148\n","Still best_val_rmse: 0.5228 (from epoch 1)\n","\n","64 steps took 63.2 seconds\n","Epoch: 2 batch_num: 10\n","train_rmse_target: 0.3108 train_rmse_stderror: 0.05718 train_kl_div: 0.198\n","val_rmse_target: 0.5368 val_rmse_stderror: 1.149\n","Still best_val_rmse: 0.5228 (from epoch 1)\n","\n","32 steps took 31.5 seconds\n","Epoch: 2 batch_num: 42\n","train_rmse_target: 0.3503 train_rmse_stderror: 0.04742 train_kl_div: 0.2473\n","val_rmse_target: 0.5196 val_rmse_stderror: 1.139\n","New best_val_rmse: 0.5196\n","\n","32 steps took 31.5 seconds\n","Epoch: 2 batch_num: 74\n","train_rmse_target: 0.1623 train_rmse_stderror: 0.05509 train_kl_div: 0.06747\n","val_rmse_target: 0.5342 val_rmse_stderror: 1.141\n","Still best_val_rmse: 0.5196 (from epoch 2)\n","\n","32 steps took 31.5 seconds\n","Epoch: 2 batch_num: 106\n","train_rmse_target: 0.2785 train_rmse_stderror: 0.03812 train_kl_div: 0.1496\n","val_rmse_target: 0.5097 val_rmse_stderror: 1.14\n","New best_val_rmse: 0.5097\n","\n","32 steps took 31.5 seconds\n","Epoch: 2 batch_num: 138\n","train_rmse_target: 0.2271 train_rmse_stderror: 0.06014 train_kl_div: 0.129\n","val_rmse_target: 0.5108 val_rmse_stderror: 1.141\n","Still best_val_rmse: 0.5097 (from epoch 2)\n","\n","32 steps took 31.5 seconds\n","Epoch: 2 batch_num: 170\n","train_rmse_target: 0.2497 train_rmse_stderror: 0.05114 train_kl_div: 0.132\n","val_rmse_target: 0.5073 val_rmse_stderror: 1.15\n","New best_val_rmse: 0.5073\n","\n","32 steps took 31.5 seconds\n","Epoch: 2 batch_num: 202\n","train_rmse_target: 0.1619 train_rmse_stderror: 0.04419 train_kl_div: 0.0579\n","val_rmse_target: 0.5166 val_rmse_stderror: 1.165\n","Still best_val_rmse: 0.5073 (from epoch 2)\n","\n","32 steps took 31.6 seconds\n","Epoch: 2 batch_num: 234\n","train_rmse_target: 0.3531 train_rmse_stderror: 0.03883 train_kl_div: 0.2246\n","val_rmse_target: 0.4942 val_rmse_stderror: 1.139\n","New best_val_rmse: 0.4942\n","\n","32 steps took 31.5 seconds\n","Epoch: 2 batch_num: 266\n","train_rmse_target: 0.3322 train_rmse_stderror: 0.04611 train_kl_div: 0.2326\n","val_rmse_target: 0.5032 val_rmse_stderror: 1.152\n","Still best_val_rmse: 0.4942 (from epoch 2)\n","\n","32 steps took 31.7 seconds\n","Epoch: 3 batch_num: 15\n","train_rmse_target: 0.1964 train_rmse_stderror: 0.06352 train_kl_div: 0.08419\n","val_rmse_target: 0.5063 val_rmse_stderror: 1.143\n","Still best_val_rmse: 0.4942 (from epoch 2)\n","\n","32 steps took 31.5 seconds\n","Epoch: 3 batch_num: 47\n","train_rmse_target: 0.08753 train_rmse_stderror: 0.03841 train_kl_div: 0.02323\n","val_rmse_target: 0.4993 val_rmse_stderror: 1.153\n","Still best_val_rmse: 0.4942 (from epoch 2)\n","\n","32 steps took 31.5 seconds\n","Epoch: 3 batch_num: 79\n","train_rmse_target: 0.1305 train_rmse_stderror: 0.05082 train_kl_div: 0.04318\n","val_rmse_target: 0.4954 val_rmse_stderror: 1.142\n","Still best_val_rmse: 0.4942 (from epoch 2)\n","\n","32 steps took 31.5 seconds\n","Epoch: 3 batch_num: 111\n","train_rmse_target: 0.156 train_rmse_stderror: 0.02631 train_kl_div: 0.05925\n","val_rmse_target: 0.5009 val_rmse_stderror: 1.151\n","Still best_val_rmse: 0.4942 (from epoch 2)\n","\n","32 steps took 31.5 seconds\n","Epoch: 3 batch_num: 143\n","train_rmse_target: 0.1968 train_rmse_stderror: 0.05127 train_kl_div: 0.09743\n","val_rmse_target: 0.4998 val_rmse_stderror: 1.151\n","Still best_val_rmse: 0.4942 (from epoch 2)\n","\n","32 steps took 31.5 seconds\n","Epoch: 3 batch_num: 175\n","train_rmse_target: 0.1227 train_rmse_stderror: 0.01994 train_kl_div: 0.03273\n","val_rmse_target: 0.5033 val_rmse_stderror: 1.148\n","Still best_val_rmse: 0.4942 (from epoch 2)\n","\n","32 steps took 31.5 seconds\n","Epoch: 3 batch_num: 207\n","train_rmse_target: 0.1162 train_rmse_stderror: 0.04037 train_kl_div: 0.0319\n","val_rmse_target: 0.5079 val_rmse_stderror: 1.147\n","Still best_val_rmse: 0.4942 (from epoch 2)\n","\n","32 steps took 31.5 seconds\n","Epoch: 3 batch_num: 239\n","train_rmse_target: 0.09137 train_rmse_stderror: 0.03686 train_kl_div: 0.02286\n","val_rmse_target: 0.504 val_rmse_stderror: 1.144\n","Still best_val_rmse: 0.4942 (from epoch 2)\n","\n","32 steps took 31.5 seconds\n","Epoch: 3 batch_num: 271\n","train_rmse_target: 0.166 train_rmse_stderror: 0.04293 train_kl_div: 0.06095\n","val_rmse_target: 0.5065 val_rmse_stderror: 1.15\n","Still best_val_rmse: 0.4942 (from epoch 2)\n","\n","32 steps took 31.7 seconds\n","Epoch: 4 batch_num: 20\n","train_rmse_target: 0.08622 train_rmse_stderror: 0.04218 train_kl_div: 0.02105\n","val_rmse_target: 0.5005 val_rmse_stderror: 1.149\n","Still best_val_rmse: 0.4942 (from epoch 2)\n","\n","32 steps took 31.5 seconds\n","Epoch: 4 batch_num: 52\n","train_rmse_target: 0.07062 train_rmse_stderror: 0.01767 train_kl_div: 0.01195\n","val_rmse_target: 0.4992 val_rmse_stderror: 1.15\n","Still best_val_rmse: 0.4942 (from epoch 2)\n","\n","32 steps took 31.5 seconds\n","Epoch: 4 batch_num: 84\n","train_rmse_target: 0.0937 train_rmse_stderror: 0.04871 train_kl_div: 0.02392\n","val_rmse_target: 0.4999 val_rmse_stderror: 1.145\n","Still best_val_rmse: 0.4942 (from epoch 2)\n","\n","32 steps took 31.5 seconds\n","Epoch: 4 batch_num: 116\n","train_rmse_target: 0.05469 train_rmse_stderror: 0.03959 train_kl_div: 0.01275\n","val_rmse_target: 0.5008 val_rmse_stderror: 1.15\n","Still best_val_rmse: 0.4942 (from epoch 2)\n","\n","32 steps took 31.5 seconds\n","Epoch: 4 batch_num: 148\n","train_rmse_target: 0.1392 train_rmse_stderror: 0.03928 train_kl_div: 0.03981\n","val_rmse_target: 0.4993 val_rmse_stderror: 1.15\n","Still best_val_rmse: 0.4942 (from epoch 2)\n","\n","32 steps took 31.5 seconds\n","Epoch: 4 batch_num: 180\n","train_rmse_target: 0.06552 train_rmse_stderror: 0.04318 train_kl_div: 0.01717\n","val_rmse_target: 0.5009 val_rmse_stderror: 1.148\n","Still best_val_rmse: 0.4942 (from epoch 2)\n","\n","32 steps took 31.5 seconds\n","Epoch: 4 batch_num: 212\n","train_rmse_target: 0.08206 train_rmse_stderror: 0.03186 train_kl_div: 0.01816\n","val_rmse_target: 0.5011 val_rmse_stderror: 1.147\n","Still best_val_rmse: 0.4942 (from epoch 2)\n","\n","32 steps took 31.5 seconds\n","Epoch: 4 batch_num: 244\n","train_rmse_target: 0.06204 train_rmse_stderror: 0.05299 train_kl_div: 0.01806\n","val_rmse_target: 0.5015 val_rmse_stderror: 1.147\n","Still best_val_rmse: 0.4942 (from epoch 2)\n","\n","32 steps took 31.5 seconds\n","Epoch: 4 batch_num: 276\n","train_rmse_target: 0.0821 train_rmse_stderror: 0.01662 train_kl_div: 0.01327\n","val_rmse_target: 0.5016 val_rmse_stderror: 1.148\n","Still best_val_rmse: 0.4942 (from epoch 2)\n","\n","Performance estimates:\n","[0.49421215826008996]\n","Mean: 0.49421215826008996\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 2/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 63.7 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 1.293 train_rmse_stderror: 0.1586 train_kl_div: 3.028\n","val_rmse_target: 0.9286 val_rmse_stderror: 1.674\n","New best_val_rmse: 0.9286\n","\n","64 steps took 63.0 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.7168 train_rmse_stderror: 0.06818 train_kl_div: 0.8226\n","val_rmse_target: 0.6403 val_rmse_stderror: 1.823\n","New best_val_rmse: 0.6403\n","\n","64 steps took 63.0 seconds\n","Epoch: 0 batch_num: 192\n","train_rmse_target: 0.5957 train_rmse_stderror: 0.1174 train_kl_div: 0.7422\n","val_rmse_target: 0.6063 val_rmse_stderror: 1.76\n","New best_val_rmse: 0.6063\n","\n","64 steps took 63.0 seconds\n","Epoch: 0 batch_num: 256\n","train_rmse_target: 0.9499 train_rmse_stderror: 0.1154 train_kl_div: 1.628\n","val_rmse_target: 0.6337 val_rmse_stderror: 1.735\n","Still best_val_rmse: 0.6063 (from epoch 0)\n","\n","64 steps took 63.2 seconds\n","Epoch: 1 batch_num: 37\n","train_rmse_target: 0.4412 train_rmse_stderror: 0.1134 train_kl_div: 0.4848\n","val_rmse_target: 0.618 val_rmse_stderror: 1.75\n","Still best_val_rmse: 0.6063 (from epoch 0)\n","\n","64 steps took 63.1 seconds\n","Epoch: 1 batch_num: 101\n","train_rmse_target: 0.5087 train_rmse_stderror: 0.07332 train_kl_div: 0.4805\n","val_rmse_target: 0.5673 val_rmse_stderror: 1.747\n","New best_val_rmse: 0.5673\n","\n","64 steps took 63.1 seconds\n","Epoch: 1 batch_num: 165\n","train_rmse_target: 0.3016 train_rmse_stderror: 0.1108 train_kl_div: 0.2527\n","val_rmse_target: 0.5069 val_rmse_stderror: 1.833\n","New best_val_rmse: 0.5069\n","\n","32 steps took 31.5 seconds\n","Epoch: 1 batch_num: 197\n","train_rmse_target: 0.6476 train_rmse_stderror: 0.07968 train_kl_div: 0.7421\n","val_rmse_target: 0.5775 val_rmse_stderror: 1.786\n","Still best_val_rmse: 0.5069 (from epoch 1)\n","\n","64 steps took 63.0 seconds\n","Epoch: 1 batch_num: 261\n","train_rmse_target: 0.3524 train_rmse_stderror: 0.06859 train_kl_div: 0.295\n","val_rmse_target: 0.512 val_rmse_stderror: 1.794\n","Still best_val_rmse: 0.5069 (from epoch 1)\n","\n","32 steps took 31.8 seconds\n","Epoch: 2 batch_num: 10\n","train_rmse_target: 0.3854 train_rmse_stderror: 0.06962 train_kl_div: 0.2603\n","val_rmse_target: 0.507 val_rmse_stderror: 1.796\n","Still best_val_rmse: 0.5069 (from epoch 1)\n","\n","32 steps took 31.6 seconds\n","Epoch: 2 batch_num: 42\n","train_rmse_target: 0.3695 train_rmse_stderror: 0.09574 train_kl_div: 0.2228\n","val_rmse_target: 0.4889 val_rmse_stderror: 1.774\n","New best_val_rmse: 0.4889\n","\n","32 steps took 31.6 seconds\n","Epoch: 2 batch_num: 74\n","train_rmse_target: 0.573 train_rmse_stderror: 0.0337 train_kl_div: 0.5798\n","val_rmse_target: 0.4942 val_rmse_stderror: 1.795\n","Still best_val_rmse: 0.4889 (from epoch 2)\n","\n","32 steps took 31.5 seconds\n","Epoch: 2 batch_num: 106\n","train_rmse_target: 0.3278 train_rmse_stderror: 0.04742 train_kl_div: 0.1964\n","val_rmse_target: 0.4895 val_rmse_stderror: 1.785\n","Still best_val_rmse: 0.4889 (from epoch 2)\n","\n","32 steps took 31.5 seconds\n","Epoch: 2 batch_num: 138\n","train_rmse_target: 0.3612 train_rmse_stderror: 0.06152 train_kl_div: 0.2934\n","val_rmse_target: 0.4996 val_rmse_stderror: 1.797\n","Still best_val_rmse: 0.4889 (from epoch 2)\n","\n","32 steps took 31.5 seconds\n","Epoch: 2 batch_num: 170\n","train_rmse_target: 0.4334 train_rmse_stderror: 0.08263 train_kl_div: 0.3642\n","val_rmse_target: 0.4897 val_rmse_stderror: 1.813\n","Still best_val_rmse: 0.4889 (from epoch 2)\n","\n","32 steps took 31.5 seconds\n","Epoch: 2 batch_num: 202\n","train_rmse_target: 0.3501 train_rmse_stderror: 0.0675 train_kl_div: 0.2795\n","val_rmse_target: 0.4913 val_rmse_stderror: 1.762\n","Still best_val_rmse: 0.4889 (from epoch 2)\n","\n","32 steps took 31.5 seconds\n","Epoch: 2 batch_num: 234\n","train_rmse_target: 0.305 train_rmse_stderror: 0.08711 train_kl_div: 0.2075\n","val_rmse_target: 0.5177 val_rmse_stderror: 1.789\n","Still best_val_rmse: 0.4889 (from epoch 2)\n","\n","32 steps took 31.5 seconds\n","Epoch: 2 batch_num: 266\n","train_rmse_target: 0.3983 train_rmse_stderror: 0.06102 train_kl_div: 0.3651\n","val_rmse_target: 0.5105 val_rmse_stderror: 1.774\n","Still best_val_rmse: 0.4889 (from epoch 2)\n","\n","32 steps took 31.7 seconds\n","Epoch: 3 batch_num: 15\n","train_rmse_target: 0.2512 train_rmse_stderror: 0.06603 train_kl_div: 0.1408\n","val_rmse_target: 0.4899 val_rmse_stderror: 1.772\n","Still best_val_rmse: 0.4889 (from epoch 2)\n","\n","32 steps took 31.5 seconds\n","Epoch: 3 batch_num: 47\n","train_rmse_target: 0.4097 train_rmse_stderror: 0.04609 train_kl_div: 0.3436\n","val_rmse_target: 0.4788 val_rmse_stderror: 1.773\n","New best_val_rmse: 0.4788\n","\n","32 steps took 31.5 seconds\n","Epoch: 3 batch_num: 79\n","train_rmse_target: 0.2445 train_rmse_stderror: 0.08474 train_kl_div: 0.1541\n","val_rmse_target: 0.4785 val_rmse_stderror: 1.787\n","New best_val_rmse: 0.4785\n","\n","32 steps took 31.5 seconds\n","Epoch: 3 batch_num: 111\n","train_rmse_target: 0.165 train_rmse_stderror: 0.04866 train_kl_div: 0.06703\n","val_rmse_target: 0.4762 val_rmse_stderror: 1.784\n","New best_val_rmse: 0.4762\n","\n","32 steps took 31.5 seconds\n","Epoch: 3 batch_num: 143\n","train_rmse_target: 0.134 train_rmse_stderror: 0.05336 train_kl_div: 0.05312\n","val_rmse_target: 0.482 val_rmse_stderror: 1.782\n","Still best_val_rmse: 0.4762 (from epoch 3)\n","\n","32 steps took 31.5 seconds\n","Epoch: 3 batch_num: 175\n","train_rmse_target: 0.2194 train_rmse_stderror: 0.07102 train_kl_div: 0.131\n","val_rmse_target: 0.476 val_rmse_stderror: 1.794\n","New best_val_rmse: 0.476\n","\n","32 steps took 31.5 seconds\n","Epoch: 3 batch_num: 207\n","train_rmse_target: 0.1422 train_rmse_stderror: 0.07647 train_kl_div: 0.06837\n","val_rmse_target: 0.4755 val_rmse_stderror: 1.78\n","New best_val_rmse: 0.4755\n","\n","32 steps took 31.5 seconds\n","Epoch: 3 batch_num: 239\n","train_rmse_target: 0.1971 train_rmse_stderror: 0.0841 train_kl_div: 0.116\n","val_rmse_target: 0.4759 val_rmse_stderror: 1.803\n","Still best_val_rmse: 0.4755 (from epoch 3)\n","\n","32 steps took 31.5 seconds\n","Epoch: 3 batch_num: 271\n","train_rmse_target: 0.2499 train_rmse_stderror: 0.06114 train_kl_div: 0.1432\n","val_rmse_target: 0.4813 val_rmse_stderror: 1.797\n","Still best_val_rmse: 0.4755 (from epoch 3)\n","\n","32 steps took 31.7 seconds\n","Epoch: 4 batch_num: 20\n","train_rmse_target: 0.1945 train_rmse_stderror: 0.05122 train_kl_div: 0.08136\n","val_rmse_target: 0.4762 val_rmse_stderror: 1.796\n","Still best_val_rmse: 0.4755 (from epoch 3)\n","\n","32 steps took 31.5 seconds\n","Epoch: 4 batch_num: 52\n","train_rmse_target: 0.1919 train_rmse_stderror: 0.07102 train_kl_div: 0.08193\n","val_rmse_target: 0.476 val_rmse_stderror: 1.792\n","Still best_val_rmse: 0.4755 (from epoch 3)\n","\n","32 steps took 31.5 seconds\n","Epoch: 4 batch_num: 84\n","train_rmse_target: 0.1036 train_rmse_stderror: 0.06567 train_kl_div: 0.04229\n","val_rmse_target: 0.4767 val_rmse_stderror: 1.797\n","Still best_val_rmse: 0.4755 (from epoch 3)\n","\n","32 steps took 31.5 seconds\n","Epoch: 4 batch_num: 116\n","train_rmse_target: 0.1048 train_rmse_stderror: 0.077 train_kl_div: 0.04958\n","val_rmse_target: 0.4759 val_rmse_stderror: 1.787\n","Still best_val_rmse: 0.4755 (from epoch 3)\n","\n","32 steps took 31.5 seconds\n","Epoch: 4 batch_num: 148\n","train_rmse_target: 0.1998 train_rmse_stderror: 0.05782 train_kl_div: 0.09317\n","val_rmse_target: 0.4777 val_rmse_stderror: 1.79\n","Still best_val_rmse: 0.4755 (from epoch 3)\n","\n","32 steps took 31.5 seconds\n","Epoch: 4 batch_num: 180\n","train_rmse_target: 0.103 train_rmse_stderror: 0.03974 train_kl_div: 0.02827\n","val_rmse_target: 0.4753 val_rmse_stderror: 1.79\n","New best_val_rmse: 0.4753\n","\n","32 steps took 31.5 seconds\n","Epoch: 4 batch_num: 212\n","train_rmse_target: 0.1786 train_rmse_stderror: 0.04282 train_kl_div: 0.07718\n","val_rmse_target: 0.4753 val_rmse_stderror: 1.788\n","New best_val_rmse: 0.4753\n","\n","32 steps took 31.5 seconds\n","Epoch: 4 batch_num: 244\n","train_rmse_target: 0.04957 train_rmse_stderror: 0.07333 train_kl_div: 0.02729\n","val_rmse_target: 0.4755 val_rmse_stderror: 1.789\n","Still best_val_rmse: 0.4753 (from epoch 4)\n","\n","32 steps took 31.5 seconds\n","Epoch: 4 batch_num: 276\n","train_rmse_target: 0.08945 train_rmse_stderror: 0.05163 train_kl_div: 0.02759\n","val_rmse_target: 0.4756 val_rmse_stderror: 1.788\n","Still best_val_rmse: 0.4753 (from epoch 4)\n","\n","Performance estimates:\n","[0.49421215826008996, 0.4752608407152704]\n","Mean: 0.48473649948768016\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 3/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 63.7 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.7889 train_rmse_stderror: 0.05908 train_kl_div: 1.34\n","val_rmse_target: 0.7027 val_rmse_stderror: 1.77\n","New best_val_rmse: 0.7027\n","\n","64 steps took 63.0 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.6711 train_rmse_stderror: 0.1097 train_kl_div: 1.037\n","val_rmse_target: 0.6219 val_rmse_stderror: 1.769\n","New best_val_rmse: 0.6219\n","\n","64 steps took 63.0 seconds\n","Epoch: 0 batch_num: 192\n","train_rmse_target: 0.74 train_rmse_stderror: 0.0948 train_kl_div: 1.216\n","val_rmse_target: 0.6578 val_rmse_stderror: 1.734\n","Still best_val_rmse: 0.6219 (from epoch 0)\n","\n","64 steps took 63.0 seconds\n","Epoch: 0 batch_num: 256\n","train_rmse_target: 0.5382 train_rmse_stderror: 0.08356 train_kl_div: 0.6556\n","val_rmse_target: 0.665 val_rmse_stderror: 1.757\n","Still best_val_rmse: 0.6219 (from epoch 0)\n","\n","64 steps took 63.2 seconds\n","Epoch: 1 batch_num: 37\n","train_rmse_target: 0.4634 train_rmse_stderror: 0.07315 train_kl_div: 0.383\n","val_rmse_target: 0.5247 val_rmse_stderror: 1.747\n","New best_val_rmse: 0.5247\n","\n","32 steps took 31.5 seconds\n","Epoch: 1 batch_num: 69\n","train_rmse_target: 0.6711 train_rmse_stderror: 0.06301 train_kl_div: 0.8848\n","val_rmse_target: 0.5871 val_rmse_stderror: 1.747\n","Still best_val_rmse: 0.5247 (from epoch 1)\n","\n","64 steps took 63.0 seconds\n","Epoch: 1 batch_num: 133\n","train_rmse_target: 0.3516 train_rmse_stderror: 0.08031 train_kl_div: 0.2739\n","val_rmse_target: 0.5217 val_rmse_stderror: 1.746\n","New best_val_rmse: 0.5217\n","\n","32 steps took 31.5 seconds\n","Epoch: 1 batch_num: 165\n","train_rmse_target: 0.2472 train_rmse_stderror: 0.07547 train_kl_div: 0.1481\n","val_rmse_target: 0.5566 val_rmse_stderror: 1.795\n","Still best_val_rmse: 0.5217 (from epoch 1)\n","\n","64 steps took 63.0 seconds\n","Epoch: 1 batch_num: 229\n","train_rmse_target: 0.4459 train_rmse_stderror: 0.06662 train_kl_div: 0.4185\n","val_rmse_target: 0.4912 val_rmse_stderror: 1.757\n","New best_val_rmse: 0.4912\n","\n","32 steps took 31.5 seconds\n","Epoch: 1 batch_num: 261\n","train_rmse_target: 0.2958 train_rmse_stderror: 0.05559 train_kl_div: 0.1965\n","val_rmse_target: 0.5326 val_rmse_stderror: 1.774\n","Still best_val_rmse: 0.4912 (from epoch 1)\n","\n","32 steps took 31.7 seconds\n","Epoch: 2 batch_num: 10\n","train_rmse_target: 0.2845 train_rmse_stderror: 0.08393 train_kl_div: 0.1855\n","val_rmse_target: 0.4981 val_rmse_stderror: 1.749\n","Still best_val_rmse: 0.4912 (from epoch 1)\n","\n","32 steps took 31.5 seconds\n","Epoch: 2 batch_num: 42\n","train_rmse_target: 0.2117 train_rmse_stderror: 0.04207 train_kl_div: 0.098\n","val_rmse_target: 0.4819 val_rmse_stderror: 1.749\n","New best_val_rmse: 0.4819\n","\n","32 steps took 31.5 seconds\n","Epoch: 2 batch_num: 74\n","train_rmse_target: 0.151 train_rmse_stderror: 0.05187 train_kl_div: 0.0593\n","val_rmse_target: 0.4912 val_rmse_stderror: 1.759\n","Still best_val_rmse: 0.4819 (from epoch 2)\n","\n","32 steps took 31.5 seconds\n","Epoch: 2 batch_num: 106\n","train_rmse_target: 0.3016 train_rmse_stderror: 0.07228 train_kl_div: 0.213\n","val_rmse_target: 0.5052 val_rmse_stderror: 1.75\n","Still best_val_rmse: 0.4819 (from epoch 2)\n","\n","32 steps took 31.5 seconds\n","Epoch: 2 batch_num: 138\n","train_rmse_target: 0.2311 train_rmse_stderror: 0.04802 train_kl_div: 0.1127\n","val_rmse_target: 0.4853 val_rmse_stderror: 1.767\n","Still best_val_rmse: 0.4819 (from epoch 2)\n","\n","32 steps took 31.5 seconds\n","Epoch: 2 batch_num: 170\n","train_rmse_target: 0.1202 train_rmse_stderror: 0.05471 train_kl_div: 0.04278\n","val_rmse_target: 0.4834 val_rmse_stderror: 1.773\n","Still best_val_rmse: 0.4819 (from epoch 2)\n","\n","32 steps took 31.5 seconds\n","Epoch: 2 batch_num: 202\n","train_rmse_target: 0.1986 train_rmse_stderror: 0.04079 train_kl_div: 0.09352\n","val_rmse_target: 0.4843 val_rmse_stderror: 1.779\n","Still best_val_rmse: 0.4819 (from epoch 2)\n","\n","32 steps took 31.5 seconds\n","Epoch: 2 batch_num: 234\n","train_rmse_target: 0.1378 train_rmse_stderror: 0.04372 train_kl_div: 0.0495\n","val_rmse_target: 0.5148 val_rmse_stderror: 1.766\n","Still best_val_rmse: 0.4819 (from epoch 2)\n","\n","32 steps took 31.5 seconds\n","Epoch: 2 batch_num: 266\n","train_rmse_target: 0.2156 train_rmse_stderror: 0.03025 train_kl_div: 0.09909\n","val_rmse_target: 0.4899 val_rmse_stderror: 1.747\n","Still best_val_rmse: 0.4819 (from epoch 2)\n","\n","32 steps took 31.7 seconds\n","Epoch: 3 batch_num: 15\n","train_rmse_target: 0.09682 train_rmse_stderror: 0.06097 train_kl_div: 0.03726\n","val_rmse_target: 0.4822 val_rmse_stderror: 1.764\n","Still best_val_rmse: 0.4819 (from epoch 2)\n","\n","32 steps took 31.5 seconds\n","Epoch: 3 batch_num: 47\n","train_rmse_target: 0.08172 train_rmse_stderror: 0.04454 train_kl_div: 0.02433\n","val_rmse_target: 0.4883 val_rmse_stderror: 1.765\n","Still best_val_rmse: 0.4819 (from epoch 2)\n","\n","32 steps took 31.5 seconds\n","Epoch: 3 batch_num: 79\n","train_rmse_target: 0.1669 train_rmse_stderror: 0.05264 train_kl_div: 0.07386\n","val_rmse_target: 0.4944 val_rmse_stderror: 1.757\n","Still best_val_rmse: 0.4819 (from epoch 2)\n","\n","32 steps took 31.5 seconds\n","Epoch: 3 batch_num: 111\n","train_rmse_target: 0.1201 train_rmse_stderror: 0.06263 train_kl_div: 0.04617\n","val_rmse_target: 0.479 val_rmse_stderror: 1.754\n","New best_val_rmse: 0.479\n","\n","32 steps took 31.5 seconds\n","Epoch: 3 batch_num: 143\n","train_rmse_target: 0.1589 train_rmse_stderror: 0.04706 train_kl_div: 0.05889\n","val_rmse_target: 0.4925 val_rmse_stderror: 1.753\n","Still best_val_rmse: 0.479 (from epoch 3)\n","\n","32 steps took 31.5 seconds\n","Epoch: 3 batch_num: 175\n","train_rmse_target: 0.07089 train_rmse_stderror: 0.04886 train_kl_div: 0.02065\n","val_rmse_target: 0.4804 val_rmse_stderror: 1.753\n","Still best_val_rmse: 0.479 (from epoch 3)\n","\n","32 steps took 31.5 seconds\n","Epoch: 3 batch_num: 207\n","train_rmse_target: 0.1178 train_rmse_stderror: 0.04925 train_kl_div: 0.03885\n","val_rmse_target: 0.4826 val_rmse_stderror: 1.761\n","Still best_val_rmse: 0.479 (from epoch 3)\n","\n","32 steps took 31.4 seconds\n","Epoch: 3 batch_num: 239\n","train_rmse_target: 0.1808 train_rmse_stderror: 0.05976 train_kl_div: 0.06354\n","val_rmse_target: 0.4796 val_rmse_stderror: 1.767\n","Still best_val_rmse: 0.479 (from epoch 3)\n","\n","32 steps took 31.5 seconds\n","Epoch: 3 batch_num: 271\n","train_rmse_target: 0.08418 train_rmse_stderror: 0.02596 train_kl_div: 0.01804\n","val_rmse_target: 0.4808 val_rmse_stderror: 1.759\n","Still best_val_rmse: 0.479 (from epoch 3)\n","\n","32 steps took 31.7 seconds\n","Epoch: 4 batch_num: 20\n","train_rmse_target: 0.1275 train_rmse_stderror: 0.0593 train_kl_div: 0.04315\n","val_rmse_target: 0.4781 val_rmse_stderror: 1.759\n","New best_val_rmse: 0.4781\n","\n","32 steps took 31.6 seconds\n","Epoch: 4 batch_num: 52\n","train_rmse_target: 0.1789 train_rmse_stderror: 0.04335 train_kl_div: 0.05227\n","val_rmse_target: 0.4812 val_rmse_stderror: 1.764\n","Still best_val_rmse: 0.4781 (from epoch 4)\n","\n","32 steps took 31.5 seconds\n","Epoch: 4 batch_num: 84\n","train_rmse_target: 0.1013 train_rmse_stderror: 0.05875 train_kl_div: 0.03285\n","val_rmse_target: 0.4819 val_rmse_stderror: 1.754\n","Still best_val_rmse: 0.4781 (from epoch 4)\n","\n","32 steps took 31.5 seconds\n","Epoch: 4 batch_num: 116\n","train_rmse_target: 0.0597 train_rmse_stderror: 0.01402 train_kl_div: 0.008744\n","val_rmse_target: 0.4821 val_rmse_stderror: 1.76\n","Still best_val_rmse: 0.4781 (from epoch 4)\n","\n","32 steps took 31.5 seconds\n","Epoch: 4 batch_num: 148\n","train_rmse_target: 0.05423 train_rmse_stderror: 0.03054 train_kl_div: 0.01064\n","val_rmse_target: 0.4812 val_rmse_stderror: 1.758\n","Still best_val_rmse: 0.4781 (from epoch 4)\n","\n","32 steps took 31.5 seconds\n","Epoch: 4 batch_num: 180\n","train_rmse_target: 0.1193 train_rmse_stderror: 0.04528 train_kl_div: 0.04011\n","val_rmse_target: 0.4808 val_rmse_stderror: 1.76\n","Still best_val_rmse: 0.4781 (from epoch 4)\n","\n","32 steps took 31.5 seconds\n","Epoch: 4 batch_num: 212\n","train_rmse_target: 0.1221 train_rmse_stderror: 0.03624 train_kl_div: 0.02981\n","val_rmse_target: 0.4814 val_rmse_stderror: 1.758\n","Still best_val_rmse: 0.4781 (from epoch 4)\n","\n","32 steps took 31.5 seconds\n","Epoch: 4 batch_num: 244\n","train_rmse_target: 0.1003 train_rmse_stderror: 0.03398 train_kl_div: 0.02225\n","val_rmse_target: 0.4809 val_rmse_stderror: 1.757\n","Still best_val_rmse: 0.4781 (from epoch 4)\n","\n","32 steps took 31.5 seconds\n","Epoch: 4 batch_num: 276\n","train_rmse_target: 0.1188 train_rmse_stderror: 0.0215 train_kl_div: 0.03028\n","val_rmse_target: 0.4808 val_rmse_stderror: 1.757\n","Still best_val_rmse: 0.4781 (from epoch 4)\n","\n","Performance estimates:\n","[0.49421215826008996, 0.4752608407152704, 0.47807585489870225]\n","Mean: 0.48251628462468754\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 4/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 63.7 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 1.47 train_rmse_stderror: 0.08312 train_kl_div: 3.842\n","val_rmse_target: 0.7429 val_rmse_stderror: 1.828\n","New best_val_rmse: 0.7429\n","\n","64 steps took 63.0 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.4918 train_rmse_stderror: 0.05792 train_kl_div: 0.543\n","val_rmse_target: 0.6752 val_rmse_stderror: 1.762\n","New best_val_rmse: 0.6752\n","\n","64 steps took 63.0 seconds\n","Epoch: 0 batch_num: 192\n","train_rmse_target: 0.5215 train_rmse_stderror: 0.04248 train_kl_div: 0.59\n","val_rmse_target: 0.6037 val_rmse_stderror: 1.738\n","New best_val_rmse: 0.6037\n","\n","64 steps took 63.0 seconds\n","Epoch: 0 batch_num: 256\n","train_rmse_target: 0.5731 train_rmse_stderror: 0.05688 train_kl_div: 0.6388\n","val_rmse_target: 0.6025 val_rmse_stderror: 1.777\n","New best_val_rmse: 0.6025\n","\n","64 steps took 63.1 seconds\n","Epoch: 1 batch_num: 37\n","train_rmse_target: 0.5019 train_rmse_stderror: 0.05626 train_kl_div: 0.5377\n","val_rmse_target: 0.5285 val_rmse_stderror: 1.785\n","New best_val_rmse: 0.5285\n","\n","32 steps took 31.6 seconds\n","Epoch: 1 batch_num: 69\n","train_rmse_target: 0.6645 train_rmse_stderror: 0.07552 train_kl_div: 0.7786\n","val_rmse_target: 0.5604 val_rmse_stderror: 1.754\n","Still best_val_rmse: 0.5285 (from epoch 1)\n","\n","64 steps took 63.0 seconds\n","Epoch: 1 batch_num: 133\n","train_rmse_target: 0.5496 train_rmse_stderror: 0.05509 train_kl_div: 0.545\n","val_rmse_target: 0.6164 val_rmse_stderror: 1.739\n","Still best_val_rmse: 0.5285 (from epoch 1)\n","\n","64 steps took 63.0 seconds\n","Epoch: 1 batch_num: 197\n","train_rmse_target: 0.356 train_rmse_stderror: 0.04397 train_kl_div: 0.2547\n","val_rmse_target: 0.5053 val_rmse_stderror: 1.745\n","New best_val_rmse: 0.5053\n","\n","32 steps took 31.5 seconds\n","Epoch: 1 batch_num: 229\n","train_rmse_target: 0.5844 train_rmse_stderror: 0.0481 train_kl_div: 0.5987\n","val_rmse_target: 0.5396 val_rmse_stderror: 1.757\n","Still best_val_rmse: 0.5053 (from epoch 1)\n","\n","32 steps took 31.6 seconds\n","Epoch: 1 batch_num: 261\n","train_rmse_target: 0.2608 train_rmse_stderror: 0.01661 train_kl_div: 0.1549\n","val_rmse_target: 0.5307 val_rmse_stderror: 1.758\n","Still best_val_rmse: 0.5053 (from epoch 1)\n","\n","32 steps took 31.7 seconds\n","Epoch: 2 batch_num: 10\n","train_rmse_target: 0.3446 train_rmse_stderror: 0.03664 train_kl_div: 0.2394\n","val_rmse_target: 0.5264 val_rmse_stderror: 1.756\n","Still best_val_rmse: 0.5053 (from epoch 1)\n","\n","32 steps took 31.5 seconds\n","Epoch: 2 batch_num: 42\n","train_rmse_target: 0.1972 train_rmse_stderror: 0.01928 train_kl_div: 0.07361\n","val_rmse_target: 0.4895 val_rmse_stderror: 1.76\n","New best_val_rmse: 0.4895\n","\n","32 steps took 31.5 seconds\n","Epoch: 2 batch_num: 74\n","train_rmse_target: 0.4667 train_rmse_stderror: 0.04263 train_kl_div: 0.4354\n","val_rmse_target: 0.5387 val_rmse_stderror: 1.772\n","Still best_val_rmse: 0.4895 (from epoch 2)\n","\n","32 steps took 31.4 seconds\n","Epoch: 2 batch_num: 106\n","train_rmse_target: 0.3174 train_rmse_stderror: 0.03952 train_kl_div: 0.2112\n","val_rmse_target: 0.4944 val_rmse_stderror: 1.783\n","Still best_val_rmse: 0.4895 (from epoch 2)\n","\n","32 steps took 31.5 seconds\n","Epoch: 2 batch_num: 138\n","train_rmse_target: 0.2389 train_rmse_stderror: 0.04141 train_kl_div: 0.124\n","val_rmse_target: 0.5202 val_rmse_stderror: 1.764\n","Still best_val_rmse: 0.4895 (from epoch 2)\n","\n","32 steps took 31.5 seconds\n","Epoch: 2 batch_num: 170\n","train_rmse_target: 0.3491 train_rmse_stderror: 0.04328 train_kl_div: 0.2234\n","val_rmse_target: 0.489 val_rmse_stderror: 1.749\n","New best_val_rmse: 0.489\n","\n","32 steps took 31.5 seconds\n","Epoch: 2 batch_num: 202\n","train_rmse_target: 0.3553 train_rmse_stderror: 0.05402 train_kl_div: 0.2489\n","val_rmse_target: 0.4834 val_rmse_stderror: 1.761\n","New best_val_rmse: 0.4834\n","\n","32 steps took 31.5 seconds\n","Epoch: 2 batch_num: 234\n","train_rmse_target: 0.2686 train_rmse_stderror: 0.03051 train_kl_div: 0.1581\n","val_rmse_target: 0.4812 val_rmse_stderror: 1.765\n","New best_val_rmse: 0.4812\n","\n","32 steps took 31.5 seconds\n","Epoch: 2 batch_num: 266\n","train_rmse_target: 0.3059 train_rmse_stderror: 0.04932 train_kl_div: 0.2131\n","val_rmse_target: 0.4804 val_rmse_stderror: 1.762\n","New best_val_rmse: 0.4804\n","\n","32 steps took 31.7 seconds\n","Epoch: 3 batch_num: 15\n","train_rmse_target: 0.1237 train_rmse_stderror: 0.04646 train_kl_div: 0.04361\n","val_rmse_target: 0.4973 val_rmse_stderror: 1.758\n","Still best_val_rmse: 0.4804 (from epoch 2)\n","\n","32 steps took 31.5 seconds\n","Epoch: 3 batch_num: 47\n","train_rmse_target: 0.1164 train_rmse_stderror: 0.038 train_kl_div: 0.0362\n","val_rmse_target: 0.4866 val_rmse_stderror: 1.771\n","Still best_val_rmse: 0.4804 (from epoch 2)\n","\n","32 steps took 31.5 seconds\n","Epoch: 3 batch_num: 79\n","train_rmse_target: 0.2268 train_rmse_stderror: 0.02157 train_kl_div: 0.1135\n","val_rmse_target: 0.4827 val_rmse_stderror: 1.751\n","Still best_val_rmse: 0.4804 (from epoch 2)\n","\n","32 steps took 31.5 seconds\n","Epoch: 3 batch_num: 111\n","train_rmse_target: 0.2135 train_rmse_stderror: 0.03701 train_kl_div: 0.09759\n","val_rmse_target: 0.4788 val_rmse_stderror: 1.766\n","New best_val_rmse: 0.4788\n","\n","32 steps took 31.6 seconds\n","Epoch: 3 batch_num: 143\n","train_rmse_target: 0.225 train_rmse_stderror: 0.02782 train_kl_div: 0.09926\n","val_rmse_target: 0.4801 val_rmse_stderror: 1.766\n","Still best_val_rmse: 0.4788 (from epoch 3)\n","\n","32 steps took 31.6 seconds\n","Epoch: 3 batch_num: 175\n","train_rmse_target: 0.1574 train_rmse_stderror: 0.02739 train_kl_div: 0.05321\n","val_rmse_target: 0.4906 val_rmse_stderror: 1.754\n","Still best_val_rmse: 0.4788 (from epoch 3)\n","\n","32 steps took 31.5 seconds\n","Epoch: 3 batch_num: 207\n","train_rmse_target: 0.1588 train_rmse_stderror: 0.03132 train_kl_div: 0.04724\n","val_rmse_target: 0.482 val_rmse_stderror: 1.762\n","Still best_val_rmse: 0.4788 (from epoch 3)\n","\n","32 steps took 31.5 seconds\n","Epoch: 3 batch_num: 239\n","train_rmse_target: 0.1598 train_rmse_stderror: 0.03911 train_kl_div: 0.05705\n","val_rmse_target: 0.4823 val_rmse_stderror: 1.762\n","Still best_val_rmse: 0.4788 (from epoch 3)\n","\n","32 steps took 31.5 seconds\n","Epoch: 3 batch_num: 271\n","train_rmse_target: 0.07737 train_rmse_stderror: 0.04033 train_kl_div: 0.0204\n","val_rmse_target: 0.4826 val_rmse_stderror: 1.761\n","Still best_val_rmse: 0.4788 (from epoch 3)\n","\n","32 steps took 31.7 seconds\n","Epoch: 4 batch_num: 20\n","train_rmse_target: 0.1018 train_rmse_stderror: 0.03541 train_kl_div: 0.02915\n","val_rmse_target: 0.4855 val_rmse_stderror: 1.761\n","Still best_val_rmse: 0.4788 (from epoch 3)\n","\n","32 steps took 31.5 seconds\n","Epoch: 4 batch_num: 52\n","train_rmse_target: 0.09669 train_rmse_stderror: 0.02769 train_kl_div: 0.02357\n","val_rmse_target: 0.4844 val_rmse_stderror: 1.761\n","Still best_val_rmse: 0.4788 (from epoch 3)\n","\n","32 steps took 31.5 seconds\n","Epoch: 4 batch_num: 84\n","train_rmse_target: 0.09465 train_rmse_stderror: 0.03812 train_kl_div: 0.02532\n","val_rmse_target: 0.4825 val_rmse_stderror: 1.762\n","Still best_val_rmse: 0.4788 (from epoch 3)\n","\n","32 steps took 31.6 seconds\n","Epoch: 4 batch_num: 116\n","train_rmse_target: 0.05481 train_rmse_stderror: 0.03177 train_kl_div: 0.01109\n","val_rmse_target: 0.4825 val_rmse_stderror: 1.753\n","Still best_val_rmse: 0.4788 (from epoch 3)\n","\n","32 steps took 31.6 seconds\n","Epoch: 4 batch_num: 148\n","train_rmse_target: 0.1579 train_rmse_stderror: 0.02713 train_kl_div: 0.04915\n","val_rmse_target: 0.4826 val_rmse_stderror: 1.762\n","Still best_val_rmse: 0.4788 (from epoch 3)\n","\n","32 steps took 31.6 seconds\n","Epoch: 4 batch_num: 180\n","train_rmse_target: 0.08743 train_rmse_stderror: 0.03322 train_kl_div: 0.01984\n","val_rmse_target: 0.4824 val_rmse_stderror: 1.761\n","Still best_val_rmse: 0.4788 (from epoch 3)\n","\n","32 steps took 31.6 seconds\n","Epoch: 4 batch_num: 212\n","train_rmse_target: 0.09624 train_rmse_stderror: 0.02152 train_kl_div: 0.01987\n","val_rmse_target: 0.4821 val_rmse_stderror: 1.759\n","Still best_val_rmse: 0.4788 (from epoch 3)\n","\n","32 steps took 31.6 seconds\n","Epoch: 4 batch_num: 244\n","train_rmse_target: 0.08296 train_rmse_stderror: 0.04116 train_kl_div: 0.02221\n","val_rmse_target: 0.4826 val_rmse_stderror: 1.759\n","Still best_val_rmse: 0.4788 (from epoch 3)\n","\n","32 steps took 31.6 seconds\n","Epoch: 4 batch_num: 276\n","train_rmse_target: 0.1384 train_rmse_stderror: 0.04121 train_kl_div: 0.04232\n","val_rmse_target: 0.4825 val_rmse_stderror: 1.759\n","Still best_val_rmse: 0.4788 (from epoch 3)\n","\n","Performance estimates:\n","[0.49421215826008996, 0.4752608407152704, 0.47807585489870225, 0.4787509217843914]\n","Mean: 0.48157494391461353\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 5/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 63.9 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.9152 train_rmse_stderror: 0.2177 train_kl_div: 1.502\n","val_rmse_target: 0.8615 val_rmse_stderror: 2.043\n","New best_val_rmse: 0.8615\n","\n","64 steps took 63.2 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 1.065 train_rmse_stderror: 0.07375 train_kl_div: 2.11\n","val_rmse_target: 0.9949 val_rmse_stderror: 1.79\n","Still best_val_rmse: 0.8615 (from epoch 0)\n","\n","64 steps took 63.2 seconds\n","Epoch: 0 batch_num: 192\n","train_rmse_target: 1.223 train_rmse_stderror: 0.09371 train_kl_div: 2.812\n","val_rmse_target: 0.7802 val_rmse_stderror: 1.787\n","New best_val_rmse: 0.7802\n","\n","64 steps took 63.2 seconds\n","Epoch: 0 batch_num: 256\n","train_rmse_target: 0.6753 train_rmse_stderror: 0.06491 train_kl_div: 0.8964\n","val_rmse_target: 0.5743 val_rmse_stderror: 1.807\n","New best_val_rmse: 0.5743\n","\n","64 steps took 63.4 seconds\n","Epoch: 1 batch_num: 37\n","train_rmse_target: 0.5643 train_rmse_stderror: 0.08372 train_kl_div: 0.753\n","val_rmse_target: 0.5473 val_rmse_stderror: 1.797\n","New best_val_rmse: 0.5473\n","\n","32 steps took 31.6 seconds\n","Epoch: 1 batch_num: 69\n","train_rmse_target: 0.4614 train_rmse_stderror: 0.07842 train_kl_div: 0.4508\n","val_rmse_target: 0.556 val_rmse_stderror: 1.809\n","Still best_val_rmse: 0.5473 (from epoch 1)\n","\n","64 steps took 63.2 seconds\n","Epoch: 1 batch_num: 133\n","train_rmse_target: 0.4612 train_rmse_stderror: 0.05261 train_kl_div: 0.4134\n","val_rmse_target: 0.5633 val_rmse_stderror: 1.79\n","Still best_val_rmse: 0.5473 (from epoch 1)\n","\n","64 steps took 63.2 seconds\n","Epoch: 1 batch_num: 197\n","train_rmse_target: 0.6184 train_rmse_stderror: 0.06897 train_kl_div: 0.7651\n","val_rmse_target: 0.6966 val_rmse_stderror: 1.815\n","Still best_val_rmse: 0.5473 (from epoch 1)\n","\n","64 steps took 63.1 seconds\n","Epoch: 1 batch_num: 261\n","train_rmse_target: 0.4703 train_rmse_stderror: 0.06226 train_kl_div: 0.5056\n","val_rmse_target: 0.6108 val_rmse_stderror: 1.816\n","Still best_val_rmse: 0.5473 (from epoch 1)\n","\n","64 steps took 63.4 seconds\n","Epoch: 2 batch_num: 42\n","train_rmse_target: 0.564 train_rmse_stderror: 0.0798 train_kl_div: 0.5497\n","val_rmse_target: 0.5562 val_rmse_stderror: 1.788\n","Still best_val_rmse: 0.5473 (from epoch 1)\n","\n","64 steps took 63.1 seconds\n","Epoch: 2 batch_num: 106\n","train_rmse_target: 0.3602 train_rmse_stderror: 0.03414 train_kl_div: 0.298\n","val_rmse_target: 0.5374 val_rmse_stderror: 1.814\n","New best_val_rmse: 0.5374\n","\n","32 steps took 31.6 seconds\n","Epoch: 2 batch_num: 138\n","train_rmse_target: 0.3781 train_rmse_stderror: 0.04961 train_kl_div: 0.2873\n","val_rmse_target: 0.5503 val_rmse_stderror: 1.784\n","Still best_val_rmse: 0.5374 (from epoch 2)\n","\n","64 steps took 63.1 seconds\n","Epoch: 2 batch_num: 202\n","train_rmse_target: 0.4151 train_rmse_stderror: 0.06878 train_kl_div: 0.3684\n","val_rmse_target: 0.5141 val_rmse_stderror: 1.79\n","New best_val_rmse: 0.5141\n","\n","32 steps took 31.6 seconds\n","Epoch: 2 batch_num: 234\n","train_rmse_target: 0.4381 train_rmse_stderror: 0.0583 train_kl_div: 0.3872\n","val_rmse_target: 0.5026 val_rmse_stderror: 1.786\n","New best_val_rmse: 0.5026\n","\n","32 steps took 31.6 seconds\n","Epoch: 2 batch_num: 266\n","train_rmse_target: 0.2825 train_rmse_stderror: 0.04484 train_kl_div: 0.1692\n","val_rmse_target: 0.5153 val_rmse_stderror: 1.784\n","Still best_val_rmse: 0.5026 (from epoch 2)\n","\n","32 steps took 31.8 seconds\n","Epoch: 3 batch_num: 15\n","train_rmse_target: 0.3961 train_rmse_stderror: 0.0644 train_kl_div: 0.2955\n","val_rmse_target: 0.5186 val_rmse_stderror: 1.804\n","Still best_val_rmse: 0.5026 (from epoch 2)\n","\n","32 steps took 31.6 seconds\n","Epoch: 3 batch_num: 47\n","train_rmse_target: 0.2042 train_rmse_stderror: 0.03631 train_kl_div: 0.09793\n","val_rmse_target: 0.5579 val_rmse_stderror: 1.788\n","Still best_val_rmse: 0.5026 (from epoch 2)\n","\n","64 steps took 63.2 seconds\n","Epoch: 3 batch_num: 111\n","train_rmse_target: 0.2739 train_rmse_stderror: 0.05285 train_kl_div: 0.1562\n","val_rmse_target: 0.5044 val_rmse_stderror: 1.803\n","Still best_val_rmse: 0.5026 (from epoch 2)\n","\n","32 steps took 31.6 seconds\n","Epoch: 3 batch_num: 143\n","train_rmse_target: 0.2403 train_rmse_stderror: 0.05757 train_kl_div: 0.1106\n","val_rmse_target: 0.5023 val_rmse_stderror: 1.803\n","New best_val_rmse: 0.5023\n","\n","32 steps took 31.6 seconds\n","Epoch: 3 batch_num: 175\n","train_rmse_target: 0.2089 train_rmse_stderror: 0.05331 train_kl_div: 0.1037\n","val_rmse_target: 0.4933 val_rmse_stderror: 1.791\n","New best_val_rmse: 0.4933\n","\n","32 steps took 31.6 seconds\n","Epoch: 3 batch_num: 207\n","train_rmse_target: 0.2211 train_rmse_stderror: 0.03955 train_kl_div: 0.1095\n","val_rmse_target: 0.5092 val_rmse_stderror: 1.794\n","Still best_val_rmse: 0.4933 (from epoch 3)\n","\n","32 steps took 31.6 seconds\n","Epoch: 3 batch_num: 239\n","train_rmse_target: 0.2421 train_rmse_stderror: 0.0496 train_kl_div: 0.1315\n","val_rmse_target: 0.5031 val_rmse_stderror: 1.79\n","Still best_val_rmse: 0.4933 (from epoch 3)\n","\n","32 steps took 31.6 seconds\n","Epoch: 3 batch_num: 271\n","train_rmse_target: 0.2821 train_rmse_stderror: 0.08355 train_kl_div: 0.1872\n","val_rmse_target: 0.5208 val_rmse_stderror: 1.797\n","Still best_val_rmse: 0.4933 (from epoch 3)\n","\n","32 steps took 31.9 seconds\n","Epoch: 4 batch_num: 20\n","train_rmse_target: 0.1002 train_rmse_stderror: 0.06623 train_kl_div: 0.04261\n","val_rmse_target: 0.5001 val_rmse_stderror: 1.802\n","Still best_val_rmse: 0.4933 (from epoch 3)\n","\n","32 steps took 31.6 seconds\n","Epoch: 4 batch_num: 52\n","train_rmse_target: 0.1706 train_rmse_stderror: 0.03397 train_kl_div: 0.06398\n","val_rmse_target: 0.5009 val_rmse_stderror: 1.801\n","Still best_val_rmse: 0.4933 (from epoch 3)\n","\n","32 steps took 31.6 seconds\n","Epoch: 4 batch_num: 84\n","train_rmse_target: 0.2028 train_rmse_stderror: 0.0417 train_kl_div: 0.09183\n","val_rmse_target: 0.492 val_rmse_stderror: 1.794\n","New best_val_rmse: 0.492\n","\n","32 steps took 31.6 seconds\n","Epoch: 4 batch_num: 116\n","train_rmse_target: 0.1246 train_rmse_stderror: 0.02549 train_kl_div: 0.03427\n","val_rmse_target: 0.5004 val_rmse_stderror: 1.796\n","Still best_val_rmse: 0.492 (from epoch 4)\n","\n","32 steps took 31.6 seconds\n","Epoch: 4 batch_num: 148\n","train_rmse_target: 0.129 train_rmse_stderror: 0.05103 train_kl_div: 0.04152\n","val_rmse_target: 0.5004 val_rmse_stderror: 1.796\n","Still best_val_rmse: 0.492 (from epoch 4)\n","\n","32 steps took 31.6 seconds\n","Epoch: 4 batch_num: 180\n","train_rmse_target: 0.1565 train_rmse_stderror: 0.04123 train_kl_div: 0.05792\n","val_rmse_target: 0.5064 val_rmse_stderror: 1.795\n","Still best_val_rmse: 0.492 (from epoch 4)\n","\n","32 steps took 31.6 seconds\n","Epoch: 4 batch_num: 212\n","train_rmse_target: 0.2089 train_rmse_stderror: 0.05748 train_kl_div: 0.105\n","val_rmse_target: 0.4996 val_rmse_stderror: 1.796\n","Still best_val_rmse: 0.492 (from epoch 4)\n","\n","32 steps took 31.6 seconds\n","Epoch: 4 batch_num: 244\n","train_rmse_target: 0.2958 train_rmse_stderror: 0.03109 train_kl_div: 0.1816\n","val_rmse_target: 0.4981 val_rmse_stderror: 1.796\n","Still best_val_rmse: 0.492 (from epoch 4)\n","\n","32 steps took 31.6 seconds\n","Epoch: 4 batch_num: 276\n","train_rmse_target: 0.1293 train_rmse_stderror: 0.04942 train_kl_div: 0.04043\n","val_rmse_target: 0.4978 val_rmse_stderror: 1.796\n","Still best_val_rmse: 0.492 (from epoch 4)\n","\n","Performance estimates:\n","[0.49421215826008996, 0.4752608407152704, 0.47807585489870225, 0.4787509217843914, 0.4919866901852834]\n","Mean: 0.4836572931687475\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"m4v-cGx-Mv7S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627844851685,"user_tz":-540,"elapsed":21,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"16e32c73-9a73-4209-85a7-13584987f4b7"},"source":["print(list_val_rmse)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["[0.49421215826008996, 0.4752608407152704, 0.47807585489870225, 0.4787509217843914, 0.4919866901852834]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XU4gRXHCBEpC","executionInfo":{"status":"ok","timestamp":1627844851685,"user_tz":-540,"elapsed":17,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"iAb99KSKBEmd","executionInfo":{"status":"ok","timestamp":1627844851686,"user_tz":-540,"elapsed":18,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"jH0aFzWxBEkG","executionInfo":{"status":"ok","timestamp":1627844851686,"user_tz":-540,"elapsed":17,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"q2CdCMuIKDMP","executionInfo":{"status":"ok","timestamp":1627844851687,"user_tz":-540,"elapsed":18,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#rep = MemReporter(model)\n","#rep.report()"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"eLl1yDOOKIe7","executionInfo":{"status":"ok","timestamp":1627844851687,"user_tz":-540,"elapsed":17,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#rep = MemReporter(model.roberta)\n","#rep.report()"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"7qkqnknA_m9D","executionInfo":{"status":"ok","timestamp":1627844851687,"user_tz":-540,"elapsed":17,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#gpuinfo()"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"PwrqSMdYA6Pu","executionInfo":{"status":"ok","timestamp":1627844851688,"user_tz":-540,"elapsed":17,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#del model\n","#del optimizer \n","#del train_loader\n","#del val_loader\n","#del scheduler \n","#del list_val_rmse\n","#del train_indices\n","#del val_indices\n","#del tokenizer\n","#torch.cuda.empty_cache()\n","#gpuinfo()"],"execution_count":28,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wXcHyUSJXecL"},"source":["# upload models"]},{"cell_type":"code","metadata":{"id":"YIV6UllSIGoa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627844957912,"user_tz":-540,"elapsed":106241,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"2eed6a8b-62a4-4d58-c44d-4f16af00fa52"},"source":["%cd\n","!mkdir .kaggle\n","!mkdir /content/model\n","!cp /content/drive/MyDrive/Colab_Files/kaggle-api/kaggle.json .kaggle/\n","\n","!cp -r /content/model_1.pth /content/model/model_1.pth\n","!cp -r /content/model_2.pth /content/model/model_2.pth\n","!cp -r /content/model_3.pth /content/model/model_3.pth\n","!cp -r /content/model_4.pth /content/model/model_4.pth\n","!cp -r /content/model_5.pth /content/model/model_5.pth\n","!cp -r /content/TFIDF_1.pkl /content/model/TFIDF_1.pkl\n","!cp -r /content/TFIDF_2.pkl /content/model/TFIDF_2.pkl\n","!cp -r /content/TFIDF_3.pkl /content/model/TFIDF_3.pkl\n","!cp -r /content/TFIDF_4.pkl /content/model/TFIDF_4.pkl\n","!cp -r /content/TFIDF_5.pkl /content/model/TFIDF_5.pkl"],"execution_count":29,"outputs":[{"output_type":"stream","text":["/root\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"14ddOZH4IMam","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627845047072,"user_tz":-540,"elapsed":89174,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"9d2d2d09-a924-4bc8-cae7-b8e66707470b"},"source":["def dataset_upload():\n","    import json\n","    from kaggle.api.kaggle_api_extended import KaggleApi\n","\n","    id = f'{USERID}/{EX_NO}'\n","\n","    dataset_metadata = {}\n","    dataset_metadata['id'] = id\n","    dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n","    dataset_metadata['title'] = f'{EX_NO}'\n","\n","    with open(UPLOAD_DIR / 'dataset-metadata.json', 'w') as f:\n","        json.dump(dataset_metadata, f, indent=4)\n","\n","    api = KaggleApi()\n","    api.authenticate()\n","\n","    # データセットがない場合\n","    if f'{USERID}/{EX_NO}' not in [str(d) for d in api.dataset_list(user=USERID, search=f'\"{EX_NO}\"')]:\n","        api.dataset_create_new(folder=UPLOAD_DIR,\n","                               convert_to_csv=False,\n","                               dir_mode='skip')\n","    # データセットがある場合\n","    else:\n","        api.dataset_create_version(folder=UPLOAD_DIR,\n","                                   version_notes='update',\n","                                   convert_to_csv=False,\n","                                   delete_old_versions=True,\n","                                   dir_mode='skip')\n","dataset_upload()\n","\n"],"execution_count":30,"outputs":[{"output_type":"stream","text":["  1%|          | 8.30M/1.33G [00:00<00:16, 85.6MB/s]"],"name":"stderr"},{"output_type":"stream","text":["Starting upload for file model_4.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [00:12<00:00, 113MB/s]\n","  0%|          | 0.00/546k [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_4.pth (1GB)\n","Starting upload for file TFIDF_5.pkl\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 546k/546k [00:00<00:00, 2.21MB/s]\n","  0%|          | 0.00/542k [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: TFIDF_5.pkl (546KB)\n","Starting upload for file TFIDF_1.pkl\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 542k/542k [00:00<00:00, 1.97MB/s]\n","  0%|          | 0.00/544k [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: TFIDF_1.pkl (542KB)\n","Starting upload for file TFIDF_2.pkl\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 544k/544k [00:00<00:00, 3.18MB/s]\n","  0%|          | 0.00/543k [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: TFIDF_2.pkl (544KB)\n","Starting upload for file TFIDF_3.pkl\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 543k/543k [00:00<00:00, 2.41MB/s]\n","  1%|          | 6.87M/1.33G [00:00<00:23, 61.6MB/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: TFIDF_3.pkl (543KB)\n","Starting upload for file model_1.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [00:19<00:00, 71.5MB/s]\n","  0%|          | 6.66M/1.33G [00:00<00:20, 69.7MB/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_1.pth (1GB)\n","Starting upload for file model_5.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [00:12<00:00, 113MB/s]\n","  0%|          | 0.00/543k [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_5.pth (1GB)\n","Starting upload for file TFIDF_4.pkl\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 543k/543k [00:00<00:00, 1.85MB/s]\n","  1%|          | 6.87M/1.33G [00:00<00:22, 61.8MB/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: TFIDF_4.pkl (543KB)\n","Starting upload for file model_3.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [00:15<00:00, 90.2MB/s]\n","  1%|          | 6.87M/1.33G [00:00<00:23, 61.3MB/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_3.pth (1GB)\n","Starting upload for file model_2.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [00:20<00:00, 68.3MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_2.pth (1GB)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":688},"id":"AhqGLA2QAiNd","executionInfo":{"status":"error","timestamp":1627845056865,"user_tz":-540,"elapsed":9796,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"7f2e9b84-7802-456b-d782-1a4c497ad558"},"source":["# validation再実行_予測結果取得\n","\n","all_predictions = np.zeros(len(train_kf_df)) # 推論結果について、「fold　× 推論df」のzero行列で枠を作る\n","\n","for fold_ in sorted(train_kf_df['kfold'].unique()):\n","    model_path = UPLOAD_DIR/f\"model_{fold_ + 1}.pth\" # 対応するモデルを読む\n","    tfidf_path = UPLOAD_DIR/f\"TFIDF_{fold_ + 1}.pkl\"\n","\n","    with open(tfidf_path, 'rb') as f:\n","        tfidf = pickle.load(f)\n","\n","    print(f\"\\nUsing {model_path}\")\n","\n","    val_idx = train_kf_df['kfold'] == fold_\n","    val_df = train_kf_df[val_idx]\n","    val_dataset = LitDataset(val_df, tfidf, inference_only=True) # TestのDataset(何で、もう一回作るのだろう？)\n","    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n","                          drop_last=False, shuffle=False, num_workers=2) # TestのDataLoader\n","\n","    model = LitModel()\n","    model.load_state_dict(torch.load(model_path))    # 対応するモデルから、重みを読み込む\n","    model.to(DEVICE) # モデルをDEVICEへぶち込む\n","\n","    all_predictions[val_idx] = predict(model, val_loader) # 推論結果行列の対象列に、推論結果を入力(以後、繰り返し)\n","\n","    del model\n","    gc.collect()\n"],"execution_count":31,"outputs":[{"output_type":"stream","text":["\n","Using /content/model/model_1.pth\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-888bf2612438>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# モデルをDEVICEへぶち込む\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mall_predictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 推論結果行列の対象列に、推論結果を入力(以後、繰り返し)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-18-6325f32ddce8>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(model, data_loader)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# 勾配の計算をしないblock(inputすると、現状の重みによる推論結果を返す)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tfidf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# data_loaderからbatchごとにinputを得る\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1201\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1227\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;31m# have message field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: Caught NameError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-15-a1405f5951d7>\", line 36, in __getitem__\n    return (input_ids, attention_mask, input_len, input_tfidf)\nNameError: name 'input_tfidf' is not defined\n"]}]},{"cell_type":"code","metadata":{"id":"huJwVMSAPuDO","executionInfo":{"status":"aborted","timestamp":1627845056857,"user_tz":-540,"elapsed":1302,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["train_kf_df['pred'] = all_predictions\n","train_kf_df['diff_sq'] = (train_kf_df['target'] - train_kf_df['pred'])**2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0zzuBPobmLFu","executionInfo":{"status":"aborted","timestamp":1627845056859,"user_tz":-540,"elapsed":1303,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["train_kf_df.plot(kind='scatter', x='target', y='diff_sq')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wpc8ro9hmNci","executionInfo":{"status":"aborted","timestamp":1627845056860,"user_tz":-540,"elapsed":1304,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 二乗誤差が2.0を超えるレコード\n","thr_ = 2.0 \n","train_kf_df[train_kf_df['diff_sq'] > thr_]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ceDI72NumT5-","executionInfo":{"status":"aborted","timestamp":1627845056861,"user_tz":-540,"elapsed":1305,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 二乗誤差が2.0を超える文章\n","thr_ = 2.0 \n","tmp_df = train_kf_df[train_kf_df['diff_sq'] > thr_].copy()\n","for i in tmp_df.index:\n","  print(tmp_df.loc[i].target)\n","  #print(tmp_df.loc[i].standard_error)\n","  print(tmp_df.loc[i].pred)\n","  print(tmp_df.loc[i].excerpt)\n","  print('--------------------------')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q8_oLwX5EBJp","executionInfo":{"status":"aborted","timestamp":1627845056861,"user_tz":-540,"elapsed":1305,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["%env MODEL_OUT_DIR '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/98_model_inf/055-054-train-03'\n","!mkdir -p $MODEL_OUT_DIR\n","!cp -r /content/model/ $MODEL_OUT_DIR"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5LQSg_DrGaGA","executionInfo":{"status":"aborted","timestamp":1627845056861,"user_tz":-540,"elapsed":1305,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["!cp -r /content/model_1.pth /content/model/model_1.pth\n","!cp -r /content/model_2.pth /content/model/model_2.pth\n","!cp -r /content/model_3.pth /content/model/model_3.pth\n","!cp -r /content/model_4.pth /content/model/model_4.pth\n","!cp -r /content/model_5.pth /content/model/model_5.pth\n","!cp -r /content/TFIDF_1.pkl /content/model/TFIDF_1.pkl\n","!cp -r /content/TFIDF_2.pkl /content/model/TFIDF_2.pkl\n","!cp -r /content/TFIDF_3.pkl /content/model/TFIDF_3.pkl\n","!cp -r /content/TFIDF_4.pkl /content/model/TFIDF_4.pkl\n","!cp -r /content/TFIDF_5.pkl /content/model/TFIDF_5.pkl"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RXEPC4eLF9Ts","executionInfo":{"status":"aborted","timestamp":1627845056862,"user_tz":-540,"elapsed":1306,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["model_path_out = Path('/content/model/')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9i8yg_02Gc4M","executionInfo":{"status":"aborted","timestamp":1627845056862,"user_tz":-540,"elapsed":1305,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["for i in list(model_path_out.iterdir()):\n","  print(i)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XHp_ddnKG6mx","executionInfo":{"status":"aborted","timestamp":1627845056862,"user_tz":-540,"elapsed":1305,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["import shutil\n","tgdir = Path('/content/drive/MyDrive/Colab_Files/kaggle/commonlit/98_model_inf/055-054')\n","\n","for file_ in list(model_path_out.iterdir()):\n","  shutil.copy(file_, tgdir)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hvVp32J-HXGn","executionInfo":{"status":"aborted","timestamp":1627845056863,"user_tz":-540,"elapsed":1306,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":null,"outputs":[]}]}