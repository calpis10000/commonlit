{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"044-train-02.ipynb","provenance":[{"file_id":"1MomdP50B716_-do7EgD3qmRMkmkMcZlX","timestamp":1626418937175},{"file_id":"1bhhkorT--y8XXaVLM8hibVgC-tLqZ16P","timestamp":1626358153868},{"file_id":"1WtT2hX6O9Qbt_hb9sF50nM2QmDXFi-XA","timestamp":1626338366006},{"file_id":"1k_p5wftcUeo711Xho1-T5an2Xkneau-J","timestamp":1626323813472},{"file_id":"1Vz2GB2BNTWuefEFkCSh3TBPEIel7KG1t","timestamp":1626317426487},{"file_id":"1djoMWojeaIPopG5tS1jNMohn8ineblRh","timestamp":1626306831897},{"file_id":"1-6tlDO8158Pi6TpptIF884oFaEiT4Uxb","timestamp":1626276420047},{"file_id":"1js8eA3mDNS8mwSpCiHuzPeARFlUPAVrg","timestamp":1626272452526},{"file_id":"1yhcPgulwJtjJKUK9IuRKmNMhJ-4YXGol","timestamp":1626267205517},{"file_id":"1mnnSv0Pofn1QxArywV81VYqnZPB8uUWN","timestamp":1626180468522},{"file_id":"1RRdjt_UAeHmr5QQBAMyC82Fq1s31OWdK","timestamp":1625833136005},{"file_id":"1JPgg44HFemzwk8VSCXih3PejL0idy-C4","timestamp":1625825483466},{"file_id":"1Ye6wqVX71xAAAhmjXkw9IpRvTqeUyJDA","timestamp":1625812137500}],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"b89493b253b74970856eb6b37a46ed72":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d6f116479bcb484bb446f6a3f771800c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a87cc5619a244f329249b32813e23bc1","IPY_MODEL_53d6631917274153b075a9066a62cfa9"]}},"d6f116479bcb484bb446f6a3f771800c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a87cc5619a244f329249b32813e23bc1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_da574321b7a9432f87b36e3b2d0e75f1","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":482,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":482,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c34930447a0548dead49f29d4acf96ad"}},"53d6631917274153b075a9066a62cfa9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9f59ebc8b9444a0a80829d5f59e257a5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 482/482 [00:00&lt;00:00, 16.6kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2467d29ebea34b79b565a54024f9760e"}},"da574321b7a9432f87b36e3b2d0e75f1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c34930447a0548dead49f29d4acf96ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9f59ebc8b9444a0a80829d5f59e257a5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2467d29ebea34b79b565a54024f9760e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8ebcd482a4874be0aace1af29576face":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_60129207d16d4134ae656e337ea93c08","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8cdb48a54b4f4df7ae521e98c6c18519","IPY_MODEL_c96b906ece774de0a09fafee1f9ce92d"]}},"60129207d16d4134ae656e337ea93c08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8cdb48a54b4f4df7ae521e98c6c18519":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0e99ca6c8a1a43d291d03cbb3bc5f9da","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":898823,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":898823,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3141751032ba4f7ea7bc676fded928be"}},"c96b906ece774de0a09fafee1f9ce92d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b3ce258fe392491695092eb9fad71d08","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 899k/899k [00:00&lt;00:00, 928kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_816139d5c8e3406c83eabcceb0ca69b6"}},"0e99ca6c8a1a43d291d03cbb3bc5f9da":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3141751032ba4f7ea7bc676fded928be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b3ce258fe392491695092eb9fad71d08":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"816139d5c8e3406c83eabcceb0ca69b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"46e3c83bea3544fca1e3cf9f6f612cec":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_cb5ba5d37d3b4ae69d08671ceb5eac92","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9042d27899c2496c83bf0c8bead781b4","IPY_MODEL_1ea13b8e865e4409a7332799c66c49a6"]}},"cb5ba5d37d3b4ae69d08671ceb5eac92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9042d27899c2496c83bf0c8bead781b4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_fe14d7d0687e4ed9af88a3c18b2fdf17","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":456318,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":456318,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_970277568ea34302aa13b3079351f837"}},"1ea13b8e865e4409a7332799c66c49a6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e4ef75fbc4bd4993b3ab3c98e2690b9b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 456k/456k [00:04&lt;00:00, 112kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9c81bb30c098462eb0f4a67263ec2a9d"}},"fe14d7d0687e4ed9af88a3c18b2fdf17":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"970277568ea34302aa13b3079351f837":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e4ef75fbc4bd4993b3ab3c98e2690b9b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9c81bb30c098462eb0f4a67263ec2a9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"99fc8b1e770d4451b4c6d55453347439":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_36a02558ac9b423d8e7c8b4cdb4fce40","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_879ec29ca1c741308273ca2f76985ad2","IPY_MODEL_8aef505065764945a5095b3964d44e34"]}},"36a02558ac9b423d8e7c8b4cdb4fce40":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"879ec29ca1c741308273ca2f76985ad2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ec8c13c3fa464a118c3bff3c503830aa","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1355863,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1355863,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0b9971fa3f514aa39daa6d1e988bf3c6"}},"8aef505065764945a5095b3964d44e34":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2d2117670dcb4dad9d16b72bd3cd98a5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.36M/1.36M [00:02&lt;00:00, 598kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3c794437e6a5453ab573458591ba7595"}},"ec8c13c3fa464a118c3bff3c503830aa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0b9971fa3f514aa39daa6d1e988bf3c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2d2117670dcb4dad9d16b72bd3cd98a5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3c794437e6a5453ab573458591ba7595":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"951f47e45dc24bea83c2ee7d1ddff835":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6f93ebaeb5f34bc8a55e240a230980f4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_25c334f063c3455ab47569c56ef436a2","IPY_MODEL_f1ba5ca1a7d54e26992feaf729316d78"]}},"6f93ebaeb5f34bc8a55e240a230980f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"25c334f063c3455ab47569c56ef436a2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3b4e207acf0c43de986f393f5ad39b8e","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1425941629,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1425941629,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e71752b8039940149a887b642546bfb9"}},"f1ba5ca1a7d54e26992feaf729316d78":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_06de09363cb74f53aa32687a66adb015","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.43G/1.43G [00:29&lt;00:00, 49.0MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_552b0d5996d94c20bc7c2d2ccaf289da"}},"3b4e207acf0c43de986f393f5ad39b8e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e71752b8039940149a887b642546bfb9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"06de09363cb74f53aa32687a66adb015":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"552b0d5996d94c20bc7c2d2ccaf289da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":86},"id":"Z6yRwt-PXtbP","executionInfo":{"status":"ok","timestamp":1626419249873,"user_tz":-540,"elapsed":418,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"f2e0b84e-6874-48c0-ebd4-e9e6a6aabdd0"},"source":["\"\"\"\n","if 'google.colab' in sys.modules:  # colab環境特有の処理_初回のみ\n","  # Google Driveのマウント\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","\n","  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules' \\\n","   -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/requirements.txt' \\\n","   --ignore-installed\n","\n","  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules' \\\n","   transformers -U\n","  !pip install gensim==4.0.1 --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\n","  !pip install pytorch_memlab --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\n","\"\"\""],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\nif 'google.colab' in sys.modules:  # colab環境特有の処理_初回のみ\\n  # Google Driveのマウント\\n  from google.colab import drive\\n  drive.mount('/content/drive')\\n\\n  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'    -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/requirements.txt'    --ignore-installed\\n\\n  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'    transformers -U\\n  !pip install gensim==4.0.1 --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\\n  !pip install pytorch_memlab --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\\n\""]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"m9BAZj_HyuIj","executionInfo":{"status":"ok","timestamp":1626419250704,"user_tz":-540,"elapsed":418,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kA8loJjZHY2-","executionInfo":{"status":"ok","timestamp":1626419253002,"user_tz":-540,"elapsed":2303,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"e3a2ac95-72b2-482b-fac4-c3c7a28d7112"},"source":["!pip install pytorch_memlab"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pytorch_memlab in /usr/local/lib/python3.7/dist-packages (0.2.3)\n","Requirement already satisfied: calmsize in /usr/local/lib/python3.7/dist-packages (from pytorch_memlab) (0.1.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytorch_memlab) (57.0.0)\n","Requirement already satisfied: pandas>=0.18 in /usr/local/lib/python3.7/dist-packages (from pytorch_memlab) (1.1.5)\n","Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch_memlab) (1.9.0+cu102)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18->pytorch_memlab) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18->pytorch_memlab) (2.8.1)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18->pytorch_memlab) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->pytorch_memlab) (3.7.4.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.18->pytorch_memlab) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ucCbvGD1XvG7","executionInfo":{"status":"ok","timestamp":1626419253003,"user_tz":-540,"elapsed":10,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"63682d59-9ea0-497d-885f-c8a314a7cce2"},"source":["import sys\n","if 'google.colab' in sys.modules:  # colab特有の処理_2回目以降\n","  # Google Driveのマウント\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","\n","  # データセットをDriveから取得\n","  !mkdir -p 'input'\n","  !cp -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/00_input' '/content/input'\n","\n","  # ライブラリのパス指定\n","  sys.path.append('/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules')\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RV9-VwbpZLZ9","executionInfo":{"status":"ok","timestamp":1626419253440,"user_tz":-540,"elapsed":441,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["from pathlib import Path\n","\n","# input\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    DATA_DIR = Path('../input/commonlitreadabilityprize/')\n","\n","elif 'google.colab' in sys.modules: # Colab環境\n","    !mkdir 'input' -p\n","    !cp '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/00_input/commonlitreadabilityprize/' './input' -r\n","    DATA_DIR = Path('/content/input/commonlitreadabilityprize')\n","\n","else:\n","    DATA_DIR = Path('../00_input/commonlitreadabilityprize/')"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"8tMampUSaDo5","executionInfo":{"status":"ok","timestamp":1626419253441,"user_tz":-540,"elapsed":5,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["from pathlib import Path\n","\n","# pre-trained model\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    PRE_TRAINED_MODEL_DIR = '../input/roberta-transformers-pytorch/roberta-large'\n","elif 'google.colab' in sys.modules: # Colab環境\n","    PRE_TRAINED_MODEL_DIR = 'roberta-large' # 仮で、毎回DLする想定のモデル名を指定。あとで変更予定。\n","else:\n","    PRE_TRAINED_MODEL_DIR = 'roberta-base'"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"tKjsUxnOeDYl","executionInfo":{"status":"ok","timestamp":1626419253441,"user_tz":-540,"elapsed":5,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["from pathlib import Path\n","\n","# pre-trained model\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    PRE_TRAINED_MODEL_DIR = '../input/roberta-transformers-pytorch/roberta-large'\n","elif 'google.colab' in sys.modules: # Colab環境\n","    PRE_TRAINED_MODEL_DIR = 'roberta-large' # 仮で、毎回DLする想定のモデル名を指定。あとで変更予定。\n","else:\n","    PRE_TRAINED_MODEL_DIR = 'roberta-large'"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZLaT2V0ReoAZ","executionInfo":{"status":"ok","timestamp":1626419253442,"user_tz":-540,"elapsed":5,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["UPLOAD_DIR = Path('/content/model')\n","EX_NO = '044-train-02'  # 実験番号などを入れる、folderのpathにする\n","USERID = 'calpis10000'"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"hOGjAb4pAJ0F","executionInfo":{"status":"ok","timestamp":1626419253442,"user_tz":-540,"elapsed":5,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["import subprocess\n","import shlex\n","\n","def gpuinfo():\n","    \"\"\"\n","    Returns size of total GPU RAM and used GPU RAM.\n","\n","    Parameters\n","    ----------\n","    None\n","\n","    Returns\n","    -------\n","    info : dict\n","        Total GPU RAM in integer for key 'total_MiB'.\n","        Used GPU RAM in integer for key 'used_MiB'.\n","    \"\"\"\n","\n","    command = 'nvidia-smi -q -d MEMORY | sed -n \"/FB Memory Usage/,/Free/p\" | sed -e \"1d\" -e \"4d\" -e \"s/ MiB//g\" | cut -d \":\" -f 2 | cut -c2-'\n","    commands = [shlex.split(part) for part in command.split(' | ')]\n","    for i, cmd in enumerate(commands):\n","        if i==0:\n","            res = subprocess.Popen(cmd, stdout=subprocess.PIPE)\n","        else:\n","            res = subprocess.Popen(cmd, stdin=res.stdout, stdout=subprocess.PIPE)\n","    total, used = map(int, res.communicate()[0].decode('utf-8').strip().split('\\n'))\n","    info = {'total_MiB':total, 'used_MiB':used}\n","    return info\n"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g3-6m5MKXecB"},"source":["# Overview\n","This nb is based on copy from https://www.kaggle.com/andretugan/lightweight-roberta-solution-in-pytorch .\n","\n","Acknowledgments(from base nb): \n","some ideas were taken from kernels by [Torch](https://www.kaggle.com/rhtsingh) and [Maunish](https://www.kaggle.com/maunish)."]},{"cell_type":"code","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-04T06:26:32.834365Z","iopub.execute_input":"2021-07-04T06:26:32.834903Z","iopub.status.idle":"2021-07-04T06:26:40.143740Z","shell.execute_reply.started":"2021-07-04T06:26:32.834785Z","shell.execute_reply":"2021-07-04T06:26:40.142864Z"},"trusted":true,"id":"HRsRZ06WXecD","executionInfo":{"status":"ok","timestamp":1626419405703,"user_tz":-540,"elapsed":152266,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["import os\n","import math\n","import random\n","import time\n","\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","\n","from transformers import AdamW # optimizer\n","from transformers import AutoTokenizer\n","from transformers import AutoModel\n","from transformers import AutoConfig\n","from transformers import get_cosine_schedule_with_warmup # scheduler\n","from pytorch_memlab import profile\n","import pytorch_memlab\n","from pytorch_memlab import MemReporter\n","\n","from sklearn.model_selection import KFold, StratifiedKFold\n","\n","import gc\n","gc.enable()"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"bPh2rvoiFrUM","executionInfo":{"status":"ok","timestamp":1626419405704,"user_tz":-540,"elapsed":26,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.145217Z","iopub.execute_input":"2021-07-04T06:26:40.145539Z","iopub.status.idle":"2021-07-04T06:26:40.201326Z","shell.execute_reply.started":"2021-07-04T06:26:40.145504Z","shell.execute_reply":"2021-07-04T06:26:40.200136Z"},"trusted":true,"id":"omBfwshTXecE","executionInfo":{"status":"ok","timestamp":1626419405705,"user_tz":-540,"elapsed":25,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["NUM_FOLDS = 5 # K Fold\n","NUM_EPOCHS = 5 # Epochs\n","BATCH_SIZE = 10 # Batch Size\n","MAX_LEN = 248 # ベクトル長\n","EVAL_SCHEDULE = [(0.50, 64), (0.49, 32), (0.48, 16), (0.47, 8), (0.46, 4), (-1., 1)] # schedulerの何らかの設定？\n","ROBERTA_PATH = PRE_TRAINED_MODEL_DIR # roberta pre-trainedモデル(モデルとして指定)\n","TOKENIZER_PATH = PRE_TRAINED_MODEL_DIR # roberta pre-trainedモデル(Tokenizerとして指定)\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\" # cudaがなければcpuを使えばいいじゃない"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.203398Z","iopub.execute_input":"2021-07-04T06:26:40.204055Z","iopub.status.idle":"2021-07-04T06:26:40.211572Z","shell.execute_reply.started":"2021-07-04T06:26:40.204015Z","shell.execute_reply":"2021-07-04T06:26:40.210762Z"},"trusted":true,"id":"4qcuXqwtXecF","executionInfo":{"status":"ok","timestamp":1626419405706,"user_tz":-540,"elapsed":25,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["def set_random_seed(random_seed):\n","    random.seed(random_seed)\n","    np.random.seed(random_seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(random_seed)\n","\n","    torch.manual_seed(random_seed)\n","    torch.cuda.manual_seed(random_seed)\n","    torch.cuda.manual_seed_all(random_seed)\n","\n","    torch.backends.cudnn.deterministic = True# cudnnによる最適化で結果が変わらないためのおまじない "],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.214188Z","iopub.execute_input":"2021-07-04T06:26:40.214809Z","iopub.status.idle":"2021-07-04T06:26:40.309744Z","shell.execute_reply.started":"2021-07-04T06:26:40.214769Z","shell.execute_reply":"2021-07-04T06:26:40.308926Z"},"trusted":true,"id":"70PyLsJTXecF","executionInfo":{"status":"ok","timestamp":1626419405707,"user_tz":-540,"elapsed":25,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# train, testを読む\n","train_df = pd.read_csv(DATA_DIR/\"train.csv\")\n","\n","# Remove incomplete entries if any.\n","train_df.drop(train_df[(train_df.target == 0) & (train_df.standard_error == 0)].index,\n","              inplace=True)\n","train_df.reset_index(drop=True, inplace=True)\n","\n","test_df = pd.read_csv(DATA_DIR/\"test.csv\")\n","submission_df = pd.read_csv(DATA_DIR/\"sample_submission.csv\")"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"9ZYOB59L8qtA","executionInfo":{"status":"ok","timestamp":1626419405708,"user_tz":-540,"elapsed":25,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"8ccce456-be10-4c11-e747-db41471a55fb"},"source":["train_df.head()\n"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>url_legal</th>\n","      <th>license</th>\n","      <th>excerpt</th>\n","      <th>target</th>\n","      <th>standard_error</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>c12129c31</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>When the young people returned to the ballroom...</td>\n","      <td>-0.340259</td>\n","      <td>0.464009</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>85aa80a4c</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>All through dinner time, Mrs. Fayre was somewh...</td>\n","      <td>-0.315372</td>\n","      <td>0.480805</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>b69ac6792</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>As Roger had predicted, the snow departed as q...</td>\n","      <td>-0.580118</td>\n","      <td>0.476676</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>dd1000b26</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>And outside before the palace a great garden w...</td>\n","      <td>-1.054013</td>\n","      <td>0.450007</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>37c1b32fb</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Once upon a time there were Three Bears who li...</td>\n","      <td>0.247197</td>\n","      <td>0.510845</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          id url_legal  ...    target standard_error\n","0  c12129c31       NaN  ... -0.340259       0.464009\n","1  85aa80a4c       NaN  ... -0.315372       0.480805\n","2  b69ac6792       NaN  ... -0.580118       0.476676\n","3  dd1000b26       NaN  ... -1.054013       0.450007\n","4  37c1b32fb       NaN  ...  0.247197       0.510845\n","\n","[5 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.311021Z","iopub.execute_input":"2021-07-04T06:26:40.311347Z","iopub.status.idle":"2021-07-04T06:26:40.624393Z","shell.execute_reply.started":"2021-07-04T06:26:40.311314Z","shell.execute_reply":"2021-07-04T06:26:40.623347Z"},"trusted":true,"id":"xf0662k4XecF","colab":{"base_uri":"https://localhost:8080/","height":213,"referenced_widgets":["b89493b253b74970856eb6b37a46ed72","d6f116479bcb484bb446f6a3f771800c","a87cc5619a244f329249b32813e23bc1","53d6631917274153b075a9066a62cfa9","da574321b7a9432f87b36e3b2d0e75f1","c34930447a0548dead49f29d4acf96ad","9f59ebc8b9444a0a80829d5f59e257a5","2467d29ebea34b79b565a54024f9760e","8ebcd482a4874be0aace1af29576face","60129207d16d4134ae656e337ea93c08","8cdb48a54b4f4df7ae521e98c6c18519","c96b906ece774de0a09fafee1f9ce92d","0e99ca6c8a1a43d291d03cbb3bc5f9da","3141751032ba4f7ea7bc676fded928be","b3ce258fe392491695092eb9fad71d08","816139d5c8e3406c83eabcceb0ca69b6","46e3c83bea3544fca1e3cf9f6f612cec","cb5ba5d37d3b4ae69d08671ceb5eac92","9042d27899c2496c83bf0c8bead781b4","1ea13b8e865e4409a7332799c66c49a6","fe14d7d0687e4ed9af88a3c18b2fdf17","970277568ea34302aa13b3079351f837","e4ef75fbc4bd4993b3ab3c98e2690b9b","9c81bb30c098462eb0f4a67263ec2a9d","99fc8b1e770d4451b4c6d55453347439","36a02558ac9b423d8e7c8b4cdb4fce40","879ec29ca1c741308273ca2f76985ad2","8aef505065764945a5095b3964d44e34","ec8c13c3fa464a118c3bff3c503830aa","0b9971fa3f514aa39daa6d1e988bf3c6","2d2117670dcb4dad9d16b72bd3cd98a5","3c794437e6a5453ab573458591ba7595"]},"executionInfo":{"status":"ok","timestamp":1626419411329,"user_tz":-540,"elapsed":5644,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"6498b29f-128d-4347-d7c3-1ffa280b7e83"},"source":["# tokenizerを指定\n","tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)"],"execution_count":14,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b89493b253b74970856eb6b37a46ed72","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=482.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8ebcd482a4874be0aace1af29576face","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"46e3c83bea3544fca1e3cf9f6f612cec","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"99fc8b1e770d4451b4c6d55453347439","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355863.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"N6aaghNkXecG"},"source":["# Dataset"]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.628883Z","iopub.execute_input":"2021-07-04T06:26:40.629347Z","iopub.status.idle":"2021-07-04T06:26:40.644338Z","shell.execute_reply.started":"2021-07-04T06:26:40.629309Z","shell.execute_reply":"2021-07-04T06:26:40.643336Z"},"trusted":true,"id":"zkopT0U1XecG","executionInfo":{"status":"ok","timestamp":1626419411334,"user_tz":-540,"elapsed":23,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# Dataset用のClass。おそらく、trainとtestでインスタンスを生成し、DataFrameと同じように扱えるような思想。\n","class LitDataset(Dataset):\n","    def __init__(self, df, inference_only=False):\n","        super().__init__()\n","\n","        self.df = df        \n","        self.inference_only = inference_only # Testデータ用フラグ\n","        self.text = df.excerpt.tolist() # 分析対象カラムをlistにする。(分かち書きではなく、Seriesをlistへ変換するような処理)\n","        #self.text = [text.replace(\"\\n\", \" \") for text in self.text] # 単語単位で分かち書きする場合\n","        \n","        if not self.inference_only:\n","            self.target = torch.tensor(df.target.values, dtype=torch.float32) # trainのみ、targetをtensorに変換\n","            self.standard_error = torch.tensor(df.standard_error.values, dtype=torch.float32) \n","\n","        self.encoded = tokenizer.batch_encode_plus( # textをtokenize\n","            self.text,\n","            padding = 'max_length',            \n","            max_length = MAX_LEN,\n","            truncation = True, # 最大長を超える文字は切り捨て\n","            return_attention_mask=True\n","        )        \n"," \n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    \n","    def __getitem__(self, index): # 変換結果を返す\n","        input_ids = torch.tensor(self.encoded['input_ids'][index])\n","        attention_mask = torch.tensor(self.encoded['attention_mask'][index])\n","        \n","        if self.inference_only:\n","            return (input_ids, attention_mask)            \n","        else:\n","            target = self.target[index]\n","            standard_error = self.standard_error[index]\n","            return (input_ids, attention_mask, target, standard_error)"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KKtdy32wXecG"},"source":["# Model\n","The model is inspired by the one from [Maunish](https://www.kaggle.com/maunish/clrp-roberta-svm)."]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.649629Z","iopub.execute_input":"2021-07-04T06:26:40.650066Z","iopub.status.idle":"2021-07-04T06:26:40.666374Z","shell.execute_reply.started":"2021-07-04T06:26:40.650002Z","shell.execute_reply":"2021-07-04T06:26:40.665211Z"},"trusted":true,"id":"BpkxjXEUXecH","executionInfo":{"status":"ok","timestamp":1626419411335,"user_tz":-540,"elapsed":22,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["class LitModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        config = AutoConfig.from_pretrained(ROBERTA_PATH) # pretrainedからconfigを読み込み\n","        config.update({\"output_hidden_states\":True, # config更新: embedding層を抽出\n","                       \"hidden_dropout_prob\": 0.0, # config更新: dropoutしない\n","                       \"layer_norm_eps\": 1e-7}) # config更新: layer normalizationのepsilon                      \n","        \n","        self.roberta = AutoModel.from_pretrained(ROBERTA_PATH, config=config) # cpuで処理する\n","            \n","        self.attention = nn.Sequential(# attentionレイヤー            \n","            nn.Linear(config.hidden_size, 512),      \n","            nn.Tanh(),                       \n","            nn.Linear(512, 1),\n","            nn.Softmax(dim=1)\n","        )\n","\n","        self.regressor = nn.Sequential( # 出力レイヤー                    \n","            nn.Linear(config.hidden_size, 2)                        \n","        )\n","\n","    def forward(self, input_ids, attention_mask):\n","        roberta_output = self.roberta(input_ids=input_ids, # robertaに入力データを流し、出力としてrobertaモデル(layerの複合体)を得る\n","                                      attention_mask=attention_mask)     \n","\n","        last_hidden_state = roberta_output.hidden_states[-1] # robertaモデルの最後のlayerを得る\n","        weights = self.attention(last_hidden_state) # robertaの最後のlayerをattentionへ入力し、出力として重みを得る                \n","        context_vector = torch.sum(weights * last_hidden_state, dim=1) # 重み×最後の層を足し合わせて文書ベクトルとする。\n","        return self.regressor(context_vector) # 文書ベクトルを線形層に入力し、targetを出力する\n","\n","        # https://www.kaggle.com/rhtsingh/utilizing-transformer-representations-efficiently\n","        #last_hidden_state = roberta_output[0]\n","        #input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        #sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        #sum_mask = input_mask_expanded.sum(1)\n","        #sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        #mean_embeddings = sum_embeddings / sum_mask\n","\n","        \n","        # Now we reduce the context vector to the prediction score.\n","        #return self.regressor(mean_embeddings) # 文書ベクトルを線形層に入力し、targetを出力する"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.672515Z","iopub.execute_input":"2021-07-04T06:26:40.672944Z","iopub.status.idle":"2021-07-04T06:26:40.684593Z","shell.execute_reply.started":"2021-07-04T06:26:40.672908Z","shell.execute_reply":"2021-07-04T06:26:40.683569Z"},"trusted":true,"id":"bB4jvQTxXecH","executionInfo":{"status":"ok","timestamp":1626419411335,"user_tz":-540,"elapsed":21,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 評価指標(MSE)の計算。最終的に、ルートしてRMSEにすると思われる。\n","def eval_mse(model, data_loader):\n","    \"\"\"Evaluates the mean squared error of the |model| on |data_loader|\"\"\"\n","    model.eval() # evalモードを選択。Batch Normとかdropoutをしなくなる           \n","    mse_mean_sum = 0\n","    mse_std_sum = 0\n","\n","    with torch.no_grad(): # 勾配の計算をしないBlock\n","        for batch_num, (input_ids, attention_mask, target, standard_error) in enumerate(data_loader): # data_loaderからinput, attentin_mask, targetをbatchごとに取り出す\n","            input_ids = input_ids.to(DEVICE)   \n","            attention_mask = attention_mask.to(DEVICE)   \n","            target = target.to(DEVICE)      \n","            standard_error = standard_error.to(DEVICE) \n","            \n","            output = model(input_ids, attention_mask) # 取得した値をモデルへ入力し、出力として予測値を得る。\n","\n","            mse_mean_sum += nn.MSELoss(reduction=\"sum\")(output[:,0].flatten(), target).item() # 誤差の合計を得る(Batchごとに計算した誤差を足し上げる)\n","            mse_std_sum += nn.MSELoss(reduction=\"sum\")(output[:,1].flatten(), target).item() # 誤差の合計を得る(Batchごとに計算した誤差を足し上げる)\n","\n","    del input_ids\n","    del attention_mask\n","    del target\n","\n","    mse_mean_result = mse_mean_sum / len(data_loader.dataset)\n","    mse_std_result = mse_std_sum / len(data_loader.dataset)\n","  \n","    return mse_mean_result, mse_std_result # 誤差の合計をdataset長で除し、mseを取得＆返す"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.690155Z","iopub.execute_input":"2021-07-04T06:26:40.692530Z","iopub.status.idle":"2021-07-04T06:26:40.703425Z","shell.execute_reply.started":"2021-07-04T06:26:40.692488Z","shell.execute_reply":"2021-07-04T06:26:40.702366Z"},"trusted":true,"id":"47bDno_LXecI","executionInfo":{"status":"ok","timestamp":1626419411335,"user_tz":-540,"elapsed":20,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 推論結果を返す\n","def predict(model, data_loader):\n","    \"\"\"Returns an np.array with predictions of the |model| on |data_loader|\"\"\"\n","    model.eval() # evalモード(dropout, batch_normしない)\n","\n","    result = np.zeros(len(data_loader.dataset)) # 結果をdataset長のzero配列として用意\n","    index = 0\n","    \n","    with torch.no_grad(): # 勾配の計算をしないblock(inputすると、現状の重みによる推論結果を返す)\n","        for batch_num, (input_ids, attention_mask) in enumerate(data_loader): # data_loaderからbatchごとにinputを得る\n","            input_ids = input_ids.to(DEVICE)\n","            attention_mask = attention_mask.to(DEVICE)\n","                        \n","            output = model(input_ids, attention_mask) # modelにinputを入力し、予測結果を得る。\n","\n","            result[index : index + output[:,0].shape[0]] = output[:,0].flatten().to(\"cpu\") # result[index ~ predの長さ]へ、予測結果を格納\n","            index += pred.shape[0] # indexを更新\n","\n","    return result # 全batchで推論が終わったら、結果を返す"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.708605Z","iopub.execute_input":"2021-07-04T06:26:40.709024Z","iopub.status.idle":"2021-07-04T06:26:40.730675Z","shell.execute_reply.started":"2021-07-04T06:26:40.708983Z","shell.execute_reply":"2021-07-04T06:26:40.729705Z"},"trusted":true,"id":"oInneuAmXecI","executionInfo":{"status":"ok","timestamp":1626419411336,"user_tz":-540,"elapsed":21,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 学習\n","def train(model, # モデル\n","          model_path, # モデルのアウトプット先\n","          train_loader, # train-setのdata_loader\n","          val_loader, # valid-setのdata_loader\n","          optimizer, # optimizer\n","          scheduler=None, # scheduler, デフォルトはNone\n","          num_epochs=NUM_EPOCHS # epoch数、notebook冒頭で指定した値\n","         ):    \n","    \n","    best_val_rmse = None\n","    best_epoch = 0\n","    step = 0\n","    last_eval_step = 0\n","    eval_period = EVAL_SCHEDULE[0][1] # eval期間(って何？) 冒頭で決めたEVAL_SCHEDULEの最初のtupleの[1]を取得\n","\n","    start = time.time() # 時間計測用\n","\n","    for epoch in range(num_epochs): # 指定したEpoch数だけ繰り返し\n","        val_rmse = None         \n","\n","        for batch_num, (input_ids, attention_mask, target, standard_error) in enumerate(train_loader): # train_loaderからinput, targetを取得\n","            input_ids = input_ids.to(DEVICE) # inputをDEVICEへ突っ込む\n","            attention_mask = attention_mask.to(DEVICE)       \n","            target = target.to(DEVICE)\n","            standard_error = standard_error.to(DEVICE)  \n","\n","            optimizer.zero_grad() # 勾配を初期化            \n","            model.train() # 学習モード開始\n","\n","            # https://www.kaggle.com/c/commonlitreadabilityprize/discussion/239421\n","            output = model(input_ids, attention_mask) # input,attention_maskを入力し、予測結果を得る\n","            p = torch.distributions.Normal(output[:,0], torch.sqrt(output[:,1]**2))\n","            q = torch.distributions.Normal(target, standard_error)\n","            kl_vector = torch.distributions.kl_divergence(p, q)\n","            loss = kl_vector.mean()\n","\n","            loss.backward() # 誤差逆伝播法により勾配を得る\n","            optimizer.step() # 重みを更新する\n","\n","            if scheduler:\n","                scheduler.step() # schedulerが与えられた場合は、schedulerの学習率更新\n","            \n","            if step >= last_eval_step + eval_period: # batchを回すごとにstepを増やしていって、「前回evalしたstep + eval_period(16)」を超えたら実行。\n","                # Evaluate the model on val_loader.\n","                elapsed_seconds = time.time() - start # 経過時間\n","                num_steps = step - last_eval_step # 経過ステップ数\n","                print(f\"\\n{num_steps} steps took {elapsed_seconds:0.3} seconds\")\n","                last_eval_step = step # 前回stepの更新\n","                \n","                # valid-setによるrmse計算\n","                train_mean_mse = nn.MSELoss(reduction=\"mean\")(output[:,0].flatten(), target) \n","                train_std_mse = nn.MSELoss(reduction=\"mean\")(torch.sqrt(output[:,1]**2).flatten(), standard_error) \n","\n","                train_mean_rmse = math.sqrt(train_mean_mse)\n","                train_std_rmse = math.sqrt(train_std_mse)\n","\n","                val_mean_mse, val_std_mse = eval_mse(model, val_loader)\n","                val_mean_rmse = math.sqrt(val_mean_mse)                            \n","                val_std_rmse = math.sqrt(val_std_mse)                            \n","\n","                print(f\"Epoch: {epoch} batch_num: {batch_num}\")\n","                print(f\"train_rmse_target: {train_mean_rmse:0.4}\",\n","                      f\"train_rmse_stderror: {train_std_rmse:0.4}\",\n","                      f\"train_kl_div: {loss:0.4}\",\n","                      )\n","                print(f\"val_rmse_target: {val_mean_rmse:0.4}\",\n","                      f\"val_rmse_stderror: {val_std_rmse:0.4}\"\n","                      )\n","\n","                for rmse, period in EVAL_SCHEDULE: # eval_periodをvalid-rmseで切り替える処理\n","                    if val_mean_rmse >= rmse: # valid rmseをEVAL_SCHEDULEと比較し、0項 > valid rmseとなるまで回す : EVAL_SCHEDULE = [(0.50, 16), (0.49, 8), (0.48, 4), (0.47, 2), (-1., 1)]\n","                        eval_period = period # eval_periodを更新\n","                        break                               \n","\n","                if not best_val_rmse or val_mean_rmse < best_val_rmse: # 初回(best_val_rmse==None), またはbest_val_rmseを更新したらモデルを保存する\n","                    best_val_rmse = val_mean_rmse\n","                    best_epoch = epoch\n","                    torch.save(model.state_dict(), model_path) # 最高の自分を保存\n","                    print(f\"New best_val_rmse: {best_val_rmse:0.4}\")\n","                else:       \n","                    print(f\"Still best_val_rmse: {best_val_rmse:0.4}\", # 更新されない場合は、元のスコアを表示\n","                          f\"(from epoch {best_epoch})\")      \n","                                                  \n","                start = time.time()\n","            \n","            # batchごとにメモリ解放\n","            del input_ids\n","            del attention_mask\n","            del target\n","            torch.cuda.empty_cache()                                            \n","            step += 1\n","    \n","    return best_val_rmse"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.735798Z","iopub.execute_input":"2021-07-04T06:26:40.738398Z","iopub.status.idle":"2021-07-04T06:26:40.750876Z","shell.execute_reply.started":"2021-07-04T06:26:40.738356Z","shell.execute_reply":"2021-07-04T06:26:40.749635Z"},"trusted":true,"id":"rMY0fjXwXecJ","executionInfo":{"status":"ok","timestamp":1626419411336,"user_tz":-540,"elapsed":20,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# optimizerの作成\n","def create_optimizer(model):\n","    named_parameters = list(model.named_parameters()) # モデルパラメータの取得\n","    \n","    roberta_parameters = list(model.roberta.named_parameters())[:-2] # パラメータをroberta用、attention用、regressor用に格納。(直接引っ張ってくる形式に変更)\n","    attention_parameters = list(model.attention.named_parameters())\n","    regressor_parameters = list(model.regressor.named_parameters())\n","        \n","    attention_group = [params for (name, params) in attention_parameters] # attention用パラメータをリストとして取得\n","    regressor_group = [params for (name, params) in regressor_parameters] # reg用パラメータをリストとして取得\n","\n","    parameters = []\n","    parameters.append({\"params\": attention_group}) # パラメータをリストに辞書として格納していく\n","    parameters.append({\"params\": regressor_group})\n","\n","    for layer_num, (name, params) in enumerate(roberta_parameters): # レイヤーごとにname, paramsを取得していろんな処理\n","        weight_decay = 0.0 if \"bias\" in name else 0.01\n","\n","        lr = 2e-6\n","\n","        if layer_num >= 69:        \n","            lr = 5e-6\n","\n","        if layer_num >= 133:\n","            lr = 1e-5\n","\n","        parameters.append({\"params\": params,\n","                           \"weight_decay\": weight_decay,\n","                           \"lr\": lr})\n","\n","    return AdamW(parameters) # 最終的に、AdamWにパラメータを入力する。\n"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"EbaJojz0Zjif","executionInfo":{"status":"ok","timestamp":1626419411337,"user_tz":-540,"elapsed":20,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# https://www.kaggle.com/abhishek/step-1-create-folds\n","def create_folds(data, num_splits, SEED, return_df=False):\n","    # we create a new column called kfold and fill it with -1\n","    data[\"kfold\"] = -1\n","    \n","    # the next step is to randomize the rows of the data\n","    data = data.sample(frac=1).reset_index(drop=True)\n","\n","    # calculate number of bins by Sturge's rule\n","    # I take the floor of the value, you can also\n","    # just round it\n","    num_bins = int(np.floor(1 + np.log2(len(data))))\n","    \n","    # bin targets\n","    data.loc[:, \"bins_tg\"] = pd.cut(\n","        data[\"target\"], bins=num_bins, labels=False\n","    ).map(lambda x: str(x))\n","\n","    # bin standard_error\n","    data.loc[:, \"bins_std\"] = pd.cut(\n","        data[\"standard_error\"], bins=num_bins, labels=False\n","    )\n","\n","    # bins\n","    data.loc[:, \"bins\"] = data['bins_tg'].map(lambda x: str(x)) + data['bins_std'].map(lambda x: str(x))\n","\n","    # initiate the kfold class from model_selection module\n","    kf = StratifiedKFold(n_splits=5, random_state=SEED, shuffle=True)\n","\n","    # note that, instead of targets, we use bins!\n","    if return_df:\n","      for f, (t_, v_) in enumerate(kf.split(X=data, y=data.bins.values)):\n","        data.loc[v_, 'kfold'] = f\n","      return data\n","    else:\n","      return kf.split(X=data, y=data.bins.values)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"id":"vAmhaYaylMk5","executionInfo":{"status":"ok","timestamp":1626419411752,"user_tz":-540,"elapsed":435,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"f691140f-1ed9-4119-d1f5-9fdd28af5c20"},"source":["# 検証用\n","SEED = 1000\n","st_kfold_bins_df = create_folds(train_df, num_splits=5, SEED=SEED, return_df=True)\n","st_kfold_bins_df['bins_tg'] = st_kfold_bins_df['bins_tg'].map(lambda x: float(x))\n","st_kfold_bins_df['bins_std'] = st_kfold_bins_df['bins_std'].map(lambda x: float(x))\n","st_kfold_bins_df.groupby('kfold').agg({'bins_tg': ['min', 'max', 'mean'],\n","                                    'bins_std': ['min', 'max', 'mean']})"],"execution_count":22,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  % (min_groups, self.n_splits)), UserWarning)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","\n","    .dataframe thead tr:last-of-type th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th></th>\n","      <th colspan=\"3\" halign=\"left\">bins_tg</th>\n","      <th colspan=\"3\" halign=\"left\">bins_std</th>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <th>min</th>\n","      <th>max</th>\n","      <th>mean</th>\n","      <th>min</th>\n","      <th>max</th>\n","      <th>mean</th>\n","    </tr>\n","    <tr>\n","      <th>kfold</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>5.552028</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>2.938272</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>5.569665</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>2.938272</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>5.544974</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>2.932981</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>5.542403</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>2.899293</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>5.540636</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>2.936396</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      bins_tg                 bins_std                \n","          min   max      mean      min   max      mean\n","kfold                                                 \n","0         0.0  11.0  5.552028      0.0  11.0  2.938272\n","1         0.0  11.0  5.569665      0.0  11.0  2.938272\n","2         0.0  11.0  5.544974      0.0  11.0  2.932981\n","3         0.0  11.0  5.542403      0.0  11.0  2.899293\n","4         0.0  11.0  5.540636      0.0  11.0  2.936396"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"TyjgRCu3mmqG","executionInfo":{"status":"ok","timestamp":1626419411752,"user_tz":-540,"elapsed":10,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"4PLKHwvKtNBn","executionInfo":{"status":"ok","timestamp":1626419411753,"user_tz":-540,"elapsed":10,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["def train_and_save_model(train_indices, val_indices, model_path):\n","    train_dataset = LitDataset(train_df.loc[train_indices]) # train, validのDataset\n","    val_dataset = LitDataset(train_df.loc[val_indices])\n","        \n","    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n","                              drop_last=True, shuffle=True, num_workers=2) # train, validのDataLoader\n","    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n","                            drop_last=False, shuffle=False, num_workers=2)    \n","\n","    model = LitModel().to(DEVICE) # modelをDEVICEへぶち込む\n","    optimizer = create_optimizer(model) # optimizerをモデルから作成\n","    scheduler = get_cosine_schedule_with_warmup( # schedulerを作成\n","        optimizer,\n","        num_training_steps=NUM_EPOCHS * len(train_loader),\n","        num_warmup_steps=50)    \n","    rmse = train(model, model_path, train_loader, val_loader, optimizer, scheduler=scheduler)\n","\n","    del train_dataset\n","    del val_dataset\n","    del train_loader\n","    del val_loader\n","    del model\n","    del optimizer\n","    del scheduler\n","    gc.collect() \n","    torch.cuda.empty_cache()\n","    return rmse"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.755813Z","iopub.execute_input":"2021-07-04T06:26:40.758373Z","iopub.status.idle":"2021-07-04T06:27:12.493221Z","shell.execute_reply.started":"2021-07-04T06:26:40.758265Z","shell.execute_reply":"2021-07-04T06:27:12.490139Z"},"trusted":true,"id":"k2LGJD3XXecK","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["951f47e45dc24bea83c2ee7d1ddff835","6f93ebaeb5f34bc8a55e240a230980f4","25c334f063c3455ab47569c56ef436a2","f1ba5ca1a7d54e26992feaf729316d78","3b4e207acf0c43de986f393f5ad39b8e","e71752b8039940149a887b642546bfb9","06de09363cb74f53aa32687a66adb015","552b0d5996d94c20bc7c2d2ccaf289da"]},"executionInfo":{"status":"ok","timestamp":1626424789704,"user_tz":-540,"elapsed":5377960,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"a6f1d99f-cdd9-4bd9-ce00-df68cd77f253"},"source":["# 実行処理。 KFold & 学習\n","SEED = 1000\n","list_val_rmse = []\n","\n","#kfold = KFold(n_splits=NUM_FOLDS, random_state=SEED, shuffle=True)\n","kfold = create_folds(train_df, 5, SEED=SEED, return_df=False) # binsで切る場合\n","\n","for fold, (train_indices, val_indices) in enumerate(kfold):    \n","    print(f\"\\nFold {fold + 1}/{NUM_FOLDS}\")\n","    print(gpuinfo())\n","    model_path = f\"model_{fold + 1}.pth\" # model_fold数_.pth\n","    set_random_seed(SEED + fold) # SEEDはfold別に変わるようにする\n","    list_val_rmse.append(train_and_save_model(train_indices, val_indices, model_path))\n","\n","    print(\"\\nPerformance estimates:\")\n","    print(list_val_rmse)\n","    print(\"Mean:\", np.array(list_val_rmse).mean())\n","    print(gpuinfo())"],"execution_count":24,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  % (min_groups, self.n_splits)), UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Fold 1/5\n","{'total_MiB': 16160, 'used_MiB': 2}\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"951f47e45dc24bea83c2ee7d1ddff835","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1425941629.0, style=ProgressStyle(descr…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 44.9 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.6692 train_rmse_stderror: 0.1012 train_kl_div: 0.7481\n","val_rmse_target: 0.6913 val_rmse_stderror: 1.775\n","New best_val_rmse: 0.6913\n","\n","64 steps took 44.2 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.5487 train_rmse_stderror: 0.0601 train_kl_div: 0.5886\n","val_rmse_target: 0.6594 val_rmse_stderror: 1.838\n","New best_val_rmse: 0.6594\n","\n","64 steps took 44.2 seconds\n","Epoch: 0 batch_num: 192\n","train_rmse_target: 0.6179 train_rmse_stderror: 0.05691 train_kl_div: 0.7617\n","val_rmse_target: 0.6032 val_rmse_stderror: 1.82\n","New best_val_rmse: 0.6032\n","\n","64 steps took 44.4 seconds\n","Epoch: 1 batch_num: 30\n","train_rmse_target: 0.5655 train_rmse_stderror: 0.03667 train_kl_div: 0.6378\n","val_rmse_target: 0.548 val_rmse_stderror: 1.817\n","New best_val_rmse: 0.548\n","\n","64 steps took 44.2 seconds\n","Epoch: 1 batch_num: 94\n","train_rmse_target: 0.4365 train_rmse_stderror: 0.03885 train_kl_div: 0.3908\n","val_rmse_target: 0.7057 val_rmse_stderror: 1.789\n","Still best_val_rmse: 0.548 (from epoch 1)\n","\n","64 steps took 44.2 seconds\n","Epoch: 1 batch_num: 158\n","train_rmse_target: 0.3474 train_rmse_stderror: 0.03191 train_kl_div: 0.2626\n","val_rmse_target: 0.5422 val_rmse_stderror: 1.833\n","New best_val_rmse: 0.5422\n","\n","64 steps took 44.2 seconds\n","Epoch: 1 batch_num: 222\n","train_rmse_target: 0.6091 train_rmse_stderror: 0.05226 train_kl_div: 0.7425\n","val_rmse_target: 0.5841 val_rmse_stderror: 1.812\n","Still best_val_rmse: 0.5422 (from epoch 1)\n","\n","64 steps took 44.4 seconds\n","Epoch: 2 batch_num: 60\n","train_rmse_target: 0.3072 train_rmse_stderror: 0.05039 train_kl_div: 0.1905\n","val_rmse_target: 0.5525 val_rmse_stderror: 1.805\n","Still best_val_rmse: 0.5422 (from epoch 1)\n","\n","64 steps took 44.3 seconds\n","Epoch: 2 batch_num: 124\n","train_rmse_target: 0.3713 train_rmse_stderror: 0.03067 train_kl_div: 0.2763\n","val_rmse_target: 0.578 val_rmse_stderror: 1.819\n","Still best_val_rmse: 0.5422 (from epoch 1)\n","\n","64 steps took 44.2 seconds\n","Epoch: 2 batch_num: 188\n","train_rmse_target: 0.3735 train_rmse_stderror: 0.04537 train_kl_div: 0.2654\n","val_rmse_target: 0.5183 val_rmse_stderror: 1.83\n","New best_val_rmse: 0.5183\n","\n","64 steps took 44.4 seconds\n","Epoch: 3 batch_num: 26\n","train_rmse_target: 0.325 train_rmse_stderror: 0.02505 train_kl_div: 0.2349\n","val_rmse_target: 0.557 val_rmse_stderror: 1.813\n","Still best_val_rmse: 0.5183 (from epoch 2)\n","\n","64 steps took 44.2 seconds\n","Epoch: 3 batch_num: 90\n","train_rmse_target: 0.2271 train_rmse_stderror: 0.02783 train_kl_div: 0.1104\n","val_rmse_target: 0.524 val_rmse_stderror: 1.822\n","Still best_val_rmse: 0.5183 (from epoch 2)\n","\n","64 steps took 44.2 seconds\n","Epoch: 3 batch_num: 154\n","train_rmse_target: 0.1886 train_rmse_stderror: 0.02015 train_kl_div: 0.08224\n","val_rmse_target: 0.534 val_rmse_stderror: 1.814\n","Still best_val_rmse: 0.5183 (from epoch 2)\n","\n","64 steps took 44.2 seconds\n","Epoch: 3 batch_num: 218\n","train_rmse_target: 0.1686 train_rmse_stderror: 0.02721 train_kl_div: 0.0568\n","val_rmse_target: 0.5335 val_rmse_stderror: 1.814\n","Still best_val_rmse: 0.5183 (from epoch 2)\n","\n","64 steps took 44.5 seconds\n","Epoch: 4 batch_num: 56\n","train_rmse_target: 0.3151 train_rmse_stderror: 0.0376 train_kl_div: 0.1619\n","val_rmse_target: 0.5402 val_rmse_stderror: 1.815\n","Still best_val_rmse: 0.5183 (from epoch 2)\n","\n","64 steps took 44.3 seconds\n","Epoch: 4 batch_num: 120\n","train_rmse_target: 0.2438 train_rmse_stderror: 0.02497 train_kl_div: 0.1291\n","val_rmse_target: 0.539 val_rmse_stderror: 1.814\n","Still best_val_rmse: 0.5183 (from epoch 2)\n","\n","64 steps took 44.4 seconds\n","Epoch: 4 batch_num: 184\n","train_rmse_target: 0.1575 train_rmse_stderror: 0.02889 train_kl_div: 0.05557\n","val_rmse_target: 0.5362 val_rmse_stderror: 1.818\n","Still best_val_rmse: 0.5183 (from epoch 2)\n","\n","Performance estimates:\n","[0.5183445760211193]\n","Mean: 0.5183445760211193\n","{'total_MiB': 16160, 'used_MiB': 1359}\n","\n","Fold 2/5\n","{'total_MiB': 16160, 'used_MiB': 1359}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 44.8 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.852 train_rmse_stderror: 0.08278 train_kl_div: 1.355\n","val_rmse_target: 0.813 val_rmse_stderror: 1.838\n","New best_val_rmse: 0.813\n","\n","64 steps took 44.4 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.9071 train_rmse_stderror: 0.04054 train_kl_div: 1.667\n","val_rmse_target: 0.6248 val_rmse_stderror: 1.792\n","New best_val_rmse: 0.6248\n","\n","64 steps took 44.3 seconds\n","Epoch: 0 batch_num: 192\n","train_rmse_target: 0.5212 train_rmse_stderror: 0.02846 train_kl_div: 0.5481\n","val_rmse_target: 0.532 val_rmse_stderror: 1.822\n","New best_val_rmse: 0.532\n","\n","64 steps took 44.6 seconds\n","Epoch: 1 batch_num: 30\n","train_rmse_target: 0.387 train_rmse_stderror: 0.03638 train_kl_div: 0.3071\n","val_rmse_target: 0.523 val_rmse_stderror: 1.794\n","New best_val_rmse: 0.523\n","\n","64 steps took 44.4 seconds\n","Epoch: 1 batch_num: 94\n","train_rmse_target: 0.4785 train_rmse_stderror: 0.02886 train_kl_div: 0.451\n","val_rmse_target: 0.5351 val_rmse_stderror: 1.791\n","Still best_val_rmse: 0.523 (from epoch 1)\n","\n","64 steps took 44.4 seconds\n","Epoch: 1 batch_num: 158\n","train_rmse_target: 0.3642 train_rmse_stderror: 0.04623 train_kl_div: 0.2783\n","val_rmse_target: 0.6241 val_rmse_stderror: 1.797\n","Still best_val_rmse: 0.523 (from epoch 1)\n","\n","64 steps took 44.4 seconds\n","Epoch: 1 batch_num: 222\n","train_rmse_target: 0.3949 train_rmse_stderror: 0.03036 train_kl_div: 0.3543\n","val_rmse_target: 0.4868 val_rmse_stderror: 1.797\n","New best_val_rmse: 0.4868\n","\n","16 steps took 11.3 seconds\n","Epoch: 2 batch_num: 12\n","train_rmse_target: 0.2781 train_rmse_stderror: 0.01752 train_kl_div: 0.1647\n","val_rmse_target: 0.4783 val_rmse_stderror: 1.801\n","New best_val_rmse: 0.4783\n","\n","8 steps took 5.52 seconds\n","Epoch: 2 batch_num: 20\n","train_rmse_target: 0.5053 train_rmse_stderror: 0.0269 train_kl_div: 0.4773\n","val_rmse_target: 0.4822 val_rmse_stderror: 1.801\n","Still best_val_rmse: 0.4783 (from epoch 2)\n","\n","16 steps took 11.1 seconds\n","Epoch: 2 batch_num: 36\n","train_rmse_target: 0.4101 train_rmse_stderror: 0.03966 train_kl_div: 0.3477\n","val_rmse_target: 0.4782 val_rmse_stderror: 1.793\n","New best_val_rmse: 0.4782\n","\n","8 steps took 5.56 seconds\n","Epoch: 2 batch_num: 44\n","train_rmse_target: 0.4189 train_rmse_stderror: 0.02751 train_kl_div: 0.3339\n","val_rmse_target: 0.5004 val_rmse_stderror: 1.812\n","Still best_val_rmse: 0.4782 (from epoch 2)\n","\n","64 steps took 44.4 seconds\n","Epoch: 2 batch_num: 108\n","train_rmse_target: 0.3434 train_rmse_stderror: 0.02574 train_kl_div: 0.2358\n","val_rmse_target: 0.4845 val_rmse_stderror: 1.797\n","Still best_val_rmse: 0.4782 (from epoch 2)\n","\n","16 steps took 11.1 seconds\n","Epoch: 2 batch_num: 124\n","train_rmse_target: 0.4352 train_rmse_stderror: 0.03351 train_kl_div: 0.39\n","val_rmse_target: 0.4827 val_rmse_stderror: 1.805\n","Still best_val_rmse: 0.4782 (from epoch 2)\n","\n","16 steps took 11.1 seconds\n","Epoch: 2 batch_num: 140\n","train_rmse_target: 0.2593 train_rmse_stderror: 0.0312 train_kl_div: 0.1476\n","val_rmse_target: 0.478 val_rmse_stderror: 1.812\n","New best_val_rmse: 0.478\n","\n","8 steps took 5.56 seconds\n","Epoch: 2 batch_num: 148\n","train_rmse_target: 0.2776 train_rmse_stderror: 0.03311 train_kl_div: 0.1573\n","val_rmse_target: 0.4941 val_rmse_stderror: 1.779\n","Still best_val_rmse: 0.478 (from epoch 2)\n","\n","32 steps took 22.2 seconds\n","Epoch: 2 batch_num: 180\n","train_rmse_target: 0.3085 train_rmse_stderror: 0.02727 train_kl_div: 0.1929\n","val_rmse_target: 0.4839 val_rmse_stderror: 1.792\n","Still best_val_rmse: 0.478 (from epoch 2)\n","\n","16 steps took 11.1 seconds\n","Epoch: 2 batch_num: 196\n","train_rmse_target: 0.3107 train_rmse_stderror: 0.03828 train_kl_div: 0.2033\n","val_rmse_target: 0.5011 val_rmse_stderror: 1.793\n","Still best_val_rmse: 0.478 (from epoch 2)\n","\n","64 steps took 44.6 seconds\n","Epoch: 3 batch_num: 34\n","train_rmse_target: 0.1395 train_rmse_stderror: 0.0297 train_kl_div: 0.04591\n","val_rmse_target: 0.4817 val_rmse_stderror: 1.793\n","Still best_val_rmse: 0.478 (from epoch 2)\n","\n","16 steps took 11.1 seconds\n","Epoch: 3 batch_num: 50\n","train_rmse_target: 0.2032 train_rmse_stderror: 0.03587 train_kl_div: 0.08488\n","val_rmse_target: 0.4743 val_rmse_stderror: 1.803\n","New best_val_rmse: 0.4743\n","\n","8 steps took 5.55 seconds\n","Epoch: 3 batch_num: 58\n","train_rmse_target: 0.2673 train_rmse_stderror: 0.04745 train_kl_div: 0.1241\n","val_rmse_target: 0.4759 val_rmse_stderror: 1.79\n","Still best_val_rmse: 0.4743 (from epoch 3)\n","\n","8 steps took 5.55 seconds\n","Epoch: 3 batch_num: 66\n","train_rmse_target: 0.174 train_rmse_stderror: 0.04131 train_kl_div: 0.05959\n","val_rmse_target: 0.4854 val_rmse_stderror: 1.796\n","Still best_val_rmse: 0.4743 (from epoch 3)\n","\n","16 steps took 11.1 seconds\n","Epoch: 3 batch_num: 82\n","train_rmse_target: 0.2297 train_rmse_stderror: 0.02743 train_kl_div: 0.1174\n","val_rmse_target: 0.4842 val_rmse_stderror: 1.798\n","Still best_val_rmse: 0.4743 (from epoch 3)\n","\n","16 steps took 11.1 seconds\n","Epoch: 3 batch_num: 98\n","train_rmse_target: 0.2267 train_rmse_stderror: 0.03742 train_kl_div: 0.1019\n","val_rmse_target: 0.4813 val_rmse_stderror: 1.792\n","Still best_val_rmse: 0.4743 (from epoch 3)\n","\n","16 steps took 11.1 seconds\n","Epoch: 3 batch_num: 114\n","train_rmse_target: 0.2252 train_rmse_stderror: 0.02472 train_kl_div: 0.1189\n","val_rmse_target: 0.4828 val_rmse_stderror: 1.796\n","Still best_val_rmse: 0.4743 (from epoch 3)\n","\n","16 steps took 11.1 seconds\n","Epoch: 3 batch_num: 130\n","train_rmse_target: 0.1527 train_rmse_stderror: 0.02645 train_kl_div: 0.0516\n","val_rmse_target: 0.4793 val_rmse_stderror: 1.788\n","Still best_val_rmse: 0.4743 (from epoch 3)\n","\n","8 steps took 5.54 seconds\n","Epoch: 3 batch_num: 138\n","train_rmse_target: 0.1125 train_rmse_stderror: 0.02631 train_kl_div: 0.02924\n","val_rmse_target: 0.4777 val_rmse_stderror: 1.797\n","Still best_val_rmse: 0.4743 (from epoch 3)\n","\n","8 steps took 5.56 seconds\n","Epoch: 3 batch_num: 146\n","train_rmse_target: 0.2269 train_rmse_stderror: 0.0205 train_kl_div: 0.1103\n","val_rmse_target: 0.4803 val_rmse_stderror: 1.797\n","Still best_val_rmse: 0.4743 (from epoch 3)\n","\n","16 steps took 11.1 seconds\n","Epoch: 3 batch_num: 162\n","train_rmse_target: 0.1472 train_rmse_stderror: 0.0231 train_kl_div: 0.04577\n","val_rmse_target: 0.4778 val_rmse_stderror: 1.798\n","Still best_val_rmse: 0.4743 (from epoch 3)\n","\n","8 steps took 5.55 seconds\n","Epoch: 3 batch_num: 170\n","train_rmse_target: 0.2176 train_rmse_stderror: 0.05091 train_kl_div: 0.108\n","val_rmse_target: 0.4803 val_rmse_stderror: 1.798\n","Still best_val_rmse: 0.4743 (from epoch 3)\n","\n","16 steps took 11.1 seconds\n","Epoch: 3 batch_num: 186\n","train_rmse_target: 0.1709 train_rmse_stderror: 0.03301 train_kl_div: 0.05681\n","val_rmse_target: 0.4821 val_rmse_stderror: 1.797\n","Still best_val_rmse: 0.4743 (from epoch 3)\n","\n","16 steps took 11.1 seconds\n","Epoch: 3 batch_num: 202\n","train_rmse_target: 0.1686 train_rmse_stderror: 0.02693 train_kl_div: 0.05882\n","val_rmse_target: 0.4771 val_rmse_stderror: 1.796\n","Still best_val_rmse: 0.4743 (from epoch 3)\n","\n","8 steps took 5.53 seconds\n","Epoch: 3 batch_num: 210\n","train_rmse_target: 0.1693 train_rmse_stderror: 0.03646 train_kl_div: 0.06209\n","val_rmse_target: 0.4806 val_rmse_stderror: 1.807\n","Still best_val_rmse: 0.4743 (from epoch 3)\n","\n","16 steps took 11.3 seconds\n","Epoch: 4 batch_num: 0\n","train_rmse_target: 0.2315 train_rmse_stderror: 0.02423 train_kl_div: 0.1095\n","val_rmse_target: 0.4818 val_rmse_stderror: 1.786\n","Still best_val_rmse: 0.4743 (from epoch 3)\n","\n","16 steps took 11.1 seconds\n","Epoch: 4 batch_num: 16\n","train_rmse_target: 0.1484 train_rmse_stderror: 0.02844 train_kl_div: 0.04725\n","val_rmse_target: 0.4766 val_rmse_stderror: 1.805\n","Still best_val_rmse: 0.4743 (from epoch 3)\n","\n","8 steps took 5.55 seconds\n","Epoch: 4 batch_num: 24\n","train_rmse_target: 0.1291 train_rmse_stderror: 0.03941 train_kl_div: 0.03659\n","val_rmse_target: 0.4776 val_rmse_stderror: 1.799\n","Still best_val_rmse: 0.4743 (from epoch 3)\n","\n","8 steps took 5.56 seconds\n","Epoch: 4 batch_num: 32\n","train_rmse_target: 0.1329 train_rmse_stderror: 0.02671 train_kl_div: 0.04066\n","val_rmse_target: 0.4836 val_rmse_stderror: 1.792\n","Still best_val_rmse: 0.4743 (from epoch 3)\n","\n","16 steps took 11.1 seconds\n","Epoch: 4 batch_num: 48\n","train_rmse_target: 0.1537 train_rmse_stderror: 0.03095 train_kl_div: 0.04596\n","val_rmse_target: 0.4834 val_rmse_stderror: 1.799\n","Still best_val_rmse: 0.4743 (from epoch 3)\n","\n","16 steps took 11.1 seconds\n","Epoch: 4 batch_num: 64\n","train_rmse_target: 0.2186 train_rmse_stderror: 0.03127 train_kl_div: 0.1052\n","val_rmse_target: 0.4797 val_rmse_stderror: 1.793\n","Still best_val_rmse: 0.4743 (from epoch 3)\n","\n","8 steps took 5.54 seconds\n","Epoch: 4 batch_num: 72\n","train_rmse_target: 0.158 train_rmse_stderror: 0.01685 train_kl_div: 0.0472\n","val_rmse_target: 0.4789 val_rmse_stderror: 1.796\n","Still best_val_rmse: 0.4743 (from epoch 3)\n","\n","8 steps took 5.57 seconds\n","Epoch: 4 batch_num: 80\n","train_rmse_target: 0.1332 train_rmse_stderror: 0.0376 train_kl_div: 0.03854\n","val_rmse_target: 0.4777 val_rmse_stderror: 1.8\n","Still best_val_rmse: 0.4743 (from epoch 3)\n","\n","8 steps took 5.55 seconds\n","Epoch: 4 batch_num: 88\n","train_rmse_target: 0.1459 train_rmse_stderror: 0.01921 train_kl_div: 0.04418\n","val_rmse_target: 0.4774 val_rmse_stderror: 1.8\n","Still best_val_rmse: 0.4743 (from epoch 3)\n","\n","8 steps took 5.55 seconds\n","Epoch: 4 batch_num: 96\n","train_rmse_target: 0.1866 train_rmse_stderror: 0.04076 train_kl_div: 0.06171\n","val_rmse_target: 0.4796 val_rmse_stderror: 1.798\n","Still best_val_rmse: 0.4743 (from epoch 3)\n","\n","8 steps took 5.56 seconds\n","Epoch: 4 batch_num: 104\n","train_rmse_target: 0.1841 train_rmse_stderror: 0.03192 train_kl_div: 0.05724\n","val_rmse_target: 0.4807 val_rmse_stderror: 1.796\n","Still best_val_rmse: 0.4743 (from epoch 3)\n","\n","16 steps took 11.1 seconds\n","Epoch: 4 batch_num: 120\n","train_rmse_target: 0.1235 train_rmse_stderror: 0.03571 train_kl_div: 0.03453\n","val_rmse_target: 0.4795 val_rmse_stderror: 1.796\n","Still best_val_rmse: 0.4743 (from epoch 3)\n","\n","8 steps took 5.56 seconds\n","Epoch: 4 batch_num: 128\n","train_rmse_target: 0.1501 train_rmse_stderror: 0.03225 train_kl_div: 0.05097\n","val_rmse_target: 0.4796 val_rmse_stderror: 1.797\n","Still best_val_rmse: 0.4743 (from epoch 3)\n","\n","8 steps took 5.56 seconds\n","Epoch: 4 batch_num: 136\n","train_rmse_target: 0.1419 train_rmse_stderror: 0.02642 train_kl_div: 0.04743\n","val_rmse_target: 0.4804 val_rmse_stderror: 1.797\n","Still best_val_rmse: 0.4743 (from epoch 3)\n","\n","16 steps took 11.1 seconds\n","Epoch: 4 batch_num: 152\n","train_rmse_target: 0.09432 train_rmse_stderror: 0.02387 train_kl_div: 0.01811\n","val_rmse_target: 0.4811 val_rmse_stderror: 1.798\n","Still best_val_rmse: 0.4743 (from epoch 3)\n","\n","16 steps took 11.1 seconds\n","Epoch: 4 batch_num: 168\n","train_rmse_target: 0.1129 train_rmse_stderror: 0.03127 train_kl_div: 0.0215\n","val_rmse_target: 0.4812 val_rmse_stderror: 1.799\n","Still best_val_rmse: 0.4743 (from epoch 3)\n","\n","16 steps took 11.1 seconds\n","Epoch: 4 batch_num: 184\n","train_rmse_target: 0.1252 train_rmse_stderror: 0.01756 train_kl_div: 0.03331\n","val_rmse_target: 0.4808 val_rmse_stderror: 1.798\n","Still best_val_rmse: 0.4743 (from epoch 3)\n","\n","16 steps took 11.1 seconds\n","Epoch: 4 batch_num: 200\n","train_rmse_target: 0.1311 train_rmse_stderror: 0.02716 train_kl_div: 0.04302\n","val_rmse_target: 0.4808 val_rmse_stderror: 1.797\n","Still best_val_rmse: 0.4743 (from epoch 3)\n","\n","16 steps took 11.1 seconds\n","Epoch: 4 batch_num: 216\n","train_rmse_target: 0.1108 train_rmse_stderror: 0.03024 train_kl_div: 0.03014\n","val_rmse_target: 0.4808 val_rmse_stderror: 1.797\n","Still best_val_rmse: 0.4743 (from epoch 3)\n","\n","Performance estimates:\n","[0.5183445760211193, 0.47429897158209877]\n","Mean: 0.496321773801609\n","{'total_MiB': 16160, 'used_MiB': 1359}\n","\n","Fold 3/5\n","{'total_MiB': 16160, 'used_MiB': 1359}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 44.8 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.6678 train_rmse_stderror: 0.08601 train_kl_div: 0.8759\n","val_rmse_target: 0.6772 val_rmse_stderror: 1.176\n","New best_val_rmse: 0.6772\n","\n","64 steps took 44.2 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.8183 train_rmse_stderror: 0.03957 train_kl_div: 1.41\n","val_rmse_target: 0.6318 val_rmse_stderror: 1.119\n","New best_val_rmse: 0.6318\n","\n","64 steps took 44.2 seconds\n","Epoch: 0 batch_num: 192\n","train_rmse_target: 0.4281 train_rmse_stderror: 0.0419 train_kl_div: 0.3625\n","val_rmse_target: 0.556 val_rmse_stderror: 1.131\n","New best_val_rmse: 0.556\n","\n","64 steps took 44.5 seconds\n","Epoch: 1 batch_num: 30\n","train_rmse_target: 0.3957 train_rmse_stderror: 0.0361 train_kl_div: 0.2735\n","val_rmse_target: 0.5358 val_rmse_stderror: 1.116\n","New best_val_rmse: 0.5358\n","\n","64 steps took 44.4 seconds\n","Epoch: 1 batch_num: 94\n","train_rmse_target: 0.418 train_rmse_stderror: 0.04687 train_kl_div: 0.3761\n","val_rmse_target: 0.5582 val_rmse_stderror: 1.117\n","Still best_val_rmse: 0.5358 (from epoch 1)\n","\n","64 steps took 44.4 seconds\n","Epoch: 1 batch_num: 158\n","train_rmse_target: 0.5318 train_rmse_stderror: 0.03624 train_kl_div: 0.5387\n","val_rmse_target: 0.5363 val_rmse_stderror: 1.126\n","Still best_val_rmse: 0.5358 (from epoch 1)\n","\n","64 steps took 44.4 seconds\n","Epoch: 1 batch_num: 222\n","train_rmse_target: 0.4533 train_rmse_stderror: 0.02988 train_kl_div: 0.4345\n","val_rmse_target: 0.5202 val_rmse_stderror: 1.136\n","New best_val_rmse: 0.5202\n","\n","64 steps took 44.7 seconds\n","Epoch: 2 batch_num: 60\n","train_rmse_target: 0.3054 train_rmse_stderror: 0.02734 train_kl_div: 0.1958\n","val_rmse_target: 0.5023 val_rmse_stderror: 1.121\n","New best_val_rmse: 0.5023\n","\n","64 steps took 44.4 seconds\n","Epoch: 2 batch_num: 124\n","train_rmse_target: 0.3134 train_rmse_stderror: 0.03996 train_kl_div: 0.1828\n","val_rmse_target: 0.5245 val_rmse_stderror: 1.132\n","Still best_val_rmse: 0.5023 (from epoch 2)\n","\n","64 steps took 44.5 seconds\n","Epoch: 2 batch_num: 188\n","train_rmse_target: 0.3154 train_rmse_stderror: 0.03431 train_kl_div: 0.2089\n","val_rmse_target: 0.5294 val_rmse_stderror: 1.133\n","Still best_val_rmse: 0.5023 (from epoch 2)\n","\n","64 steps took 44.7 seconds\n","Epoch: 3 batch_num: 26\n","train_rmse_target: 0.1986 train_rmse_stderror: 0.03171 train_kl_div: 0.08529\n","val_rmse_target: 0.4993 val_rmse_stderror: 1.139\n","New best_val_rmse: 0.4993\n","\n","32 steps took 22.2 seconds\n","Epoch: 3 batch_num: 58\n","train_rmse_target: 0.2042 train_rmse_stderror: 0.03633 train_kl_div: 0.09418\n","val_rmse_target: 0.4964 val_rmse_stderror: 1.131\n","New best_val_rmse: 0.4964\n","\n","32 steps took 22.2 seconds\n","Epoch: 3 batch_num: 90\n","train_rmse_target: 0.142 train_rmse_stderror: 0.02841 train_kl_div: 0.03956\n","val_rmse_target: 0.5088 val_rmse_stderror: 1.131\n","Still best_val_rmse: 0.4964 (from epoch 3)\n","\n","64 steps took 44.5 seconds\n","Epoch: 3 batch_num: 154\n","train_rmse_target: 0.2557 train_rmse_stderror: 0.04961 train_kl_div: 0.1024\n","val_rmse_target: 0.501 val_rmse_stderror: 1.13\n","Still best_val_rmse: 0.4964 (from epoch 3)\n","\n","64 steps took 44.4 seconds\n","Epoch: 3 batch_num: 218\n","train_rmse_target: 0.1508 train_rmse_stderror: 0.04122 train_kl_div: 0.05261\n","val_rmse_target: 0.5027 val_rmse_stderror: 1.129\n","Still best_val_rmse: 0.4964 (from epoch 3)\n","\n","64 steps took 44.5 seconds\n","Epoch: 4 batch_num: 56\n","train_rmse_target: 0.1108 train_rmse_stderror: 0.03341 train_kl_div: 0.02932\n","val_rmse_target: 0.5027 val_rmse_stderror: 1.133\n","Still best_val_rmse: 0.4964 (from epoch 3)\n","\n","64 steps took 44.4 seconds\n","Epoch: 4 batch_num: 120\n","train_rmse_target: 0.06274 train_rmse_stderror: 0.02226 train_kl_div: 0.009436\n","val_rmse_target: 0.5013 val_rmse_stderror: 1.133\n","Still best_val_rmse: 0.4964 (from epoch 3)\n","\n","64 steps took 44.4 seconds\n","Epoch: 4 batch_num: 184\n","train_rmse_target: 0.08254 train_rmse_stderror: 0.02266 train_kl_div: 0.0169\n","val_rmse_target: 0.5026 val_rmse_stderror: 1.131\n","Still best_val_rmse: 0.4964 (from epoch 3)\n","\n","Performance estimates:\n","[0.5183445760211193, 0.47429897158209877, 0.49644332834065924]\n","Mean: 0.49636229198129245\n","{'total_MiB': 16160, 'used_MiB': 1359}\n","\n","Fold 4/5\n","{'total_MiB': 16160, 'used_MiB': 1359}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 44.9 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.5855 train_rmse_stderror: 0.0643 train_kl_div: 0.709\n","val_rmse_target: 0.798 val_rmse_stderror: 1.13\n","New best_val_rmse: 0.798\n","\n","64 steps took 44.4 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.5662 train_rmse_stderror: 0.05882 train_kl_div: 0.6982\n","val_rmse_target: 0.662 val_rmse_stderror: 1.119\n","New best_val_rmse: 0.662\n","\n","64 steps took 44.4 seconds\n","Epoch: 0 batch_num: 192\n","train_rmse_target: 0.6804 train_rmse_stderror: 0.04962 train_kl_div: 0.9948\n","val_rmse_target: 0.5527 val_rmse_stderror: 1.128\n","New best_val_rmse: 0.5527\n","\n","64 steps took 44.6 seconds\n","Epoch: 1 batch_num: 30\n","train_rmse_target: 0.548 train_rmse_stderror: 0.07271 train_kl_div: 0.4936\n","val_rmse_target: 0.5249 val_rmse_stderror: 1.136\n","New best_val_rmse: 0.5249\n","\n","64 steps took 44.4 seconds\n","Epoch: 1 batch_num: 94\n","train_rmse_target: 0.4328 train_rmse_stderror: 0.04557 train_kl_div: 0.382\n","val_rmse_target: 0.5314 val_rmse_stderror: 1.133\n","Still best_val_rmse: 0.5249 (from epoch 1)\n","\n","64 steps took 44.5 seconds\n","Epoch: 1 batch_num: 158\n","train_rmse_target: 0.4584 train_rmse_stderror: 0.04684 train_kl_div: 0.3972\n","val_rmse_target: 0.5546 val_rmse_stderror: 1.128\n","Still best_val_rmse: 0.5249 (from epoch 1)\n","\n","64 steps took 44.4 seconds\n","Epoch: 1 batch_num: 222\n","train_rmse_target: 0.5008 train_rmse_stderror: 0.03918 train_kl_div: 0.4904\n","val_rmse_target: 0.5059 val_rmse_stderror: 1.123\n","New best_val_rmse: 0.5059\n","\n","64 steps took 44.7 seconds\n","Epoch: 2 batch_num: 60\n","train_rmse_target: 0.2548 train_rmse_stderror: 0.02989 train_kl_div: 0.1373\n","val_rmse_target: 0.501 val_rmse_stderror: 1.132\n","New best_val_rmse: 0.501\n","\n","64 steps took 44.4 seconds\n","Epoch: 2 batch_num: 124\n","train_rmse_target: 0.2677 train_rmse_stderror: 0.03191 train_kl_div: 0.1603\n","val_rmse_target: 0.49 val_rmse_stderror: 1.131\n","New best_val_rmse: 0.49\n","\n","16 steps took 11.1 seconds\n","Epoch: 2 batch_num: 140\n","train_rmse_target: 0.355 train_rmse_stderror: 0.02978 train_kl_div: 0.2748\n","val_rmse_target: 0.5088 val_rmse_stderror: 1.121\n","Still best_val_rmse: 0.49 (from epoch 2)\n","\n","64 steps took 44.4 seconds\n","Epoch: 2 batch_num: 204\n","train_rmse_target: 0.2317 train_rmse_stderror: 0.04289 train_kl_div: 0.1203\n","val_rmse_target: 0.4918 val_rmse_stderror: 1.128\n","Still best_val_rmse: 0.49 (from epoch 2)\n","\n","32 steps took 22.4 seconds\n","Epoch: 3 batch_num: 10\n","train_rmse_target: 0.2401 train_rmse_stderror: 0.05253 train_kl_div: 0.1182\n","val_rmse_target: 0.4968 val_rmse_stderror: 1.137\n","Still best_val_rmse: 0.49 (from epoch 2)\n","\n","32 steps took 22.2 seconds\n","Epoch: 3 batch_num: 42\n","train_rmse_target: 0.2849 train_rmse_stderror: 0.02348 train_kl_div: 0.1774\n","val_rmse_target: 0.4946 val_rmse_stderror: 1.125\n","Still best_val_rmse: 0.49 (from epoch 2)\n","\n","32 steps took 22.2 seconds\n","Epoch: 3 batch_num: 74\n","train_rmse_target: 0.169 train_rmse_stderror: 0.03694 train_kl_div: 0.06921\n","val_rmse_target: 0.4921 val_rmse_stderror: 1.135\n","Still best_val_rmse: 0.49 (from epoch 2)\n","\n","32 steps took 22.2 seconds\n","Epoch: 3 batch_num: 106\n","train_rmse_target: 0.1967 train_rmse_stderror: 0.02938 train_kl_div: 0.08257\n","val_rmse_target: 0.4897 val_rmse_stderror: 1.129\n","New best_val_rmse: 0.4897\n","\n","16 steps took 11.1 seconds\n","Epoch: 3 batch_num: 122\n","train_rmse_target: 0.2366 train_rmse_stderror: 0.02151 train_kl_div: 0.1245\n","val_rmse_target: 0.4904 val_rmse_stderror: 1.136\n","Still best_val_rmse: 0.4897 (from epoch 3)\n","\n","32 steps took 22.2 seconds\n","Epoch: 3 batch_num: 154\n","train_rmse_target: 0.2357 train_rmse_stderror: 0.01895 train_kl_div: 0.1172\n","val_rmse_target: 0.4928 val_rmse_stderror: 1.132\n","Still best_val_rmse: 0.4897 (from epoch 3)\n","\n","32 steps took 22.1 seconds\n","Epoch: 3 batch_num: 186\n","train_rmse_target: 0.2375 train_rmse_stderror: 0.03161 train_kl_div: 0.1008\n","val_rmse_target: 0.4986 val_rmse_stderror: 1.13\n","Still best_val_rmse: 0.4897 (from epoch 3)\n","\n","32 steps took 22.2 seconds\n","Epoch: 3 batch_num: 218\n","train_rmse_target: 0.1998 train_rmse_stderror: 0.01945 train_kl_div: 0.07761\n","val_rmse_target: 0.4937 val_rmse_stderror: 1.134\n","Still best_val_rmse: 0.4897 (from epoch 3)\n","\n","32 steps took 22.3 seconds\n","Epoch: 4 batch_num: 24\n","train_rmse_target: 0.183 train_rmse_stderror: 0.03444 train_kl_div: 0.07987\n","val_rmse_target: 0.4884 val_rmse_stderror: 1.13\n","New best_val_rmse: 0.4884\n","\n","16 steps took 11.1 seconds\n","Epoch: 4 batch_num: 40\n","train_rmse_target: 0.172 train_rmse_stderror: 0.02942 train_kl_div: 0.07468\n","val_rmse_target: 0.4916 val_rmse_stderror: 1.131\n","Still best_val_rmse: 0.4884 (from epoch 4)\n","\n","32 steps took 22.3 seconds\n","Epoch: 4 batch_num: 72\n","train_rmse_target: 0.2402 train_rmse_stderror: 0.03174 train_kl_div: 0.1017\n","val_rmse_target: 0.4921 val_rmse_stderror: 1.133\n","Still best_val_rmse: 0.4884 (from epoch 4)\n","\n","32 steps took 22.2 seconds\n","Epoch: 4 batch_num: 104\n","train_rmse_target: 0.1825 train_rmse_stderror: 0.01964 train_kl_div: 0.07346\n","val_rmse_target: 0.4917 val_rmse_stderror: 1.131\n","Still best_val_rmse: 0.4884 (from epoch 4)\n","\n","32 steps took 22.2 seconds\n","Epoch: 4 batch_num: 136\n","train_rmse_target: 0.194 train_rmse_stderror: 0.02996 train_kl_div: 0.07072\n","val_rmse_target: 0.4912 val_rmse_stderror: 1.134\n","Still best_val_rmse: 0.4884 (from epoch 4)\n","\n","32 steps took 22.2 seconds\n","Epoch: 4 batch_num: 168\n","train_rmse_target: 0.1782 train_rmse_stderror: 0.02825 train_kl_div: 0.06361\n","val_rmse_target: 0.492 val_rmse_stderror: 1.131\n","Still best_val_rmse: 0.4884 (from epoch 4)\n","\n","32 steps took 22.2 seconds\n","Epoch: 4 batch_num: 200\n","train_rmse_target: 0.1402 train_rmse_stderror: 0.02615 train_kl_div: 0.04697\n","val_rmse_target: 0.4926 val_rmse_stderror: 1.131\n","Still best_val_rmse: 0.4884 (from epoch 4)\n","\n","Performance estimates:\n","[0.5183445760211193, 0.47429897158209877, 0.49644332834065924, 0.4883908674041909]\n","Mean: 0.4943694358370171\n","{'total_MiB': 16160, 'used_MiB': 1359}\n","\n","Fold 5/5\n","{'total_MiB': 16160, 'used_MiB': 1359}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 45.0 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.7468 train_rmse_stderror: 0.07719 train_kl_div: 1.009\n","val_rmse_target: 0.6818 val_rmse_stderror: 1.114\n","New best_val_rmse: 0.6818\n","\n","64 steps took 44.5 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.3556 train_rmse_stderror: 0.03797 train_kl_div: 0.2272\n","val_rmse_target: 0.6001 val_rmse_stderror: 1.082\n","New best_val_rmse: 0.6001\n","\n","64 steps took 44.5 seconds\n","Epoch: 0 batch_num: 192\n","train_rmse_target: 0.5018 train_rmse_stderror: 0.03214 train_kl_div: 0.4333\n","val_rmse_target: 0.5724 val_rmse_stderror: 1.091\n","New best_val_rmse: 0.5724\n","\n","64 steps took 44.7 seconds\n","Epoch: 1 batch_num: 30\n","train_rmse_target: 0.5699 train_rmse_stderror: 0.06066 train_kl_div: 0.5681\n","val_rmse_target: 0.6369 val_rmse_stderror: 1.111\n","Still best_val_rmse: 0.5724 (from epoch 0)\n","\n","64 steps took 44.5 seconds\n","Epoch: 1 batch_num: 94\n","train_rmse_target: 0.3747 train_rmse_stderror: 0.03552 train_kl_div: 0.3001\n","val_rmse_target: 0.5059 val_rmse_stderror: 1.102\n","New best_val_rmse: 0.5059\n","\n","64 steps took 44.4 seconds\n","Epoch: 1 batch_num: 158\n","train_rmse_target: 0.3439 train_rmse_stderror: 0.0306 train_kl_div: 0.2675\n","val_rmse_target: 0.5228 val_rmse_stderror: 1.098\n","Still best_val_rmse: 0.5059 (from epoch 1)\n","\n","64 steps took 44.4 seconds\n","Epoch: 1 batch_num: 222\n","train_rmse_target: 0.4113 train_rmse_stderror: 0.03958 train_kl_div: 0.3582\n","val_rmse_target: 0.5281 val_rmse_stderror: 1.095\n","Still best_val_rmse: 0.5059 (from epoch 1)\n","\n","64 steps took 44.6 seconds\n","Epoch: 2 batch_num: 60\n","train_rmse_target: 0.179 train_rmse_stderror: 0.03844 train_kl_div: 0.0758\n","val_rmse_target: 0.4966 val_rmse_stderror: 1.106\n","New best_val_rmse: 0.4966\n","\n","32 steps took 22.2 seconds\n","Epoch: 2 batch_num: 92\n","train_rmse_target: 0.3152 train_rmse_stderror: 0.01907 train_kl_div: 0.2071\n","val_rmse_target: 0.4883 val_rmse_stderror: 1.108\n","New best_val_rmse: 0.4883\n","\n","16 steps took 11.1 seconds\n","Epoch: 2 batch_num: 108\n","train_rmse_target: 0.3655 train_rmse_stderror: 0.02463 train_kl_div: 0.2795\n","val_rmse_target: 0.4913 val_rmse_stderror: 1.094\n","Still best_val_rmse: 0.4883 (from epoch 2)\n","\n","32 steps took 22.2 seconds\n","Epoch: 2 batch_num: 140\n","train_rmse_target: 0.3215 train_rmse_stderror: 0.03605 train_kl_div: 0.2224\n","val_rmse_target: 0.4862 val_rmse_stderror: 1.103\n","New best_val_rmse: 0.4862\n","\n","16 steps took 11.1 seconds\n","Epoch: 2 batch_num: 156\n","train_rmse_target: 0.308 train_rmse_stderror: 0.03201 train_kl_div: 0.2345\n","val_rmse_target: 0.5022 val_rmse_stderror: 1.1\n","Still best_val_rmse: 0.4862 (from epoch 2)\n","\n","64 steps took 44.4 seconds\n","Epoch: 2 batch_num: 220\n","train_rmse_target: 0.3682 train_rmse_stderror: 0.03189 train_kl_div: 0.251\n","val_rmse_target: 0.4848 val_rmse_stderror: 1.104\n","New best_val_rmse: 0.4848\n","\n","16 steps took 11.3 seconds\n","Epoch: 3 batch_num: 10\n","train_rmse_target: 0.1379 train_rmse_stderror: 0.04437 train_kl_div: 0.04354\n","val_rmse_target: 0.4923 val_rmse_stderror: 1.095\n","Still best_val_rmse: 0.4848 (from epoch 2)\n","\n","32 steps took 22.2 seconds\n","Epoch: 3 batch_num: 42\n","train_rmse_target: 0.2926 train_rmse_stderror: 0.02976 train_kl_div: 0.1593\n","val_rmse_target: 0.4848 val_rmse_stderror: 1.096\n","Still best_val_rmse: 0.4848 (from epoch 2)\n","\n","16 steps took 11.1 seconds\n","Epoch: 3 batch_num: 58\n","train_rmse_target: 0.1526 train_rmse_stderror: 0.02435 train_kl_div: 0.05408\n","val_rmse_target: 0.4924 val_rmse_stderror: 1.102\n","Still best_val_rmse: 0.4848 (from epoch 2)\n","\n","32 steps took 22.2 seconds\n","Epoch: 3 batch_num: 90\n","train_rmse_target: 0.1888 train_rmse_stderror: 0.0196 train_kl_div: 0.06629\n","val_rmse_target: 0.4857 val_rmse_stderror: 1.11\n","Still best_val_rmse: 0.4848 (from epoch 2)\n","\n","16 steps took 11.1 seconds\n","Epoch: 3 batch_num: 106\n","train_rmse_target: 0.2362 train_rmse_stderror: 0.02094 train_kl_div: 0.1237\n","val_rmse_target: 0.4884 val_rmse_stderror: 1.104\n","Still best_val_rmse: 0.4848 (from epoch 2)\n","\n","16 steps took 11.1 seconds\n","Epoch: 3 batch_num: 122\n","train_rmse_target: 0.1953 train_rmse_stderror: 0.02521 train_kl_div: 0.08519\n","val_rmse_target: 0.4907 val_rmse_stderror: 1.102\n","Still best_val_rmse: 0.4848 (from epoch 2)\n","\n","32 steps took 22.2 seconds\n","Epoch: 3 batch_num: 154\n","train_rmse_target: 0.1563 train_rmse_stderror: 0.02311 train_kl_div: 0.05173\n","val_rmse_target: 0.4985 val_rmse_stderror: 1.102\n","Still best_val_rmse: 0.4848 (from epoch 2)\n","\n","32 steps took 22.2 seconds\n","Epoch: 3 batch_num: 186\n","train_rmse_target: 0.2602 train_rmse_stderror: 0.02797 train_kl_div: 0.1463\n","val_rmse_target: 0.4949 val_rmse_stderror: 1.108\n","Still best_val_rmse: 0.4848 (from epoch 2)\n","\n","32 steps took 22.2 seconds\n","Epoch: 3 batch_num: 218\n","train_rmse_target: 0.2533 train_rmse_stderror: 0.02448 train_kl_div: 0.1312\n","val_rmse_target: 0.4885 val_rmse_stderror: 1.104\n","Still best_val_rmse: 0.4848 (from epoch 2)\n","\n","16 steps took 11.3 seconds\n","Epoch: 4 batch_num: 8\n","train_rmse_target: 0.1841 train_rmse_stderror: 0.01906 train_kl_div: 0.06619\n","val_rmse_target: 0.4941 val_rmse_stderror: 1.1\n","Still best_val_rmse: 0.4848 (from epoch 2)\n","\n","32 steps took 22.2 seconds\n","Epoch: 4 batch_num: 40\n","train_rmse_target: 0.1571 train_rmse_stderror: 0.01611 train_kl_div: 0.05208\n","val_rmse_target: 0.493 val_rmse_stderror: 1.106\n","Still best_val_rmse: 0.4848 (from epoch 2)\n","\n","32 steps took 22.2 seconds\n","Epoch: 4 batch_num: 72\n","train_rmse_target: 0.2188 train_rmse_stderror: 0.03308 train_kl_div: 0.09377\n","val_rmse_target: 0.4923 val_rmse_stderror: 1.101\n","Still best_val_rmse: 0.4848 (from epoch 2)\n","\n","32 steps took 22.2 seconds\n","Epoch: 4 batch_num: 104\n","train_rmse_target: 0.2665 train_rmse_stderror: 0.02798 train_kl_div: 0.1389\n","val_rmse_target: 0.4968 val_rmse_stderror: 1.106\n","Still best_val_rmse: 0.4848 (from epoch 2)\n","\n","32 steps took 22.2 seconds\n","Epoch: 4 batch_num: 136\n","train_rmse_target: 0.144 train_rmse_stderror: 0.0172 train_kl_div: 0.04416\n","val_rmse_target: 0.494 val_rmse_stderror: 1.102\n","Still best_val_rmse: 0.4848 (from epoch 2)\n","\n","32 steps took 22.2 seconds\n","Epoch: 4 batch_num: 168\n","train_rmse_target: 0.1057 train_rmse_stderror: 0.02983 train_kl_div: 0.02919\n","val_rmse_target: 0.4979 val_rmse_stderror: 1.103\n","Still best_val_rmse: 0.4848 (from epoch 2)\n","\n","32 steps took 22.2 seconds\n","Epoch: 4 batch_num: 200\n","train_rmse_target: 0.2297 train_rmse_stderror: 0.02352 train_kl_div: 0.08213\n","val_rmse_target: 0.4973 val_rmse_stderror: 1.103\n","Still best_val_rmse: 0.4848 (from epoch 2)\n","\n","Performance estimates:\n","[0.5183445760211193, 0.47429897158209877, 0.49644332834065924, 0.4883908674041909, 0.484784364529958]\n","Mean: 0.4924524215756053\n","{'total_MiB': 16160, 'used_MiB': 1359}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HgUJCFeLhLaP","executionInfo":{"status":"ok","timestamp":1626424789705,"user_tz":-540,"elapsed":30,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"a50b5cd2-2ee0-4cd7-a5c0-cb7876782bbc"},"source":["import tracemalloc\n","\n","tracemalloc.start()\n","\n","# ... run your application ...\n","\n","snapshot = tracemalloc.take_snapshot()\n","top_stats = snapshot.statistics('lineno')\n","\n","print(\"[ Top 10 ]\")\n","for stat in top_stats[:10]:\n","    print(stat)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["[ Top 10 ]\n","/usr/lib/python3.7/codeop.py:141: size=189 B, count=2, average=94 B\n","/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2820: size=112 B, count=3, average=37 B\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"m4v-cGx-Mv7S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626424789706,"user_tz":-540,"elapsed":24,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"e65b6b94-17d8-4a35-d6a6-3a84d0f2bf4d"},"source":["print(list_val_rmse)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["[0.5183445760211193, 0.47429897158209877, 0.49644332834065924, 0.4883908674041909, 0.484784364529958]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"q2CdCMuIKDMP","executionInfo":{"status":"ok","timestamp":1626424789707,"user_tz":-540,"elapsed":22,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#rep = MemReporter(model)\n","#rep.report()"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"eLl1yDOOKIe7","executionInfo":{"status":"ok","timestamp":1626424789707,"user_tz":-540,"elapsed":20,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#rep = MemReporter(model.roberta)\n","#rep.report()"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"7qkqnknA_m9D","executionInfo":{"status":"ok","timestamp":1626424789708,"user_tz":-540,"elapsed":19,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#gpuinfo()"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"PwrqSMdYA6Pu","executionInfo":{"status":"ok","timestamp":1626424789708,"user_tz":-540,"elapsed":18,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#del model\n","#del optimizer \n","#del train_loader\n","#del val_loader\n","#del scheduler \n","#del list_val_rmse\n","#del train_indices\n","#del val_indices\n","#del tokenizer\n","#torch.cuda.empty_cache()\n","#gpuinfo()"],"execution_count":30,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wXcHyUSJXecL"},"source":["# Inference"]},{"cell_type":"code","metadata":{"id":"YIV6UllSIGoa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626424905874,"user_tz":-540,"elapsed":116184,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"4b051aa2-e72a-4c3b-c13c-c3037b9ba4e0"},"source":["%cd\n","!mkdir .kaggle\n","!mkdir /content/model\n","!cp /content/drive/MyDrive/Colab_Files/kaggle-api/kaggle.json .kaggle/\n","\n","!cp -r /content/model_1.pth /content/model/model_1.pth\n","!cp -r /content/model_2.pth /content/model/model_2.pth\n","!cp -r /content/model_3.pth /content/model/model_3.pth\n","!cp -r /content/model_4.pth /content/model/model_4.pth\n","!cp -r /content/model_5.pth /content/model/model_5.pth"],"execution_count":31,"outputs":[{"output_type":"stream","text":["/root\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"14ddOZH4IMam","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626425161102,"user_tz":-540,"elapsed":255233,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"bb843ff2-4afe-46ae-d6e4-4e286b1ab1e8"},"source":["\n","\n","def dataset_upload():\n","    import json\n","    from kaggle.api.kaggle_api_extended import KaggleApi\n","\n","    id = f'{USERID}/{EX_NO}'\n","\n","    dataset_metadata = {}\n","    dataset_metadata['id'] = id\n","    dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n","    dataset_metadata['title'] = f'{EX_NO}'\n","\n","    with open(UPLOAD_DIR / 'dataset-metadata.json', 'w') as f:\n","        json.dump(dataset_metadata, f, indent=4)\n","\n","    api = KaggleApi()\n","    api.authenticate()\n","\n","    # データセットがない場合\n","    if f'{USERID}/{EX_NO}' not in [str(d) for d in api.dataset_list(user=USERID, search=f'\"{EX_NO}\"')]:\n","        api.dataset_create_new(folder=UPLOAD_DIR,\n","                               convert_to_csv=False,\n","                               dir_mode='skip')\n","    # データセットがある場合\n","    else:\n","        api.dataset_create_version(folder=UPLOAD_DIR,\n","                                   version_notes='update',\n","                                   convert_to_csv=False,\n","                                   delete_old_versions=True,\n","                                   dir_mode='skip')\n","dataset_upload()\n","\n"],"execution_count":32,"outputs":[{"output_type":"stream","text":["\r  0%|          | 0.00/1.33G [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Starting upload for file model_3.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [00:51<00:00, 27.9MB/s]\n","  0%|          | 0.00/1.33G [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_3.pth (1GB)\n","Starting upload for file model_1.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [00:47<00:00, 30.0MB/s]\n","  0%|          | 0.00/1.33G [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_1.pth (1GB)\n","Starting upload for file model_5.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [00:51<00:00, 27.7MB/s]\n","  0%|          | 0.00/1.33G [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_5.pth (1GB)\n","Starting upload for file model_2.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [00:51<00:00, 27.9MB/s]\n","  0%|          | 0.00/1.33G [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_2.pth (1GB)\n","Starting upload for file model_4.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [00:49<00:00, 28.6MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_4.pth (1GB)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"huJwVMSAPuDO","executionInfo":{"status":"ok","timestamp":1626425161103,"user_tz":-540,"elapsed":28,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"0zzuBPobmLFu","executionInfo":{"status":"ok","timestamp":1626425161103,"user_tz":-540,"elapsed":26,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wpc8ro9hmNci","executionInfo":{"status":"ok","timestamp":1626425161104,"user_tz":-540,"elapsed":26,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"ceDI72NumT5-","executionInfo":{"status":"ok","timestamp":1626425161105,"user_tz":-540,"elapsed":27,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":32,"outputs":[]}]}