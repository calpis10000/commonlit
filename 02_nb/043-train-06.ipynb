{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"043-train-06.ipynb","provenance":[{"file_id":"1k_p5wftcUeo711Xho1-T5an2Xkneau-J","timestamp":1626323813472},{"file_id":"1Vz2GB2BNTWuefEFkCSh3TBPEIel7KG1t","timestamp":1626317426487},{"file_id":"1djoMWojeaIPopG5tS1jNMohn8ineblRh","timestamp":1626306831897},{"file_id":"1-6tlDO8158Pi6TpptIF884oFaEiT4Uxb","timestamp":1626276420047},{"file_id":"1js8eA3mDNS8mwSpCiHuzPeARFlUPAVrg","timestamp":1626272452526},{"file_id":"1yhcPgulwJtjJKUK9IuRKmNMhJ-4YXGol","timestamp":1626267205517},{"file_id":"1mnnSv0Pofn1QxArywV81VYqnZPB8uUWN","timestamp":1626180468522},{"file_id":"1RRdjt_UAeHmr5QQBAMyC82Fq1s31OWdK","timestamp":1625833136005},{"file_id":"1JPgg44HFemzwk8VSCXih3PejL0idy-C4","timestamp":1625825483466},{"file_id":"1Ye6wqVX71xAAAhmjXkw9IpRvTqeUyJDA","timestamp":1625812137500}],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":86},"id":"Z6yRwt-PXtbP","executionInfo":{"status":"ok","timestamp":1626328507756,"user_tz":-540,"elapsed":456,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"6cf51142-bfbd-4b21-e80a-ef7cf198c340"},"source":["\"\"\"\n","if 'google.colab' in sys.modules:  # colab環境特有の処理_初回のみ\n","  # Google Driveのマウント\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","\n","  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules' \\\n","   -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/requirements.txt' \\\n","   --ignore-installed\n","\n","  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules' \\\n","   transformers -U\n","  !pip install gensim==4.0.1 --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\n","  !pip install pytorch_memlab --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\n","\"\"\""],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\nif 'google.colab' in sys.modules:  # colab環境特有の処理_初回のみ\\n  # Google Driveのマウント\\n  from google.colab import drive\\n  drive.mount('/content/drive')\\n\\n  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'    -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/requirements.txt'    --ignore-installed\\n\\n  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'    transformers -U\\n  !pip install gensim==4.0.1 --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\\n  !pip install pytorch_memlab --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\\n\""]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kA8loJjZHY2-","executionInfo":{"status":"ok","timestamp":1626328511465,"user_tz":-540,"elapsed":3277,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"c72e0e57-4b41-4608-e459-78b6dad1d2c8"},"source":["!pip install pytorch_memlab"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pytorch_memlab in /usr/local/lib/python3.7/dist-packages (0.2.3)\n","Requirement already satisfied: calmsize in /usr/local/lib/python3.7/dist-packages (from pytorch_memlab) (0.1.3)\n","Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch_memlab) (1.9.0+cu102)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytorch_memlab) (57.0.0)\n","Requirement already satisfied: pandas>=0.18 in /usr/local/lib/python3.7/dist-packages (from pytorch_memlab) (1.1.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->pytorch_memlab) (3.7.4.3)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18->pytorch_memlab) (1.19.5)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18->pytorch_memlab) (2.8.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18->pytorch_memlab) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.18->pytorch_memlab) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ucCbvGD1XvG7","executionInfo":{"status":"ok","timestamp":1626328511466,"user_tz":-540,"elapsed":13,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"5d08c10e-7b16-4e81-b373-bb650d3dab12"},"source":["import sys\n","if 'google.colab' in sys.modules:  # colab特有の処理_2回目以降\n","  # Google Driveのマウント\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","\n","  # データセットをDriveから取得\n","  !mkdir -p 'input'\n","  !cp -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/00_input' '/content/input'\n","\n","  # ライブラリのパス指定\n","  sys.path.append('/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules')\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RV9-VwbpZLZ9"},"source":["from pathlib import Path\n","\n","# input\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    DATA_DIR = Path('../input/commonlitreadabilityprize/')\n","\n","elif 'google.colab' in sys.modules: # Colab環境\n","    !mkdir 'input' -p\n","    !cp '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/00_input/commonlitreadabilityprize/' './input' -r\n","    DATA_DIR = Path('/content/input/commonlitreadabilityprize')\n","\n","else:\n","    DATA_DIR = Path('../00_input/commonlitreadabilityprize/')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8tMampUSaDo5"},"source":["from pathlib import Path\n","\n","# pre-trained model\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    PRE_TRAINED_MODEL_DIR = '../input/roberta-transformers-pytorch/roberta-large'\n","elif 'google.colab' in sys.modules: # Colab環境\n","    PRE_TRAINED_MODEL_DIR = 'roberta-base' # 仮で、毎回DLする想定のモデル名を指定。あとで変更予定。\n","else:\n","    PRE_TRAINED_MODEL_DIR = 'roberta-base'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tKjsUxnOeDYl"},"source":["from pathlib import Path\n","\n","# pre-trained model\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    PRE_TRAINED_MODEL_DIR = '../input/roberta-transformers-pytorch/roberta-base'\n","elif 'google.colab' in sys.modules: # Colab環境\n","    PRE_TRAINED_MODEL_DIR = 'roberta-base' # 仮で、毎回DLする想定のモデル名を指定。あとで変更予定。\n","else:\n","    PRE_TRAINED_MODEL_DIR = 'roberta-base'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZLaT2V0ReoAZ"},"source":["UPLOAD_DIR = Path('/content/model')\n","EX_NO = '043-train-06'  # 実験番号などを入れる、folderのpathにする\n","USERID = 'calpis10000'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hOGjAb4pAJ0F"},"source":["import subprocess\n","import shlex\n","\n","def gpuinfo():\n","    \"\"\"\n","    Returns size of total GPU RAM and used GPU RAM.\n","\n","    Parameters\n","    ----------\n","    None\n","\n","    Returns\n","    -------\n","    info : dict\n","        Total GPU RAM in integer for key 'total_MiB'.\n","        Used GPU RAM in integer for key 'used_MiB'.\n","    \"\"\"\n","\n","    command = 'nvidia-smi -q -d MEMORY | sed -n \"/FB Memory Usage/,/Free/p\" | sed -e \"1d\" -e \"4d\" -e \"s/ MiB//g\" | cut -d \":\" -f 2 | cut -c2-'\n","    commands = [shlex.split(part) for part in command.split(' | ')]\n","    for i, cmd in enumerate(commands):\n","        if i==0:\n","            res = subprocess.Popen(cmd, stdout=subprocess.PIPE)\n","        else:\n","            res = subprocess.Popen(cmd, stdin=res.stdout, stdout=subprocess.PIPE)\n","    total, used = map(int, res.communicate()[0].decode('utf-8').strip().split('\\n'))\n","    info = {'total_MiB':total, 'used_MiB':used}\n","    return info\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g3-6m5MKXecB"},"source":["# Overview\n","This nb is based on copy from https://www.kaggle.com/andretugan/lightweight-roberta-solution-in-pytorch .\n","\n","Acknowledgments(from base nb): \n","some ideas were taken from kernels by [Torch](https://www.kaggle.com/rhtsingh) and [Maunish](https://www.kaggle.com/maunish)."]},{"cell_type":"code","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-04T06:26:32.834365Z","iopub.execute_input":"2021-07-04T06:26:32.834903Z","iopub.status.idle":"2021-07-04T06:26:40.143740Z","shell.execute_reply.started":"2021-07-04T06:26:32.834785Z","shell.execute_reply":"2021-07-04T06:26:40.142864Z"},"trusted":true,"id":"HRsRZ06WXecD"},"source":["import os\n","import math\n","import random\n","import time\n","\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","\n","from transformers import AdamW # optimizer\n","from transformers import AutoTokenizer\n","from transformers import AutoModel\n","from transformers import AutoConfig\n","from transformers import get_cosine_schedule_with_warmup # scheduler\n","from pytorch_memlab import profile\n","import pytorch_memlab\n","from pytorch_memlab import MemReporter\n","\n","from sklearn.model_selection import KFold, StratifiedKFold\n","\n","import gc\n","gc.enable()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bPh2rvoiFrUM"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.145217Z","iopub.execute_input":"2021-07-04T06:26:40.145539Z","iopub.status.idle":"2021-07-04T06:26:40.201326Z","shell.execute_reply.started":"2021-07-04T06:26:40.145504Z","shell.execute_reply":"2021-07-04T06:26:40.200136Z"},"trusted":true,"id":"omBfwshTXecE"},"source":["NUM_FOLDS = 5 # K Fold\n","NUM_EPOCHS = 5 # Epochs\n","BATCH_SIZE = 32 # Batch Size\n","MAX_LEN = 248 # ベクトル長\n","EVAL_SCHEDULE = [(0.50, 16), (0.49, 8), (0.48, 4), (0.47, 2), (-1., 1)] # schedulerの何らかの設定？\n","ROBERTA_PATH = PRE_TRAINED_MODEL_DIR # roberta pre-trainedモデル(モデルとして指定)\n","TOKENIZER_PATH = PRE_TRAINED_MODEL_DIR # roberta pre-trainedモデル(Tokenizerとして指定)\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\" # cudaがなければcpuを使えばいいじゃない"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.203398Z","iopub.execute_input":"2021-07-04T06:26:40.204055Z","iopub.status.idle":"2021-07-04T06:26:40.211572Z","shell.execute_reply.started":"2021-07-04T06:26:40.204015Z","shell.execute_reply":"2021-07-04T06:26:40.210762Z"},"trusted":true,"id":"4qcuXqwtXecF"},"source":["def set_random_seed(random_seed):\n","    random.seed(random_seed)\n","    np.random.seed(random_seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(random_seed)\n","\n","    torch.manual_seed(random_seed)\n","    torch.cuda.manual_seed(random_seed)\n","    torch.cuda.manual_seed_all(random_seed)\n","\n","    torch.backends.cudnn.deterministic = True# cudnnによる最適化で結果が変わらないためのおまじない "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.214188Z","iopub.execute_input":"2021-07-04T06:26:40.214809Z","iopub.status.idle":"2021-07-04T06:26:40.309744Z","shell.execute_reply.started":"2021-07-04T06:26:40.214769Z","shell.execute_reply":"2021-07-04T06:26:40.308926Z"},"trusted":true,"id":"70PyLsJTXecF"},"source":["# train, testを読む\n","train_df = pd.read_csv(DATA_DIR/\"train.csv\")\n","\n","# Remove incomplete entries if any.\n","train_df.drop(train_df[(train_df.target == 0) & (train_df.standard_error == 0)].index,\n","              inplace=True)\n","train_df.reset_index(drop=True, inplace=True)\n","\n","test_df = pd.read_csv(DATA_DIR/\"test.csv\")\n","submission_df = pd.read_csv(DATA_DIR/\"sample_submission.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"9ZYOB59L8qtA","executionInfo":{"status":"ok","timestamp":1626328516311,"user_tz":-540,"elapsed":15,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"688b693d-5705-4ec4-a5c0-f77d8cfd35f4"},"source":["train_df.head()\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>url_legal</th>\n","      <th>license</th>\n","      <th>excerpt</th>\n","      <th>target</th>\n","      <th>standard_error</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>c12129c31</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>When the young people returned to the ballroom...</td>\n","      <td>-0.340259</td>\n","      <td>0.464009</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>85aa80a4c</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>All through dinner time, Mrs. Fayre was somewh...</td>\n","      <td>-0.315372</td>\n","      <td>0.480805</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>b69ac6792</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>As Roger had predicted, the snow departed as q...</td>\n","      <td>-0.580118</td>\n","      <td>0.476676</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>dd1000b26</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>And outside before the palace a great garden w...</td>\n","      <td>-1.054013</td>\n","      <td>0.450007</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>37c1b32fb</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Once upon a time there were Three Bears who li...</td>\n","      <td>0.247197</td>\n","      <td>0.510845</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          id url_legal  ...    target standard_error\n","0  c12129c31       NaN  ... -0.340259       0.464009\n","1  85aa80a4c       NaN  ... -0.315372       0.480805\n","2  b69ac6792       NaN  ... -0.580118       0.476676\n","3  dd1000b26       NaN  ... -1.054013       0.450007\n","4  37c1b32fb       NaN  ...  0.247197       0.510845\n","\n","[5 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.311021Z","iopub.execute_input":"2021-07-04T06:26:40.311347Z","iopub.status.idle":"2021-07-04T06:26:40.624393Z","shell.execute_reply.started":"2021-07-04T06:26:40.311314Z","shell.execute_reply":"2021-07-04T06:26:40.623347Z"},"trusted":true,"id":"xf0662k4XecF"},"source":["# tokenizerを指定\n","tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N6aaghNkXecG"},"source":["# Dataset"]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.628883Z","iopub.execute_input":"2021-07-04T06:26:40.629347Z","iopub.status.idle":"2021-07-04T06:26:40.644338Z","shell.execute_reply.started":"2021-07-04T06:26:40.629309Z","shell.execute_reply":"2021-07-04T06:26:40.643336Z"},"trusted":true,"id":"zkopT0U1XecG"},"source":["# Dataset用のClass。おそらく、trainとtestでインスタンスを生成し、DataFrameと同じように扱えるような思想。\n","class LitDataset(Dataset):\n","    def __init__(self, df, inference_only=False):\n","        super().__init__()\n","\n","        self.df = df        \n","        self.inference_only = inference_only # Testデータ用フラグ\n","        self.text = df.excerpt.tolist() # 分析対象カラムをlistにする。(分かち書きではなく、Seriesをlistへ変換するような処理)\n","        #self.text = [text.replace(\"\\n\", \" \") for text in self.text] # 単語単位で分かち書きする場合\n","        \n","        if not self.inference_only:\n","            self.target = torch.tensor(df.target.values, dtype=torch.float32) # trainのみ、targetをtensorに変換\n","            self.standard_error = torch.tensor(df.standard_error.values, dtype=torch.float32) \n","\n","        self.encoded = tokenizer.batch_encode_plus( # textをtokenize\n","            self.text,\n","            padding = 'max_length',            \n","            max_length = MAX_LEN,\n","            truncation = True, # 最大長を超える文字は切り捨て\n","            return_attention_mask=True\n","        )        \n"," \n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    \n","    def __getitem__(self, index): # 変換結果を返す\n","        input_ids = torch.tensor(self.encoded['input_ids'][index])\n","        attention_mask = torch.tensor(self.encoded['attention_mask'][index])\n","        \n","        if self.inference_only:\n","            return (input_ids, attention_mask)            \n","        else:\n","            target = self.target[index]\n","            standard_error = self.standard_error[index]\n","            return (input_ids, attention_mask, target, standard_error)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KKtdy32wXecG"},"source":["# Model\n","The model is inspired by the one from [Maunish](https://www.kaggle.com/maunish/clrp-roberta-svm)."]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.649629Z","iopub.execute_input":"2021-07-04T06:26:40.650066Z","iopub.status.idle":"2021-07-04T06:26:40.666374Z","shell.execute_reply.started":"2021-07-04T06:26:40.650002Z","shell.execute_reply":"2021-07-04T06:26:40.665211Z"},"trusted":true,"id":"BpkxjXEUXecH"},"source":["class LitModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        config = AutoConfig.from_pretrained(ROBERTA_PATH) # pretrainedからconfigを読み込み\n","        config.update({\"output_hidden_states\":True, # config更新: embedding層を抽出\n","                       \"hidden_dropout_prob\": 0.0, # config更新: dropoutしない\n","                       \"layer_norm_eps\": 1e-7}) # config更新: layer normalizationのepsilon                      \n","        \n","        self.roberta = AutoModel.from_pretrained(ROBERTA_PATH, config=config) # cpuで処理する\n","            \n","        self.attention = nn.Sequential(# attentionレイヤー            \n","            nn.Linear(config.hidden_size, 512), # 768は、ベースとなる学習済みモデルの重みをハードコードしてる。イケてないので、configから取得する感じにしたい。     \n","            nn.Tanh(),                       \n","            nn.Linear(512, 1),\n","            nn.Softmax(dim=1)\n","        )\n","\n","        self.regressor = nn.Sequential( # 出力レイヤー                    \n","            nn.Linear(config.hidden_size, 2)                        \n","        )\n","\n","    def forward(self, input_ids, attention_mask):\n","        #print('model: get_roberta_out: Start', gpuinfo())                 \n","        roberta_output = self.roberta(input_ids=input_ids, # robertaに入力データを流し、出力としてrobertaモデル(layerの複合体)を得る\n","                                      attention_mask=attention_mask)     \n","        #print('model: get_roberta_out: Done', gpuinfo())                 \n","\n","        # There are a total of 13 layers of hidden states.\n","        # 1 for the embedding layer, and 12 for the 12 Roberta layers.\n","        # We take the hidden states from the last Roberta layer.\n","        #last_hidden_state = roberta_output.hidden_states[-1] # robertaモデルの最後のlayerを得る\n","        last_hidden_state = roberta_output[0]\n","\n","        # https://www.kaggle.com/rhtsingh/utilizing-transformer-representations-efficiently\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        sum_mask = input_mask_expanded.sum(1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        mean_embeddings = sum_embeddings / sum_mask\n","\n","        # The number of cells is MAX_LEN.\n","        # The size of the hidden state of each cell is 768 (for roberta-base). # \n","        # In order to condense hidden states of all cells to a context vector,\n","        # we compute a weighted average of the hidden states of all cells.\n","        # We compute the weight of each cell, using the attention neural network.\n","        #weights = self.attention(last_layer_hidden_states) # robertaの最後のlayerをattentionへ入力し、出力として重みを得る\n","                \n","        # weights.shape is BATCH_SIZE x MAX_LEN x 1\n","        # last_layer_hidden_states.shape is BATCH_SIZE x MAX_LEN x 768        \n","        # Now we compute context_vector as the weighted average.\n","        # context_vector.shape is BATCH_SIZE x 768\n","        #context_vector = torch.sum(weights * last_layer_hidden_states, dim=1) # 重み×最後の層を足し合わせて文書ベクトルとする。\n","        \n","        # Now we reduce the context vector to the prediction score.\n","        return self.regressor(mean_embeddings) # 文書ベクトルを線形層に入力し、targetを出力する"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.672515Z","iopub.execute_input":"2021-07-04T06:26:40.672944Z","iopub.status.idle":"2021-07-04T06:26:40.684593Z","shell.execute_reply.started":"2021-07-04T06:26:40.672908Z","shell.execute_reply":"2021-07-04T06:26:40.683569Z"},"trusted":true,"id":"bB4jvQTxXecH"},"source":["# 評価指標(MSE)の計算。最終的に、ルートしてRMSEにすると思われる。\n","def eval_mse(model, data_loader):\n","    \"\"\"Evaluates the mean squared error of the |model| on |data_loader|\"\"\"\n","    model.eval() # evalモードを選択。Batch Normとかdropoutをしなくなる           \n","    mse_mean_sum = 0\n","    mse_std_sum = 0\n","\n","    with torch.no_grad(): # 勾配の計算をしないBlock\n","        for batch_num, (input_ids, attention_mask, target, standard_error) in enumerate(data_loader): # data_loaderからinput, attentin_mask, targetをbatchごとに取り出す\n","            input_ids = input_ids.to(DEVICE)   \n","            attention_mask = attention_mask.to(DEVICE)   \n","            target = target.to(DEVICE)      \n","            standard_error = standard_error.to(DEVICE) \n","            \n","            output = model(input_ids, attention_mask) # 取得した値をモデルへ入力し、出力として予測値を得る。\n","\n","            mse_mean_sum += nn.MSELoss(reduction=\"sum\")(output[:,0].flatten(), target).item() # 誤差の合計を得る(Batchごとに計算した誤差を足し上げる)\n","            mse_std_sum += nn.MSELoss(reduction=\"sum\")(output[:,1].flatten(), target).item() # 誤差の合計を得る(Batchごとに計算した誤差を足し上げる)\n","\n","    del input_ids\n","    del attention_mask\n","    del target\n","\n","    mse_mean_result = mse_mean_sum / len(data_loader.dataset)\n","    mse_std_result = mse_std_sum / len(data_loader.dataset)\n","  \n","    return mse_mean_result, mse_std_result # 誤差の合計をdataset長で除し、mseを取得＆返す"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.690155Z","iopub.execute_input":"2021-07-04T06:26:40.692530Z","iopub.status.idle":"2021-07-04T06:26:40.703425Z","shell.execute_reply.started":"2021-07-04T06:26:40.692488Z","shell.execute_reply":"2021-07-04T06:26:40.702366Z"},"trusted":true,"id":"47bDno_LXecI"},"source":["# 推論結果を返す\n","def predict(model, data_loader):\n","    \"\"\"Returns an np.array with predictions of the |model| on |data_loader|\"\"\"\n","    model.eval() # evalモード(dropout, batch_normしない)\n","\n","    result = np.zeros(len(data_loader.dataset)) # 結果をdataset長のzero配列として用意\n","    index = 0\n","    \n","    with torch.no_grad(): # 勾配の計算をしないblock(inputすると、現状の重みによる推論結果を返す)\n","        for batch_num, (input_ids, attention_mask) in enumerate(data_loader): # data_loaderからbatchごとにinputを得る\n","            input_ids = input_ids.to(DEVICE)\n","            attention_mask = attention_mask.to(DEVICE)\n","                        \n","            output = model(input_ids, attention_mask) # modelにinputを入力し、予測結果を得る。\n","\n","            result[index : index + output[:,0].shape[0]] = output[:,0].flatten().to(\"cpu\") # result[index ~ predの長さ]へ、予測結果を格納\n","            index += pred.shape[0] # indexを更新\n","\n","    return result # 全batchで推論が終わったら、結果を返す"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.708605Z","iopub.execute_input":"2021-07-04T06:26:40.709024Z","iopub.status.idle":"2021-07-04T06:26:40.730675Z","shell.execute_reply.started":"2021-07-04T06:26:40.708983Z","shell.execute_reply":"2021-07-04T06:26:40.729705Z"},"trusted":true,"id":"oInneuAmXecI"},"source":["# 学習\n","def train(model, # モデル\n","          model_path, # モデルのアウトプット先\n","          train_loader, # train-setのdata_loader\n","          val_loader, # valid-setのdata_loader\n","          optimizer, # optimizer\n","          scheduler=None, # scheduler, デフォルトはNone\n","          num_epochs=NUM_EPOCHS # epoch数、notebook冒頭で指定した値\n","         ):    \n","    \n","    best_val_rmse = None\n","    best_epoch = 0\n","    step = 0\n","    last_eval_step = 0\n","    eval_period = EVAL_SCHEDULE[0][1] # eval期間(って何？) 冒頭で決めたEVAL_SCHEDULEの最初のtupleの[1]を取得\n","\n","    start = time.time() # 時間計測用\n","\n","    for epoch in range(num_epochs): # 指定したEpoch数だけ繰り返し\n","        val_rmse = None         \n","\n","        for batch_num, (input_ids, attention_mask, target, standard_error) in enumerate(train_loader): # train_loaderからinput, targetを取得\n","            input_ids = input_ids.to(DEVICE) # inputをDEVICEへ突っ込む\n","            attention_mask = attention_mask.to(DEVICE)       \n","            target = target.to(DEVICE)\n","            standard_error = standard_error.to(DEVICE)  \n","\n","            optimizer.zero_grad() # 勾配を初期化            \n","            model.train() # 学習モード開始\n","\n","            # https://www.kaggle.com/c/commonlitreadabilityprize/discussion/239421\n","            output = model(input_ids, attention_mask) # input,attention_maskを入力し、予測結果を得る\n","            p = torch.distributions.Normal(output[:,0], torch.sqrt(output[:,1]**2))\n","            q = torch.distributions.Normal(target, standard_error)\n","            kl_vector = torch.distributions.kl_divergence(p, q)\n","            loss = kl_vector.mean()\n","\n","            loss.backward() # 誤差逆伝播法により勾配を得る\n","            optimizer.step() # 重みを更新する\n","\n","            if scheduler:\n","                scheduler.step() # schedulerが与えられた場合は、schedulerの学習率更新\n","            \n","            if step >= last_eval_step + eval_period: # batchを回すごとにstepを増やしていって、「前回evalしたstep + eval_period(16)」を超えたら実行。\n","                # Evaluate the model on val_loader.\n","                elapsed_seconds = time.time() - start # 経過時間\n","                num_steps = step - last_eval_step # 経過ステップ数\n","                print(f\"\\n{num_steps} steps took {elapsed_seconds:0.3} seconds\")\n","                last_eval_step = step # 前回stepの更新\n","                \n","                # valid-setによるrmse計算\n","                val_mean_mse, val_std_mse = eval_mse(model, val_loader)\n","                val_mean_rmse = math.sqrt(val_mean_mse)                            \n","                val_std_rmse = math.sqrt(val_std_mse)                            \n","\n","                print(f\"Epoch: {epoch} batch_num: {batch_num}\", \n","                      f\"val_rmse_target: {val_mean_rmse:0.4}\",\n","                      f\"val_rmse_stderror: {val_std_rmse:0.4}\"\n","                      )\n","\n","                for rmse, period in EVAL_SCHEDULE: # eval_periodをvalid-rmseで切り替える処理\n","                    if val_mean_rmse >= rmse: # valid rmseをEVAL_SCHEDULEと比較し、0項 > valid rmseとなるまで回す : EVAL_SCHEDULE = [(0.50, 16), (0.49, 8), (0.48, 4), (0.47, 2), (-1., 1)]\n","                        eval_period = period # eval_periodを更新\n","                        break                               \n","\n","                if not best_val_rmse or val_mean_rmse < best_val_rmse: # 初回(best_val_rmse==None), またはbest_val_rmseを更新したらモデルを保存する\n","                    best_val_rmse = val_mean_rmse\n","                    best_epoch = epoch\n","                    torch.save(model.state_dict(), model_path) # 最高の自分を保存\n","                    print(f\"New best_val_rmse: {best_val_rmse:0.4}\")\n","                else:       \n","                    print(f\"Still best_val_rmse: {best_val_rmse:0.4}\", # 更新されない場合は、元のスコアを表示\n","                          f\"(from epoch {best_epoch})\")      \n","                                                  \n","                start = time.time()\n","            \n","            # batchごとにメモリ解放\n","            #print(f'train_{epoch}_{batch_num}: free_memory: Start', gpuinfo())                  \n","            del input_ids\n","            del attention_mask\n","            #del target\n","            torch.cuda.empty_cache()\n","            #print(f'train_{epoch}_{batch_num}: free_memory: Done', gpuinfo())  \n","                                            \n","            step += 1\n","    \n","    return best_val_rmse"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.735798Z","iopub.execute_input":"2021-07-04T06:26:40.738398Z","iopub.status.idle":"2021-07-04T06:26:40.750876Z","shell.execute_reply.started":"2021-07-04T06:26:40.738356Z","shell.execute_reply":"2021-07-04T06:26:40.749635Z"},"trusted":true,"id":"rMY0fjXwXecJ"},"source":["# optimizerの作成\n","def create_optimizer(model):\n","    named_parameters = list(model.named_parameters()) # モデルパラメータの取得\n","    \n","    roberta_parameters = list(model.roberta.named_parameters())[:-2] # パラメータをroberta用、attention用、regressor用に格納。(直接引っ張ってくる形式に変更)\n","    attention_parameters = list(model.attention.named_parameters())\n","    regressor_parameters = list(model.regressor.named_parameters())\n","        \n","    attention_group = [params for (name, params) in attention_parameters] # attention用パラメータをリストとして取得\n","    regressor_group = [params for (name, params) in regressor_parameters] # reg用パラメータをリストとして取得\n","\n","    parameters = []\n","    #parameters.append({\"params\": attention_group}) # パラメータをリストに辞書として格納していく\n","    parameters.append({\"params\": regressor_group})\n","\n","    for layer_num, (name, params) in enumerate(roberta_parameters): # レイヤーごとにname, paramsを取得していろんな処理\n","        weight_decay = 0.0 if \"bias\" in name else 0.01\n","\n","        lr = 2e-5\n","\n","        if layer_num >= 69:        \n","            lr = 5e-5\n","\n","        if layer_num >= 133:\n","            lr = 1e-4\n","\n","        parameters.append({\"params\": params,\n","                           \"weight_decay\": weight_decay,\n","                           \"lr\": lr})\n","\n","    return AdamW(parameters) # 最終的に、AdamWにパラメータを入力する。\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EbaJojz0Zjif"},"source":["# https://www.kaggle.com/abhishek/step-1-create-folds\n","def create_folds(data, num_splits, return_df=False):\n","    # we create a new column called kfold and fill it with -1\n","    data[\"kfold\"] = -1\n","    \n","    # the next step is to randomize the rows of the data\n","    data = data.sample(frac=1).reset_index(drop=True)\n","\n","    # calculate number of bins by Sturge's rule\n","    # I take the floor of the value, you can also\n","    # just round it\n","    num_bins = int(np.floor(1 + np.log2(len(data))))\n","    \n","    # bin targets\n","    data.loc[:, \"bins_tg\"] = pd.cut(\n","        data[\"target\"], bins=num_bins, labels=False\n","    ).map(lambda x: str(x))\n","\n","    # bin standard_error\n","    data.loc[:, \"bins_std\"] = pd.cut(\n","        data[\"standard_error\"], bins=num_bins, labels=False\n","    )\n","\n","    # bins\n","    data.loc[:, \"bins\"] = data['bins_tg'].map(lambda x: str(x)) + data['bins_std'].map(lambda x: str(x))\n","\n","    # initiate the kfold class from model_selection module\n","    kf = StratifiedKFold(n_splits=5)\n","\n","    # note that, instead of targets, we use bins!\n","    if return_df:\n","      for f, (t_, v_) in enumerate(kf.split(X=data, y=data.bins.values)):\n","        data.loc[v_, 'kfold'] = f\n","      return data\n","    else:\n","      return kf.split(X=data, y=data.bins.values)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"id":"vAmhaYaylMk5","executionInfo":{"status":"ok","timestamp":1626328531148,"user_tz":-540,"elapsed":361,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"d163e1db-07a0-47ab-9b08-7200ff8f5b52"},"source":["# 検証用\n","st_kfold_bins_df = create_folds(train_df, 5, return_df=True)\n","st_kfold_bins_df['bins_tg'] = st_kfold_bins_df['bins_tg'].map(lambda x: float(x))\n","st_kfold_bins_df['bins_std'] = st_kfold_bins_df['bins_std'].map(lambda x: float(x))\n","st_kfold_bins_df.groupby('kfold').agg({'bins_tg': ['min', 'max', 'mean'],\n","                                    'bins_std': ['min', 'max', 'mean']})"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  % (min_groups, self.n_splits)), UserWarning)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","\n","    .dataframe thead tr:last-of-type th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th></th>\n","      <th colspan=\"3\" halign=\"left\">bins_tg</th>\n","      <th colspan=\"3\" halign=\"left\">bins_std</th>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <th>min</th>\n","      <th>max</th>\n","      <th>mean</th>\n","      <th>min</th>\n","      <th>max</th>\n","      <th>mean</th>\n","    </tr>\n","    <tr>\n","      <th>kfold</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>5.587302</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>2.917108</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>5.543210</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>2.925926</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>5.553792</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>2.934744</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>5.556537</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>2.925795</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>5.508834</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>2.941696</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      bins_tg                 bins_std                \n","          min   max      mean      min   max      mean\n","kfold                                                 \n","0         0.0  11.0  5.587302      0.0  11.0  2.917108\n","1         0.0  11.0  5.543210      0.0  11.0  2.925926\n","2         0.0  11.0  5.553792      0.0  11.0  2.934744\n","3         0.0  11.0  5.556537      0.0  11.0  2.925795\n","4         0.0  11.0  5.508834      0.0  11.0  2.941696"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TyjgRCu3mmqG","executionInfo":{"status":"ok","timestamp":1626328535679,"user_tz":-540,"elapsed":315,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"1a8cf7a0-428e-4db2-f071-214139b666bf"},"source":["# 実際に使うKFold\n","st_kfold_bins = create_folds(train_df, 5, return_df=False)\n","st_kfold_bins"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<generator object _BaseKFold.split at 0x7f65ecfed650>"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.755813Z","iopub.execute_input":"2021-07-04T06:26:40.758373Z","iopub.status.idle":"2021-07-04T06:27:12.493221Z","shell.execute_reply.started":"2021-07-04T06:26:40.758265Z","shell.execute_reply":"2021-07-04T06:27:12.490139Z"},"trusted":true,"id":"k2LGJD3XXecK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626330256064,"user_tz":-540,"elapsed":1714536,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"6ba7e162-e743-44f9-fa9c-6789fb5cf700"},"source":["# 実行処理。 KFold & 学習\n","gc.collect()\n","\n","SEED = 1000\n","list_val_rmse = []\n","\n","kfold = KFold(n_splits=NUM_FOLDS, random_state=SEED, shuffle=True)\n","\n","for fold, (train_indices, val_indices) in enumerate(st_kfold_bins):    \n","    print(f\"\\nFold {fold + 1}/{NUM_FOLDS}\")\n","    model_path = f\"model_{fold + 1}.pth\" # model_fold数_.pth\n","        \n","    set_random_seed(SEED + fold) # SEEDはfold別に変わるようにする\n","    \n","    train_dataset = LitDataset(train_df.loc[train_indices]) # train, validのDataset\n","    val_dataset = LitDataset(train_df.loc[val_indices])\n","        \n","    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n","                              drop_last=True, shuffle=True, num_workers=2) # train, validのDataLoader\n","    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n","                            drop_last=False, shuffle=False, num_workers=2)    \n","        \n","    set_random_seed(SEED + fold) # なんで二回SEEDをセットするのだろう？\n","\n","    #print('getmodel: Start', gpuinfo())                 \n","    model = LitModel().to(DEVICE) # modelをDEVICEへぶち込む\n","    #print('getmodel: Done', gpuinfo())                 \n","\n","    #print('get_optim_sched: Start', gpuinfo())                 \n","    optimizer = create_optimizer(model) # optimizerをモデルから作成\n","    scheduler = get_cosine_schedule_with_warmup( # schedulerを作成\n","        optimizer,\n","        num_training_steps=NUM_EPOCHS * len(train_loader),\n","        num_warmup_steps=50)    \n","    #print('get_optim_sched: Done', gpuinfo())                 \n","\n","    list_val_rmse.append(train(model, model_path, train_loader,\n","                               val_loader, optimizer, scheduler=scheduler)) # 学習開始し、val_rmseのリストを格納\n","\n","    del model # モデルは保存したので、消す\n","    gc.collect() \n","    \n","    print(\"\\nPerformance estimates:\")\n","    print(list_val_rmse)\n","    print(\"Mean:\", np.array(list_val_rmse).mean())\n","    "],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  % (min_groups, self.n_splits)), UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Fold 1/5\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"stream","text":["\n","16 steps took 10.2 seconds\n","Epoch: 0 batch_num: 16 val_rmse_target: 0.9055 val_rmse_stderror: 2.003\n","New best_val_rmse: 0.9055\n","\n","16 steps took 9.72 seconds\n","Epoch: 0 batch_num: 32 val_rmse_target: 0.8565 val_rmse_stderror: 1.625\n","New best_val_rmse: 0.8565\n","\n","16 steps took 9.67 seconds\n","Epoch: 0 batch_num: 48 val_rmse_target: 0.7666 val_rmse_stderror: 1.681\n","New best_val_rmse: 0.7666\n","\n","16 steps took 9.71 seconds\n","Epoch: 0 batch_num: 64 val_rmse_target: 0.6497 val_rmse_stderror: 1.67\n","New best_val_rmse: 0.6497\n","\n","16 steps took 9.93 seconds\n","Epoch: 1 batch_num: 10 val_rmse_target: 0.6463 val_rmse_stderror: 1.659\n","New best_val_rmse: 0.6463\n","\n","16 steps took 9.63 seconds\n","Epoch: 1 batch_num: 26 val_rmse_target: 0.579 val_rmse_stderror: 1.659\n","New best_val_rmse: 0.579\n","\n","16 steps took 9.63 seconds\n","Epoch: 1 batch_num: 42 val_rmse_target: 0.632 val_rmse_stderror: 1.636\n","Still best_val_rmse: 0.579 (from epoch 1)\n","\n","16 steps took 9.68 seconds\n","Epoch: 1 batch_num: 58 val_rmse_target: 0.582 val_rmse_stderror: 1.646\n","Still best_val_rmse: 0.579 (from epoch 1)\n","\n","16 steps took 9.94 seconds\n","Epoch: 2 batch_num: 4 val_rmse_target: 0.542 val_rmse_stderror: 1.634\n","New best_val_rmse: 0.542\n","\n","16 steps took 9.63 seconds\n","Epoch: 2 batch_num: 20 val_rmse_target: 0.51 val_rmse_stderror: 1.639\n","New best_val_rmse: 0.51\n","\n","16 steps took 9.68 seconds\n","Epoch: 2 batch_num: 36 val_rmse_target: 0.5101 val_rmse_stderror: 1.633\n","Still best_val_rmse: 0.51 (from epoch 2)\n","\n","16 steps took 9.74 seconds\n","Epoch: 2 batch_num: 52 val_rmse_target: 0.5098 val_rmse_stderror: 1.638\n","New best_val_rmse: 0.5098\n","\n","16 steps took 9.61 seconds\n","Epoch: 2 batch_num: 68 val_rmse_target: 0.5013 val_rmse_stderror: 1.632\n","New best_val_rmse: 0.5013\n","\n","16 steps took 9.81 seconds\n","Epoch: 3 batch_num: 14 val_rmse_target: 0.4927 val_rmse_stderror: 1.632\n","New best_val_rmse: 0.4927\n","\n","8 steps took 4.83 seconds\n","Epoch: 3 batch_num: 22 val_rmse_target: 0.4959 val_rmse_stderror: 1.624\n","Still best_val_rmse: 0.4927 (from epoch 3)\n","\n","8 steps took 4.81 seconds\n","Epoch: 3 batch_num: 30 val_rmse_target: 0.5135 val_rmse_stderror: 1.635\n","Still best_val_rmse: 0.4927 (from epoch 3)\n","\n","16 steps took 9.59 seconds\n","Epoch: 3 batch_num: 46 val_rmse_target: 0.4827 val_rmse_stderror: 1.633\n","New best_val_rmse: 0.4827\n","\n","4 steps took 2.4 seconds\n","Epoch: 3 batch_num: 50 val_rmse_target: 0.4805 val_rmse_stderror: 1.633\n","New best_val_rmse: 0.4805\n","\n","4 steps took 2.4 seconds\n","Epoch: 3 batch_num: 54 val_rmse_target: 0.4859 val_rmse_stderror: 1.635\n","Still best_val_rmse: 0.4805 (from epoch 3)\n","\n","4 steps took 2.4 seconds\n","Epoch: 3 batch_num: 58 val_rmse_target: 0.4856 val_rmse_stderror: 1.636\n","Still best_val_rmse: 0.4805 (from epoch 3)\n","\n","4 steps took 2.42 seconds\n","Epoch: 3 batch_num: 62 val_rmse_target: 0.4853 val_rmse_stderror: 1.635\n","Still best_val_rmse: 0.4805 (from epoch 3)\n","\n","4 steps took 2.41 seconds\n","Epoch: 3 batch_num: 66 val_rmse_target: 0.4845 val_rmse_stderror: 1.636\n","Still best_val_rmse: 0.4805 (from epoch 3)\n","\n","4 steps took 2.59 seconds\n","Epoch: 4 batch_num: 0 val_rmse_target: 0.4864 val_rmse_stderror: 1.636\n","Still best_val_rmse: 0.4805 (from epoch 3)\n","\n","4 steps took 2.41 seconds\n","Epoch: 4 batch_num: 4 val_rmse_target: 0.4803 val_rmse_stderror: 1.636\n","New best_val_rmse: 0.4803\n","\n","4 steps took 2.44 seconds\n","Epoch: 4 batch_num: 8 val_rmse_target: 0.4801 val_rmse_stderror: 1.636\n","New best_val_rmse: 0.4801\n","\n","4 steps took 2.4 seconds\n","Epoch: 4 batch_num: 12 val_rmse_target: 0.4794 val_rmse_stderror: 1.636\n","New best_val_rmse: 0.4794\n","\n","2 steps took 1.2 seconds\n","Epoch: 4 batch_num: 14 val_rmse_target: 0.4793 val_rmse_stderror: 1.635\n","New best_val_rmse: 0.4793\n","\n","2 steps took 1.2 seconds\n","Epoch: 4 batch_num: 16 val_rmse_target: 0.4807 val_rmse_stderror: 1.635\n","Still best_val_rmse: 0.4793 (from epoch 4)\n","\n","4 steps took 2.39 seconds\n","Epoch: 4 batch_num: 20 val_rmse_target: 0.481 val_rmse_stderror: 1.635\n","Still best_val_rmse: 0.4793 (from epoch 4)\n","\n","4 steps took 2.41 seconds\n","Epoch: 4 batch_num: 24 val_rmse_target: 0.4809 val_rmse_stderror: 1.634\n","Still best_val_rmse: 0.4793 (from epoch 4)\n","\n","4 steps took 2.41 seconds\n","Epoch: 4 batch_num: 28 val_rmse_target: 0.4786 val_rmse_stderror: 1.633\n","New best_val_rmse: 0.4786\n","\n","2 steps took 1.21 seconds\n","Epoch: 4 batch_num: 30 val_rmse_target: 0.4786 val_rmse_stderror: 1.633\n","Still best_val_rmse: 0.4786 (from epoch 4)\n","\n","2 steps took 1.2 seconds\n","Epoch: 4 batch_num: 32 val_rmse_target: 0.4793 val_rmse_stderror: 1.633\n","Still best_val_rmse: 0.4786 (from epoch 4)\n","\n","2 steps took 1.2 seconds\n","Epoch: 4 batch_num: 34 val_rmse_target: 0.4806 val_rmse_stderror: 1.633\n","Still best_val_rmse: 0.4786 (from epoch 4)\n","\n","4 steps took 2.39 seconds\n","Epoch: 4 batch_num: 38 val_rmse_target: 0.4822 val_rmse_stderror: 1.632\n","Still best_val_rmse: 0.4786 (from epoch 4)\n","\n","4 steps took 2.41 seconds\n","Epoch: 4 batch_num: 42 val_rmse_target: 0.4837 val_rmse_stderror: 1.632\n","Still best_val_rmse: 0.4786 (from epoch 4)\n","\n","4 steps took 2.41 seconds\n","Epoch: 4 batch_num: 46 val_rmse_target: 0.4848 val_rmse_stderror: 1.632\n","Still best_val_rmse: 0.4786 (from epoch 4)\n","\n","4 steps took 2.4 seconds\n","Epoch: 4 batch_num: 50 val_rmse_target: 0.4852 val_rmse_stderror: 1.632\n","Still best_val_rmse: 0.4786 (from epoch 4)\n","\n","4 steps took 2.4 seconds\n","Epoch: 4 batch_num: 54 val_rmse_target: 0.4855 val_rmse_stderror: 1.632\n","Still best_val_rmse: 0.4786 (from epoch 4)\n","\n","4 steps took 2.41 seconds\n","Epoch: 4 batch_num: 58 val_rmse_target: 0.4856 val_rmse_stderror: 1.632\n","Still best_val_rmse: 0.4786 (from epoch 4)\n","\n","4 steps took 2.4 seconds\n","Epoch: 4 batch_num: 62 val_rmse_target: 0.4856 val_rmse_stderror: 1.633\n","Still best_val_rmse: 0.4786 (from epoch 4)\n","\n","4 steps took 2.4 seconds\n","Epoch: 4 batch_num: 66 val_rmse_target: 0.4855 val_rmse_stderror: 1.633\n","Still best_val_rmse: 0.4786 (from epoch 4)\n","\n","Performance estimates:\n","[0.478616777174999]\n","Mean: 0.478616777174999\n","\n","Fold 2/5\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"stream","text":["\n","16 steps took 9.76 seconds\n","Epoch: 0 batch_num: 16 val_rmse_target: 1.133 val_rmse_stderror: 1.028\n","New best_val_rmse: 1.133\n","\n","16 steps took 9.26 seconds\n","Epoch: 0 batch_num: 32 val_rmse_target: 0.9575 val_rmse_stderror: 1.02\n","New best_val_rmse: 0.9575\n","\n","16 steps took 9.24 seconds\n","Epoch: 0 batch_num: 48 val_rmse_target: 0.7657 val_rmse_stderror: 1.007\n","New best_val_rmse: 0.7657\n","\n","16 steps took 9.25 seconds\n","Epoch: 0 batch_num: 64 val_rmse_target: 0.6882 val_rmse_stderror: 1.019\n","New best_val_rmse: 0.6882\n","\n","16 steps took 9.38 seconds\n","Epoch: 1 batch_num: 10 val_rmse_target: 0.6202 val_rmse_stderror: 1.024\n","New best_val_rmse: 0.6202\n","\n","16 steps took 9.28 seconds\n","Epoch: 1 batch_num: 26 val_rmse_target: 0.5996 val_rmse_stderror: 1.025\n","New best_val_rmse: 0.5996\n","\n","16 steps took 9.25 seconds\n","Epoch: 1 batch_num: 42 val_rmse_target: 0.5779 val_rmse_stderror: 1.026\n","New best_val_rmse: 0.5779\n","\n","16 steps took 9.28 seconds\n","Epoch: 1 batch_num: 58 val_rmse_target: 0.5645 val_rmse_stderror: 1.021\n","New best_val_rmse: 0.5645\n","\n","16 steps took 9.45 seconds\n","Epoch: 2 batch_num: 4 val_rmse_target: 0.517 val_rmse_stderror: 1.032\n","New best_val_rmse: 0.517\n","\n","16 steps took 9.25 seconds\n","Epoch: 2 batch_num: 20 val_rmse_target: 0.5357 val_rmse_stderror: 1.015\n","Still best_val_rmse: 0.517 (from epoch 2)\n","\n","16 steps took 9.28 seconds\n","Epoch: 2 batch_num: 36 val_rmse_target: 0.5033 val_rmse_stderror: 1.026\n","New best_val_rmse: 0.5033\n","\n","16 steps took 9.26 seconds\n","Epoch: 2 batch_num: 52 val_rmse_target: 0.5096 val_rmse_stderror: 1.024\n","Still best_val_rmse: 0.5033 (from epoch 2)\n","\n","16 steps took 9.24 seconds\n","Epoch: 2 batch_num: 68 val_rmse_target: 0.5158 val_rmse_stderror: 1.024\n","Still best_val_rmse: 0.5033 (from epoch 2)\n","\n","16 steps took 9.42 seconds\n","Epoch: 3 batch_num: 14 val_rmse_target: 0.5164 val_rmse_stderror: 1.021\n","Still best_val_rmse: 0.5033 (from epoch 2)\n","\n","16 steps took 9.22 seconds\n","Epoch: 3 batch_num: 30 val_rmse_target: 0.4908 val_rmse_stderror: 1.028\n","New best_val_rmse: 0.4908\n","\n","8 steps took 4.64 seconds\n","Epoch: 3 batch_num: 38 val_rmse_target: 0.4848 val_rmse_stderror: 1.026\n","New best_val_rmse: 0.4848\n","\n","4 steps took 2.32 seconds\n","Epoch: 3 batch_num: 42 val_rmse_target: 0.4828 val_rmse_stderror: 1.024\n","New best_val_rmse: 0.4828\n","\n","4 steps took 2.33 seconds\n","Epoch: 3 batch_num: 46 val_rmse_target: 0.5083 val_rmse_stderror: 1.026\n","Still best_val_rmse: 0.4828 (from epoch 3)\n","\n","16 steps took 9.27 seconds\n","Epoch: 3 batch_num: 62 val_rmse_target: 0.4976 val_rmse_stderror: 1.023\n","Still best_val_rmse: 0.4828 (from epoch 3)\n","\n","8 steps took 4.8 seconds\n","Epoch: 4 batch_num: 0 val_rmse_target: 0.4992 val_rmse_stderror: 1.021\n","Still best_val_rmse: 0.4828 (from epoch 3)\n","\n","8 steps took 4.62 seconds\n","Epoch: 4 batch_num: 8 val_rmse_target: 0.4911 val_rmse_stderror: 1.022\n","Still best_val_rmse: 0.4828 (from epoch 3)\n","\n","8 steps took 4.62 seconds\n","Epoch: 4 batch_num: 16 val_rmse_target: 0.4916 val_rmse_stderror: 1.024\n","Still best_val_rmse: 0.4828 (from epoch 3)\n","\n","8 steps took 4.65 seconds\n","Epoch: 4 batch_num: 24 val_rmse_target: 0.4912 val_rmse_stderror: 1.025\n","Still best_val_rmse: 0.4828 (from epoch 3)\n","\n","8 steps took 4.61 seconds\n","Epoch: 4 batch_num: 32 val_rmse_target: 0.4876 val_rmse_stderror: 1.024\n","Still best_val_rmse: 0.4828 (from epoch 3)\n","\n","4 steps took 2.32 seconds\n","Epoch: 4 batch_num: 36 val_rmse_target: 0.4883 val_rmse_stderror: 1.024\n","Still best_val_rmse: 0.4828 (from epoch 3)\n","\n","4 steps took 2.31 seconds\n","Epoch: 4 batch_num: 40 val_rmse_target: 0.4903 val_rmse_stderror: 1.024\n","Still best_val_rmse: 0.4828 (from epoch 3)\n","\n","8 steps took 4.66 seconds\n","Epoch: 4 batch_num: 48 val_rmse_target: 0.492 val_rmse_stderror: 1.025\n","Still best_val_rmse: 0.4828 (from epoch 3)\n","\n","8 steps took 4.67 seconds\n","Epoch: 4 batch_num: 56 val_rmse_target: 0.4925 val_rmse_stderror: 1.025\n","Still best_val_rmse: 0.4828 (from epoch 3)\n","\n","8 steps took 4.64 seconds\n","Epoch: 4 batch_num: 64 val_rmse_target: 0.4929 val_rmse_stderror: 1.025\n","Still best_val_rmse: 0.4828 (from epoch 3)\n","\n","Performance estimates:\n","[0.478616777174999, 0.4827653314789129]\n","Mean: 0.4806910543269559\n","\n","Fold 3/5\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"stream","text":["\n","16 steps took 9.72 seconds\n","Epoch: 0 batch_num: 16 val_rmse_target: 1.269 val_rmse_stderror: 2.644\n","New best_val_rmse: 1.269\n","\n","16 steps took 9.11 seconds\n","Epoch: 0 batch_num: 32 val_rmse_target: 1.087 val_rmse_stderror: 2.151\n","New best_val_rmse: 1.087\n","\n","16 steps took 9.1 seconds\n","Epoch: 0 batch_num: 48 val_rmse_target: 0.9465 val_rmse_stderror: 2.044\n","New best_val_rmse: 0.9465\n","\n","16 steps took 9.11 seconds\n","Epoch: 0 batch_num: 64 val_rmse_target: 0.7015 val_rmse_stderror: 2.115\n","New best_val_rmse: 0.7015\n","\n","16 steps took 9.29 seconds\n","Epoch: 1 batch_num: 10 val_rmse_target: 0.6597 val_rmse_stderror: 2.089\n","New best_val_rmse: 0.6597\n","\n","16 steps took 9.09 seconds\n","Epoch: 1 batch_num: 26 val_rmse_target: 0.5736 val_rmse_stderror: 2.114\n","New best_val_rmse: 0.5736\n","\n","16 steps took 9.12 seconds\n","Epoch: 1 batch_num: 42 val_rmse_target: 0.5334 val_rmse_stderror: 2.106\n","New best_val_rmse: 0.5334\n","\n","16 steps took 9.17 seconds\n","Epoch: 1 batch_num: 58 val_rmse_target: 0.6742 val_rmse_stderror: 2.117\n","Still best_val_rmse: 0.5334 (from epoch 1)\n","\n","16 steps took 9.35 seconds\n","Epoch: 2 batch_num: 4 val_rmse_target: 0.5727 val_rmse_stderror: 2.11\n","Still best_val_rmse: 0.5334 (from epoch 1)\n","\n","16 steps took 9.15 seconds\n","Epoch: 2 batch_num: 20 val_rmse_target: 0.528 val_rmse_stderror: 2.108\n","New best_val_rmse: 0.528\n","\n","16 steps took 9.16 seconds\n","Epoch: 2 batch_num: 36 val_rmse_target: 0.4909 val_rmse_stderror: 2.112\n","New best_val_rmse: 0.4909\n","\n","8 steps took 4.61 seconds\n","Epoch: 2 batch_num: 44 val_rmse_target: 0.5488 val_rmse_stderror: 2.113\n","Still best_val_rmse: 0.4909 (from epoch 2)\n","\n","16 steps took 9.14 seconds\n","Epoch: 2 batch_num: 60 val_rmse_target: 0.4926 val_rmse_stderror: 2.124\n","Still best_val_rmse: 0.4909 (from epoch 2)\n","\n","8 steps took 4.56 seconds\n","Epoch: 2 batch_num: 68 val_rmse_target: 0.4836 val_rmse_stderror: 2.111\n","New best_val_rmse: 0.4836\n","\n","4 steps took 2.47 seconds\n","Epoch: 3 batch_num: 2 val_rmse_target: 0.4876 val_rmse_stderror: 2.109\n","Still best_val_rmse: 0.4836 (from epoch 2)\n","\n","4 steps took 2.28 seconds\n","Epoch: 3 batch_num: 6 val_rmse_target: 0.5112 val_rmse_stderror: 2.107\n","Still best_val_rmse: 0.4836 (from epoch 2)\n","\n","16 steps took 9.12 seconds\n","Epoch: 3 batch_num: 22 val_rmse_target: 0.4766 val_rmse_stderror: 2.113\n","New best_val_rmse: 0.4766\n","\n","2 steps took 1.13 seconds\n","Epoch: 3 batch_num: 24 val_rmse_target: 0.4766 val_rmse_stderror: 2.114\n","New best_val_rmse: 0.4766\n","\n","2 steps took 1.14 seconds\n","Epoch: 3 batch_num: 26 val_rmse_target: 0.48 val_rmse_stderror: 2.115\n","Still best_val_rmse: 0.4766 (from epoch 3)\n","\n","2 steps took 1.13 seconds\n","Epoch: 3 batch_num: 28 val_rmse_target: 0.488 val_rmse_stderror: 2.114\n","Still best_val_rmse: 0.4766 (from epoch 3)\n","\n","4 steps took 2.27 seconds\n","Epoch: 3 batch_num: 32 val_rmse_target: 0.4758 val_rmse_stderror: 2.113\n","New best_val_rmse: 0.4758\n","\n","2 steps took 1.14 seconds\n","Epoch: 3 batch_num: 34 val_rmse_target: 0.478 val_rmse_stderror: 2.114\n","Still best_val_rmse: 0.4758 (from epoch 3)\n","\n","2 steps took 1.13 seconds\n","Epoch: 3 batch_num: 36 val_rmse_target: 0.4793 val_rmse_stderror: 2.113\n","Still best_val_rmse: 0.4758 (from epoch 3)\n","\n","2 steps took 1.14 seconds\n","Epoch: 3 batch_num: 38 val_rmse_target: 0.525 val_rmse_stderror: 2.111\n","Still best_val_rmse: 0.4758 (from epoch 3)\n","\n","16 steps took 9.11 seconds\n","Epoch: 3 batch_num: 54 val_rmse_target: 0.5056 val_rmse_stderror: 2.109\n","Still best_val_rmse: 0.4758 (from epoch 3)\n","\n","16 steps took 9.29 seconds\n","Epoch: 4 batch_num: 0 val_rmse_target: 0.4726 val_rmse_stderror: 2.111\n","New best_val_rmse: 0.4726\n","\n","2 steps took 1.14 seconds\n","Epoch: 4 batch_num: 2 val_rmse_target: 0.4707 val_rmse_stderror: 2.112\n","New best_val_rmse: 0.4707\n","\n","2 steps took 1.15 seconds\n","Epoch: 4 batch_num: 4 val_rmse_target: 0.4712 val_rmse_stderror: 2.111\n","Still best_val_rmse: 0.4707 (from epoch 4)\n","\n","2 steps took 1.14 seconds\n","Epoch: 4 batch_num: 6 val_rmse_target: 0.4706 val_rmse_stderror: 2.111\n","New best_val_rmse: 0.4706\n","\n","2 steps took 1.13 seconds\n","Epoch: 4 batch_num: 8 val_rmse_target: 0.4758 val_rmse_stderror: 2.111\n","Still best_val_rmse: 0.4706 (from epoch 4)\n","\n","2 steps took 1.14 seconds\n","Epoch: 4 batch_num: 10 val_rmse_target: 0.4855 val_rmse_stderror: 2.111\n","Still best_val_rmse: 0.4706 (from epoch 4)\n","\n","4 steps took 2.28 seconds\n","Epoch: 4 batch_num: 14 val_rmse_target: 0.4778 val_rmse_stderror: 2.112\n","Still best_val_rmse: 0.4706 (from epoch 4)\n","\n","2 steps took 1.13 seconds\n","Epoch: 4 batch_num: 16 val_rmse_target: 0.4742 val_rmse_stderror: 2.113\n","Still best_val_rmse: 0.4706 (from epoch 4)\n","\n","2 steps took 1.14 seconds\n","Epoch: 4 batch_num: 18 val_rmse_target: 0.472 val_rmse_stderror: 2.113\n","Still best_val_rmse: 0.4706 (from epoch 4)\n","\n","2 steps took 1.14 seconds\n","Epoch: 4 batch_num: 20 val_rmse_target: 0.4708 val_rmse_stderror: 2.113\n","Still best_val_rmse: 0.4706 (from epoch 4)\n","\n","2 steps took 1.13 seconds\n","Epoch: 4 batch_num: 22 val_rmse_target: 0.4723 val_rmse_stderror: 2.113\n","Still best_val_rmse: 0.4706 (from epoch 4)\n","\n","2 steps took 1.13 seconds\n","Epoch: 4 batch_num: 24 val_rmse_target: 0.4782 val_rmse_stderror: 2.113\n","Still best_val_rmse: 0.4706 (from epoch 4)\n","\n","2 steps took 1.13 seconds\n","Epoch: 4 batch_num: 26 val_rmse_target: 0.484 val_rmse_stderror: 2.113\n","Still best_val_rmse: 0.4706 (from epoch 4)\n","\n","4 steps took 2.27 seconds\n","Epoch: 4 batch_num: 30 val_rmse_target: 0.4892 val_rmse_stderror: 2.112\n","Still best_val_rmse: 0.4706 (from epoch 4)\n","\n","4 steps took 2.28 seconds\n","Epoch: 4 batch_num: 34 val_rmse_target: 0.4776 val_rmse_stderror: 2.113\n","Still best_val_rmse: 0.4706 (from epoch 4)\n","\n","2 steps took 1.14 seconds\n","Epoch: 4 batch_num: 36 val_rmse_target: 0.4753 val_rmse_stderror: 2.113\n","Still best_val_rmse: 0.4706 (from epoch 4)\n","\n","2 steps took 1.13 seconds\n","Epoch: 4 batch_num: 38 val_rmse_target: 0.4744 val_rmse_stderror: 2.113\n","Still best_val_rmse: 0.4706 (from epoch 4)\n","\n","2 steps took 1.14 seconds\n","Epoch: 4 batch_num: 40 val_rmse_target: 0.4742 val_rmse_stderror: 2.113\n","Still best_val_rmse: 0.4706 (from epoch 4)\n","\n","2 steps took 1.14 seconds\n","Epoch: 4 batch_num: 42 val_rmse_target: 0.4731 val_rmse_stderror: 2.113\n","Still best_val_rmse: 0.4706 (from epoch 4)\n","\n","2 steps took 1.13 seconds\n","Epoch: 4 batch_num: 44 val_rmse_target: 0.4725 val_rmse_stderror: 2.113\n","Still best_val_rmse: 0.4706 (from epoch 4)\n","\n","2 steps took 1.14 seconds\n","Epoch: 4 batch_num: 46 val_rmse_target: 0.4725 val_rmse_stderror: 2.113\n","Still best_val_rmse: 0.4706 (from epoch 4)\n","\n","2 steps took 1.14 seconds\n","Epoch: 4 batch_num: 48 val_rmse_target: 0.4726 val_rmse_stderror: 2.113\n","Still best_val_rmse: 0.4706 (from epoch 4)\n","\n","2 steps took 1.14 seconds\n","Epoch: 4 batch_num: 50 val_rmse_target: 0.4728 val_rmse_stderror: 2.113\n","Still best_val_rmse: 0.4706 (from epoch 4)\n","\n","2 steps took 1.14 seconds\n","Epoch: 4 batch_num: 52 val_rmse_target: 0.473 val_rmse_stderror: 2.113\n","Still best_val_rmse: 0.4706 (from epoch 4)\n","\n","2 steps took 1.15 seconds\n","Epoch: 4 batch_num: 54 val_rmse_target: 0.4734 val_rmse_stderror: 2.113\n","Still best_val_rmse: 0.4706 (from epoch 4)\n","\n","2 steps took 1.14 seconds\n","Epoch: 4 batch_num: 56 val_rmse_target: 0.4736 val_rmse_stderror: 2.113\n","Still best_val_rmse: 0.4706 (from epoch 4)\n","\n","2 steps took 1.13 seconds\n","Epoch: 4 batch_num: 58 val_rmse_target: 0.4736 val_rmse_stderror: 2.113\n","Still best_val_rmse: 0.4706 (from epoch 4)\n","\n","2 steps took 1.14 seconds\n","Epoch: 4 batch_num: 60 val_rmse_target: 0.4735 val_rmse_stderror: 2.113\n","Still best_val_rmse: 0.4706 (from epoch 4)\n","\n","2 steps took 1.13 seconds\n","Epoch: 4 batch_num: 62 val_rmse_target: 0.4734 val_rmse_stderror: 2.113\n","Still best_val_rmse: 0.4706 (from epoch 4)\n","\n","2 steps took 1.14 seconds\n","Epoch: 4 batch_num: 64 val_rmse_target: 0.4734 val_rmse_stderror: 2.113\n","Still best_val_rmse: 0.4706 (from epoch 4)\n","\n","2 steps took 1.14 seconds\n","Epoch: 4 batch_num: 66 val_rmse_target: 0.4734 val_rmse_stderror: 2.113\n","Still best_val_rmse: 0.4706 (from epoch 4)\n","\n","2 steps took 1.13 seconds\n","Epoch: 4 batch_num: 68 val_rmse_target: 0.4734 val_rmse_stderror: 2.113\n","Still best_val_rmse: 0.4706 (from epoch 4)\n","\n","Performance estimates:\n","[0.478616777174999, 0.4827653314789129, 0.4705673261181756]\n","Mean: 0.47731647825736245\n","\n","Fold 4/5\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"stream","text":["\n","16 steps took 9.46 seconds\n","Epoch: 0 batch_num: 16 val_rmse_target: 1.143 val_rmse_stderror: 1.325\n","New best_val_rmse: 1.143\n","\n","16 steps took 8.87 seconds\n","Epoch: 0 batch_num: 32 val_rmse_target: 1.028 val_rmse_stderror: 1.299\n","New best_val_rmse: 1.028\n","\n","16 steps took 8.87 seconds\n","Epoch: 0 batch_num: 48 val_rmse_target: 0.7248 val_rmse_stderror: 1.291\n","New best_val_rmse: 0.7248\n","\n","16 steps took 8.84 seconds\n","Epoch: 0 batch_num: 64 val_rmse_target: 0.6624 val_rmse_stderror: 1.295\n","New best_val_rmse: 0.6624\n","\n","16 steps took 9.05 seconds\n","Epoch: 1 batch_num: 10 val_rmse_target: 0.5529 val_rmse_stderror: 1.299\n","New best_val_rmse: 0.5529\n","\n","16 steps took 8.86 seconds\n","Epoch: 1 batch_num: 26 val_rmse_target: 0.5231 val_rmse_stderror: 1.301\n","New best_val_rmse: 0.5231\n","\n","16 steps took 8.86 seconds\n","Epoch: 1 batch_num: 42 val_rmse_target: 0.5805 val_rmse_stderror: 1.28\n","Still best_val_rmse: 0.5231 (from epoch 1)\n","\n","16 steps took 8.86 seconds\n","Epoch: 1 batch_num: 58 val_rmse_target: 0.5239 val_rmse_stderror: 1.285\n","Still best_val_rmse: 0.5231 (from epoch 1)\n","\n","16 steps took 9.07 seconds\n","Epoch: 2 batch_num: 4 val_rmse_target: 0.5119 val_rmse_stderror: 1.29\n","New best_val_rmse: 0.5119\n","\n","16 steps took 8.87 seconds\n","Epoch: 2 batch_num: 20 val_rmse_target: 0.4922 val_rmse_stderror: 1.274\n","New best_val_rmse: 0.4922\n","\n","8 steps took 4.44 seconds\n","Epoch: 2 batch_num: 28 val_rmse_target: 0.5094 val_rmse_stderror: 1.287\n","Still best_val_rmse: 0.4922 (from epoch 2)\n","\n","16 steps took 8.86 seconds\n","Epoch: 2 batch_num: 44 val_rmse_target: 0.4976 val_rmse_stderror: 1.28\n","Still best_val_rmse: 0.4922 (from epoch 2)\n","\n","8 steps took 4.41 seconds\n","Epoch: 2 batch_num: 52 val_rmse_target: 0.5204 val_rmse_stderror: 1.275\n","Still best_val_rmse: 0.4922 (from epoch 2)\n","\n","16 steps took 8.83 seconds\n","Epoch: 2 batch_num: 68 val_rmse_target: 0.4905 val_rmse_stderror: 1.278\n","New best_val_rmse: 0.4905\n","\n","8 steps took 4.64 seconds\n","Epoch: 3 batch_num: 6 val_rmse_target: 0.4739 val_rmse_stderror: 1.274\n","New best_val_rmse: 0.4739\n","\n","2 steps took 1.1 seconds\n","Epoch: 3 batch_num: 8 val_rmse_target: 0.477 val_rmse_stderror: 1.278\n","Still best_val_rmse: 0.4739 (from epoch 3)\n","\n","2 steps took 1.13 seconds\n","Epoch: 3 batch_num: 10 val_rmse_target: 0.4798 val_rmse_stderror: 1.284\n","Still best_val_rmse: 0.4739 (from epoch 3)\n","\n","2 steps took 1.11 seconds\n","Epoch: 3 batch_num: 12 val_rmse_target: 0.4834 val_rmse_stderror: 1.29\n","Still best_val_rmse: 0.4739 (from epoch 3)\n","\n","4 steps took 2.23 seconds\n","Epoch: 3 batch_num: 16 val_rmse_target: 0.4706 val_rmse_stderror: 1.289\n","New best_val_rmse: 0.4706\n","\n","2 steps took 1.11 seconds\n","Epoch: 3 batch_num: 18 val_rmse_target: 0.4839 val_rmse_stderror: 1.283\n","Still best_val_rmse: 0.4706 (from epoch 3)\n","\n","4 steps took 2.23 seconds\n","Epoch: 3 batch_num: 22 val_rmse_target: 0.5044 val_rmse_stderror: 1.274\n","Still best_val_rmse: 0.4706 (from epoch 3)\n","\n","16 steps took 8.91 seconds\n","Epoch: 3 batch_num: 38 val_rmse_target: 0.47 val_rmse_stderror: 1.278\n","New best_val_rmse: 0.47\n","\n","1 steps took 0.554 seconds\n","Epoch: 3 batch_num: 39 val_rmse_target: 0.4735 val_rmse_stderror: 1.283\n","Still best_val_rmse: 0.47 (from epoch 3)\n","\n","2 steps took 1.1 seconds\n","Epoch: 3 batch_num: 41 val_rmse_target: 0.4926 val_rmse_stderror: 1.288\n","Still best_val_rmse: 0.47 (from epoch 3)\n","\n","8 steps took 4.4 seconds\n","Epoch: 3 batch_num: 49 val_rmse_target: 0.477 val_rmse_stderror: 1.276\n","Still best_val_rmse: 0.47 (from epoch 3)\n","\n","2 steps took 1.1 seconds\n","Epoch: 3 batch_num: 51 val_rmse_target: 0.4738 val_rmse_stderror: 1.282\n","Still best_val_rmse: 0.47 (from epoch 3)\n","\n","2 steps took 1.1 seconds\n","Epoch: 3 batch_num: 53 val_rmse_target: 0.4824 val_rmse_stderror: 1.287\n","Still best_val_rmse: 0.47 (from epoch 3)\n","\n","4 steps took 2.21 seconds\n","Epoch: 3 batch_num: 57 val_rmse_target: 0.4859 val_rmse_stderror: 1.287\n","Still best_val_rmse: 0.47 (from epoch 3)\n","\n","4 steps took 2.22 seconds\n","Epoch: 3 batch_num: 61 val_rmse_target: 0.4704 val_rmse_stderror: 1.276\n","Still best_val_rmse: 0.47 (from epoch 3)\n","\n","2 steps took 1.11 seconds\n","Epoch: 3 batch_num: 63 val_rmse_target: 0.4756 val_rmse_stderror: 1.272\n","Still best_val_rmse: 0.47 (from epoch 3)\n","\n","2 steps took 1.11 seconds\n","Epoch: 3 batch_num: 65 val_rmse_target: 0.4685 val_rmse_stderror: 1.274\n","New best_val_rmse: 0.4685\n","\n","1 steps took 0.551 seconds\n","Epoch: 3 batch_num: 66 val_rmse_target: 0.4682 val_rmse_stderror: 1.275\n","New best_val_rmse: 0.4682\n","\n","1 steps took 0.546 seconds\n","Epoch: 3 batch_num: 67 val_rmse_target: 0.4738 val_rmse_stderror: 1.278\n","Still best_val_rmse: 0.4682 (from epoch 3)\n","\n","2 steps took 1.11 seconds\n","Epoch: 3 batch_num: 69 val_rmse_target: 0.4933 val_rmse_stderror: 1.282\n","Still best_val_rmse: 0.4682 (from epoch 3)\n","\n","8 steps took 4.66 seconds\n","Epoch: 4 batch_num: 7 val_rmse_target: 0.4717 val_rmse_stderror: 1.279\n","Still best_val_rmse: 0.4682 (from epoch 3)\n","\n","2 steps took 1.13 seconds\n","Epoch: 4 batch_num: 9 val_rmse_target: 0.4718 val_rmse_stderror: 1.279\n","Still best_val_rmse: 0.4682 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 11 val_rmse_target: 0.4695 val_rmse_stderror: 1.278\n","Still best_val_rmse: 0.4682 (from epoch 3)\n","\n","1 steps took 0.553 seconds\n","Epoch: 4 batch_num: 12 val_rmse_target: 0.4697 val_rmse_stderror: 1.279\n","Still best_val_rmse: 0.4682 (from epoch 3)\n","\n","1 steps took 0.553 seconds\n","Epoch: 4 batch_num: 13 val_rmse_target: 0.4718 val_rmse_stderror: 1.28\n","Still best_val_rmse: 0.4682 (from epoch 3)\n","\n","2 steps took 1.1 seconds\n","Epoch: 4 batch_num: 15 val_rmse_target: 0.4781 val_rmse_stderror: 1.281\n","Still best_val_rmse: 0.4682 (from epoch 3)\n","\n","2 steps took 1.11 seconds\n","Epoch: 4 batch_num: 17 val_rmse_target: 0.48 val_rmse_stderror: 1.282\n","Still best_val_rmse: 0.4682 (from epoch 3)\n","\n","4 steps took 2.23 seconds\n","Epoch: 4 batch_num: 21 val_rmse_target: 0.4722 val_rmse_stderror: 1.284\n","Still best_val_rmse: 0.4682 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 23 val_rmse_target: 0.4697 val_rmse_stderror: 1.284\n","Still best_val_rmse: 0.4682 (from epoch 3)\n","\n","1 steps took 0.561 seconds\n","Epoch: 4 batch_num: 24 val_rmse_target: 0.4688 val_rmse_stderror: 1.283\n","Still best_val_rmse: 0.4682 (from epoch 3)\n","\n","1 steps took 0.552 seconds\n","Epoch: 4 batch_num: 25 val_rmse_target: 0.468 val_rmse_stderror: 1.283\n","New best_val_rmse: 0.468\n","\n","1 steps took 0.557 seconds\n","Epoch: 4 batch_num: 26 val_rmse_target: 0.4676 val_rmse_stderror: 1.283\n","New best_val_rmse: 0.4676\n","\n","1 steps took 0.56 seconds\n","Epoch: 4 batch_num: 27 val_rmse_target: 0.4675 val_rmse_stderror: 1.283\n","New best_val_rmse: 0.4675\n","\n","1 steps took 0.549 seconds\n","Epoch: 4 batch_num: 28 val_rmse_target: 0.4674 val_rmse_stderror: 1.282\n","New best_val_rmse: 0.4674\n","\n","1 steps took 0.553 seconds\n","Epoch: 4 batch_num: 29 val_rmse_target: 0.4674 val_rmse_stderror: 1.282\n","New best_val_rmse: 0.4674\n","\n","1 steps took 0.548 seconds\n","Epoch: 4 batch_num: 30 val_rmse_target: 0.4674 val_rmse_stderror: 1.282\n","Still best_val_rmse: 0.4674 (from epoch 4)\n","\n","1 steps took 0.557 seconds\n","Epoch: 4 batch_num: 31 val_rmse_target: 0.4676 val_rmse_stderror: 1.281\n","Still best_val_rmse: 0.4674 (from epoch 4)\n","\n","1 steps took 0.553 seconds\n","Epoch: 4 batch_num: 32 val_rmse_target: 0.4678 val_rmse_stderror: 1.281\n","Still best_val_rmse: 0.4674 (from epoch 4)\n","\n","1 steps took 0.55 seconds\n","Epoch: 4 batch_num: 33 val_rmse_target: 0.468 val_rmse_stderror: 1.281\n","Still best_val_rmse: 0.4674 (from epoch 4)\n","\n","1 steps took 0.554 seconds\n","Epoch: 4 batch_num: 34 val_rmse_target: 0.4685 val_rmse_stderror: 1.281\n","Still best_val_rmse: 0.4674 (from epoch 4)\n","\n","1 steps took 0.551 seconds\n","Epoch: 4 batch_num: 35 val_rmse_target: 0.4691 val_rmse_stderror: 1.281\n","Still best_val_rmse: 0.4674 (from epoch 4)\n","\n","1 steps took 0.548 seconds\n","Epoch: 4 batch_num: 36 val_rmse_target: 0.4696 val_rmse_stderror: 1.281\n","Still best_val_rmse: 0.4674 (from epoch 4)\n","\n","1 steps took 0.558 seconds\n","Epoch: 4 batch_num: 37 val_rmse_target: 0.47 val_rmse_stderror: 1.281\n","Still best_val_rmse: 0.4674 (from epoch 4)\n","\n","1 steps took 0.557 seconds\n","Epoch: 4 batch_num: 38 val_rmse_target: 0.4704 val_rmse_stderror: 1.28\n","Still best_val_rmse: 0.4674 (from epoch 4)\n","\n","2 steps took 1.1 seconds\n","Epoch: 4 batch_num: 40 val_rmse_target: 0.4708 val_rmse_stderror: 1.28\n","Still best_val_rmse: 0.4674 (from epoch 4)\n","\n","2 steps took 1.11 seconds\n","Epoch: 4 batch_num: 42 val_rmse_target: 0.4713 val_rmse_stderror: 1.28\n","Still best_val_rmse: 0.4674 (from epoch 4)\n","\n","2 steps took 1.11 seconds\n","Epoch: 4 batch_num: 44 val_rmse_target: 0.4711 val_rmse_stderror: 1.28\n","Still best_val_rmse: 0.4674 (from epoch 4)\n","\n","2 steps took 1.1 seconds\n","Epoch: 4 batch_num: 46 val_rmse_target: 0.4709 val_rmse_stderror: 1.28\n","Still best_val_rmse: 0.4674 (from epoch 4)\n","\n","2 steps took 1.1 seconds\n","Epoch: 4 batch_num: 48 val_rmse_target: 0.4708 val_rmse_stderror: 1.279\n","Still best_val_rmse: 0.4674 (from epoch 4)\n","\n","2 steps took 1.11 seconds\n","Epoch: 4 batch_num: 50 val_rmse_target: 0.4708 val_rmse_stderror: 1.279\n","Still best_val_rmse: 0.4674 (from epoch 4)\n","\n","2 steps took 1.11 seconds\n","Epoch: 4 batch_num: 52 val_rmse_target: 0.4704 val_rmse_stderror: 1.279\n","Still best_val_rmse: 0.4674 (from epoch 4)\n","\n","2 steps took 1.11 seconds\n","Epoch: 4 batch_num: 54 val_rmse_target: 0.4702 val_rmse_stderror: 1.278\n","Still best_val_rmse: 0.4674 (from epoch 4)\n","\n","2 steps took 1.11 seconds\n","Epoch: 4 batch_num: 56 val_rmse_target: 0.47 val_rmse_stderror: 1.278\n","Still best_val_rmse: 0.4674 (from epoch 4)\n","\n","2 steps took 1.11 seconds\n","Epoch: 4 batch_num: 58 val_rmse_target: 0.4699 val_rmse_stderror: 1.278\n","Still best_val_rmse: 0.4674 (from epoch 4)\n","\n","1 steps took 0.563 seconds\n","Epoch: 4 batch_num: 59 val_rmse_target: 0.4698 val_rmse_stderror: 1.278\n","Still best_val_rmse: 0.4674 (from epoch 4)\n","\n","1 steps took 0.558 seconds\n","Epoch: 4 batch_num: 60 val_rmse_target: 0.4698 val_rmse_stderror: 1.278\n","Still best_val_rmse: 0.4674 (from epoch 4)\n","\n","1 steps took 0.552 seconds\n","Epoch: 4 batch_num: 61 val_rmse_target: 0.4698 val_rmse_stderror: 1.278\n","Still best_val_rmse: 0.4674 (from epoch 4)\n","\n","1 steps took 0.558 seconds\n","Epoch: 4 batch_num: 62 val_rmse_target: 0.4697 val_rmse_stderror: 1.278\n","Still best_val_rmse: 0.4674 (from epoch 4)\n","\n","1 steps took 0.556 seconds\n","Epoch: 4 batch_num: 63 val_rmse_target: 0.4697 val_rmse_stderror: 1.278\n","Still best_val_rmse: 0.4674 (from epoch 4)\n","\n","1 steps took 0.56 seconds\n","Epoch: 4 batch_num: 64 val_rmse_target: 0.4697 val_rmse_stderror: 1.278\n","Still best_val_rmse: 0.4674 (from epoch 4)\n","\n","1 steps took 0.555 seconds\n","Epoch: 4 batch_num: 65 val_rmse_target: 0.4697 val_rmse_stderror: 1.278\n","Still best_val_rmse: 0.4674 (from epoch 4)\n","\n","1 steps took 0.552 seconds\n","Epoch: 4 batch_num: 66 val_rmse_target: 0.4697 val_rmse_stderror: 1.278\n","Still best_val_rmse: 0.4674 (from epoch 4)\n","\n","1 steps took 0.56 seconds\n","Epoch: 4 batch_num: 67 val_rmse_target: 0.4697 val_rmse_stderror: 1.278\n","Still best_val_rmse: 0.4674 (from epoch 4)\n","\n","1 steps took 0.556 seconds\n","Epoch: 4 batch_num: 68 val_rmse_target: 0.4697 val_rmse_stderror: 1.278\n","Still best_val_rmse: 0.4674 (from epoch 4)\n","\n","1 steps took 0.548 seconds\n","Epoch: 4 batch_num: 69 val_rmse_target: 0.4697 val_rmse_stderror: 1.278\n","Still best_val_rmse: 0.4674 (from epoch 4)\n","\n","Performance estimates:\n","[0.478616777174999, 0.4827653314789129, 0.4705673261181756, 0.46737645070255673]\n","Mean: 0.474831471368661\n","\n","Fold 5/5\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"stream","text":["\n","16 steps took 9.18 seconds\n","Epoch: 0 batch_num: 16 val_rmse_target: 0.9623 val_rmse_stderror: 1.813\n","New best_val_rmse: 0.9623\n","\n","16 steps took 8.65 seconds\n","Epoch: 0 batch_num: 32 val_rmse_target: 0.9053 val_rmse_stderror: 1.874\n","New best_val_rmse: 0.9053\n","\n","16 steps took 8.63 seconds\n","Epoch: 0 batch_num: 48 val_rmse_target: 0.7985 val_rmse_stderror: 1.611\n","New best_val_rmse: 0.7985\n","\n","16 steps took 8.59 seconds\n","Epoch: 0 batch_num: 64 val_rmse_target: 0.6974 val_rmse_stderror: 1.655\n","New best_val_rmse: 0.6974\n","\n","16 steps took 8.88 seconds\n","Epoch: 1 batch_num: 10 val_rmse_target: 0.6716 val_rmse_stderror: 1.65\n","New best_val_rmse: 0.6716\n","\n","16 steps took 8.64 seconds\n","Epoch: 1 batch_num: 26 val_rmse_target: 0.605 val_rmse_stderror: 1.667\n","New best_val_rmse: 0.605\n","\n","16 steps took 8.63 seconds\n","Epoch: 1 batch_num: 42 val_rmse_target: 0.6046 val_rmse_stderror: 1.657\n","New best_val_rmse: 0.6046\n","\n","16 steps took 8.59 seconds\n","Epoch: 1 batch_num: 58 val_rmse_target: 0.5583 val_rmse_stderror: 1.662\n","New best_val_rmse: 0.5583\n","\n","16 steps took 8.8 seconds\n","Epoch: 2 batch_num: 4 val_rmse_target: 0.5399 val_rmse_stderror: 1.664\n","New best_val_rmse: 0.5399\n","\n","16 steps took 8.6 seconds\n","Epoch: 2 batch_num: 20 val_rmse_target: 0.5332 val_rmse_stderror: 1.662\n","New best_val_rmse: 0.5332\n","\n","16 steps took 8.64 seconds\n","Epoch: 2 batch_num: 36 val_rmse_target: 0.5478 val_rmse_stderror: 1.665\n","Still best_val_rmse: 0.5332 (from epoch 2)\n","\n","16 steps took 8.61 seconds\n","Epoch: 2 batch_num: 52 val_rmse_target: 0.5272 val_rmse_stderror: 1.66\n","New best_val_rmse: 0.5272\n","\n","16 steps took 8.61 seconds\n","Epoch: 2 batch_num: 68 val_rmse_target: 0.5179 val_rmse_stderror: 1.66\n","New best_val_rmse: 0.5179\n","\n","16 steps took 8.82 seconds\n","Epoch: 3 batch_num: 14 val_rmse_target: 0.522 val_rmse_stderror: 1.661\n","Still best_val_rmse: 0.5179 (from epoch 2)\n","\n","16 steps took 8.61 seconds\n","Epoch: 3 batch_num: 30 val_rmse_target: 0.539 val_rmse_stderror: 1.666\n","Still best_val_rmse: 0.5179 (from epoch 2)\n","\n","16 steps took 8.63 seconds\n","Epoch: 3 batch_num: 46 val_rmse_target: 0.5114 val_rmse_stderror: 1.661\n","New best_val_rmse: 0.5114\n","\n","16 steps took 8.61 seconds\n","Epoch: 3 batch_num: 62 val_rmse_target: 0.5055 val_rmse_stderror: 1.665\n","New best_val_rmse: 0.5055\n","\n","16 steps took 8.81 seconds\n","Epoch: 4 batch_num: 8 val_rmse_target: 0.5118 val_rmse_stderror: 1.66\n","Still best_val_rmse: 0.5055 (from epoch 3)\n","\n","16 steps took 8.59 seconds\n","Epoch: 4 batch_num: 24 val_rmse_target: 0.5094 val_rmse_stderror: 1.661\n","Still best_val_rmse: 0.5055 (from epoch 3)\n","\n","16 steps took 8.64 seconds\n","Epoch: 4 batch_num: 40 val_rmse_target: 0.5088 val_rmse_stderror: 1.661\n","Still best_val_rmse: 0.5055 (from epoch 3)\n","\n","16 steps took 8.63 seconds\n","Epoch: 4 batch_num: 56 val_rmse_target: 0.5085 val_rmse_stderror: 1.662\n","Still best_val_rmse: 0.5055 (from epoch 3)\n","\n","Performance estimates:\n","[0.478616777174999, 0.4827653314789129, 0.4705673261181756, 0.46737645070255673, 0.5055172785882021]\n","Mean: 0.4809686328125692\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"m4v-cGx-Mv7S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626330256066,"user_tz":-540,"elapsed":18,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"cc06fb45-1b7d-47ad-f1d6-2319d9aff167"},"source":["print(list_val_rmse)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[0.478616777174999, 0.4827653314789129, 0.4705673261181756, 0.46737645070255673, 0.5055172785882021]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"q2CdCMuIKDMP"},"source":["#rep = MemReporter(model)\n","#rep.report()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eLl1yDOOKIe7"},"source":["#rep = MemReporter(model.roberta)\n","#rep.report()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7qkqnknA_m9D"},"source":["#gpuinfo()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PwrqSMdYA6Pu"},"source":["#del model\n","#del optimizer \n","#del train_loader\n","#del val_loader\n","#del scheduler \n","#del list_val_rmse\n","#del train_indices\n","#del val_indices\n","#del tokenizer\n","#torch.cuda.empty_cache()\n","#gpuinfo()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wXcHyUSJXecL"},"source":["# Inference"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YIV6UllSIGoa","executionInfo":{"status":"ok","timestamp":1626330290490,"user_tz":-540,"elapsed":34435,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"cccf9fe5-08c2-4c90-b7d1-547d1cbfafa3"},"source":["%cd\n","!mkdir .kaggle\n","!mkdir /content/model\n","!cp /content/drive/MyDrive/Colab_Files/kaggle-api/kaggle.json .kaggle/\n","\n","!cp -r /content/model_1.pth /content/model/model_1.pth\n","!cp -r /content/model_2.pth /content/model/model_2.pth\n","!cp -r /content/model_3.pth /content/model/model_3.pth\n","!cp -r /content/model_4.pth /content/model/model_4.pth\n","!cp -r /content/model_5.pth /content/model/model_5.pth"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/root\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"14ddOZH4IMam","executionInfo":{"status":"ok","timestamp":1626330397206,"user_tz":-540,"elapsed":106720,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"77824286-9e6c-464a-b0c7-9ccc6ceeb741"},"source":["\n","\n","def dataset_upload():\n","    import json\n","    from kaggle.api.kaggle_api_extended import KaggleApi\n","\n","    id = f'{USERID}/{EX_NO}'\n","\n","    dataset_metadata = {}\n","    dataset_metadata['id'] = id\n","    dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n","    dataset_metadata['title'] = f'{EX_NO}'\n","\n","    with open(UPLOAD_DIR / 'dataset-metadata.json', 'w') as f:\n","        json.dump(dataset_metadata, f, indent=4)\n","\n","    api = KaggleApi()\n","    api.authenticate()\n","\n","    # データセットがない場合\n","    if f'{USERID}/{EX_NO}' not in [str(d) for d in api.dataset_list(user=USERID, search=f'\"{EX_NO}\"')]:\n","        api.dataset_create_new(folder=UPLOAD_DIR,\n","                               convert_to_csv=False,\n","                               dir_mode='skip')\n","    # データセットがある場合\n","    else:\n","        api.dataset_create_version(folder=UPLOAD_DIR,\n","                                   version_notes='update',\n","                                   convert_to_csv=False,\n","                                   delete_old_versions=True,\n","                                   dir_mode='skip')\n","dataset_upload()\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\r  0%|          | 0.00/477M [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Starting upload for file model_2.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 477M/477M [00:19<00:00, 25.8MB/s]\n","  0%|          | 0.00/477M [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_2.pth (477MB)\n","Starting upload for file model_3.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 477M/477M [00:19<00:00, 25.2MB/s]\n","  0%|          | 0.00/477M [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_3.pth (477MB)\n","Starting upload for file model_5.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 477M/477M [00:21<00:00, 23.6MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_5.pth (477MB)\n","Starting upload for file model_4.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 477M/477M [00:19<00:00, 25.0MB/s]\n","  0%|          | 0.00/477M [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_4.pth (477MB)\n","Starting upload for file model_1.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 477M/477M [00:20<00:00, 24.5MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_1.pth (477MB)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"huJwVMSAPuDO"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0zzuBPobmLFu"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wpc8ro9hmNci"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ceDI72NumT5-"},"source":[""],"execution_count":null,"outputs":[]}]}