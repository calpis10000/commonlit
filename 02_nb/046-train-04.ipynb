{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"046-train-04.ipynb","provenance":[{"file_id":"17a4F4aC9L0QBqU8BRTrdqPn0WwJ0b08b","timestamp":1626701946013},{"file_id":"1G_W9irFTrEmDeHR0S6_u0bjpk8nxipXW","timestamp":1626689695352},{"file_id":"1bhhkorT--y8XXaVLM8hibVgC-tLqZ16P","timestamp":1626358153868},{"file_id":"1WtT2hX6O9Qbt_hb9sF50nM2QmDXFi-XA","timestamp":1626338366006},{"file_id":"1k_p5wftcUeo711Xho1-T5an2Xkneau-J","timestamp":1626323813472},{"file_id":"1Vz2GB2BNTWuefEFkCSh3TBPEIel7KG1t","timestamp":1626317426487},{"file_id":"1djoMWojeaIPopG5tS1jNMohn8ineblRh","timestamp":1626306831897},{"file_id":"1-6tlDO8158Pi6TpptIF884oFaEiT4Uxb","timestamp":1626276420047},{"file_id":"1js8eA3mDNS8mwSpCiHuzPeARFlUPAVrg","timestamp":1626272452526},{"file_id":"1yhcPgulwJtjJKUK9IuRKmNMhJ-4YXGol","timestamp":1626267205517},{"file_id":"1mnnSv0Pofn1QxArywV81VYqnZPB8uUWN","timestamp":1626180468522},{"file_id":"1RRdjt_UAeHmr5QQBAMyC82Fq1s31OWdK","timestamp":1625833136005},{"file_id":"1JPgg44HFemzwk8VSCXih3PejL0idy-C4","timestamp":1625825483466},{"file_id":"1Ye6wqVX71xAAAhmjXkw9IpRvTqeUyJDA","timestamp":1625812137500}],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"051e66f48cc0474594fd5de32c6bf4c4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_74094efcb082400cb8b30a6e7edcbcdf","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4f89f53db1884f8d8b3a0e91799ab6be","IPY_MODEL_a3ee672135844adba0025457878d8d7e"]}},"74094efcb082400cb8b30a6e7edcbcdf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4f89f53db1884f8d8b3a0e91799ab6be":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b61c7cfaa862467b8eea3b6d2e96416c","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":482,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":482,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1f128fe85e004d0a88afdd36d4820966"}},"a3ee672135844adba0025457878d8d7e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_51a4d847b70d408b80ed4df59e185b8a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 482/482 [00:02&lt;00:00, 236B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_75c08af17aa24a53ac66a714061ca911"}},"b61c7cfaa862467b8eea3b6d2e96416c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1f128fe85e004d0a88afdd36d4820966":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"51a4d847b70d408b80ed4df59e185b8a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"75c08af17aa24a53ac66a714061ca911":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d43722255299432bb009017e148b8796":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9e8029e194044eb48bccf949df90d32e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3c1805fe447a4a87b75cefc205fc34c3","IPY_MODEL_74877cc184fa424588b9827a8cc06dd6"]}},"9e8029e194044eb48bccf949df90d32e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3c1805fe447a4a87b75cefc205fc34c3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e97a94c968a94aa4a2d54f49ed74baff","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":898823,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":898823,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_71bb6137342a40f991209ae54ff43289"}},"74877cc184fa424588b9827a8cc06dd6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cb07a93996644867967f2ce52bacf6b3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 899k/899k [00:01&lt;00:00, 698kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ba807408f6304a60a465fc15ced1499f"}},"e97a94c968a94aa4a2d54f49ed74baff":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"71bb6137342a40f991209ae54ff43289":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cb07a93996644867967f2ce52bacf6b3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ba807408f6304a60a465fc15ced1499f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a4b644f0eeec48f5a16efb89d22dd149":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ecef3761b5844ec8b37402d7f3b51716","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_87e6c3c8f1714820bd96aeb184256d5c","IPY_MODEL_9c05bdb038284cdd982b29af908d75f4"]}},"ecef3761b5844ec8b37402d7f3b51716":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"87e6c3c8f1714820bd96aeb184256d5c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_927dc4aa3dd245d49a45cca816c74dbd","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":456318,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":456318,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_06d2be049bf142d790b8d098106c203e"}},"9c05bdb038284cdd982b29af908d75f4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_81f44a1951a642e78d9bbe0cd0e34af5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 456k/456k [29:54&lt;00:00, 254B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d86d5c8c8ad9477b8c6304dddfe7e527"}},"927dc4aa3dd245d49a45cca816c74dbd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"06d2be049bf142d790b8d098106c203e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"81f44a1951a642e78d9bbe0cd0e34af5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d86d5c8c8ad9477b8c6304dddfe7e527":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fe72ff1cf08349dd9511ebdda0c5ba2b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bf0881c716de49419ddb52f92187605e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0c4be4411a114a7f852ea408a592174a","IPY_MODEL_f7cf553b17a84019a446bb0c09f108f0"]}},"bf0881c716de49419ddb52f92187605e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0c4be4411a114a7f852ea408a592174a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_00d7ca27600b4f3580e308ad23efc7dd","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1355863,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1355863,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4c2faede028e4df5b338548429a7872d"}},"f7cf553b17a84019a446bb0c09f108f0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2e3fd76552ae45978fb3d3d04acf2ed3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.36M/1.36M [00:03&lt;00:00, 381kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9e6556225e514929a91f3823a84794f2"}},"00d7ca27600b4f3580e308ad23efc7dd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4c2faede028e4df5b338548429a7872d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2e3fd76552ae45978fb3d3d04acf2ed3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9e6556225e514929a91f3823a84794f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":86},"id":"Z6yRwt-PXtbP","executionInfo":{"status":"ok","timestamp":1626717373308,"user_tz":-540,"elapsed":387,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"d415f4b0-d7f2-42c1-bd06-3b67a55178da"},"source":["\"\"\"\n","if 'google.colab' in sys.modules:  # colab環境特有の処理_初回のみ\n","  # Google Driveのマウント\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","\n","  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules' \\\n","   -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/requirements.txt' \\\n","   --ignore-installed\n","\n","  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules' \\\n","   transformers -U\n","  !pip install gensim==4.0.1 --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\n","  !pip install pytorch_memlab --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\n","\"\"\""],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\nif 'google.colab' in sys.modules:  # colab環境特有の処理_初回のみ\\n  # Google Driveのマウント\\n  from google.colab import drive\\n  drive.mount('/content/drive')\\n\\n  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'    -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/requirements.txt'    --ignore-installed\\n\\n  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'    transformers -U\\n  !pip install gensim==4.0.1 --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\\n  !pip install pytorch_memlab --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\\n\""]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ucCbvGD1XvG7","executionInfo":{"status":"ok","timestamp":1626717378910,"user_tz":-540,"elapsed":4957,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"50ecc75c-8154-482b-817c-67794716a5ec"},"source":["import sys\n","if 'google.colab' in sys.modules:  # colab特有の処理_2回目以降\n","  # Google Driveのマウント\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","\n","  # データセットをDriveから取得\n","  !mkdir -p 'input'\n","  !cp -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/00_input/commonlitreadabilityprize/' '/content/input'\n","  !cp -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/97_pre_trained/clrp_pretrained_03' '/content/clrp-roberta-large'\n","  # ライブラリのパス指定\n","  sys.path.append('/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules')\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RV9-VwbpZLZ9","executionInfo":{"status":"ok","timestamp":1626717378911,"user_tz":-540,"elapsed":19,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["from pathlib import Path\n","\n","# input\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    DATA_DIR = Path('../input/commonlitreadabilityprize/')\n","\n","elif 'google.colab' in sys.modules: # Colab環境\n","    DATA_DIR = Path('/content/input/commonlitreadabilityprize')\n","\n","else:\n","    DATA_DIR = Path('../00_input/commonlitreadabilityprize/')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"x5difyXe00UV","executionInfo":{"status":"ok","timestamp":1626717378912,"user_tz":-540,"elapsed":19,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["from pathlib import Path\n","\n","# tokenizer\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    TOKENIZER_DIR = '../input/roberta-transformers-pytorch/roberta-large'\n","elif 'google.colab' in sys.modules: # Colab環境\n","    TOKENIZER_DIR = 'roberta-large' # 仮で、毎回DLする想定のモデル名を指定。あとで変更予定。\n","else:\n","    TOKENIZER_DIR = 'roberta-large'"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"tKjsUxnOeDYl","executionInfo":{"status":"ok","timestamp":1626717378912,"user_tz":-540,"elapsed":18,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["from pathlib import Path\n","\n","# pre-trained model\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    PRE_TRAINED_MODEL_DIR = '../input/roberta-transformers-pytorch/roberta-large'\n","elif 'google.colab' in sys.modules: # Colab環境\n","    PRE_TRAINED_MODEL_DIR = '/content/clrp-roberta-large' # 仮で、毎回DLする想定のモデル名を指定。あとで変更予定。\n","else:\n","    PRE_TRAINED_MODEL_DIR = 'roberta-large'"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZLaT2V0ReoAZ","executionInfo":{"status":"ok","timestamp":1626717378913,"user_tz":-540,"elapsed":19,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["UPLOAD_DIR = Path('/content/model')\n","EX_NO = '046-train-04'  # 実験番号などを入れる、folderのpathにする\n","USERID = 'calpis10000'"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"hOGjAb4pAJ0F","executionInfo":{"status":"ok","timestamp":1626717378913,"user_tz":-540,"elapsed":18,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["import subprocess\n","import shlex\n","\n","def gpuinfo():\n","    \"\"\"\n","    Returns size of total GPU RAM and used GPU RAM.\n","\n","    Parameters\n","    ----------\n","    None\n","\n","    Returns\n","    -------\n","    info : dict\n","        Total GPU RAM in integer for key 'total_MiB'.\n","        Used GPU RAM in integer for key 'used_MiB'.\n","    \"\"\"\n","\n","    command = 'nvidia-smi -q -d MEMORY | sed -n \"/FB Memory Usage/,/Free/p\" | sed -e \"1d\" -e \"4d\" -e \"s/ MiB//g\" | cut -d \":\" -f 2 | cut -c2-'\n","    commands = [shlex.split(part) for part in command.split(' | ')]\n","    for i, cmd in enumerate(commands):\n","        if i==0:\n","            res = subprocess.Popen(cmd, stdout=subprocess.PIPE)\n","        else:\n","            res = subprocess.Popen(cmd, stdin=res.stdout, stdout=subprocess.PIPE)\n","    total, used = map(int, res.communicate()[0].decode('utf-8').strip().split('\\n'))\n","    info = {'total_MiB':total, 'used_MiB':used}\n","    return info\n"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g3-6m5MKXecB"},"source":["# Overview\n","This nb is based on copy from https://www.kaggle.com/andretugan/lightweight-roberta-solution-in-pytorch .\n","\n","Acknowledgments(from base nb): \n","some ideas were taken from kernels by [Torch](https://www.kaggle.com/rhtsingh) and [Maunish](https://www.kaggle.com/maunish)."]},{"cell_type":"code","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-04T06:26:32.834365Z","iopub.execute_input":"2021-07-04T06:26:32.834903Z","iopub.status.idle":"2021-07-04T06:26:40.143740Z","shell.execute_reply.started":"2021-07-04T06:26:32.834785Z","shell.execute_reply":"2021-07-04T06:26:40.142864Z"},"trusted":true,"id":"HRsRZ06WXecD","executionInfo":{"status":"ok","timestamp":1626717547220,"user_tz":-540,"elapsed":168324,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["import os\n","import math\n","import random\n","import time\n","\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","\n","from transformers import AdamW # optimizer\n","from transformers import AutoTokenizer\n","from transformers import AutoModel\n","from transformers import AutoConfig\n","from transformers import get_cosine_schedule_with_warmup # scheduler\n","from pytorch_memlab import profile\n","import pytorch_memlab\n","from pytorch_memlab import MemReporter\n","\n","from sklearn.model_selection import KFold, StratifiedKFold\n","\n","import gc\n","gc.enable()"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.145217Z","iopub.execute_input":"2021-07-04T06:26:40.145539Z","iopub.status.idle":"2021-07-04T06:26:40.201326Z","shell.execute_reply.started":"2021-07-04T06:26:40.145504Z","shell.execute_reply":"2021-07-04T06:26:40.200136Z"},"trusted":true,"id":"omBfwshTXecE","executionInfo":{"status":"ok","timestamp":1626717547220,"user_tz":-540,"elapsed":21,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["NUM_FOLDS = 5 # K Fold\n","NUM_EPOCHS = 5 # Epochs\n","BATCH_SIZE = 12 # Batch Size\n","MAX_LEN = 248 # ベクトル長\n","EVAL_SCHEDULE = [(0.55, 64), (0.50, 32), (0.49, 16), (0.48, 8), (0.47, 4), (0.46, 2), (-1., 1)] # schedulerの何らかの設定？\n","ROBERTA_PATH = PRE_TRAINED_MODEL_DIR # roberta pre-trainedモデル(モデルとして指定)\n","TOKENIZER_PATH = TOKENIZER_DIR # roberta pre-trainedモデル(Tokenizerとして指定)\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\" # cudaがなければcpuを使えばいいじゃない"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.203398Z","iopub.execute_input":"2021-07-04T06:26:40.204055Z","iopub.status.idle":"2021-07-04T06:26:40.211572Z","shell.execute_reply.started":"2021-07-04T06:26:40.204015Z","shell.execute_reply":"2021-07-04T06:26:40.210762Z"},"trusted":true,"id":"4qcuXqwtXecF","executionInfo":{"status":"ok","timestamp":1626717547221,"user_tz":-540,"elapsed":21,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["def set_random_seed(random_seed):\n","    random.seed(random_seed)\n","    np.random.seed(random_seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(random_seed)\n","\n","    torch.manual_seed(random_seed)\n","    torch.cuda.manual_seed(random_seed)\n","    torch.cuda.manual_seed_all(random_seed)\n","\n","    torch.backends.cudnn.deterministic = True# cudnnによる最適化で結果が変わらないためのおまじない "],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.214188Z","iopub.execute_input":"2021-07-04T06:26:40.214809Z","iopub.status.idle":"2021-07-04T06:26:40.309744Z","shell.execute_reply.started":"2021-07-04T06:26:40.214769Z","shell.execute_reply":"2021-07-04T06:26:40.308926Z"},"trusted":true,"id":"70PyLsJTXecF","executionInfo":{"status":"ok","timestamp":1626717547222,"user_tz":-540,"elapsed":21,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# train, testを読む\n","train_df = pd.read_csv(DATA_DIR/\"train.csv\")\n","\n","# Remove incomplete entries if any.\n","train_df.drop(train_df[(train_df.target == 0) & (train_df.standard_error == 0)].index,\n","              inplace=True)\n","train_df.reset_index(drop=True, inplace=True)\n","\n","test_df = pd.read_csv(DATA_DIR/\"test.csv\")\n","submission_df = pd.read_csv(DATA_DIR/\"sample_submission.csv\")"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"9ZYOB59L8qtA","executionInfo":{"status":"ok","timestamp":1626717547223,"user_tz":-540,"elapsed":21,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"a4be60e4-9692-478d-874d-c57177fb84d2"},"source":["train_df.head()\n"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>url_legal</th>\n","      <th>license</th>\n","      <th>excerpt</th>\n","      <th>target</th>\n","      <th>standard_error</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>c12129c31</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>When the young people returned to the ballroom...</td>\n","      <td>-0.340259</td>\n","      <td>0.464009</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>85aa80a4c</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>All through dinner time, Mrs. Fayre was somewh...</td>\n","      <td>-0.315372</td>\n","      <td>0.480805</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>b69ac6792</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>As Roger had predicted, the snow departed as q...</td>\n","      <td>-0.580118</td>\n","      <td>0.476676</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>dd1000b26</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>And outside before the palace a great garden w...</td>\n","      <td>-1.054013</td>\n","      <td>0.450007</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>37c1b32fb</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Once upon a time there were Three Bears who li...</td>\n","      <td>0.247197</td>\n","      <td>0.510845</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          id url_legal  ...    target standard_error\n","0  c12129c31       NaN  ... -0.340259       0.464009\n","1  85aa80a4c       NaN  ... -0.315372       0.480805\n","2  b69ac6792       NaN  ... -0.580118       0.476676\n","3  dd1000b26       NaN  ... -1.054013       0.450007\n","4  37c1b32fb       NaN  ...  0.247197       0.510845\n","\n","[5 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.311021Z","iopub.execute_input":"2021-07-04T06:26:40.311347Z","iopub.status.idle":"2021-07-04T06:26:40.624393Z","shell.execute_reply.started":"2021-07-04T06:26:40.311314Z","shell.execute_reply":"2021-07-04T06:26:40.623347Z"},"trusted":true,"id":"xf0662k4XecF","colab":{"base_uri":"https://localhost:8080/","height":213,"referenced_widgets":["051e66f48cc0474594fd5de32c6bf4c4","74094efcb082400cb8b30a6e7edcbcdf","4f89f53db1884f8d8b3a0e91799ab6be","a3ee672135844adba0025457878d8d7e","b61c7cfaa862467b8eea3b6d2e96416c","1f128fe85e004d0a88afdd36d4820966","51a4d847b70d408b80ed4df59e185b8a","75c08af17aa24a53ac66a714061ca911","d43722255299432bb009017e148b8796","9e8029e194044eb48bccf949df90d32e","3c1805fe447a4a87b75cefc205fc34c3","74877cc184fa424588b9827a8cc06dd6","e97a94c968a94aa4a2d54f49ed74baff","71bb6137342a40f991209ae54ff43289","cb07a93996644867967f2ce52bacf6b3","ba807408f6304a60a465fc15ced1499f","a4b644f0eeec48f5a16efb89d22dd149","ecef3761b5844ec8b37402d7f3b51716","87e6c3c8f1714820bd96aeb184256d5c","9c05bdb038284cdd982b29af908d75f4","927dc4aa3dd245d49a45cca816c74dbd","06d2be049bf142d790b8d098106c203e","81f44a1951a642e78d9bbe0cd0e34af5","d86d5c8c8ad9477b8c6304dddfe7e527","fe72ff1cf08349dd9511ebdda0c5ba2b","bf0881c716de49419ddb52f92187605e","0c4be4411a114a7f852ea408a592174a","f7cf553b17a84019a446bb0c09f108f0","00d7ca27600b4f3580e308ad23efc7dd","4c2faede028e4df5b338548429a7872d","2e3fd76552ae45978fb3d3d04acf2ed3","9e6556225e514929a91f3823a84794f2"]},"executionInfo":{"status":"ok","timestamp":1626717554692,"user_tz":-540,"elapsed":7488,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"a8f699d9-76d7-476b-c7f0-4f3ee3dbe222"},"source":["# tokenizerを指定\n","tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)"],"execution_count":13,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"051e66f48cc0474594fd5de32c6bf4c4","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=482.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d43722255299432bb009017e148b8796","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a4b644f0eeec48f5a16efb89d22dd149","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fe72ff1cf08349dd9511ebdda0c5ba2b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355863.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"N6aaghNkXecG"},"source":["# Dataset"]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.628883Z","iopub.execute_input":"2021-07-04T06:26:40.629347Z","iopub.status.idle":"2021-07-04T06:26:40.644338Z","shell.execute_reply.started":"2021-07-04T06:26:40.629309Z","shell.execute_reply":"2021-07-04T06:26:40.643336Z"},"trusted":true,"id":"zkopT0U1XecG","executionInfo":{"status":"ok","timestamp":1626717554700,"user_tz":-540,"elapsed":31,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# Dataset用のClass。おそらく、trainとtestでインスタンスを生成し、DataFrameと同じように扱えるような思想。\n","class LitDataset(Dataset):\n","    def __init__(self, df, inference_only=False):\n","        super().__init__()\n","\n","        self.df = df        \n","        self.inference_only = inference_only # Testデータ用フラグ\n","        self.text = df.excerpt.tolist() # 分析対象カラムをlistにする。(分かち書きではなく、Seriesをlistへ変換するような処理)\n","        #self.text = [text.replace(\"\\n\", \" \") for text in self.text] # 単語単位で分かち書きする場合\n","        \n","        if not self.inference_only:\n","            self.target = torch.tensor(df.target.values, dtype=torch.float32) # trainのみ、targetをtensorに変換\n","            self.standard_error = torch.tensor(df.standard_error.values, dtype=torch.float32) \n","\n","        self.encoded = tokenizer.batch_encode_plus( # textをtokenize\n","            self.text,\n","            padding = 'max_length',            \n","            max_length = MAX_LEN,\n","            truncation = True, # 最大長を超える文字は切り捨て\n","            return_attention_mask=True\n","        )        \n"," \n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    \n","    def __getitem__(self, index): # 変換結果を返す\n","        input_ids = torch.tensor(self.encoded['input_ids'][index])\n","        attention_mask = torch.tensor(self.encoded['attention_mask'][index])\n","        \n","        if self.inference_only:\n","            return (input_ids, attention_mask)            \n","        else:\n","            target = self.target[index]\n","            standard_error = self.standard_error[index]\n","            return (input_ids, attention_mask, target, standard_error)"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KKtdy32wXecG"},"source":["# Model\n","The model is inspired by the one from [Maunish](https://www.kaggle.com/maunish/clrp-roberta-svm)."]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.649629Z","iopub.execute_input":"2021-07-04T06:26:40.650066Z","iopub.status.idle":"2021-07-04T06:26:40.666374Z","shell.execute_reply.started":"2021-07-04T06:26:40.650002Z","shell.execute_reply":"2021-07-04T06:26:40.665211Z"},"trusted":true,"id":"BpkxjXEUXecH","executionInfo":{"status":"ok","timestamp":1626717554701,"user_tz":-540,"elapsed":30,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["class LitModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        config = AutoConfig.from_pretrained(ROBERTA_PATH) # pretrainedからconfigを読み込み\n","        config.update({\"output_hidden_states\":True, # config更新: embedding層を抽出\n","                       \"hidden_dropout_prob\": 0.0, # config更新: dropoutしない\n","                       \"layer_norm_eps\": 1e-7}) # config更新: layer normalizationのepsilon                      \n","        \n","        self.roberta = AutoModel.from_pretrained(ROBERTA_PATH, config=config) # cpuで処理する\n","            \n","        self.attention = nn.Sequential(# attentionレイヤー            \n","            nn.Linear(config.hidden_size, 512),      \n","            nn.Tanh(),                       \n","            nn.Linear(512, 1),\n","            nn.Softmax(dim=1)\n","        )\n","\n","        self.regressor = nn.Sequential( # 出力レイヤー                    \n","            nn.Linear(config.hidden_size, 2)                        \n","        )\n","\n","    def forward(self, input_ids, attention_mask):\n","        roberta_output = self.roberta(input_ids=input_ids, # robertaに入力データを流し、出力としてrobertaモデル(layerの複合体)を得る\n","                                      attention_mask=attention_mask)     \n","\n","        #last_hidden_state = roberta_output.hidden_states[-1] # robertaモデルの最後のlayerを得る\n","        #weights = self.attention(last_hidden_state) # robertaの最後のlayerをattentionへ入力し、出力として重みを得る                \n","        #context_vector = torch.sum(weights * last_hidden_state, dim=1) # 重み×最後の層を足し合わせて文書ベクトルとする。\n","        #return self.regressor(context_vector) # 文書ベクトルを線形層に入力し、targetを出力する\n","\n","        # https://www.kaggle.com/rhtsingh/utilizing-transformer-representations-efficiently\n","        last_hidden_state = roberta_output[0]\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        sum_mask = input_mask_expanded.sum(1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        mean_embeddings = sum_embeddings / sum_mask\n","        return self.regressor(mean_embeddings) # 文書ベクトルを線形層に入力し、targetを出力する        "],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.672515Z","iopub.execute_input":"2021-07-04T06:26:40.672944Z","iopub.status.idle":"2021-07-04T06:26:40.684593Z","shell.execute_reply.started":"2021-07-04T06:26:40.672908Z","shell.execute_reply":"2021-07-04T06:26:40.683569Z"},"trusted":true,"id":"bB4jvQTxXecH","executionInfo":{"status":"ok","timestamp":1626717554702,"user_tz":-540,"elapsed":30,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 評価指標(MSE)の計算。最終的に、ルートしてRMSEにすると思われる。\n","def eval_mse(model, data_loader):\n","    \"\"\"Evaluates the mean squared error of the |model| on |data_loader|\"\"\"\n","    model.eval() # evalモードを選択。Batch Normとかdropoutをしなくなる           \n","    mse_mean_sum = 0\n","    mse_std_sum = 0\n","\n","    with torch.no_grad(): # 勾配の計算をしないBlock\n","        for batch_num, (input_ids, attention_mask, target, standard_error) in enumerate(data_loader): # data_loaderからinput, attentin_mask, targetをbatchごとに取り出す\n","            input_ids = input_ids.to(DEVICE)   \n","            attention_mask = attention_mask.to(DEVICE)   \n","            target = target.to(DEVICE)      \n","            standard_error = standard_error.to(DEVICE) \n","            \n","            output = model(input_ids, attention_mask) # 取得した値をモデルへ入力し、出力として予測値を得る。\n","\n","            mse_mean_sum += nn.MSELoss(reduction=\"sum\")(output[:,0].flatten(), target).item() # 誤差の合計を得る(Batchごとに計算した誤差を足し上げる)\n","            mse_std_sum += nn.MSELoss(reduction=\"sum\")(output[:,1].flatten(), target).item() # 誤差の合計を得る(Batchごとに計算した誤差を足し上げる)\n","\n","    del input_ids\n","    del attention_mask\n","    del target\n","\n","    mse_mean_result = mse_mean_sum / len(data_loader.dataset)\n","    mse_std_result = mse_std_sum / len(data_loader.dataset)\n","  \n","    return mse_mean_result, mse_std_result # 誤差の合計をdataset長で除し、mseを取得＆返す"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.690155Z","iopub.execute_input":"2021-07-04T06:26:40.692530Z","iopub.status.idle":"2021-07-04T06:26:40.703425Z","shell.execute_reply.started":"2021-07-04T06:26:40.692488Z","shell.execute_reply":"2021-07-04T06:26:40.702366Z"},"trusted":true,"id":"47bDno_LXecI","executionInfo":{"status":"ok","timestamp":1626717554703,"user_tz":-540,"elapsed":30,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 推論結果を返す\n","def predict(model, data_loader):\n","    \"\"\"Returns an np.array with predictions of the |model| on |data_loader|\"\"\"\n","    model.eval() # evalモード(dropout, batch_normしない)\n","\n","    result = np.zeros(len(data_loader.dataset)) # 結果をdataset長のzero配列として用意\n","    index = 0\n","    \n","    with torch.no_grad(): # 勾配の計算をしないblock(inputすると、現状の重みによる推論結果を返す)\n","        for batch_num, (input_ids, attention_mask) in enumerate(data_loader): # data_loaderからbatchごとにinputを得る\n","            input_ids = input_ids.to(DEVICE)\n","            attention_mask = attention_mask.to(DEVICE)\n","                        \n","            output = model(input_ids, attention_mask) # modelにinputを入力し、予測結果を得る。\n","\n","            result[index : index + output[:,0].shape[0]] = output[:,0].flatten().to(\"cpu\") # result[index ~ predの長さ]へ、予測結果を格納\n","            index += pred.shape[0] # indexを更新\n","\n","    return result # 全batchで推論が終わったら、結果を返す"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.708605Z","iopub.execute_input":"2021-07-04T06:26:40.709024Z","iopub.status.idle":"2021-07-04T06:26:40.730675Z","shell.execute_reply.started":"2021-07-04T06:26:40.708983Z","shell.execute_reply":"2021-07-04T06:26:40.729705Z"},"trusted":true,"id":"oInneuAmXecI","executionInfo":{"status":"ok","timestamp":1626717554704,"user_tz":-540,"elapsed":30,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 学習\n","def train(model, # モデル\n","          model_path, # モデルのアウトプット先\n","          train_loader, # train-setのdata_loader\n","          val_loader, # valid-setのdata_loader\n","          optimizer, # optimizer\n","          scheduler=None, # scheduler, デフォルトはNone\n","          num_epochs=NUM_EPOCHS # epoch数、notebook冒頭で指定した値\n","         ):    \n","    \n","    best_val_rmse = None\n","    best_epoch = 0\n","    step = 0\n","    last_eval_step = 0\n","    eval_period = EVAL_SCHEDULE[0][1] # eval期間(って何？) 冒頭で決めたEVAL_SCHEDULEの最初のtupleの[1]を取得\n","\n","    start = time.time() # 時間計測用\n","\n","    for epoch in range(num_epochs): # 指定したEpoch数だけ繰り返し\n","        val_rmse = None         \n","\n","        for batch_num, (input_ids, attention_mask, target, standard_error) in enumerate(train_loader): # train_loaderからinput, targetを取得\n","            input_ids = input_ids.to(DEVICE) # inputをDEVICEへ突っ込む\n","            attention_mask = attention_mask.to(DEVICE)       \n","            target = target.to(DEVICE)\n","            standard_error = standard_error.to(DEVICE)  \n","\n","            optimizer.zero_grad() # 勾配を初期化            \n","            model.train() # 学習モード開始\n","\n","            # https://www.kaggle.com/c/commonlitreadabilityprize/discussion/239421\n","            output = model(input_ids, attention_mask) # input,attention_maskを入力し、予測結果を得る\n","            p = torch.distributions.Normal(output[:,0], torch.sqrt(output[:,1]**2))\n","            q = torch.distributions.Normal(target, standard_error)\n","            kl_vector = torch.distributions.kl_divergence(p, q)\n","            loss = kl_vector.mean()\n","\n","            loss.backward() # 誤差逆伝播法により勾配を得る\n","            optimizer.step() # 重みを更新する\n","\n","            if scheduler:\n","                scheduler.step() # schedulerが与えられた場合は、schedulerの学習率更新\n","            \n","            if step >= last_eval_step + eval_period: # batchを回すごとにstepを増やしていって、「前回evalしたstep + eval_period(16)」を超えたら実行。\n","                # Evaluate the model on val_loader.\n","                elapsed_seconds = time.time() - start # 経過時間\n","                num_steps = step - last_eval_step # 経過ステップ数\n","                print(f\"\\n{num_steps} steps took {elapsed_seconds:0.3} seconds\")\n","                last_eval_step = step # 前回stepの更新\n","                \n","                # valid-setによるrmse計算\n","                train_mean_mse = nn.MSELoss(reduction=\"mean\")(output[:,0].flatten(), target) \n","                train_std_mse = nn.MSELoss(reduction=\"mean\")(torch.sqrt(output[:,1]**2).flatten(), standard_error) \n","\n","                train_mean_rmse = math.sqrt(train_mean_mse)\n","                train_std_rmse = math.sqrt(train_std_mse)\n","\n","                val_mean_mse, val_std_mse = eval_mse(model, val_loader)\n","                val_mean_rmse = math.sqrt(val_mean_mse)                            \n","                val_std_rmse = math.sqrt(val_std_mse)                            \n","\n","                print(f\"Epoch: {epoch} batch_num: {batch_num}\")\n","                print(f\"train_rmse_target: {train_mean_rmse:0.4}\",\n","                      f\"train_rmse_stderror: {train_std_rmse:0.4}\",\n","                      f\"train_kl_div: {loss:0.4}\",\n","                      )\n","                print(f\"val_rmse_target: {val_mean_rmse:0.4}\",\n","                      f\"val_rmse_stderror: {val_std_rmse:0.4}\"\n","                      )\n","\n","                for rmse, period in EVAL_SCHEDULE: # eval_periodをvalid-rmseで切り替える処理\n","                    if val_mean_rmse >= rmse: # valid rmseをEVAL_SCHEDULEと比較し、0項 > valid rmseとなるまで回す : EVAL_SCHEDULE = [(0.50, 16), (0.49, 8), (0.48, 4), (0.47, 2), (-1., 1)]\n","                        eval_period = period # eval_periodを更新\n","                        break                               \n","\n","                if not best_val_rmse or val_mean_rmse < best_val_rmse: # 初回(best_val_rmse==None), またはbest_val_rmseを更新したらモデルを保存する\n","                    best_val_rmse = val_mean_rmse\n","                    best_epoch = epoch\n","                    torch.save(model.state_dict(), model_path) # 最高の自分を保存\n","                    print(f\"New best_val_rmse: {best_val_rmse:0.4}\")\n","                else:       \n","                    print(f\"Still best_val_rmse: {best_val_rmse:0.4}\", # 更新されない場合は、元のスコアを表示\n","                          f\"(from epoch {best_epoch})\")      \n","                                                  \n","                start = time.time()\n","            \n","            # batchごとにメモリ解放\n","            del input_ids\n","            del attention_mask\n","            del target\n","            torch.cuda.empty_cache()                                            \n","            step += 1\n","    \n","    return best_val_rmse"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.735798Z","iopub.execute_input":"2021-07-04T06:26:40.738398Z","iopub.status.idle":"2021-07-04T06:26:40.750876Z","shell.execute_reply.started":"2021-07-04T06:26:40.738356Z","shell.execute_reply":"2021-07-04T06:26:40.749635Z"},"trusted":true,"id":"rMY0fjXwXecJ","executionInfo":{"status":"ok","timestamp":1626717554704,"user_tz":-540,"elapsed":30,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# optimizerの作成\n","def create_optimizer(model):\n","    named_parameters = list(model.named_parameters()) # モデルパラメータの取得\n","    \n","    roberta_parameters = list(model.roberta.named_parameters())[:-2] # パラメータをroberta用、attention用、regressor用に格納。(直接引っ張ってくる形式に変更)\n","    #attention_parameters = list(model.attention.named_parameters())\n","    regressor_parameters = list(model.regressor.named_parameters())\n","        \n","    #attention_group = [params for (name, params) in attention_parameters] # attention用パラメータをリストとして取得\n","    regressor_group = [params for (name, params) in regressor_parameters] # reg用パラメータをリストとして取得\n","\n","    parameters = []\n","    #parameters.append({\"params\": attention_group}) # パラメータをリストに辞書として格納していく\n","    parameters.append({\"params\": regressor_group})\n","\n","    for layer_num, (name, params) in enumerate(roberta_parameters): # レイヤーごとにname, paramsを取得していろんな処理\n","        weight_decay = 0.0 if \"bias\" in name else 0.01\n","\n","        lr = 8e-6\n","\n","        if layer_num >= 69:        \n","            lr = 2e-5\n","\n","        if layer_num >= 133:\n","            lr = 4e-5\n","\n","        parameters.append({\"params\": params,\n","                           \"weight_decay\": weight_decay,\n","                           \"lr\": lr})\n","\n","    return AdamW(parameters) # 最終的に、AdamWにパラメータを入力する。\n"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"EbaJojz0Zjif","executionInfo":{"status":"ok","timestamp":1626717554705,"user_tz":-540,"elapsed":30,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# https://www.kaggle.com/abhishek/step-1-create-folds\n","def create_folds(data, num_splits, SEED, return_df=False):\n","    # we create a new column called kfold and fill it with -1\n","    data[\"kfold\"] = -1\n","    \n","    # the next step is to randomize the rows of the data\n","    data = data.sample(frac=1).reset_index(drop=True)\n","\n","    # calculate number of bins by Sturge's rule\n","    # I take the floor of the value, you can also\n","    # just round it\n","    num_bins = int(np.floor(1 + np.log2(len(data))))\n","    \n","    # bin targets\n","    data.loc[:, \"bins_tg\"] = pd.cut(\n","        data[\"target\"], bins=num_bins, labels=False\n","    ).map(lambda x: str(x))\n","\n","    # bin standard_error\n","    data.loc[:, \"bins_std\"] = pd.cut(\n","        data[\"standard_error\"], bins=num_bins, labels=False\n","    )\n","\n","    # bins\n","    data.loc[:, \"bins\"] = data['bins_tg'].map(lambda x: str(x)) + data['bins_std'].map(lambda x: str(x))\n","\n","    # initiate the kfold class from model_selection module\n","    kf = StratifiedKFold(n_splits=5, random_state=SEED, shuffle=True)\n","\n","    # note that, instead of targets, we use bins!\n","    if return_df:\n","      for f, (t_, v_) in enumerate(kf.split(X=data, y=data.bins.values)):\n","        data.loc[v_, 'kfold'] = f\n","      return data\n","    else:\n","      return kf.split(X=data, y=data.bins.values)"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"id":"vAmhaYaylMk5","executionInfo":{"status":"ok","timestamp":1626717554706,"user_tz":-540,"elapsed":30,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"6d8bbbc0-c551-43b0-bb10-2333f9e4502c"},"source":["# 検証用\n","SEED = 1000\n","st_kfold_bins_df = create_folds(train_df, num_splits=5, SEED=SEED, return_df=True)\n","st_kfold_bins_df['bins_tg'] = st_kfold_bins_df['bins_tg'].map(lambda x: float(x))\n","st_kfold_bins_df['bins_std'] = st_kfold_bins_df['bins_std'].map(lambda x: float(x))\n","st_kfold_bins_df.groupby('kfold').agg({'bins_tg': ['min', 'max', 'mean'],\n","                                    'bins_std': ['min', 'max', 'mean']})"],"execution_count":21,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  % (min_groups, self.n_splits)), UserWarning)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","\n","    .dataframe thead tr:last-of-type th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th></th>\n","      <th colspan=\"3\" halign=\"left\">bins_tg</th>\n","      <th colspan=\"3\" halign=\"left\">bins_std</th>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <th>min</th>\n","      <th>max</th>\n","      <th>mean</th>\n","      <th>min</th>\n","      <th>max</th>\n","      <th>mean</th>\n","    </tr>\n","    <tr>\n","      <th>kfold</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>5.541446</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>2.941799</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>5.525573</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>2.932981</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>5.513228</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>2.890653</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>5.567138</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>2.929329</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>5.602473</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>2.950530</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      bins_tg                 bins_std                \n","          min   max      mean      min   max      mean\n","kfold                                                 \n","0         0.0  11.0  5.541446      0.0  11.0  2.941799\n","1         0.0  11.0  5.525573      0.0  11.0  2.932981\n","2         0.0  11.0  5.513228      0.0  11.0  2.890653\n","3         0.0  11.0  5.567138      0.0  11.0  2.929329\n","4         0.0  11.0  5.602473      0.0  11.0  2.950530"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"TyjgRCu3mmqG","executionInfo":{"status":"ok","timestamp":1626717554707,"user_tz":-540,"elapsed":27,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"4PLKHwvKtNBn","executionInfo":{"status":"ok","timestamp":1626717554708,"user_tz":-540,"elapsed":27,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["def train_and_save_model(train_indices, val_indices, model_path):\n","    train_dataset = LitDataset(train_df.loc[train_indices]) # train, validのDataset\n","    val_dataset = LitDataset(train_df.loc[val_indices])\n","        \n","    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n","                              drop_last=True, shuffle=True, num_workers=2) # train, validのDataLoader\n","    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n","                            drop_last=False, shuffle=False, num_workers=2)    \n","\n","    model = LitModel().to(DEVICE) # modelをDEVICEへぶち込む\n","    optimizer = create_optimizer(model) # optimizerをモデルから作成\n","    scheduler = get_cosine_schedule_with_warmup( # schedulerを作成\n","        optimizer,\n","        num_training_steps=NUM_EPOCHS * len(train_loader),\n","        num_warmup_steps=50)    \n","    rmse = train(model, model_path, train_loader, val_loader, optimizer, scheduler=scheduler)\n","\n","    del train_dataset\n","    del val_dataset\n","    del train_loader\n","    del val_loader\n","    del model\n","    del optimizer\n","    del scheduler\n","    gc.collect() \n","    torch.cuda.empty_cache()\n","    return rmse"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.755813Z","iopub.execute_input":"2021-07-04T06:26:40.758373Z","iopub.status.idle":"2021-07-04T06:27:12.493221Z","shell.execute_reply.started":"2021-07-04T06:26:40.758265Z","shell.execute_reply":"2021-07-04T06:27:12.490139Z"},"trusted":true,"id":"k2LGJD3XXecK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626727809655,"user_tz":-540,"elapsed":10254974,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"53df736f-5065-4570-858c-3b236ce8dd13"},"source":["# 実行処理。 KFold & 学習\n","SEED = 1000\n","list_val_rmse = []\n","\n","#kfold = KFold(n_splits=NUM_FOLDS, random_state=SEED, shuffle=True)\n","kfold = create_folds(train_df, 5, SEED=SEED, return_df=False) # binsで切る場合\n","\n","for fold, (train_indices, val_indices) in enumerate(kfold):    \n","    print(f\"\\nFold {fold + 1}/{NUM_FOLDS}\")\n","    print(gpuinfo())\n","    model_path = f\"model_{fold + 1}.pth\" # model_fold数_.pth\n","    set_random_seed(SEED + fold) # SEEDはfold別に変わるようにする\n","    list_val_rmse.append(train_and_save_model(train_indices, val_indices, model_path))\n","\n","    print(\"\\nPerformance estimates:\")\n","    print(list_val_rmse)\n","    print(\"Mean:\", np.array(list_val_rmse).mean())\n","    print(gpuinfo())"],"execution_count":23,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  % (min_groups, self.n_splits)), UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Fold 1/5\n","{'total_MiB': 16280, 'used_MiB': 2}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 81.6 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.5391 train_rmse_stderror: 0.07496 train_kl_div: 0.6909\n","val_rmse_target: 0.636 val_rmse_stderror: 1.78\n","New best_val_rmse: 0.636\n","\n","64 steps took 80.6 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.7178 train_rmse_stderror: 0.03531 train_kl_div: 1.075\n","val_rmse_target: 0.6937 val_rmse_stderror: 1.746\n","Still best_val_rmse: 0.636 (from epoch 0)\n","\n","64 steps took 80.7 seconds\n","Epoch: 1 batch_num: 4\n","train_rmse_target: 0.4891 train_rmse_stderror: 0.06893 train_kl_div: 0.4907\n","val_rmse_target: 0.535 val_rmse_stderror: 1.739\n","New best_val_rmse: 0.535\n","\n","32 steps took 40.3 seconds\n","Epoch: 1 batch_num: 36\n","train_rmse_target: 0.2657 train_rmse_stderror: 0.04241 train_kl_div: 0.1582\n","val_rmse_target: 0.5305 val_rmse_stderror: 1.728\n","New best_val_rmse: 0.5305\n","\n","32 steps took 40.2 seconds\n","Epoch: 1 batch_num: 68\n","train_rmse_target: 0.599 train_rmse_stderror: 0.04758 train_kl_div: 0.6938\n","val_rmse_target: 0.5408 val_rmse_stderror: 1.73\n","Still best_val_rmse: 0.5305 (from epoch 1)\n","\n","32 steps took 40.3 seconds\n","Epoch: 1 batch_num: 100\n","train_rmse_target: 0.7375 train_rmse_stderror: 0.04936 train_kl_div: 0.9331\n","val_rmse_target: 0.5451 val_rmse_stderror: 1.735\n","Still best_val_rmse: 0.5305 (from epoch 1)\n","\n","32 steps took 40.3 seconds\n","Epoch: 1 batch_num: 132\n","train_rmse_target: 0.4487 train_rmse_stderror: 0.02739 train_kl_div: 0.4614\n","val_rmse_target: 0.5311 val_rmse_stderror: 1.742\n","Still best_val_rmse: 0.5305 (from epoch 1)\n","\n","32 steps took 40.2 seconds\n","Epoch: 1 batch_num: 164\n","train_rmse_target: 0.2917 train_rmse_stderror: 0.01777 train_kl_div: 0.1693\n","val_rmse_target: 0.5105 val_rmse_stderror: 1.754\n","New best_val_rmse: 0.5105\n","\n","32 steps took 40.4 seconds\n","Epoch: 2 batch_num: 8\n","train_rmse_target: 0.3352 train_rmse_stderror: 0.0268 train_kl_div: 0.2684\n","val_rmse_target: 0.5485 val_rmse_stderror: 1.729\n","Still best_val_rmse: 0.5105 (from epoch 1)\n","\n","32 steps took 40.3 seconds\n","Epoch: 2 batch_num: 40\n","train_rmse_target: 0.1589 train_rmse_stderror: 0.03411 train_kl_div: 0.05981\n","val_rmse_target: 0.5242 val_rmse_stderror: 1.743\n","Still best_val_rmse: 0.5105 (from epoch 1)\n","\n","32 steps took 40.3 seconds\n","Epoch: 2 batch_num: 72\n","train_rmse_target: 0.3767 train_rmse_stderror: 0.02222 train_kl_div: 0.265\n","val_rmse_target: 0.5057 val_rmse_stderror: 1.743\n","New best_val_rmse: 0.5057\n","\n","32 steps took 40.3 seconds\n","Epoch: 2 batch_num: 104\n","train_rmse_target: 0.2139 train_rmse_stderror: 0.02954 train_kl_div: 0.104\n","val_rmse_target: 0.4951 val_rmse_stderror: 1.74\n","New best_val_rmse: 0.4951\n","\n","16 steps took 20.1 seconds\n","Epoch: 2 batch_num: 120\n","train_rmse_target: 0.2401 train_rmse_stderror: 0.01795 train_kl_div: 0.127\n","val_rmse_target: 0.5105 val_rmse_stderror: 1.746\n","Still best_val_rmse: 0.4951 (from epoch 2)\n","\n","32 steps took 40.3 seconds\n","Epoch: 2 batch_num: 152\n","train_rmse_target: 0.2592 train_rmse_stderror: 0.0327 train_kl_div: 0.1414\n","val_rmse_target: 0.5364 val_rmse_stderror: 1.743\n","Still best_val_rmse: 0.4951 (from epoch 2)\n","\n","32 steps took 40.3 seconds\n","Epoch: 2 batch_num: 184\n","train_rmse_target: 0.2241 train_rmse_stderror: 0.04315 train_kl_div: 0.1223\n","val_rmse_target: 0.5094 val_rmse_stderror: 1.733\n","Still best_val_rmse: 0.4951 (from epoch 2)\n","\n","32 steps took 40.4 seconds\n","Epoch: 3 batch_num: 28\n","train_rmse_target: 0.1072 train_rmse_stderror: 0.02137 train_kl_div: 0.02778\n","val_rmse_target: 0.4978 val_rmse_stderror: 1.731\n","Still best_val_rmse: 0.4951 (from epoch 2)\n","\n","16 steps took 20.1 seconds\n","Epoch: 3 batch_num: 44\n","train_rmse_target: 0.1367 train_rmse_stderror: 0.01994 train_kl_div: 0.04517\n","val_rmse_target: 0.4961 val_rmse_stderror: 1.741\n","Still best_val_rmse: 0.4951 (from epoch 2)\n","\n","16 steps took 20.1 seconds\n","Epoch: 3 batch_num: 60\n","train_rmse_target: 0.1069 train_rmse_stderror: 0.01297 train_kl_div: 0.02507\n","val_rmse_target: 0.4987 val_rmse_stderror: 1.737\n","Still best_val_rmse: 0.4951 (from epoch 2)\n","\n","16 steps took 20.1 seconds\n","Epoch: 3 batch_num: 76\n","train_rmse_target: 0.1277 train_rmse_stderror: 0.02421 train_kl_div: 0.03524\n","val_rmse_target: 0.4953 val_rmse_stderror: 1.736\n","Still best_val_rmse: 0.4951 (from epoch 2)\n","\n","16 steps took 20.1 seconds\n","Epoch: 3 batch_num: 92\n","train_rmse_target: 0.1158 train_rmse_stderror: 0.02181 train_kl_div: 0.0305\n","val_rmse_target: 0.4975 val_rmse_stderror: 1.736\n","Still best_val_rmse: 0.4951 (from epoch 2)\n","\n","16 steps took 20.1 seconds\n","Epoch: 3 batch_num: 108\n","train_rmse_target: 0.1519 train_rmse_stderror: 0.01459 train_kl_div: 0.05213\n","val_rmse_target: 0.491 val_rmse_stderror: 1.739\n","New best_val_rmse: 0.491\n","\n","16 steps took 20.2 seconds\n","Epoch: 3 batch_num: 124\n","train_rmse_target: 0.2501 train_rmse_stderror: 0.0264 train_kl_div: 0.1389\n","val_rmse_target: 0.4956 val_rmse_stderror: 1.74\n","Still best_val_rmse: 0.491 (from epoch 3)\n","\n","16 steps took 20.1 seconds\n","Epoch: 3 batch_num: 140\n","train_rmse_target: 0.1463 train_rmse_stderror: 0.01953 train_kl_div: 0.04865\n","val_rmse_target: 0.4927 val_rmse_stderror: 1.737\n","Still best_val_rmse: 0.491 (from epoch 3)\n","\n","16 steps took 20.1 seconds\n","Epoch: 3 batch_num: 156\n","train_rmse_target: 0.1737 train_rmse_stderror: 0.03256 train_kl_div: 0.05195\n","val_rmse_target: 0.4948 val_rmse_stderror: 1.738\n","Still best_val_rmse: 0.491 (from epoch 3)\n","\n","16 steps took 20.1 seconds\n","Epoch: 3 batch_num: 172\n","train_rmse_target: 0.1585 train_rmse_stderror: 0.02595 train_kl_div: 0.05576\n","val_rmse_target: 0.4933 val_rmse_stderror: 1.749\n","Still best_val_rmse: 0.491 (from epoch 3)\n","\n","16 steps took 20.3 seconds\n","Epoch: 4 batch_num: 0\n","train_rmse_target: 0.0929 train_rmse_stderror: 0.01656 train_kl_div: 0.02025\n","val_rmse_target: 0.4961 val_rmse_stderror: 1.737\n","Still best_val_rmse: 0.491 (from epoch 3)\n","\n","16 steps took 20.1 seconds\n","Epoch: 4 batch_num: 16\n","train_rmse_target: 0.07255 train_rmse_stderror: 0.02406 train_kl_div: 0.01307\n","val_rmse_target: 0.4926 val_rmse_stderror: 1.74\n","Still best_val_rmse: 0.491 (from epoch 3)\n","\n","16 steps took 20.1 seconds\n","Epoch: 4 batch_num: 32\n","train_rmse_target: 0.09837 train_rmse_stderror: 0.01511 train_kl_div: 0.01996\n","val_rmse_target: 0.494 val_rmse_stderror: 1.737\n","Still best_val_rmse: 0.491 (from epoch 3)\n","\n","16 steps took 20.1 seconds\n","Epoch: 4 batch_num: 48\n","train_rmse_target: 0.131 train_rmse_stderror: 0.01857 train_kl_div: 0.03025\n","val_rmse_target: 0.4942 val_rmse_stderror: 1.741\n","Still best_val_rmse: 0.491 (from epoch 3)\n","\n","16 steps took 20.1 seconds\n","Epoch: 4 batch_num: 64\n","train_rmse_target: 0.05577 train_rmse_stderror: 0.01478 train_kl_div: 0.007277\n","val_rmse_target: 0.4934 val_rmse_stderror: 1.743\n","Still best_val_rmse: 0.491 (from epoch 3)\n","\n","16 steps took 20.1 seconds\n","Epoch: 4 batch_num: 80\n","train_rmse_target: 0.1057 train_rmse_stderror: 0.01453 train_kl_div: 0.02324\n","val_rmse_target: 0.4941 val_rmse_stderror: 1.738\n","Still best_val_rmse: 0.491 (from epoch 3)\n","\n","16 steps took 20.1 seconds\n","Epoch: 4 batch_num: 96\n","train_rmse_target: 0.08906 train_rmse_stderror: 0.02294 train_kl_div: 0.01837\n","val_rmse_target: 0.4934 val_rmse_stderror: 1.741\n","Still best_val_rmse: 0.491 (from epoch 3)\n","\n","16 steps took 20.1 seconds\n","Epoch: 4 batch_num: 112\n","train_rmse_target: 0.04937 train_rmse_stderror: 0.01441 train_kl_div: 0.005987\n","val_rmse_target: 0.4937 val_rmse_stderror: 1.741\n","Still best_val_rmse: 0.491 (from epoch 3)\n","\n","16 steps took 20.1 seconds\n","Epoch: 4 batch_num: 128\n","train_rmse_target: 0.1244 train_rmse_stderror: 0.01485 train_kl_div: 0.0323\n","val_rmse_target: 0.4941 val_rmse_stderror: 1.739\n","Still best_val_rmse: 0.491 (from epoch 3)\n","\n","16 steps took 20.1 seconds\n","Epoch: 4 batch_num: 144\n","train_rmse_target: 0.09096 train_rmse_stderror: 0.02329 train_kl_div: 0.01931\n","val_rmse_target: 0.4938 val_rmse_stderror: 1.739\n","Still best_val_rmse: 0.491 (from epoch 3)\n","\n","16 steps took 20.1 seconds\n","Epoch: 4 batch_num: 160\n","train_rmse_target: 0.05896 train_rmse_stderror: 0.01736 train_kl_div: 0.009361\n","val_rmse_target: 0.4937 val_rmse_stderror: 1.74\n","Still best_val_rmse: 0.491 (from epoch 3)\n","\n","16 steps took 20.1 seconds\n","Epoch: 4 batch_num: 176\n","train_rmse_target: 0.1317 train_rmse_stderror: 0.01533 train_kl_div: 0.03287\n","val_rmse_target: 0.4937 val_rmse_stderror: 1.74\n","Still best_val_rmse: 0.491 (from epoch 3)\n","\n","Performance estimates:\n","[0.4910475498330881]\n","Mean: 0.4910475498330881\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 2/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 81.4 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.6823 train_rmse_stderror: 0.056 train_kl_div: 0.9611\n","val_rmse_target: 0.6303 val_rmse_stderror: 1.074\n","New best_val_rmse: 0.6303\n","\n","64 steps took 80.6 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.7287 train_rmse_stderror: 0.03563 train_kl_div: 1.122\n","val_rmse_target: 0.6184 val_rmse_stderror: 1.103\n","New best_val_rmse: 0.6184\n","\n","64 steps took 80.7 seconds\n","Epoch: 1 batch_num: 4\n","train_rmse_target: 0.3606 train_rmse_stderror: 0.02903 train_kl_div: 0.2699\n","val_rmse_target: 0.5582 val_rmse_stderror: 1.098\n","New best_val_rmse: 0.5582\n","\n","64 steps took 80.6 seconds\n","Epoch: 1 batch_num: 68\n","train_rmse_target: 0.3362 train_rmse_stderror: 0.03588 train_kl_div: 0.2512\n","val_rmse_target: 0.5164 val_rmse_stderror: 1.096\n","New best_val_rmse: 0.5164\n","\n","32 steps took 40.3 seconds\n","Epoch: 1 batch_num: 100\n","train_rmse_target: 0.476 train_rmse_stderror: 0.03347 train_kl_div: 0.4438\n","val_rmse_target: 0.5736 val_rmse_stderror: 1.082\n","Still best_val_rmse: 0.5164 (from epoch 1)\n","\n","64 steps took 80.6 seconds\n","Epoch: 1 batch_num: 164\n","train_rmse_target: 0.29 train_rmse_stderror: 0.03091 train_kl_div: 0.1781\n","val_rmse_target: 0.5014 val_rmse_stderror: 1.095\n","New best_val_rmse: 0.5014\n","\n","32 steps took 40.5 seconds\n","Epoch: 2 batch_num: 8\n","train_rmse_target: 0.2199 train_rmse_stderror: 0.02018 train_kl_div: 0.1061\n","val_rmse_target: 0.5214 val_rmse_stderror: 1.088\n","Still best_val_rmse: 0.5014 (from epoch 1)\n","\n","32 steps took 40.3 seconds\n","Epoch: 2 batch_num: 40\n","train_rmse_target: 0.1792 train_rmse_stderror: 0.03239 train_kl_div: 0.06998\n","val_rmse_target: 0.491 val_rmse_stderror: 1.102\n","New best_val_rmse: 0.491\n","\n","16 steps took 20.1 seconds\n","Epoch: 2 batch_num: 56\n","train_rmse_target: 0.2396 train_rmse_stderror: 0.03091 train_kl_div: 0.1188\n","val_rmse_target: 0.4903 val_rmse_stderror: 1.1\n","New best_val_rmse: 0.4903\n","\n","16 steps took 20.1 seconds\n","Epoch: 2 batch_num: 72\n","train_rmse_target: 0.1904 train_rmse_stderror: 0.02363 train_kl_div: 0.07166\n","val_rmse_target: 0.4966 val_rmse_stderror: 1.092\n","Still best_val_rmse: 0.4903 (from epoch 2)\n","\n","16 steps took 20.1 seconds\n","Epoch: 2 batch_num: 88\n","train_rmse_target: 0.171 train_rmse_stderror: 0.04414 train_kl_div: 0.0721\n","val_rmse_target: 0.4878 val_rmse_stderror: 1.093\n","New best_val_rmse: 0.4878\n","\n","8 steps took 10.1 seconds\n","Epoch: 2 batch_num: 96\n","train_rmse_target: 0.2597 train_rmse_stderror: 0.02423 train_kl_div: 0.146\n","val_rmse_target: 0.5339 val_rmse_stderror: 1.086\n","Still best_val_rmse: 0.4878 (from epoch 2)\n","\n","32 steps took 40.3 seconds\n","Epoch: 2 batch_num: 128\n","train_rmse_target: 0.3085 train_rmse_stderror: 0.03189 train_kl_div: 0.1949\n","val_rmse_target: 0.4788 val_rmse_stderror: 1.104\n","New best_val_rmse: 0.4788\n","\n","4 steps took 5.04 seconds\n","Epoch: 2 batch_num: 132\n","train_rmse_target: 0.2175 train_rmse_stderror: 0.01897 train_kl_div: 0.1054\n","val_rmse_target: 0.4873 val_rmse_stderror: 1.083\n","Still best_val_rmse: 0.4788 (from epoch 2)\n","\n","8 steps took 10.1 seconds\n","Epoch: 2 batch_num: 140\n","train_rmse_target: 0.1644 train_rmse_stderror: 0.01932 train_kl_div: 0.05667\n","val_rmse_target: 0.5003 val_rmse_stderror: 1.08\n","Still best_val_rmse: 0.4788 (from epoch 2)\n","\n","32 steps took 40.3 seconds\n","Epoch: 2 batch_num: 172\n","train_rmse_target: 0.2622 train_rmse_stderror: 0.03097 train_kl_div: 0.1568\n","val_rmse_target: 0.4915 val_rmse_stderror: 1.094\n","Still best_val_rmse: 0.4788 (from epoch 2)\n","\n","16 steps took 20.3 seconds\n","Epoch: 3 batch_num: 0\n","train_rmse_target: 0.0794 train_rmse_stderror: 0.01777 train_kl_div: 0.01478\n","val_rmse_target: 0.4945 val_rmse_stderror: 1.097\n","Still best_val_rmse: 0.4788 (from epoch 2)\n","\n","16 steps took 20.1 seconds\n","Epoch: 3 batch_num: 16\n","train_rmse_target: 0.1577 train_rmse_stderror: 0.02286 train_kl_div: 0.05493\n","val_rmse_target: 0.4851 val_rmse_stderror: 1.091\n","Still best_val_rmse: 0.4788 (from epoch 2)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 24\n","train_rmse_target: 0.1667 train_rmse_stderror: 0.02752 train_kl_div: 0.05286\n","val_rmse_target: 0.4887 val_rmse_stderror: 1.093\n","Still best_val_rmse: 0.4788 (from epoch 2)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 32\n","train_rmse_target: 0.1699 train_rmse_stderror: 0.02804 train_kl_div: 0.05734\n","val_rmse_target: 0.4814 val_rmse_stderror: 1.101\n","Still best_val_rmse: 0.4788 (from epoch 2)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 40\n","train_rmse_target: 0.1281 train_rmse_stderror: 0.02276 train_kl_div: 0.03526\n","val_rmse_target: 0.4829 val_rmse_stderror: 1.092\n","Still best_val_rmse: 0.4788 (from epoch 2)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 48\n","train_rmse_target: 0.1613 train_rmse_stderror: 0.01702 train_kl_div: 0.05957\n","val_rmse_target: 0.4816 val_rmse_stderror: 1.092\n","Still best_val_rmse: 0.4788 (from epoch 2)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 56\n","train_rmse_target: 0.1396 train_rmse_stderror: 0.03086 train_kl_div: 0.04407\n","val_rmse_target: 0.4787 val_rmse_stderror: 1.091\n","New best_val_rmse: 0.4787\n","\n","4 steps took 5.05 seconds\n","Epoch: 3 batch_num: 60\n","train_rmse_target: 0.1331 train_rmse_stderror: 0.02651 train_kl_div: 0.04038\n","val_rmse_target: 0.4774 val_rmse_stderror: 1.104\n","New best_val_rmse: 0.4774\n","\n","4 steps took 5.03 seconds\n","Epoch: 3 batch_num: 64\n","train_rmse_target: 0.1433 train_rmse_stderror: 0.02059 train_kl_div: 0.04279\n","val_rmse_target: 0.4804 val_rmse_stderror: 1.101\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","8 steps took 10.0 seconds\n","Epoch: 3 batch_num: 72\n","train_rmse_target: 0.1825 train_rmse_stderror: 0.0252 train_kl_div: 0.0674\n","val_rmse_target: 0.4779 val_rmse_stderror: 1.096\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","4 steps took 5.02 seconds\n","Epoch: 3 batch_num: 76\n","train_rmse_target: 0.12 train_rmse_stderror: 0.02624 train_kl_div: 0.03257\n","val_rmse_target: 0.4867 val_rmse_stderror: 1.102\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 84\n","train_rmse_target: 0.1396 train_rmse_stderror: 0.02415 train_kl_div: 0.04535\n","val_rmse_target: 0.4794 val_rmse_stderror: 1.094\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","4 steps took 5.03 seconds\n","Epoch: 3 batch_num: 88\n","train_rmse_target: 0.1234 train_rmse_stderror: 0.02262 train_kl_div: 0.03433\n","val_rmse_target: 0.4798 val_rmse_stderror: 1.102\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","4 steps took 5.02 seconds\n","Epoch: 3 batch_num: 92\n","train_rmse_target: 0.174 train_rmse_stderror: 0.03723 train_kl_div: 0.0573\n","val_rmse_target: 0.4824 val_rmse_stderror: 1.096\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","8 steps took 10.0 seconds\n","Epoch: 3 batch_num: 100\n","train_rmse_target: 0.1341 train_rmse_stderror: 0.01976 train_kl_div: 0.03789\n","val_rmse_target: 0.4823 val_rmse_stderror: 1.096\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 108\n","train_rmse_target: 0.2067 train_rmse_stderror: 0.01582 train_kl_div: 0.07842\n","val_rmse_target: 0.4805 val_rmse_stderror: 1.097\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 116\n","train_rmse_target: 0.2847 train_rmse_stderror: 0.02993 train_kl_div: 0.1531\n","val_rmse_target: 0.4789 val_rmse_stderror: 1.096\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","4 steps took 5.02 seconds\n","Epoch: 3 batch_num: 120\n","train_rmse_target: 0.112 train_rmse_stderror: 0.01816 train_kl_div: 0.03068\n","val_rmse_target: 0.4797 val_rmse_stderror: 1.099\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","4 steps took 5.03 seconds\n","Epoch: 3 batch_num: 124\n","train_rmse_target: 0.1466 train_rmse_stderror: 0.02031 train_kl_div: 0.04787\n","val_rmse_target: 0.4804 val_rmse_stderror: 1.092\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","8 steps took 10.0 seconds\n","Epoch: 3 batch_num: 132\n","train_rmse_target: 0.2239 train_rmse_stderror: 0.02413 train_kl_div: 0.09676\n","val_rmse_target: 0.4789 val_rmse_stderror: 1.098\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","4 steps took 5.02 seconds\n","Epoch: 3 batch_num: 136\n","train_rmse_target: 0.1639 train_rmse_stderror: 0.02494 train_kl_div: 0.05037\n","val_rmse_target: 0.4787 val_rmse_stderror: 1.097\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","4 steps took 5.02 seconds\n","Epoch: 3 batch_num: 140\n","train_rmse_target: 0.1651 train_rmse_stderror: 0.02957 train_kl_div: 0.05514\n","val_rmse_target: 0.4786 val_rmse_stderror: 1.091\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","4 steps took 5.02 seconds\n","Epoch: 3 batch_num: 144\n","train_rmse_target: 0.1501 train_rmse_stderror: 0.03286 train_kl_div: 0.03944\n","val_rmse_target: 0.4795 val_rmse_stderror: 1.096\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","4 steps took 5.02 seconds\n","Epoch: 3 batch_num: 148\n","train_rmse_target: 0.1122 train_rmse_stderror: 0.02551 train_kl_div: 0.02626\n","val_rmse_target: 0.4831 val_rmse_stderror: 1.099\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 156\n","train_rmse_target: 0.05923 train_rmse_stderror: 0.0156 train_kl_div: 0.008907\n","val_rmse_target: 0.484 val_rmse_stderror: 1.097\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 164\n","train_rmse_target: 0.1166 train_rmse_stderror: 0.02804 train_kl_div: 0.03009\n","val_rmse_target: 0.4806 val_rmse_stderror: 1.097\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 172\n","train_rmse_target: 0.1519 train_rmse_stderror: 0.02135 train_kl_div: 0.05126\n","val_rmse_target: 0.4832 val_rmse_stderror: 1.094\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","8 steps took 10.0 seconds\n","Epoch: 3 batch_num: 180\n","train_rmse_target: 0.1614 train_rmse_stderror: 0.04389 train_kl_div: 0.05183\n","val_rmse_target: 0.482 val_rmse_stderror: 1.094\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","8 steps took 10.2 seconds\n","Epoch: 4 batch_num: 0\n","train_rmse_target: 0.05772 train_rmse_stderror: 0.02519 train_kl_div: 0.01021\n","val_rmse_target: 0.4799 val_rmse_stderror: 1.088\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","4 steps took 5.02 seconds\n","Epoch: 4 batch_num: 4\n","train_rmse_target: 0.09995 train_rmse_stderror: 0.03051 train_kl_div: 0.02059\n","val_rmse_target: 0.4793 val_rmse_stderror: 1.094\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","4 steps took 5.02 seconds\n","Epoch: 4 batch_num: 8\n","train_rmse_target: 0.08889 train_rmse_stderror: 0.02343 train_kl_div: 0.0179\n","val_rmse_target: 0.4793 val_rmse_stderror: 1.095\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","4 steps took 5.03 seconds\n","Epoch: 4 batch_num: 12\n","train_rmse_target: 0.06532 train_rmse_stderror: 0.02514 train_kl_div: 0.01221\n","val_rmse_target: 0.4801 val_rmse_stderror: 1.094\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 20\n","train_rmse_target: 0.09669 train_rmse_stderror: 0.02285 train_kl_div: 0.02135\n","val_rmse_target: 0.4816 val_rmse_stderror: 1.094\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 28\n","train_rmse_target: 0.06911 train_rmse_stderror: 0.01749 train_kl_div: 0.01021\n","val_rmse_target: 0.4797 val_rmse_stderror: 1.092\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","4 steps took 5.03 seconds\n","Epoch: 4 batch_num: 32\n","train_rmse_target: 0.1228 train_rmse_stderror: 0.01412 train_kl_div: 0.02901\n","val_rmse_target: 0.4796 val_rmse_stderror: 1.094\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","4 steps took 5.02 seconds\n","Epoch: 4 batch_num: 36\n","train_rmse_target: 0.103 train_rmse_stderror: 0.02131 train_kl_div: 0.0224\n","val_rmse_target: 0.48 val_rmse_stderror: 1.095\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 44\n","train_rmse_target: 0.08449 train_rmse_stderror: 0.01827 train_kl_div: 0.01586\n","val_rmse_target: 0.4806 val_rmse_stderror: 1.095\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 52\n","train_rmse_target: 0.07125 train_rmse_stderror: 0.02315 train_kl_div: 0.01203\n","val_rmse_target: 0.4796 val_rmse_stderror: 1.099\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","4 steps took 5.02 seconds\n","Epoch: 4 batch_num: 56\n","train_rmse_target: 0.1136 train_rmse_stderror: 0.02838 train_kl_div: 0.02849\n","val_rmse_target: 0.4795 val_rmse_stderror: 1.099\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","4 steps took 5.02 seconds\n","Epoch: 4 batch_num: 60\n","train_rmse_target: 0.0815 train_rmse_stderror: 0.0257 train_kl_div: 0.01533\n","val_rmse_target: 0.4798 val_rmse_stderror: 1.098\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","4 steps took 5.02 seconds\n","Epoch: 4 batch_num: 64\n","train_rmse_target: 0.06151 train_rmse_stderror: 0.02578 train_kl_div: 0.01102\n","val_rmse_target: 0.4803 val_rmse_stderror: 1.096\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 72\n","train_rmse_target: 0.09598 train_rmse_stderror: 0.02843 train_kl_div: 0.02171\n","val_rmse_target: 0.4801 val_rmse_stderror: 1.096\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","8 steps took 10.0 seconds\n","Epoch: 4 batch_num: 80\n","train_rmse_target: 0.09122 train_rmse_stderror: 0.02512 train_kl_div: 0.02011\n","val_rmse_target: 0.4783 val_rmse_stderror: 1.095\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","4 steps took 5.02 seconds\n","Epoch: 4 batch_num: 84\n","train_rmse_target: 0.1074 train_rmse_stderror: 0.02261 train_kl_div: 0.02626\n","val_rmse_target: 0.4778 val_rmse_stderror: 1.094\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","4 steps took 5.03 seconds\n","Epoch: 4 batch_num: 88\n","train_rmse_target: 0.1089 train_rmse_stderror: 0.02209 train_kl_div: 0.02766\n","val_rmse_target: 0.4776 val_rmse_stderror: 1.093\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","4 steps took 5.02 seconds\n","Epoch: 4 batch_num: 92\n","train_rmse_target: 0.1617 train_rmse_stderror: 0.02356 train_kl_div: 0.0513\n","val_rmse_target: 0.4775 val_rmse_stderror: 1.094\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","4 steps took 5.01 seconds\n","Epoch: 4 batch_num: 96\n","train_rmse_target: 0.07021 train_rmse_stderror: 0.02029 train_kl_div: 0.01243\n","val_rmse_target: 0.4782 val_rmse_stderror: 1.094\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","4 steps took 5.03 seconds\n","Epoch: 4 batch_num: 100\n","train_rmse_target: 0.07602 train_rmse_stderror: 0.01815 train_kl_div: 0.01512\n","val_rmse_target: 0.479 val_rmse_stderror: 1.094\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","4 steps took 5.03 seconds\n","Epoch: 4 batch_num: 104\n","train_rmse_target: 0.08858 train_rmse_stderror: 0.01885 train_kl_div: 0.01925\n","val_rmse_target: 0.4794 val_rmse_stderror: 1.095\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","4 steps took 5.02 seconds\n","Epoch: 4 batch_num: 108\n","train_rmse_target: 0.08393 train_rmse_stderror: 0.01386 train_kl_div: 0.01675\n","val_rmse_target: 0.4793 val_rmse_stderror: 1.095\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","4 steps took 5.02 seconds\n","Epoch: 4 batch_num: 112\n","train_rmse_target: 0.1203 train_rmse_stderror: 0.02287 train_kl_div: 0.02855\n","val_rmse_target: 0.4791 val_rmse_stderror: 1.096\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","4 steps took 5.03 seconds\n","Epoch: 4 batch_num: 116\n","train_rmse_target: 0.08458 train_rmse_stderror: 0.01827 train_kl_div: 0.01493\n","val_rmse_target: 0.4789 val_rmse_stderror: 1.096\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","4 steps took 5.02 seconds\n","Epoch: 4 batch_num: 120\n","train_rmse_target: 0.07542 train_rmse_stderror: 0.02541 train_kl_div: 0.01465\n","val_rmse_target: 0.479 val_rmse_stderror: 1.096\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","4 steps took 5.02 seconds\n","Epoch: 4 batch_num: 124\n","train_rmse_target: 0.1071 train_rmse_stderror: 0.02834 train_kl_div: 0.02178\n","val_rmse_target: 0.4789 val_rmse_stderror: 1.096\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","4 steps took 5.03 seconds\n","Epoch: 4 batch_num: 128\n","train_rmse_target: 0.1112 train_rmse_stderror: 0.02298 train_kl_div: 0.02875\n","val_rmse_target: 0.4787 val_rmse_stderror: 1.096\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","4 steps took 5.02 seconds\n","Epoch: 4 batch_num: 132\n","train_rmse_target: 0.04075 train_rmse_stderror: 0.01396 train_kl_div: 0.004476\n","val_rmse_target: 0.4787 val_rmse_stderror: 1.095\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","4 steps took 5.03 seconds\n","Epoch: 4 batch_num: 136\n","train_rmse_target: 0.08332 train_rmse_stderror: 0.03174 train_kl_div: 0.0183\n","val_rmse_target: 0.4787 val_rmse_stderror: 1.095\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","4 steps took 5.03 seconds\n","Epoch: 4 batch_num: 140\n","train_rmse_target: 0.09002 train_rmse_stderror: 0.01349 train_kl_div: 0.0189\n","val_rmse_target: 0.4788 val_rmse_stderror: 1.095\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","4 steps took 5.02 seconds\n","Epoch: 4 batch_num: 144\n","train_rmse_target: 0.07722 train_rmse_stderror: 0.02169 train_kl_div: 0.01378\n","val_rmse_target: 0.4787 val_rmse_stderror: 1.096\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","4 steps took 5.02 seconds\n","Epoch: 4 batch_num: 148\n","train_rmse_target: 0.09942 train_rmse_stderror: 0.01539 train_kl_div: 0.02213\n","val_rmse_target: 0.4787 val_rmse_stderror: 1.096\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","4 steps took 5.02 seconds\n","Epoch: 4 batch_num: 152\n","train_rmse_target: 0.0841 train_rmse_stderror: 0.0174 train_kl_div: 0.01494\n","val_rmse_target: 0.4787 val_rmse_stderror: 1.096\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","4 steps took 5.02 seconds\n","Epoch: 4 batch_num: 156\n","train_rmse_target: 0.1068 train_rmse_stderror: 0.0221 train_kl_div: 0.02647\n","val_rmse_target: 0.4787 val_rmse_stderror: 1.096\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","4 steps took 5.03 seconds\n","Epoch: 4 batch_num: 160\n","train_rmse_target: 0.09747 train_rmse_stderror: 0.01488 train_kl_div: 0.0207\n","val_rmse_target: 0.4786 val_rmse_stderror: 1.096\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","4 steps took 5.02 seconds\n","Epoch: 4 batch_num: 164\n","train_rmse_target: 0.06456 train_rmse_stderror: 0.02041 train_kl_div: 0.009599\n","val_rmse_target: 0.4786 val_rmse_stderror: 1.096\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","4 steps took 5.02 seconds\n","Epoch: 4 batch_num: 168\n","train_rmse_target: 0.1116 train_rmse_stderror: 0.01705 train_kl_div: 0.02348\n","val_rmse_target: 0.4786 val_rmse_stderror: 1.096\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","4 steps took 5.02 seconds\n","Epoch: 4 batch_num: 172\n","train_rmse_target: 0.1196 train_rmse_stderror: 0.02412 train_kl_div: 0.03366\n","val_rmse_target: 0.4786 val_rmse_stderror: 1.096\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","4 steps took 5.03 seconds\n","Epoch: 4 batch_num: 176\n","train_rmse_target: 0.1037 train_rmse_stderror: 0.01702 train_kl_div: 0.02422\n","val_rmse_target: 0.4786 val_rmse_stderror: 1.096\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","4 steps took 5.02 seconds\n","Epoch: 4 batch_num: 180\n","train_rmse_target: 0.08217 train_rmse_stderror: 0.02406 train_kl_div: 0.01701\n","val_rmse_target: 0.4786 val_rmse_stderror: 1.096\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","4 steps took 5.02 seconds\n","Epoch: 4 batch_num: 184\n","train_rmse_target: 0.1218 train_rmse_stderror: 0.01367 train_kl_div: 0.03136\n","val_rmse_target: 0.4786 val_rmse_stderror: 1.096\n","Still best_val_rmse: 0.4774 (from epoch 3)\n","\n","Performance estimates:\n","[0.4910475498330881, 0.4774353469674259]\n","Mean: 0.484241448400257\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 3/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 81.5 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.724 train_rmse_stderror: 0.08749 train_kl_div: 1.047\n","val_rmse_target: 0.6824 val_rmse_stderror: 1.721\n","New best_val_rmse: 0.6824\n","\n","64 steps took 80.5 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.4929 train_rmse_stderror: 0.05399 train_kl_div: 0.5253\n","val_rmse_target: 0.598 val_rmse_stderror: 1.711\n","New best_val_rmse: 0.598\n","\n","64 steps took 80.8 seconds\n","Epoch: 1 batch_num: 4\n","train_rmse_target: 0.4955 train_rmse_stderror: 0.0344 train_kl_div: 0.4362\n","val_rmse_target: 0.5274 val_rmse_stderror: 1.754\n","New best_val_rmse: 0.5274\n","\n","32 steps took 40.3 seconds\n","Epoch: 1 batch_num: 36\n","train_rmse_target: 0.4389 train_rmse_stderror: 0.04577 train_kl_div: 0.4434\n","val_rmse_target: 0.5223 val_rmse_stderror: 1.726\n","New best_val_rmse: 0.5223\n","\n","32 steps took 40.3 seconds\n","Epoch: 1 batch_num: 68\n","train_rmse_target: 0.5092 train_rmse_stderror: 0.04614 train_kl_div: 0.5011\n","val_rmse_target: 0.5185 val_rmse_stderror: 1.755\n","New best_val_rmse: 0.5185\n","\n","32 steps took 40.3 seconds\n","Epoch: 1 batch_num: 100\n","train_rmse_target: 0.4955 train_rmse_stderror: 0.0258 train_kl_div: 0.5008\n","val_rmse_target: 0.5191 val_rmse_stderror: 1.719\n","Still best_val_rmse: 0.5185 (from epoch 1)\n","\n","32 steps took 40.3 seconds\n","Epoch: 1 batch_num: 132\n","train_rmse_target: 0.432 train_rmse_stderror: 0.03893 train_kl_div: 0.3195\n","val_rmse_target: 0.5101 val_rmse_stderror: 1.742\n","New best_val_rmse: 0.5101\n","\n","32 steps took 40.3 seconds\n","Epoch: 1 batch_num: 164\n","train_rmse_target: 0.6201 train_rmse_stderror: 0.03414 train_kl_div: 0.8581\n","val_rmse_target: 0.5595 val_rmse_stderror: 1.714\n","Still best_val_rmse: 0.5101 (from epoch 1)\n","\n","64 steps took 80.7 seconds\n","Epoch: 2 batch_num: 40\n","train_rmse_target: 0.2802 train_rmse_stderror: 0.02181 train_kl_div: 0.1505\n","val_rmse_target: 0.5548 val_rmse_stderror: 1.706\n","Still best_val_rmse: 0.5101 (from epoch 1)\n","\n","64 steps took 80.6 seconds\n","Epoch: 2 batch_num: 104\n","train_rmse_target: 0.2169 train_rmse_stderror: 0.01831 train_kl_div: 0.09499\n","val_rmse_target: 0.501 val_rmse_stderror: 1.724\n","New best_val_rmse: 0.501\n","\n","32 steps took 40.3 seconds\n","Epoch: 2 batch_num: 136\n","train_rmse_target: 0.2256 train_rmse_stderror: 0.02395 train_kl_div: 0.1061\n","val_rmse_target: 0.4874 val_rmse_stderror: 1.732\n","New best_val_rmse: 0.4874\n","\n","8 steps took 10.1 seconds\n","Epoch: 2 batch_num: 144\n","train_rmse_target: 0.1865 train_rmse_stderror: 0.02231 train_kl_div: 0.07674\n","val_rmse_target: 0.4903 val_rmse_stderror: 1.731\n","Still best_val_rmse: 0.4874 (from epoch 2)\n","\n","16 steps took 20.1 seconds\n","Epoch: 2 batch_num: 160\n","train_rmse_target: 0.1657 train_rmse_stderror: 0.02459 train_kl_div: 0.06302\n","val_rmse_target: 0.5213 val_rmse_stderror: 1.729\n","Still best_val_rmse: 0.4874 (from epoch 2)\n","\n","32 steps took 40.5 seconds\n","Epoch: 3 batch_num: 4\n","train_rmse_target: 0.1075 train_rmse_stderror: 0.02133 train_kl_div: 0.02871\n","val_rmse_target: 0.479 val_rmse_stderror: 1.728\n","New best_val_rmse: 0.479\n","\n","4 steps took 5.04 seconds\n","Epoch: 3 batch_num: 8\n","train_rmse_target: 0.1782 train_rmse_stderror: 0.03163 train_kl_div: 0.05855\n","val_rmse_target: 0.4793 val_rmse_stderror: 1.724\n","Still best_val_rmse: 0.479 (from epoch 3)\n","\n","4 steps took 5.02 seconds\n","Epoch: 3 batch_num: 12\n","train_rmse_target: 0.2112 train_rmse_stderror: 0.03107 train_kl_div: 0.1031\n","val_rmse_target: 0.4836 val_rmse_stderror: 1.727\n","Still best_val_rmse: 0.479 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 20\n","train_rmse_target: 0.1458 train_rmse_stderror: 0.01714 train_kl_div: 0.04737\n","val_rmse_target: 0.4807 val_rmse_stderror: 1.728\n","Still best_val_rmse: 0.479 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 28\n","train_rmse_target: 0.1412 train_rmse_stderror: 0.03164 train_kl_div: 0.04108\n","val_rmse_target: 0.4832 val_rmse_stderror: 1.713\n","Still best_val_rmse: 0.479 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 36\n","train_rmse_target: 0.09301 train_rmse_stderror: 0.0194 train_kl_div: 0.02042\n","val_rmse_target: 0.483 val_rmse_stderror: 1.739\n","Still best_val_rmse: 0.479 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 44\n","train_rmse_target: 0.1403 train_rmse_stderror: 0.02028 train_kl_div: 0.04594\n","val_rmse_target: 0.4852 val_rmse_stderror: 1.712\n","Still best_val_rmse: 0.479 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 52\n","train_rmse_target: 0.1202 train_rmse_stderror: 0.03059 train_kl_div: 0.03374\n","val_rmse_target: 0.4795 val_rmse_stderror: 1.729\n","Still best_val_rmse: 0.479 (from epoch 3)\n","\n","4 steps took 5.01 seconds\n","Epoch: 3 batch_num: 56\n","train_rmse_target: 0.135 train_rmse_stderror: 0.0281 train_kl_div: 0.04033\n","val_rmse_target: 0.4795 val_rmse_stderror: 1.712\n","Still best_val_rmse: 0.479 (from epoch 3)\n","\n","4 steps took 5.03 seconds\n","Epoch: 3 batch_num: 60\n","train_rmse_target: 0.07661 train_rmse_stderror: 0.02047 train_kl_div: 0.01422\n","val_rmse_target: 0.4868 val_rmse_stderror: 1.725\n","Still best_val_rmse: 0.479 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 68\n","train_rmse_target: 0.1325 train_rmse_stderror: 0.0242 train_kl_div: 0.03736\n","val_rmse_target: 0.4866 val_rmse_stderror: 1.725\n","Still best_val_rmse: 0.479 (from epoch 3)\n","\n","8 steps took 10.0 seconds\n","Epoch: 3 batch_num: 76\n","train_rmse_target: 0.2042 train_rmse_stderror: 0.04312 train_kl_div: 0.08067\n","val_rmse_target: 0.4796 val_rmse_stderror: 1.726\n","Still best_val_rmse: 0.479 (from epoch 3)\n","\n","4 steps took 5.03 seconds\n","Epoch: 3 batch_num: 80\n","train_rmse_target: 0.1416 train_rmse_stderror: 0.02511 train_kl_div: 0.04511\n","val_rmse_target: 0.485 val_rmse_stderror: 1.719\n","Still best_val_rmse: 0.479 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 88\n","train_rmse_target: 0.1234 train_rmse_stderror: 0.01739 train_kl_div: 0.03237\n","val_rmse_target: 0.488 val_rmse_stderror: 1.731\n","Still best_val_rmse: 0.479 (from epoch 3)\n","\n","8 steps took 10.0 seconds\n","Epoch: 3 batch_num: 96\n","train_rmse_target: 0.1252 train_rmse_stderror: 0.02113 train_kl_div: 0.03552\n","val_rmse_target: 0.4801 val_rmse_stderror: 1.731\n","Still best_val_rmse: 0.479 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 104\n","train_rmse_target: 0.1634 train_rmse_stderror: 0.02313 train_kl_div: 0.0579\n","val_rmse_target: 0.4902 val_rmse_stderror: 1.722\n","Still best_val_rmse: 0.479 (from epoch 3)\n","\n","16 steps took 20.1 seconds\n","Epoch: 3 batch_num: 120\n","train_rmse_target: 0.1555 train_rmse_stderror: 0.02833 train_kl_div: 0.05203\n","val_rmse_target: 0.4798 val_rmse_stderror: 1.721\n","Still best_val_rmse: 0.479 (from epoch 3)\n","\n","4 steps took 5.03 seconds\n","Epoch: 3 batch_num: 124\n","train_rmse_target: 0.08791 train_rmse_stderror: 0.026 train_kl_div: 0.02015\n","val_rmse_target: 0.4825 val_rmse_stderror: 1.721\n","Still best_val_rmse: 0.479 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 132\n","train_rmse_target: 0.1586 train_rmse_stderror: 0.01819 train_kl_div: 0.05338\n","val_rmse_target: 0.4843 val_rmse_stderror: 1.727\n","Still best_val_rmse: 0.479 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 140\n","train_rmse_target: 0.1468 train_rmse_stderror: 0.0205 train_kl_div: 0.05151\n","val_rmse_target: 0.4844 val_rmse_stderror: 1.724\n","Still best_val_rmse: 0.479 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 148\n","train_rmse_target: 0.1547 train_rmse_stderror: 0.01942 train_kl_div: 0.05129\n","val_rmse_target: 0.4839 val_rmse_stderror: 1.726\n","Still best_val_rmse: 0.479 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 156\n","train_rmse_target: 0.1519 train_rmse_stderror: 0.02093 train_kl_div: 0.0548\n","val_rmse_target: 0.4783 val_rmse_stderror: 1.73\n","New best_val_rmse: 0.4783\n","\n","4 steps took 5.05 seconds\n","Epoch: 3 batch_num: 160\n","train_rmse_target: 0.1156 train_rmse_stderror: 0.01611 train_kl_div: 0.03153\n","val_rmse_target: 0.4794 val_rmse_stderror: 1.723\n","Still best_val_rmse: 0.4783 (from epoch 3)\n","\n","4 steps took 5.02 seconds\n","Epoch: 3 batch_num: 164\n","train_rmse_target: 0.1486 train_rmse_stderror: 0.02748 train_kl_div: 0.04276\n","val_rmse_target: 0.4824 val_rmse_stderror: 1.723\n","Still best_val_rmse: 0.4783 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 172\n","train_rmse_target: 0.1194 train_rmse_stderror: 0.02916 train_kl_div: 0.03108\n","val_rmse_target: 0.4793 val_rmse_stderror: 1.725\n","Still best_val_rmse: 0.4783 (from epoch 3)\n","\n","4 steps took 5.02 seconds\n","Epoch: 3 batch_num: 176\n","train_rmse_target: 0.1271 train_rmse_stderror: 0.02266 train_kl_div: 0.03926\n","val_rmse_target: 0.4798 val_rmse_stderror: 1.733\n","Still best_val_rmse: 0.4783 (from epoch 3)\n","\n","4 steps took 5.02 seconds\n","Epoch: 3 batch_num: 180\n","train_rmse_target: 0.1701 train_rmse_stderror: 0.02407 train_kl_div: 0.06084\n","val_rmse_target: 0.4788 val_rmse_stderror: 1.737\n","Still best_val_rmse: 0.4783 (from epoch 3)\n","\n","4 steps took 5.03 seconds\n","Epoch: 3 batch_num: 184\n","train_rmse_target: 0.1858 train_rmse_stderror: 0.02077 train_kl_div: 0.06532\n","val_rmse_target: 0.4795 val_rmse_stderror: 1.731\n","Still best_val_rmse: 0.4783 (from epoch 3)\n","\n","4 steps took 5.2 seconds\n","Epoch: 4 batch_num: 0\n","train_rmse_target: 0.1042 train_rmse_stderror: 0.01862 train_kl_div: 0.02473\n","val_rmse_target: 0.4826 val_rmse_stderror: 1.72\n","Still best_val_rmse: 0.4783 (from epoch 3)\n","\n","8 steps took 10.0 seconds\n","Epoch: 4 batch_num: 8\n","train_rmse_target: 0.0731 train_rmse_stderror: 0.02208 train_kl_div: 0.01186\n","val_rmse_target: 0.4807 val_rmse_stderror: 1.726\n","Still best_val_rmse: 0.4783 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 16\n","train_rmse_target: 0.1155 train_rmse_stderror: 0.02521 train_kl_div: 0.02807\n","val_rmse_target: 0.4843 val_rmse_stderror: 1.728\n","Still best_val_rmse: 0.4783 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 24\n","train_rmse_target: 0.107 train_rmse_stderror: 0.02551 train_kl_div: 0.02374\n","val_rmse_target: 0.4826 val_rmse_stderror: 1.723\n","Still best_val_rmse: 0.4783 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 32\n","train_rmse_target: 0.1007 train_rmse_stderror: 0.01666 train_kl_div: 0.02084\n","val_rmse_target: 0.4796 val_rmse_stderror: 1.723\n","Still best_val_rmse: 0.4783 (from epoch 3)\n","\n","4 steps took 5.01 seconds\n","Epoch: 4 batch_num: 36\n","train_rmse_target: 0.0777 train_rmse_stderror: 0.01667 train_kl_div: 0.01382\n","val_rmse_target: 0.478 val_rmse_stderror: 1.723\n","New best_val_rmse: 0.478\n","\n","4 steps took 5.05 seconds\n","Epoch: 4 batch_num: 40\n","train_rmse_target: 0.1519 train_rmse_stderror: 0.02731 train_kl_div: 0.05087\n","val_rmse_target: 0.478 val_rmse_stderror: 1.725\n","New best_val_rmse: 0.478\n","\n","4 steps took 5.01 seconds\n","Epoch: 4 batch_num: 44\n","train_rmse_target: 0.1272 train_rmse_stderror: 0.01882 train_kl_div: 0.03764\n","val_rmse_target: 0.4795 val_rmse_stderror: 1.725\n","Still best_val_rmse: 0.478 (from epoch 4)\n","\n","4 steps took 5.02 seconds\n","Epoch: 4 batch_num: 48\n","train_rmse_target: 0.07658 train_rmse_stderror: 0.01618 train_kl_div: 0.01361\n","val_rmse_target: 0.4818 val_rmse_stderror: 1.724\n","Still best_val_rmse: 0.478 (from epoch 4)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 56\n","train_rmse_target: 0.06778 train_rmse_stderror: 0.03286 train_kl_div: 0.01374\n","val_rmse_target: 0.4816 val_rmse_stderror: 1.725\n","Still best_val_rmse: 0.478 (from epoch 4)\n","\n","8 steps took 10.0 seconds\n","Epoch: 4 batch_num: 64\n","train_rmse_target: 0.1165 train_rmse_stderror: 0.02325 train_kl_div: 0.03148\n","val_rmse_target: 0.48 val_rmse_stderror: 1.729\n","Still best_val_rmse: 0.478 (from epoch 4)\n","\n","4 steps took 5.02 seconds\n","Epoch: 4 batch_num: 68\n","train_rmse_target: 0.09336 train_rmse_stderror: 0.01701 train_kl_div: 0.02013\n","val_rmse_target: 0.4806 val_rmse_stderror: 1.73\n","Still best_val_rmse: 0.478 (from epoch 4)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 76\n","train_rmse_target: 0.08619 train_rmse_stderror: 0.02429 train_kl_div: 0.01636\n","val_rmse_target: 0.4801 val_rmse_stderror: 1.727\n","Still best_val_rmse: 0.478 (from epoch 4)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 84\n","train_rmse_target: 0.09239 train_rmse_stderror: 0.0178 train_kl_div: 0.01924\n","val_rmse_target: 0.4795 val_rmse_stderror: 1.728\n","Still best_val_rmse: 0.478 (from epoch 4)\n","\n","4 steps took 5.02 seconds\n","Epoch: 4 batch_num: 88\n","train_rmse_target: 0.08469 train_rmse_stderror: 0.02681 train_kl_div: 0.01852\n","val_rmse_target: 0.4796 val_rmse_stderror: 1.729\n","Still best_val_rmse: 0.478 (from epoch 4)\n","\n","4 steps took 5.02 seconds\n","Epoch: 4 batch_num: 92\n","train_rmse_target: 0.09713 train_rmse_stderror: 0.02193 train_kl_div: 0.02198\n","val_rmse_target: 0.481 val_rmse_stderror: 1.728\n","Still best_val_rmse: 0.478 (from epoch 4)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 100\n","train_rmse_target: 0.1435 train_rmse_stderror: 0.02019 train_kl_div: 0.03748\n","val_rmse_target: 0.4823 val_rmse_stderror: 1.723\n","Still best_val_rmse: 0.478 (from epoch 4)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 108\n","train_rmse_target: 0.1011 train_rmse_stderror: 0.02643 train_kl_div: 0.0256\n","val_rmse_target: 0.4819 val_rmse_stderror: 1.722\n","Still best_val_rmse: 0.478 (from epoch 4)\n","\n","8 steps took 10.0 seconds\n","Epoch: 4 batch_num: 116\n","train_rmse_target: 0.1597 train_rmse_stderror: 0.01839 train_kl_div: 0.04592\n","val_rmse_target: 0.482 val_rmse_stderror: 1.723\n","Still best_val_rmse: 0.478 (from epoch 4)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 124\n","train_rmse_target: 0.1311 train_rmse_stderror: 0.02098 train_kl_div: 0.03634\n","val_rmse_target: 0.4811 val_rmse_stderror: 1.725\n","Still best_val_rmse: 0.478 (from epoch 4)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 132\n","train_rmse_target: 0.08616 train_rmse_stderror: 0.02427 train_kl_div: 0.01812\n","val_rmse_target: 0.4804 val_rmse_stderror: 1.725\n","Still best_val_rmse: 0.478 (from epoch 4)\n","\n","8 steps took 10.0 seconds\n","Epoch: 4 batch_num: 140\n","train_rmse_target: 0.162 train_rmse_stderror: 0.02975 train_kl_div: 0.04911\n","val_rmse_target: 0.4807 val_rmse_stderror: 1.725\n","Still best_val_rmse: 0.478 (from epoch 4)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 148\n","train_rmse_target: 0.1061 train_rmse_stderror: 0.02144 train_kl_div: 0.02307\n","val_rmse_target: 0.481 val_rmse_stderror: 1.725\n","Still best_val_rmse: 0.478 (from epoch 4)\n","\n","8 steps took 10.0 seconds\n","Epoch: 4 batch_num: 156\n","train_rmse_target: 0.08002 train_rmse_stderror: 0.02419 train_kl_div: 0.01653\n","val_rmse_target: 0.4813 val_rmse_stderror: 1.725\n","Still best_val_rmse: 0.478 (from epoch 4)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 164\n","train_rmse_target: 0.06575 train_rmse_stderror: 0.01379 train_kl_div: 0.01098\n","val_rmse_target: 0.4814 val_rmse_stderror: 1.725\n","Still best_val_rmse: 0.478 (from epoch 4)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 172\n","train_rmse_target: 0.09611 train_rmse_stderror: 0.01798 train_kl_div: 0.02\n","val_rmse_target: 0.4814 val_rmse_stderror: 1.725\n","Still best_val_rmse: 0.478 (from epoch 4)\n","\n","8 steps took 10.0 seconds\n","Epoch: 4 batch_num: 180\n","train_rmse_target: 0.08319 train_rmse_stderror: 0.01366 train_kl_div: 0.01549\n","val_rmse_target: 0.4814 val_rmse_stderror: 1.725\n","Still best_val_rmse: 0.478 (from epoch 4)\n","\n","Performance estimates:\n","[0.4910475498330881, 0.4774353469674259, 0.47800463182048586]\n","Mean: 0.4821625095403333\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 4/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 81.5 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.5455 train_rmse_stderror: 0.06228 train_kl_div: 0.64\n","val_rmse_target: 0.6115 val_rmse_stderror: 1.839\n","New best_val_rmse: 0.6115\n","\n","64 steps took 80.5 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.5712 train_rmse_stderror: 0.03646 train_kl_div: 0.667\n","val_rmse_target: 0.5588 val_rmse_stderror: 1.851\n","New best_val_rmse: 0.5588\n","\n","64 steps took 80.7 seconds\n","Epoch: 1 batch_num: 4\n","train_rmse_target: 0.3477 train_rmse_stderror: 0.03079 train_kl_div: 0.2453\n","val_rmse_target: 0.5854 val_rmse_stderror: 1.836\n","Still best_val_rmse: 0.5588 (from epoch 0)\n","\n","64 steps took 80.5 seconds\n","Epoch: 1 batch_num: 68\n","train_rmse_target: 0.3841 train_rmse_stderror: 0.05456 train_kl_div: 0.2816\n","val_rmse_target: 0.5201 val_rmse_stderror: 1.818\n","New best_val_rmse: 0.5201\n","\n","32 steps took 40.2 seconds\n","Epoch: 1 batch_num: 100\n","train_rmse_target: 0.4798 train_rmse_stderror: 0.02043 train_kl_div: 0.4646\n","val_rmse_target: 0.5539 val_rmse_stderror: 1.83\n","Still best_val_rmse: 0.5201 (from epoch 1)\n","\n","64 steps took 80.5 seconds\n","Epoch: 1 batch_num: 164\n","train_rmse_target: 0.3795 train_rmse_stderror: 0.03334 train_kl_div: 0.3027\n","val_rmse_target: 0.5006 val_rmse_stderror: 1.833\n","New best_val_rmse: 0.5006\n","\n","32 steps took 40.5 seconds\n","Epoch: 2 batch_num: 8\n","train_rmse_target: 0.2515 train_rmse_stderror: 0.02151 train_kl_div: 0.133\n","val_rmse_target: 0.4893 val_rmse_stderror: 1.838\n","New best_val_rmse: 0.4893\n","\n","8 steps took 10.1 seconds\n","Epoch: 2 batch_num: 16\n","train_rmse_target: 0.284 train_rmse_stderror: 0.02875 train_kl_div: 0.1773\n","val_rmse_target: 0.4927 val_rmse_stderror: 1.834\n","Still best_val_rmse: 0.4893 (from epoch 2)\n","\n","16 steps took 20.2 seconds\n","Epoch: 2 batch_num: 32\n","train_rmse_target: 0.2128 train_rmse_stderror: 0.02352 train_kl_div: 0.09075\n","val_rmse_target: 0.4933 val_rmse_stderror: 1.834\n","Still best_val_rmse: 0.4893 (from epoch 2)\n","\n","16 steps took 20.1 seconds\n","Epoch: 2 batch_num: 48\n","train_rmse_target: 0.2619 train_rmse_stderror: 0.03073 train_kl_div: 0.1493\n","val_rmse_target: 0.5539 val_rmse_stderror: 1.821\n","Still best_val_rmse: 0.4893 (from epoch 2)\n","\n","64 steps took 80.5 seconds\n","Epoch: 2 batch_num: 112\n","train_rmse_target: 0.1805 train_rmse_stderror: 0.01602 train_kl_div: 0.07535\n","val_rmse_target: 0.4903 val_rmse_stderror: 1.822\n","Still best_val_rmse: 0.4893 (from epoch 2)\n","\n","16 steps took 20.1 seconds\n","Epoch: 2 batch_num: 128\n","train_rmse_target: 0.2582 train_rmse_stderror: 0.02612 train_kl_div: 0.1488\n","val_rmse_target: 0.4783 val_rmse_stderror: 1.827\n","New best_val_rmse: 0.4783\n","\n","4 steps took 5.04 seconds\n","Epoch: 2 batch_num: 132\n","train_rmse_target: 0.2615 train_rmse_stderror: 0.04577 train_kl_div: 0.1379\n","val_rmse_target: 0.4946 val_rmse_stderror: 1.837\n","Still best_val_rmse: 0.4783 (from epoch 2)\n","\n","16 steps took 20.1 seconds\n","Epoch: 2 batch_num: 148\n","train_rmse_target: 0.2489 train_rmse_stderror: 0.02616 train_kl_div: 0.1354\n","val_rmse_target: 0.4959 val_rmse_stderror: 1.835\n","Still best_val_rmse: 0.4783 (from epoch 2)\n","\n","16 steps took 20.1 seconds\n","Epoch: 2 batch_num: 164\n","train_rmse_target: 0.1762 train_rmse_stderror: 0.03254 train_kl_div: 0.06254\n","val_rmse_target: 0.4784 val_rmse_stderror: 1.829\n","Still best_val_rmse: 0.4783 (from epoch 2)\n","\n","4 steps took 5.03 seconds\n","Epoch: 2 batch_num: 168\n","train_rmse_target: 0.3161 train_rmse_stderror: 0.02114 train_kl_div: 0.2071\n","val_rmse_target: 0.5022 val_rmse_stderror: 1.839\n","Still best_val_rmse: 0.4783 (from epoch 2)\n","\n","32 steps took 40.4 seconds\n","Epoch: 3 batch_num: 12\n","train_rmse_target: 0.207 train_rmse_stderror: 0.03086 train_kl_div: 0.09896\n","val_rmse_target: 0.4756 val_rmse_stderror: 1.841\n","New best_val_rmse: 0.4756\n","\n","4 steps took 5.05 seconds\n","Epoch: 3 batch_num: 16\n","train_rmse_target: 0.1145 train_rmse_stderror: 0.02548 train_kl_div: 0.03087\n","val_rmse_target: 0.4898 val_rmse_stderror: 1.816\n","Still best_val_rmse: 0.4756 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 24\n","train_rmse_target: 0.1702 train_rmse_stderror: 0.02617 train_kl_div: 0.06704\n","val_rmse_target: 0.488 val_rmse_stderror: 1.838\n","Still best_val_rmse: 0.4756 (from epoch 3)\n","\n","8 steps took 10.0 seconds\n","Epoch: 3 batch_num: 32\n","train_rmse_target: 0.1349 train_rmse_stderror: 0.02518 train_kl_div: 0.03462\n","val_rmse_target: 0.4893 val_rmse_stderror: 1.823\n","Still best_val_rmse: 0.4756 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 40\n","train_rmse_target: 0.1271 train_rmse_stderror: 0.01977 train_kl_div: 0.03673\n","val_rmse_target: 0.4913 val_rmse_stderror: 1.827\n","Still best_val_rmse: 0.4756 (from epoch 3)\n","\n","16 steps took 20.1 seconds\n","Epoch: 3 batch_num: 56\n","train_rmse_target: 0.1975 train_rmse_stderror: 0.02251 train_kl_div: 0.08658\n","val_rmse_target: 0.5035 val_rmse_stderror: 1.831\n","Still best_val_rmse: 0.4756 (from epoch 3)\n","\n","32 steps took 40.3 seconds\n","Epoch: 3 batch_num: 88\n","train_rmse_target: 0.1538 train_rmse_stderror: 0.02273 train_kl_div: 0.05474\n","val_rmse_target: 0.4901 val_rmse_stderror: 1.837\n","Still best_val_rmse: 0.4756 (from epoch 3)\n","\n","16 steps took 20.1 seconds\n","Epoch: 3 batch_num: 104\n","train_rmse_target: 0.1435 train_rmse_stderror: 0.02688 train_kl_div: 0.04486\n","val_rmse_target: 0.4823 val_rmse_stderror: 1.839\n","Still best_val_rmse: 0.4756 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 112\n","train_rmse_target: 0.2192 train_rmse_stderror: 0.01457 train_kl_div: 0.1062\n","val_rmse_target: 0.4883 val_rmse_stderror: 1.824\n","Still best_val_rmse: 0.4756 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 120\n","train_rmse_target: 0.1506 train_rmse_stderror: 0.02707 train_kl_div: 0.05161\n","val_rmse_target: 0.4889 val_rmse_stderror: 1.835\n","Still best_val_rmse: 0.4756 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 128\n","train_rmse_target: 0.08783 train_rmse_stderror: 0.02035 train_kl_div: 0.01751\n","val_rmse_target: 0.4875 val_rmse_stderror: 1.826\n","Still best_val_rmse: 0.4756 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 136\n","train_rmse_target: 0.1684 train_rmse_stderror: 0.02342 train_kl_div: 0.0609\n","val_rmse_target: 0.4906 val_rmse_stderror: 1.84\n","Still best_val_rmse: 0.4756 (from epoch 3)\n","\n","16 steps took 20.1 seconds\n","Epoch: 3 batch_num: 152\n","train_rmse_target: 0.1044 train_rmse_stderror: 0.01667 train_kl_div: 0.0255\n","val_rmse_target: 0.4896 val_rmse_stderror: 1.832\n","Still best_val_rmse: 0.4756 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 160\n","train_rmse_target: 0.1226 train_rmse_stderror: 0.02791 train_kl_div: 0.03377\n","val_rmse_target: 0.4869 val_rmse_stderror: 1.835\n","Still best_val_rmse: 0.4756 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 168\n","train_rmse_target: 0.1576 train_rmse_stderror: 0.03232 train_kl_div: 0.0523\n","val_rmse_target: 0.4968 val_rmse_stderror: 1.823\n","Still best_val_rmse: 0.4756 (from epoch 3)\n","\n","16 steps took 20.1 seconds\n","Epoch: 3 batch_num: 184\n","train_rmse_target: 0.164 train_rmse_stderror: 0.01066 train_kl_div: 0.05605\n","val_rmse_target: 0.4794 val_rmse_stderror: 1.831\n","Still best_val_rmse: 0.4756 (from epoch 3)\n","\n","4 steps took 5.22 seconds\n","Epoch: 4 batch_num: 0\n","train_rmse_target: 0.06939 train_rmse_stderror: 0.03387 train_kl_div: 0.01305\n","val_rmse_target: 0.4842 val_rmse_stderror: 1.825\n","Still best_val_rmse: 0.4756 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 8\n","train_rmse_target: 0.09078 train_rmse_stderror: 0.01584 train_kl_div: 0.0187\n","val_rmse_target: 0.4965 val_rmse_stderror: 1.83\n","Still best_val_rmse: 0.4756 (from epoch 3)\n","\n","16 steps took 20.1 seconds\n","Epoch: 4 batch_num: 24\n","train_rmse_target: 0.07325 train_rmse_stderror: 0.0208 train_kl_div: 0.01234\n","val_rmse_target: 0.4921 val_rmse_stderror: 1.83\n","Still best_val_rmse: 0.4756 (from epoch 3)\n","\n","16 steps took 20.1 seconds\n","Epoch: 4 batch_num: 40\n","train_rmse_target: 0.06197 train_rmse_stderror: 0.02039 train_kl_div: 0.008952\n","val_rmse_target: 0.4849 val_rmse_stderror: 1.838\n","Still best_val_rmse: 0.4756 (from epoch 3)\n","\n","8 steps took 10.0 seconds\n","Epoch: 4 batch_num: 48\n","train_rmse_target: 0.0939 train_rmse_stderror: 0.01369 train_kl_div: 0.01991\n","val_rmse_target: 0.4916 val_rmse_stderror: 1.831\n","Still best_val_rmse: 0.4756 (from epoch 3)\n","\n","16 steps took 20.1 seconds\n","Epoch: 4 batch_num: 64\n","train_rmse_target: 0.0833 train_rmse_stderror: 0.01946 train_kl_div: 0.01586\n","val_rmse_target: 0.4878 val_rmse_stderror: 1.827\n","Still best_val_rmse: 0.4756 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 72\n","train_rmse_target: 0.07606 train_rmse_stderror: 0.02923 train_kl_div: 0.01421\n","val_rmse_target: 0.4862 val_rmse_stderror: 1.832\n","Still best_val_rmse: 0.4756 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 80\n","train_rmse_target: 0.07449 train_rmse_stderror: 0.03374 train_kl_div: 0.01455\n","val_rmse_target: 0.4881 val_rmse_stderror: 1.83\n","Still best_val_rmse: 0.4756 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 88\n","train_rmse_target: 0.1156 train_rmse_stderror: 0.02205 train_kl_div: 0.02891\n","val_rmse_target: 0.4875 val_rmse_stderror: 1.829\n","Still best_val_rmse: 0.4756 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 96\n","train_rmse_target: 0.09553 train_rmse_stderror: 0.02102 train_kl_div: 0.02078\n","val_rmse_target: 0.4864 val_rmse_stderror: 1.83\n","Still best_val_rmse: 0.4756 (from epoch 3)\n","\n","8 steps took 10.0 seconds\n","Epoch: 4 batch_num: 104\n","train_rmse_target: 0.08786 train_rmse_stderror: 0.02206 train_kl_div: 0.01759\n","val_rmse_target: 0.4867 val_rmse_stderror: 1.831\n","Still best_val_rmse: 0.4756 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 112\n","train_rmse_target: 0.1057 train_rmse_stderror: 0.02327 train_kl_div: 0.0244\n","val_rmse_target: 0.4867 val_rmse_stderror: 1.831\n","Still best_val_rmse: 0.4756 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 120\n","train_rmse_target: 0.1385 train_rmse_stderror: 0.02656 train_kl_div: 0.03692\n","val_rmse_target: 0.4857 val_rmse_stderror: 1.831\n","Still best_val_rmse: 0.4756 (from epoch 3)\n","\n","8 steps took 10.0 seconds\n","Epoch: 4 batch_num: 128\n","train_rmse_target: 0.09144 train_rmse_stderror: 0.03136 train_kl_div: 0.01844\n","val_rmse_target: 0.4854 val_rmse_stderror: 1.831\n","Still best_val_rmse: 0.4756 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 136\n","train_rmse_target: 0.1206 train_rmse_stderror: 0.03212 train_kl_div: 0.03038\n","val_rmse_target: 0.4856 val_rmse_stderror: 1.832\n","Still best_val_rmse: 0.4756 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 144\n","train_rmse_target: 0.08895 train_rmse_stderror: 0.02094 train_kl_div: 0.01961\n","val_rmse_target: 0.4866 val_rmse_stderror: 1.832\n","Still best_val_rmse: 0.4756 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 152\n","train_rmse_target: 0.09106 train_rmse_stderror: 0.02479 train_kl_div: 0.0194\n","val_rmse_target: 0.487 val_rmse_stderror: 1.832\n","Still best_val_rmse: 0.4756 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 160\n","train_rmse_target: 0.1018 train_rmse_stderror: 0.02236 train_kl_div: 0.02371\n","val_rmse_target: 0.4872 val_rmse_stderror: 1.832\n","Still best_val_rmse: 0.4756 (from epoch 3)\n","\n","8 steps took 10.0 seconds\n","Epoch: 4 batch_num: 168\n","train_rmse_target: 0.103 train_rmse_stderror: 0.02615 train_kl_div: 0.02352\n","val_rmse_target: 0.4874 val_rmse_stderror: 1.832\n","Still best_val_rmse: 0.4756 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 176\n","train_rmse_target: 0.1044 train_rmse_stderror: 0.03 train_kl_div: 0.02468\n","val_rmse_target: 0.4875 val_rmse_stderror: 1.832\n","Still best_val_rmse: 0.4756 (from epoch 3)\n","\n","8 steps took 10.0 seconds\n","Epoch: 4 batch_num: 184\n","train_rmse_target: 0.0862 train_rmse_stderror: 0.01977 train_kl_div: 0.0171\n","val_rmse_target: 0.4875 val_rmse_stderror: 1.832\n","Still best_val_rmse: 0.4756 (from epoch 3)\n","\n","Performance estimates:\n","[0.4910475498330881, 0.4774353469674259, 0.47800463182048586, 0.4755566461798465]\n","Mean: 0.4805110437002116\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 5/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 81.5 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.6339 train_rmse_stderror: 0.05658 train_kl_div: 0.7511\n","val_rmse_target: 0.7573 val_rmse_stderror: 1.829\n","New best_val_rmse: 0.7573\n","\n","64 steps took 80.7 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.8029 train_rmse_stderror: 0.03911 train_kl_div: 1.266\n","val_rmse_target: 0.5809 val_rmse_stderror: 1.849\n","New best_val_rmse: 0.5809\n","\n","64 steps took 80.7 seconds\n","Epoch: 1 batch_num: 4\n","train_rmse_target: 0.3693 train_rmse_stderror: 0.02711 train_kl_div: 0.2863\n","val_rmse_target: 0.576 val_rmse_stderror: 1.87\n","New best_val_rmse: 0.576\n","\n","64 steps took 80.6 seconds\n","Epoch: 1 batch_num: 68\n","train_rmse_target: 0.376 train_rmse_stderror: 0.02749 train_kl_div: 0.3059\n","val_rmse_target: 0.5307 val_rmse_stderror: 1.866\n","New best_val_rmse: 0.5307\n","\n","32 steps took 40.3 seconds\n","Epoch: 1 batch_num: 100\n","train_rmse_target: 0.3238 train_rmse_stderror: 0.02761 train_kl_div: 0.2373\n","val_rmse_target: 0.519 val_rmse_stderror: 1.884\n","New best_val_rmse: 0.519\n","\n","32 steps took 40.3 seconds\n","Epoch: 1 batch_num: 132\n","train_rmse_target: 0.3335 train_rmse_stderror: 0.03142 train_kl_div: 0.2264\n","val_rmse_target: 0.5347 val_rmse_stderror: 1.877\n","Still best_val_rmse: 0.519 (from epoch 1)\n","\n","32 steps took 40.3 seconds\n","Epoch: 1 batch_num: 164\n","train_rmse_target: 0.535 train_rmse_stderror: 0.03109 train_kl_div: 0.5864\n","val_rmse_target: 0.5407 val_rmse_stderror: 1.893\n","Still best_val_rmse: 0.519 (from epoch 1)\n","\n","32 steps took 40.5 seconds\n","Epoch: 2 batch_num: 8\n","train_rmse_target: 0.2577 train_rmse_stderror: 0.02141 train_kl_div: 0.1288\n","val_rmse_target: 0.5367 val_rmse_stderror: 1.879\n","Still best_val_rmse: 0.519 (from epoch 1)\n","\n","32 steps took 40.3 seconds\n","Epoch: 2 batch_num: 40\n","train_rmse_target: 0.2162 train_rmse_stderror: 0.02693 train_kl_div: 0.1042\n","val_rmse_target: 0.5157 val_rmse_stderror: 1.851\n","New best_val_rmse: 0.5157\n","\n","32 steps took 40.3 seconds\n","Epoch: 2 batch_num: 72\n","train_rmse_target: 0.2051 train_rmse_stderror: 0.02094 train_kl_div: 0.08874\n","val_rmse_target: 0.5152 val_rmse_stderror: 1.862\n","New best_val_rmse: 0.5152\n","\n","32 steps took 40.3 seconds\n","Epoch: 2 batch_num: 104\n","train_rmse_target: 0.1964 train_rmse_stderror: 0.03026 train_kl_div: 0.07779\n","val_rmse_target: 0.5255 val_rmse_stderror: 1.87\n","Still best_val_rmse: 0.5152 (from epoch 2)\n","\n","32 steps took 40.3 seconds\n","Epoch: 2 batch_num: 136\n","train_rmse_target: 0.3254 train_rmse_stderror: 0.04733 train_kl_div: 0.1644\n","val_rmse_target: 0.5203 val_rmse_stderror: 1.862\n","Still best_val_rmse: 0.5152 (from epoch 2)\n","\n","32 steps took 40.3 seconds\n","Epoch: 2 batch_num: 168\n","train_rmse_target: 0.3054 train_rmse_stderror: 0.03084 train_kl_div: 0.1732\n","val_rmse_target: 0.5242 val_rmse_stderror: 1.863\n","Still best_val_rmse: 0.5152 (from epoch 2)\n","\n","32 steps took 40.4 seconds\n","Epoch: 3 batch_num: 12\n","train_rmse_target: 0.153 train_rmse_stderror: 0.01644 train_kl_div: 0.04126\n","val_rmse_target: 0.5207 val_rmse_stderror: 1.859\n","Still best_val_rmse: 0.5152 (from epoch 2)\n","\n","32 steps took 40.3 seconds\n","Epoch: 3 batch_num: 44\n","train_rmse_target: 0.06312 train_rmse_stderror: 0.02449 train_kl_div: 0.01132\n","val_rmse_target: 0.5304 val_rmse_stderror: 1.855\n","Still best_val_rmse: 0.5152 (from epoch 2)\n","\n","32 steps took 40.3 seconds\n","Epoch: 3 batch_num: 76\n","train_rmse_target: 0.1532 train_rmse_stderror: 0.02354 train_kl_div: 0.05274\n","val_rmse_target: 0.5321 val_rmse_stderror: 1.852\n","Still best_val_rmse: 0.5152 (from epoch 2)\n","\n","32 steps took 40.3 seconds\n","Epoch: 3 batch_num: 108\n","train_rmse_target: 0.1125 train_rmse_stderror: 0.01989 train_kl_div: 0.02875\n","val_rmse_target: 0.5287 val_rmse_stderror: 1.861\n","Still best_val_rmse: 0.5152 (from epoch 2)\n","\n","32 steps took 40.3 seconds\n","Epoch: 3 batch_num: 140\n","train_rmse_target: 0.1493 train_rmse_stderror: 0.01822 train_kl_div: 0.0528\n","val_rmse_target: 0.5327 val_rmse_stderror: 1.866\n","Still best_val_rmse: 0.5152 (from epoch 2)\n","\n","32 steps took 40.3 seconds\n","Epoch: 3 batch_num: 172\n","train_rmse_target: 0.2142 train_rmse_stderror: 0.01756 train_kl_div: 0.08138\n","val_rmse_target: 0.5153 val_rmse_stderror: 1.863\n","Still best_val_rmse: 0.5152 (from epoch 2)\n","\n","32 steps took 40.5 seconds\n","Epoch: 4 batch_num: 16\n","train_rmse_target: 0.09659 train_rmse_stderror: 0.02817 train_kl_div: 0.02133\n","val_rmse_target: 0.5168 val_rmse_stderror: 1.869\n","Still best_val_rmse: 0.5152 (from epoch 2)\n","\n","32 steps took 40.2 seconds\n","Epoch: 4 batch_num: 48\n","train_rmse_target: 0.0956 train_rmse_stderror: 0.03001 train_kl_div: 0.01938\n","val_rmse_target: 0.5149 val_rmse_stderror: 1.857\n","New best_val_rmse: 0.5149\n","\n","32 steps took 40.3 seconds\n","Epoch: 4 batch_num: 80\n","train_rmse_target: 0.09111 train_rmse_stderror: 0.02321 train_kl_div: 0.01987\n","val_rmse_target: 0.5143 val_rmse_stderror: 1.858\n","New best_val_rmse: 0.5143\n","\n","32 steps took 40.3 seconds\n","Epoch: 4 batch_num: 112\n","train_rmse_target: 0.0652 train_rmse_stderror: 0.01659 train_kl_div: 0.009897\n","val_rmse_target: 0.5137 val_rmse_stderror: 1.862\n","New best_val_rmse: 0.5137\n","\n","32 steps took 40.3 seconds\n","Epoch: 4 batch_num: 144\n","train_rmse_target: 0.07413 train_rmse_stderror: 0.02443 train_kl_div: 0.01393\n","val_rmse_target: 0.5132 val_rmse_stderror: 1.861\n","New best_val_rmse: 0.5132\n","\n","32 steps took 40.3 seconds\n","Epoch: 4 batch_num: 176\n","train_rmse_target: 0.07078 train_rmse_stderror: 0.01244 train_kl_div: 0.01061\n","val_rmse_target: 0.5135 val_rmse_stderror: 1.861\n","Still best_val_rmse: 0.5132 (from epoch 4)\n","\n","Performance estimates:\n","[0.4910475498330881, 0.4774353469674259, 0.47800463182048586, 0.4755566461798465, 0.513180793495776]\n","Mean: 0.48704499365932447\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"m4v-cGx-Mv7S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626727809657,"user_tz":-540,"elapsed":24,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"1c6b32e7-e3ba-402d-c1d6-f96f10ec9c60"},"source":["print(list_val_rmse)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["[0.4910475498330881, 0.4774353469674259, 0.47800463182048586, 0.4755566461798465, 0.513180793495776]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"q2CdCMuIKDMP","executionInfo":{"status":"ok","timestamp":1626727809658,"user_tz":-540,"elapsed":13,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#rep = MemReporter(model)\n","#rep.report()"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"eLl1yDOOKIe7","executionInfo":{"status":"ok","timestamp":1626727809658,"user_tz":-540,"elapsed":13,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#rep = MemReporter(model.roberta)\n","#rep.report()"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"7qkqnknA_m9D","executionInfo":{"status":"ok","timestamp":1626727809659,"user_tz":-540,"elapsed":13,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#gpuinfo()"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"PwrqSMdYA6Pu","executionInfo":{"status":"ok","timestamp":1626727809659,"user_tz":-540,"elapsed":12,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#del model\n","#del optimizer \n","#del train_loader\n","#del val_loader\n","#del scheduler \n","#del list_val_rmse\n","#del train_indices\n","#del val_indices\n","#del tokenizer\n","#torch.cuda.empty_cache()\n","#gpuinfo()"],"execution_count":28,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wXcHyUSJXecL"},"source":["# Inference"]},{"cell_type":"code","metadata":{"id":"YIV6UllSIGoa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626727930145,"user_tz":-540,"elapsed":120498,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"88fd9796-5579-4f9c-cbb2-425ba8ff88e5"},"source":["%cd\n","!mkdir .kaggle\n","!mkdir /content/model\n","!cp /content/drive/MyDrive/Colab_Files/kaggle-api/kaggle.json .kaggle/\n","\n","!cp -r /content/model_1.pth /content/model/model_1.pth\n","!cp -r /content/model_2.pth /content/model/model_2.pth\n","!cp -r /content/model_3.pth /content/model/model_3.pth\n","!cp -r /content/model_4.pth /content/model/model_4.pth\n","!cp -r /content/model_5.pth /content/model/model_5.pth"],"execution_count":29,"outputs":[{"output_type":"stream","text":["/root\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"14ddOZH4IMam","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626728189035,"user_tz":-540,"elapsed":258905,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"9fd08363-6128-4c6d-b232-8d1aa0ca3cbc"},"source":["def dataset_upload():\n","    import json\n","    from kaggle.api.kaggle_api_extended import KaggleApi\n","\n","    id = f'{USERID}/{EX_NO}'\n","\n","    dataset_metadata = {}\n","    dataset_metadata['id'] = id\n","    dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n","    dataset_metadata['title'] = f'{EX_NO}'\n","\n","    with open(UPLOAD_DIR / 'dataset-metadata.json', 'w') as f:\n","        json.dump(dataset_metadata, f, indent=4)\n","\n","    api = KaggleApi()\n","    api.authenticate()\n","\n","    # データセットがない場合\n","    if f'{USERID}/{EX_NO}' not in [str(d) for d in api.dataset_list(user=USERID, search=f'\"{EX_NO}\"')]:\n","        api.dataset_create_new(folder=UPLOAD_DIR,\n","                               convert_to_csv=False,\n","                               dir_mode='skip')\n","    # データセットがある場合\n","    else:\n","        api.dataset_create_version(folder=UPLOAD_DIR,\n","                                   version_notes='update',\n","                                   convert_to_csv=False,\n","                                   delete_old_versions=True,\n","                                   dir_mode='skip')\n","dataset_upload()\n","\n"],"execution_count":30,"outputs":[{"output_type":"stream","text":["Starting upload for file model_2.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [00:51<00:00, 27.6MB/s]\n","  0%|          | 0.00/1.33G [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_2.pth (1GB)\n","Starting upload for file model_4.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [00:49<00:00, 28.8MB/s]\n","  0%|          | 0.00/1.33G [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_4.pth (1GB)\n","Starting upload for file model_1.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [00:51<00:00, 27.4MB/s]\n","  0%|          | 0.00/1.33G [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_1.pth (1GB)\n","Starting upload for file model_5.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [00:51<00:00, 27.5MB/s]\n","  0%|          | 0.00/1.33G [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_5.pth (1GB)\n","Starting upload for file model_3.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [00:49<00:00, 28.6MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_3.pth (1GB)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"huJwVMSAPuDO","executionInfo":{"status":"ok","timestamp":1626728189038,"user_tz":-540,"elapsed":19,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"0zzuBPobmLFu","executionInfo":{"status":"ok","timestamp":1626728189038,"user_tz":-540,"elapsed":16,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wpc8ro9hmNci","executionInfo":{"status":"ok","timestamp":1626728189039,"user_tz":-540,"elapsed":16,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"ceDI72NumT5-","executionInfo":{"status":"ok","timestamp":1626728189039,"user_tz":-540,"elapsed":16,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"PvRi_JQgwcKI","executionInfo":{"status":"ok","timestamp":1626728189040,"user_tz":-540,"elapsed":16,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":30,"outputs":[]}]}