{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"043-train-05.ipynb","provenance":[{"file_id":"1Vz2GB2BNTWuefEFkCSh3TBPEIel7KG1t","timestamp":1626317426487},{"file_id":"1djoMWojeaIPopG5tS1jNMohn8ineblRh","timestamp":1626306831897},{"file_id":"1-6tlDO8158Pi6TpptIF884oFaEiT4Uxb","timestamp":1626276420047},{"file_id":"1js8eA3mDNS8mwSpCiHuzPeARFlUPAVrg","timestamp":1626272452526},{"file_id":"1yhcPgulwJtjJKUK9IuRKmNMhJ-4YXGol","timestamp":1626267205517},{"file_id":"1mnnSv0Pofn1QxArywV81VYqnZPB8uUWN","timestamp":1626180468522},{"file_id":"1RRdjt_UAeHmr5QQBAMyC82Fq1s31OWdK","timestamp":1625833136005},{"file_id":"1JPgg44HFemzwk8VSCXih3PejL0idy-C4","timestamp":1625825483466},{"file_id":"1Ye6wqVX71xAAAhmjXkw9IpRvTqeUyJDA","timestamp":1625812137500}],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"193de91d6e8c4cb1b971858929c10977":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0c70737461c74cdf80c31b4457414a93","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_567546c433144347afac9b1d7c4dec28","IPY_MODEL_14cd0e04bd3749ffb58a597624053e1c"]}},"0c70737461c74cdf80c31b4457414a93":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"567546c433144347afac9b1d7c4dec28":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4a11593f95004fad853c097e6093894a","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":481,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":481,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_14411e44ed1e4a0d9ca067e1e859ebe4"}},"14cd0e04bd3749ffb58a597624053e1c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_929c492487254fd98d3310ba69794c93","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 481/481 [00:04&lt;00:00, 102B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0a1f9283b7174c909bca31e61a3027ac"}},"4a11593f95004fad853c097e6093894a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"14411e44ed1e4a0d9ca067e1e859ebe4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"929c492487254fd98d3310ba69794c93":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0a1f9283b7174c909bca31e61a3027ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9d34c6673be5467f9bdd4b649afb4258":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c4e0e47e5ff545f6bc17ff648c05142a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f55a5ffa299847c89de11a68d43f720c","IPY_MODEL_6ec8bf13c2a642c48536e6958133dc33"]}},"c4e0e47e5ff545f6bc17ff648c05142a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f55a5ffa299847c89de11a68d43f720c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e39225f7474847daae665321813a26dd","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":898823,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":898823,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fc8d5ffc4ff5443abce4593311821606"}},"6ec8bf13c2a642c48536e6958133dc33":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a444abe2e4e94c5ba70eec8f086355d7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 899k/899k [00:00&lt;00:00, 1.15MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4f0d4e70b78f42fb88c30b7a29e35836"}},"e39225f7474847daae665321813a26dd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"fc8d5ffc4ff5443abce4593311821606":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a444abe2e4e94c5ba70eec8f086355d7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4f0d4e70b78f42fb88c30b7a29e35836":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bb088fcd5ea14d169b463f3ac7a7c161":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_173f760578a44a3cb525ad0638b04196","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7d6c4d9e6891485293466709f356f94b","IPY_MODEL_79eff56b025f401593a72299eab57cfa"]}},"173f760578a44a3cb525ad0638b04196":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7d6c4d9e6891485293466709f356f94b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f6c23d3d62ba4074be1a6f4a0f34312c","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":456318,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":456318,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_792c2814aeed40e28845c045e5f8a7fb"}},"79eff56b025f401593a72299eab57cfa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5f4a0b797bb142c496362e82cc81c1ef","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 456k/456k [00:03&lt;00:00, 136kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4e94fcb69740451486dc0b851d5f46d6"}},"f6c23d3d62ba4074be1a6f4a0f34312c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"792c2814aeed40e28845c045e5f8a7fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5f4a0b797bb142c496362e82cc81c1ef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4e94fcb69740451486dc0b851d5f46d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1b8753a820fa4dabb6cfbb14bbaf37f2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_92c45bcc65a14e84867123b308c61b8b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_66fef6f9b3934bfbb00156d59eeb1156","IPY_MODEL_e60d3a4438804f23ba4e471f9480bf4d"]}},"92c45bcc65a14e84867123b308c61b8b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"66fef6f9b3934bfbb00156d59eeb1156":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_822d510f9af549e6b18e5a037024af68","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1355863,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1355863,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c185f5e2aa9e4076b4a8dd42fac137c4"}},"e60d3a4438804f23ba4e471f9480bf4d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_beb00c2a51274f8eb358b245bab968f1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.36M/1.36M [00:02&lt;00:00, 583kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_52bebccdc65b49c9bf1755a675b4e916"}},"822d510f9af549e6b18e5a037024af68":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c185f5e2aa9e4076b4a8dd42fac137c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"beb00c2a51274f8eb358b245bab968f1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"52bebccdc65b49c9bf1755a675b4e916":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fa4f3a80ea0847fca278e4e0fc258963":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1e0e53f0f6f04906b168adc6e9459f41","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_28ab2e98d2484468bba6cde8104e517e","IPY_MODEL_c90a522776434b99b9c6009a2ab7d426"]}},"1e0e53f0f6f04906b168adc6e9459f41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"28ab2e98d2484468bba6cde8104e517e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_bdb44edaa82b4690bef9dbf8201da115","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":501200538,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":501200538,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0f19863a85f543b7b999544a2d5ac145"}},"c90a522776434b99b9c6009a2ab7d426":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1af94c95b09f4a039ab54628d789ed2f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 501M/501M [00:16&lt;00:00, 30.3MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6e5d3b8ddfc940ac89602d7b3771492b"}},"bdb44edaa82b4690bef9dbf8201da115":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0f19863a85f543b7b999544a2d5ac145":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1af94c95b09f4a039ab54628d789ed2f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6e5d3b8ddfc940ac89602d7b3771492b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":86},"id":"Z6yRwt-PXtbP","executionInfo":{"status":"ok","timestamp":1626317545346,"user_tz":-540,"elapsed":294,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"d1002a3a-5372-49b3-b3d4-129badfaccb4"},"source":["\"\"\"\n","if 'google.colab' in sys.modules:  # colab環境特有の処理_初回のみ\n","  # Google Driveのマウント\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","\n","  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules' \\\n","   -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/requirements.txt' \\\n","   --ignore-installed\n","\n","  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules' \\\n","   transformers -U\n","  !pip install gensim==4.0.1 --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\n","  !pip install pytorch_memlab --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\n","\"\"\""],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\nif 'google.colab' in sys.modules:  # colab環境特有の処理_初回のみ\\n  # Google Driveのマウント\\n  from google.colab import drive\\n  drive.mount('/content/drive')\\n\\n  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'    -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/requirements.txt'    --ignore-installed\\n\\n  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'    transformers -U\\n  !pip install gensim==4.0.1 --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\\n  !pip install pytorch_memlab --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\\n\""]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kA8loJjZHY2-","executionInfo":{"status":"ok","timestamp":1626317547997,"user_tz":-540,"elapsed":2348,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"ae7458a0-cec5-4e9f-8cbc-bc815cd2961f"},"source":["!pip install pytorch_memlab"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pytorch_memlab in /usr/local/lib/python3.7/dist-packages (0.2.3)\n","Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch_memlab) (1.9.0+cu102)\n","Requirement already satisfied: pandas>=0.18 in /usr/local/lib/python3.7/dist-packages (from pytorch_memlab) (1.1.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytorch_memlab) (57.0.0)\n","Requirement already satisfied: calmsize in /usr/local/lib/python3.7/dist-packages (from pytorch_memlab) (0.1.3)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->pytorch_memlab) (3.7.4.3)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18->pytorch_memlab) (2.8.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18->pytorch_memlab) (2018.9)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18->pytorch_memlab) (1.19.5)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.18->pytorch_memlab) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ucCbvGD1XvG7","executionInfo":{"status":"ok","timestamp":1626317548343,"user_tz":-540,"elapsed":356,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"39cb29da-2be9-4ae5-f34c-3b188ffc06f4"},"source":["import sys\n","if 'google.colab' in sys.modules:  # colab特有の処理_2回目以降\n","  # Google Driveのマウント\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","\n","  # データセットをDriveから取得\n","  !mkdir -p 'input'\n","  !cp -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/00_input' '/content/input'\n","\n","  # ライブラリのパス指定\n","  sys.path.append('/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules')\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RV9-VwbpZLZ9"},"source":["from pathlib import Path\n","\n","# input\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    DATA_DIR = Path('../input/commonlitreadabilityprize/')\n","\n","elif 'google.colab' in sys.modules: # Colab環境\n","    !mkdir 'input' -p\n","    !cp '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/00_input/commonlitreadabilityprize/' './input' -r\n","    DATA_DIR = Path('/content/input/commonlitreadabilityprize')\n","\n","else:\n","    DATA_DIR = Path('../00_input/commonlitreadabilityprize/')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8tMampUSaDo5"},"source":["from pathlib import Path\n","\n","# pre-trained model\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    PRE_TRAINED_MODEL_DIR = '../input/roberta-transformers-pytorch/roberta-large'\n","elif 'google.colab' in sys.modules: # Colab環境\n","    PRE_TRAINED_MODEL_DIR = 'roberta-base' # 仮で、毎回DLする想定のモデル名を指定。あとで変更予定。\n","else:\n","    PRE_TRAINED_MODEL_DIR = 'roberta-base'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tKjsUxnOeDYl"},"source":["from pathlib import Path\n","\n","# pre-trained model\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    PRE_TRAINED_MODEL_DIR = '../input/roberta-transformers-pytorch/roberta-base'\n","elif 'google.colab' in sys.modules: # Colab環境\n","    PRE_TRAINED_MODEL_DIR = 'roberta-base' # 仮で、毎回DLする想定のモデル名を指定。あとで変更予定。\n","else:\n","    PRE_TRAINED_MODEL_DIR = 'roberta-base'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZLaT2V0ReoAZ"},"source":["UPLOAD_DIR = Path('/content/model')\n","EX_NO = '043-train-05'  # 実験番号などを入れる、folderのpathにする\n","USERID = 'calpis10000'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hOGjAb4pAJ0F"},"source":["import subprocess\n","import shlex\n","\n","def gpuinfo():\n","    \"\"\"\n","    Returns size of total GPU RAM and used GPU RAM.\n","\n","    Parameters\n","    ----------\n","    None\n","\n","    Returns\n","    -------\n","    info : dict\n","        Total GPU RAM in integer for key 'total_MiB'.\n","        Used GPU RAM in integer for key 'used_MiB'.\n","    \"\"\"\n","\n","    command = 'nvidia-smi -q -d MEMORY | sed -n \"/FB Memory Usage/,/Free/p\" | sed -e \"1d\" -e \"4d\" -e \"s/ MiB//g\" | cut -d \":\" -f 2 | cut -c2-'\n","    commands = [shlex.split(part) for part in command.split(' | ')]\n","    for i, cmd in enumerate(commands):\n","        if i==0:\n","            res = subprocess.Popen(cmd, stdout=subprocess.PIPE)\n","        else:\n","            res = subprocess.Popen(cmd, stdin=res.stdout, stdout=subprocess.PIPE)\n","    total, used = map(int, res.communicate()[0].decode('utf-8').strip().split('\\n'))\n","    info = {'total_MiB':total, 'used_MiB':used}\n","    return info\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g3-6m5MKXecB"},"source":["# Overview\n","This nb is based on copy from https://www.kaggle.com/andretugan/lightweight-roberta-solution-in-pytorch .\n","\n","Acknowledgments(from base nb): \n","some ideas were taken from kernels by [Torch](https://www.kaggle.com/rhtsingh) and [Maunish](https://www.kaggle.com/maunish)."]},{"cell_type":"code","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-04T06:26:32.834365Z","iopub.execute_input":"2021-07-04T06:26:32.834903Z","iopub.status.idle":"2021-07-04T06:26:40.143740Z","shell.execute_reply.started":"2021-07-04T06:26:32.834785Z","shell.execute_reply":"2021-07-04T06:26:40.142864Z"},"trusted":true,"id":"HRsRZ06WXecD"},"source":["import os\n","import math\n","import random\n","import time\n","\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","\n","from transformers import AdamW # optimizer\n","from transformers import AutoTokenizer\n","from transformers import AutoModel\n","from transformers import AutoConfig\n","from transformers import get_cosine_schedule_with_warmup # scheduler\n","from pytorch_memlab import profile\n","import pytorch_memlab\n","from pytorch_memlab import MemReporter\n","\n","from sklearn.model_selection import KFold, StratifiedKFold\n","\n","import gc\n","gc.enable()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bPh2rvoiFrUM"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.145217Z","iopub.execute_input":"2021-07-04T06:26:40.145539Z","iopub.status.idle":"2021-07-04T06:26:40.201326Z","shell.execute_reply.started":"2021-07-04T06:26:40.145504Z","shell.execute_reply":"2021-07-04T06:26:40.200136Z"},"trusted":true,"id":"omBfwshTXecE"},"source":["NUM_FOLDS = 5 # K Fold\n","NUM_EPOCHS = 5 # Epochs\n","BATCH_SIZE = 16 # Batch Size\n","MAX_LEN = 248 # ベクトル長\n","EVAL_SCHEDULE = [(0.50, 16), (0.49, 8), (0.48, 4), (0.47, 2), (-1., 1)] # schedulerの何らかの設定？\n","ROBERTA_PATH = PRE_TRAINED_MODEL_DIR # roberta pre-trainedモデル(モデルとして指定)\n","TOKENIZER_PATH = PRE_TRAINED_MODEL_DIR # roberta pre-trainedモデル(Tokenizerとして指定)\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\" # cudaがなければcpuを使えばいいじゃない"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.203398Z","iopub.execute_input":"2021-07-04T06:26:40.204055Z","iopub.status.idle":"2021-07-04T06:26:40.211572Z","shell.execute_reply.started":"2021-07-04T06:26:40.204015Z","shell.execute_reply":"2021-07-04T06:26:40.210762Z"},"trusted":true,"id":"4qcuXqwtXecF"},"source":["def set_random_seed(random_seed):\n","    random.seed(random_seed)\n","    np.random.seed(random_seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(random_seed)\n","\n","    torch.manual_seed(random_seed)\n","    torch.cuda.manual_seed(random_seed)\n","    torch.cuda.manual_seed_all(random_seed)\n","\n","    torch.backends.cudnn.deterministic = True# cudnnによる最適化で結果が変わらないためのおまじない "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.214188Z","iopub.execute_input":"2021-07-04T06:26:40.214809Z","iopub.status.idle":"2021-07-04T06:26:40.309744Z","shell.execute_reply.started":"2021-07-04T06:26:40.214769Z","shell.execute_reply":"2021-07-04T06:26:40.308926Z"},"trusted":true,"id":"70PyLsJTXecF"},"source":["# train, testを読む\n","train_df = pd.read_csv(DATA_DIR/\"train.csv\")\n","\n","# Remove incomplete entries if any.\n","train_df.drop(train_df[(train_df.target == 0) & (train_df.standard_error == 0)].index,\n","              inplace=True)\n","train_df.reset_index(drop=True, inplace=True)\n","\n","test_df = pd.read_csv(DATA_DIR/\"test.csv\")\n","submission_df = pd.read_csv(DATA_DIR/\"sample_submission.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"9ZYOB59L8qtA","executionInfo":{"status":"ok","timestamp":1626317694357,"user_tz":-540,"elapsed":20,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"9055ec26-7474-4a2c-f788-08fd9c0804c3"},"source":["train_df.head()\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>url_legal</th>\n","      <th>license</th>\n","      <th>excerpt</th>\n","      <th>target</th>\n","      <th>standard_error</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>c12129c31</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>When the young people returned to the ballroom...</td>\n","      <td>-0.340259</td>\n","      <td>0.464009</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>85aa80a4c</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>All through dinner time, Mrs. Fayre was somewh...</td>\n","      <td>-0.315372</td>\n","      <td>0.480805</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>b69ac6792</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>As Roger had predicted, the snow departed as q...</td>\n","      <td>-0.580118</td>\n","      <td>0.476676</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>dd1000b26</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>And outside before the palace a great garden w...</td>\n","      <td>-1.054013</td>\n","      <td>0.450007</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>37c1b32fb</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Once upon a time there were Three Bears who li...</td>\n","      <td>0.247197</td>\n","      <td>0.510845</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          id url_legal  ...    target standard_error\n","0  c12129c31       NaN  ... -0.340259       0.464009\n","1  85aa80a4c       NaN  ... -0.315372       0.480805\n","2  b69ac6792       NaN  ... -0.580118       0.476676\n","3  dd1000b26       NaN  ... -1.054013       0.450007\n","4  37c1b32fb       NaN  ...  0.247197       0.510845\n","\n","[5 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.311021Z","iopub.execute_input":"2021-07-04T06:26:40.311347Z","iopub.status.idle":"2021-07-04T06:26:40.624393Z","shell.execute_reply.started":"2021-07-04T06:26:40.311314Z","shell.execute_reply":"2021-07-04T06:26:40.623347Z"},"trusted":true,"id":"xf0662k4XecF","colab":{"base_uri":"https://localhost:8080/","height":213,"referenced_widgets":["193de91d6e8c4cb1b971858929c10977","0c70737461c74cdf80c31b4457414a93","567546c433144347afac9b1d7c4dec28","14cd0e04bd3749ffb58a597624053e1c","4a11593f95004fad853c097e6093894a","14411e44ed1e4a0d9ca067e1e859ebe4","929c492487254fd98d3310ba69794c93","0a1f9283b7174c909bca31e61a3027ac","9d34c6673be5467f9bdd4b649afb4258","c4e0e47e5ff545f6bc17ff648c05142a","f55a5ffa299847c89de11a68d43f720c","6ec8bf13c2a642c48536e6958133dc33","e39225f7474847daae665321813a26dd","fc8d5ffc4ff5443abce4593311821606","a444abe2e4e94c5ba70eec8f086355d7","4f0d4e70b78f42fb88c30b7a29e35836","bb088fcd5ea14d169b463f3ac7a7c161","173f760578a44a3cb525ad0638b04196","7d6c4d9e6891485293466709f356f94b","79eff56b025f401593a72299eab57cfa","f6c23d3d62ba4074be1a6f4a0f34312c","792c2814aeed40e28845c045e5f8a7fb","5f4a0b797bb142c496362e82cc81c1ef","4e94fcb69740451486dc0b851d5f46d6","1b8753a820fa4dabb6cfbb14bbaf37f2","92c45bcc65a14e84867123b308c61b8b","66fef6f9b3934bfbb00156d59eeb1156","e60d3a4438804f23ba4e471f9480bf4d","822d510f9af549e6b18e5a037024af68","c185f5e2aa9e4076b4a8dd42fac137c4","beb00c2a51274f8eb358b245bab968f1","52bebccdc65b49c9bf1755a675b4e916"]},"executionInfo":{"status":"ok","timestamp":1626317699618,"user_tz":-540,"elapsed":5279,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"08bf7c14-dc52-4511-b479-51b1ea4a4fa1"},"source":["# tokenizerを指定\n","tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"193de91d6e8c4cb1b971858929c10977","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=481.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9d34c6673be5467f9bdd4b649afb4258","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bb088fcd5ea14d169b463f3ac7a7c161","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1b8753a820fa4dabb6cfbb14bbaf37f2","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355863.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"N6aaghNkXecG"},"source":["# Dataset"]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.628883Z","iopub.execute_input":"2021-07-04T06:26:40.629347Z","iopub.status.idle":"2021-07-04T06:26:40.644338Z","shell.execute_reply.started":"2021-07-04T06:26:40.629309Z","shell.execute_reply":"2021-07-04T06:26:40.643336Z"},"trusted":true,"id":"zkopT0U1XecG"},"source":["# Dataset用のClass。おそらく、trainとtestでインスタンスを生成し、DataFrameと同じように扱えるような思想。\n","class LitDataset(Dataset):\n","    def __init__(self, df, inference_only=False):\n","        super().__init__()\n","\n","        self.df = df        \n","        self.inference_only = inference_only # Testデータ用フラグ\n","        self.text = df.excerpt.tolist() # 分析対象カラムをlistにする。(分かち書きではなく、Seriesをlistへ変換するような処理)\n","        #self.text = [text.replace(\"\\n\", \" \") for text in self.text] # 単語単位で分かち書きする場合\n","        \n","        if not self.inference_only:\n","            self.target = torch.tensor(df.target.values, dtype=torch.float32) # trainのみ、targetをtensorに変換\n","            self.standard_error = torch.tensor(df.standard_error.values, dtype=torch.float32) \n","\n","        self.encoded = tokenizer.batch_encode_plus( # textをtokenize\n","            self.text,\n","            padding = 'max_length',            \n","            max_length = MAX_LEN,\n","            truncation = True, # 最大長を超える文字は切り捨て\n","            return_attention_mask=True\n","        )        \n"," \n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    \n","    def __getitem__(self, index): # 変換結果を返す\n","        input_ids = torch.tensor(self.encoded['input_ids'][index])\n","        attention_mask = torch.tensor(self.encoded['attention_mask'][index])\n","        \n","        if self.inference_only:\n","            return (input_ids, attention_mask)            \n","        else:\n","            target = self.target[index]\n","            standard_error = self.standard_error[index]\n","            return (input_ids, attention_mask, target, standard_error)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KKtdy32wXecG"},"source":["# Model\n","The model is inspired by the one from [Maunish](https://www.kaggle.com/maunish/clrp-roberta-svm)."]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.649629Z","iopub.execute_input":"2021-07-04T06:26:40.650066Z","iopub.status.idle":"2021-07-04T06:26:40.666374Z","shell.execute_reply.started":"2021-07-04T06:26:40.650002Z","shell.execute_reply":"2021-07-04T06:26:40.665211Z"},"trusted":true,"id":"BpkxjXEUXecH"},"source":["class LitModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        config = AutoConfig.from_pretrained(ROBERTA_PATH) # pretrainedからconfigを読み込み\n","        config.update({\"output_hidden_states\":True, # config更新: embedding層を抽出\n","                       \"hidden_dropout_prob\": 0.0, # config更新: dropoutしない\n","                       \"layer_norm_eps\": 1e-7}) # config更新: layer normalizationのepsilon                      \n","        \n","        self.roberta = AutoModel.from_pretrained(ROBERTA_PATH, config=config) # cpuで処理する\n","            \n","        self.attention = nn.Sequential(# attentionレイヤー            \n","            nn.Linear(config.hidden_size, 512), # 768は、ベースとなる学習済みモデルの重みをハードコードしてる。イケてないので、configから取得する感じにしたい。     \n","            nn.Tanh(),                       \n","            nn.Linear(512, 1),\n","            nn.Softmax(dim=1)\n","        )\n","\n","        self.regressor = nn.Sequential( # 出力レイヤー                    \n","            nn.Linear(config.hidden_size, 2)                        \n","        )\n","\n","    def forward(self, input_ids, attention_mask):\n","        #print('model: get_roberta_out: Start', gpuinfo())                 \n","        roberta_output = self.roberta(input_ids=input_ids, # robertaに入力データを流し、出力としてrobertaモデル(layerの複合体)を得る\n","                                      attention_mask=attention_mask)     \n","        #print('model: get_roberta_out: Done', gpuinfo())                 \n","\n","        # There are a total of 13 layers of hidden states.\n","        # 1 for the embedding layer, and 12 for the 12 Roberta layers.\n","        # We take the hidden states from the last Roberta layer.\n","        #last_hidden_state = roberta_output.hidden_states[-1] # robertaモデルの最後のlayerを得る\n","        last_hidden_state = roberta_output[0]\n","\n","        # https://www.kaggle.com/rhtsingh/utilizing-transformer-representations-efficiently\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        sum_mask = input_mask_expanded.sum(1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        mean_embeddings = sum_embeddings / sum_mask\n","\n","        # The number of cells is MAX_LEN.\n","        # The size of the hidden state of each cell is 768 (for roberta-base). # \n","        # In order to condense hidden states of all cells to a context vector,\n","        # we compute a weighted average of the hidden states of all cells.\n","        # We compute the weight of each cell, using the attention neural network.\n","        #weights = self.attention(last_layer_hidden_states) # robertaの最後のlayerをattentionへ入力し、出力として重みを得る\n","                \n","        # weights.shape is BATCH_SIZE x MAX_LEN x 1\n","        # last_layer_hidden_states.shape is BATCH_SIZE x MAX_LEN x 768        \n","        # Now we compute context_vector as the weighted average.\n","        # context_vector.shape is BATCH_SIZE x 768\n","        #context_vector = torch.sum(weights * last_layer_hidden_states, dim=1) # 重み×最後の層を足し合わせて文書ベクトルとする。\n","        \n","        # Now we reduce the context vector to the prediction score.\n","        return self.regressor(mean_embeddings) # 文書ベクトルを線形層に入力し、targetを出力する"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.672515Z","iopub.execute_input":"2021-07-04T06:26:40.672944Z","iopub.status.idle":"2021-07-04T06:26:40.684593Z","shell.execute_reply.started":"2021-07-04T06:26:40.672908Z","shell.execute_reply":"2021-07-04T06:26:40.683569Z"},"trusted":true,"id":"bB4jvQTxXecH"},"source":["# 評価指標(MSE)の計算。最終的に、ルートしてRMSEにすると思われる。\n","def eval_mse(model, data_loader):\n","    \"\"\"Evaluates the mean squared error of the |model| on |data_loader|\"\"\"\n","    model.eval() # evalモードを選択。Batch Normとかdropoutをしなくなる           \n","    mse_mean_sum = 0\n","    mse_std_sum = 0\n","\n","    with torch.no_grad(): # 勾配の計算をしないBlock\n","        for batch_num, (input_ids, attention_mask, target, standard_error) in enumerate(data_loader): # data_loaderからinput, attentin_mask, targetをbatchごとに取り出す\n","            input_ids = input_ids.to(DEVICE)   \n","            attention_mask = attention_mask.to(DEVICE)   \n","            target = target.to(DEVICE)      \n","            standard_error = standard_error.to(DEVICE) \n","            \n","            output = model(input_ids, attention_mask) # 取得した値をモデルへ入力し、出力として予測値を得る。\n","\n","            mse_mean_sum += nn.MSELoss(reduction=\"sum\")(output[:,0].flatten(), target).item() # 誤差の合計を得る(Batchごとに計算した誤差を足し上げる)\n","            mse_std_sum += nn.MSELoss(reduction=\"sum\")(output[:,1].flatten(), target).item() # 誤差の合計を得る(Batchごとに計算した誤差を足し上げる)\n","\n","    del input_ids\n","    del attention_mask\n","    del target\n","\n","    mse_mean_result = mse_mean_sum / len(data_loader.dataset)\n","    mse_std_result = mse_std_sum / len(data_loader.dataset)\n","  \n","    return mse_mean_result, mse_std_result # 誤差の合計をdataset長で除し、mseを取得＆返す"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.690155Z","iopub.execute_input":"2021-07-04T06:26:40.692530Z","iopub.status.idle":"2021-07-04T06:26:40.703425Z","shell.execute_reply.started":"2021-07-04T06:26:40.692488Z","shell.execute_reply":"2021-07-04T06:26:40.702366Z"},"trusted":true,"id":"47bDno_LXecI"},"source":["# 推論結果を返す\n","def predict(model, data_loader):\n","    \"\"\"Returns an np.array with predictions of the |model| on |data_loader|\"\"\"\n","    model.eval() # evalモード(dropout, batch_normしない)\n","\n","    result = np.zeros(len(data_loader.dataset)) # 結果をdataset長のzero配列として用意\n","    index = 0\n","    \n","    with torch.no_grad(): # 勾配の計算をしないblock(inputすると、現状の重みによる推論結果を返す)\n","        for batch_num, (input_ids, attention_mask) in enumerate(data_loader): # data_loaderからbatchごとにinputを得る\n","            input_ids = input_ids.to(DEVICE)\n","            attention_mask = attention_mask.to(DEVICE)\n","                        \n","            output = model(input_ids, attention_mask) # modelにinputを入力し、予測結果を得る。\n","\n","            result[index : index + output[:,0].shape[0]] = output[:,0].flatten().to(\"cpu\") # result[index ~ predの長さ]へ、予測結果を格納\n","            index += pred.shape[0] # indexを更新\n","\n","    return result # 全batchで推論が終わったら、結果を返す"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.708605Z","iopub.execute_input":"2021-07-04T06:26:40.709024Z","iopub.status.idle":"2021-07-04T06:26:40.730675Z","shell.execute_reply.started":"2021-07-04T06:26:40.708983Z","shell.execute_reply":"2021-07-04T06:26:40.729705Z"},"trusted":true,"id":"oInneuAmXecI"},"source":["# 学習\n","def train(model, # モデル\n","          model_path, # モデルのアウトプット先\n","          train_loader, # train-setのdata_loader\n","          val_loader, # valid-setのdata_loader\n","          optimizer, # optimizer\n","          scheduler=None, # scheduler, デフォルトはNone\n","          num_epochs=NUM_EPOCHS # epoch数、notebook冒頭で指定した値\n","         ):    \n","    \n","    best_val_rmse = None\n","    best_epoch = 0\n","    step = 0\n","    last_eval_step = 0\n","    eval_period = EVAL_SCHEDULE[0][1] # eval期間(って何？) 冒頭で決めたEVAL_SCHEDULEの最初のtupleの[1]を取得\n","\n","    start = time.time() # 時間計測用\n","\n","    for epoch in range(num_epochs): # 指定したEpoch数だけ繰り返し\n","        val_rmse = None         \n","\n","        for batch_num, (input_ids, attention_mask, target, standard_error) in enumerate(train_loader): # train_loaderからinput, targetを取得\n","            input_ids = input_ids.to(DEVICE) # inputをDEVICEへ突っ込む\n","            attention_mask = attention_mask.to(DEVICE)       \n","            target = target.to(DEVICE)\n","            standard_error = standard_error.to(DEVICE)  \n","\n","            optimizer.zero_grad() # 勾配を初期化            \n","            model.train() # 学習モード開始\n","\n","            # https://www.kaggle.com/c/commonlitreadabilityprize/discussion/239421\n","            output = model(input_ids, attention_mask) # input,attention_maskを入力し、予測結果を得る\n","            p = torch.distributions.Normal(output[:,0], torch.sqrt(output[:,1]**2))\n","            q = torch.distributions.Normal(target, standard_error)\n","            kl_vector = torch.distributions.kl_divergence(p, q)\n","            loss = kl_vector.mean()\n","\n","            loss.backward() # 誤差逆伝播法により勾配を得る\n","            optimizer.step() # 重みを更新する\n","\n","            if scheduler:\n","                scheduler.step() # schedulerが与えられた場合は、schedulerの学習率更新\n","            \n","            if step >= last_eval_step + eval_period: # batchを回すごとにstepを増やしていって、「前回evalしたstep + eval_period(16)」を超えたら実行。\n","                # Evaluate the model on val_loader.\n","                elapsed_seconds = time.time() - start # 経過時間\n","                num_steps = step - last_eval_step # 経過ステップ数\n","                print(f\"\\n{num_steps} steps took {elapsed_seconds:0.3} seconds\")\n","                last_eval_step = step # 前回stepの更新\n","                \n","                # valid-setによるrmse計算\n","                val_mean_mse, val_std_mse = eval_mse(model, val_loader)\n","                val_mean_rmse = math.sqrt(val_mean_mse)                            \n","                val_std_rmse = math.sqrt(val_std_mse)                            \n","\n","                print(f\"Epoch: {epoch} batch_num: {batch_num}\", \n","                      f\"val_rmse_target: {val_mean_rmse:0.4}\",\n","                      f\"val_rmse_stderror: {val_std_rmse:0.4}\"\n","                      )\n","\n","                for rmse, period in EVAL_SCHEDULE: # eval_periodをvalid-rmseで切り替える処理\n","                    if val_mean_rmse >= rmse: # valid rmseをEVAL_SCHEDULEと比較し、0項 > valid rmseとなるまで回す : EVAL_SCHEDULE = [(0.50, 16), (0.49, 8), (0.48, 4), (0.47, 2), (-1., 1)]\n","                        eval_period = period # eval_periodを更新\n","                        break                               \n","\n","                if not best_val_rmse or val_mean_rmse < best_val_rmse: # 初回(best_val_rmse==None), またはbest_val_rmseを更新したらモデルを保存する\n","                    best_val_rmse = val_mean_rmse\n","                    best_epoch = epoch\n","                    torch.save(model.state_dict(), model_path) # 最高の自分を保存\n","                    print(f\"New best_val_rmse: {best_val_rmse:0.4}\")\n","                else:       \n","                    print(f\"Still best_val_rmse: {best_val_rmse:0.4}\", # 更新されない場合は、元のスコアを表示\n","                          f\"(from epoch {best_epoch})\")      \n","                                                  \n","                start = time.time()\n","            \n","            # batchごとにメモリ解放\n","            #print(f'train_{epoch}_{batch_num}: free_memory: Start', gpuinfo())                  \n","            del input_ids\n","            del attention_mask\n","            #del target\n","            torch.cuda.empty_cache()\n","            #print(f'train_{epoch}_{batch_num}: free_memory: Done', gpuinfo())  \n","                                            \n","            step += 1\n","    \n","    return best_val_rmse"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.735798Z","iopub.execute_input":"2021-07-04T06:26:40.738398Z","iopub.status.idle":"2021-07-04T06:26:40.750876Z","shell.execute_reply.started":"2021-07-04T06:26:40.738356Z","shell.execute_reply":"2021-07-04T06:26:40.749635Z"},"trusted":true,"id":"rMY0fjXwXecJ"},"source":["# optimizerの作成\n","def create_optimizer(model):\n","    named_parameters = list(model.named_parameters()) # モデルパラメータの取得\n","    \n","    roberta_parameters = list(model.roberta.named_parameters())[:-2] # パラメータをroberta用、attention用、regressor用に格納。(直接引っ張ってくる形式に変更)\n","    attention_parameters = list(model.attention.named_parameters())\n","    regressor_parameters = list(model.regressor.named_parameters())\n","        \n","    attention_group = [params for (name, params) in attention_parameters] # attention用パラメータをリストとして取得\n","    regressor_group = [params for (name, params) in regressor_parameters] # reg用パラメータをリストとして取得\n","\n","    parameters = []\n","    #parameters.append({\"params\": attention_group}) # パラメータをリストに辞書として格納していく\n","    parameters.append({\"params\": regressor_group})\n","\n","    for layer_num, (name, params) in enumerate(roberta_parameters): # レイヤーごとにname, paramsを取得していろんな処理\n","        weight_decay = 0.0 if \"bias\" in name else 0.01\n","\n","        lr = 2e-5\n","\n","        if layer_num >= 69:        \n","            lr = 5e-5\n","\n","        if layer_num >= 133:\n","            lr = 1e-4\n","\n","        parameters.append({\"params\": params,\n","                           \"weight_decay\": weight_decay,\n","                           \"lr\": lr})\n","\n","    return AdamW(parameters) # 最終的に、AdamWにパラメータを入力する。\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EbaJojz0Zjif"},"source":["# https://www.kaggle.com/abhishek/step-1-create-folds\n","def create_folds(data, num_splits):\n","    # we create a new column called kfold and fill it with -1\n","    data[\"kfold\"] = -1\n","    \n","    # the next step is to randomize the rows of the data\n","    data = data.sample(frac=1).reset_index(drop=True)\n","\n","    # calculate number of bins by Sturge's rule\n","    # I take the floor of the value, you can also\n","    # just round it\n","    num_bins = int(np.floor(1 + np.log2(len(data))))\n","    \n","    # bin targets\n","    data.loc[:, \"bins\"] = pd.cut(\n","        data[\"target\"], bins=num_bins, labels=False\n","    )\n","    \n","    # initiate the kfold class from model_selection module\n","    kf = StratifiedKFold(n_splits=num_splits)\n","    \n","    # note that, instead of targets, we use bins!\n","    return kf.split(X=data, y=data.bins.values)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ky_W8QP_aDWc"},"source":["st_kfold_bins = create_folds(train_df, num_splits=5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.755813Z","iopub.execute_input":"2021-07-04T06:26:40.758373Z","iopub.status.idle":"2021-07-04T06:27:12.493221Z","shell.execute_reply.started":"2021-07-04T06:26:40.758265Z","shell.execute_reply":"2021-07-04T06:27:12.490139Z"},"trusted":true,"id":"k2LGJD3XXecK","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["fa4f3a80ea0847fca278e4e0fc258963","1e0e53f0f6f04906b168adc6e9459f41","28ab2e98d2484468bba6cde8104e517e","c90a522776434b99b9c6009a2ab7d426","bdb44edaa82b4690bef9dbf8201da115","0f19863a85f543b7b999544a2d5ac145","1af94c95b09f4a039ab54628d789ed2f","6e5d3b8ddfc940ac89602d7b3771492b"]},"executionInfo":{"status":"ok","timestamp":1626322873336,"user_tz":-540,"elapsed":5173724,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"4c9a731e-d9d1-409e-fcfd-4ab69d3c635d"},"source":["# 実行処理。 KFold & 学習\n","gc.collect()\n","\n","SEED = 1000\n","list_val_rmse = []\n","\n","kfold = KFold(n_splits=NUM_FOLDS, random_state=SEED, shuffle=True)\n","\n","for fold, (train_indices, val_indices) in enumerate(st_kfold_bins):    \n","    print(f\"\\nFold {fold + 1}/{NUM_FOLDS}\")\n","    model_path = f\"model_{fold + 1}.pth\" # model_fold数_.pth\n","        \n","    set_random_seed(SEED + fold) # SEEDはfold別に変わるようにする\n","    \n","    train_dataset = LitDataset(train_df.loc[train_indices]) # train, validのDataset\n","    val_dataset = LitDataset(train_df.loc[val_indices])\n","        \n","    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n","                              drop_last=True, shuffle=True, num_workers=2) # train, validのDataLoader\n","    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n","                            drop_last=False, shuffle=False, num_workers=2)    \n","        \n","    set_random_seed(SEED + fold) # なんで二回SEEDをセットするのだろう？\n","\n","    #print('getmodel: Start', gpuinfo())                 \n","    model = LitModel().to(DEVICE) # modelをDEVICEへぶち込む\n","    #print('getmodel: Done', gpuinfo())                 \n","\n","    #print('get_optim_sched: Start', gpuinfo())                 \n","    optimizer = create_optimizer(model) # optimizerをモデルから作成\n","    scheduler = get_cosine_schedule_with_warmup( # schedulerを作成\n","        optimizer,\n","        num_training_steps=NUM_EPOCHS * len(train_loader),\n","        num_warmup_steps=50)    \n","    #print('get_optim_sched: Done', gpuinfo())                 \n","\n","    list_val_rmse.append(train(model, model_path, train_loader,\n","                               val_loader, optimizer, scheduler=scheduler)) # 学習開始し、val_rmseのリストを格納\n","\n","    del model # モデルは保存したので、消す\n","    gc.collect() \n","    \n","    print(\"\\nPerformance estimates:\")\n","    print(list_val_rmse)\n","    print(\"Mean:\", np.array(list_val_rmse).mean())\n","    "],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Fold 1/5\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fa4f3a80ea0847fca278e4e0fc258963","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=501200538.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"stream","text":["\n","16 steps took 9.58 seconds\n","Epoch: 0 batch_num: 16 val_rmse_target: 0.9146 val_rmse_stderror: 0.9014\n","New best_val_rmse: 0.9146\n","\n","16 steps took 8.99 seconds\n","Epoch: 0 batch_num: 32 val_rmse_target: 0.8509 val_rmse_stderror: 0.9821\n","New best_val_rmse: 0.8509\n","\n","16 steps took 9.0 seconds\n","Epoch: 0 batch_num: 48 val_rmse_target: 0.762 val_rmse_stderror: 0.979\n","New best_val_rmse: 0.762\n","\n","16 steps took 8.99 seconds\n","Epoch: 0 batch_num: 64 val_rmse_target: 0.6812 val_rmse_stderror: 0.9638\n","New best_val_rmse: 0.6812\n","\n","16 steps took 9.0 seconds\n","Epoch: 0 batch_num: 80 val_rmse_target: 0.6482 val_rmse_stderror: 0.9718\n","New best_val_rmse: 0.6482\n","\n","16 steps took 9.0 seconds\n","Epoch: 0 batch_num: 96 val_rmse_target: 0.605 val_rmse_stderror: 0.9796\n","New best_val_rmse: 0.605\n","\n","16 steps took 9.0 seconds\n","Epoch: 0 batch_num: 112 val_rmse_target: 0.5601 val_rmse_stderror: 0.9732\n","New best_val_rmse: 0.5601\n","\n","16 steps took 9.0 seconds\n","Epoch: 0 batch_num: 128 val_rmse_target: 0.6753 val_rmse_stderror: 0.9798\n","Still best_val_rmse: 0.5601 (from epoch 0)\n","\n","16 steps took 9.11 seconds\n","Epoch: 1 batch_num: 3 val_rmse_target: 0.5573 val_rmse_stderror: 0.9759\n","New best_val_rmse: 0.5573\n","\n","16 steps took 8.99 seconds\n","Epoch: 1 batch_num: 19 val_rmse_target: 0.5856 val_rmse_stderror: 0.9653\n","Still best_val_rmse: 0.5573 (from epoch 1)\n","\n","16 steps took 8.99 seconds\n","Epoch: 1 batch_num: 35 val_rmse_target: 0.5403 val_rmse_stderror: 0.9892\n","New best_val_rmse: 0.5403\n","\n","16 steps took 9.0 seconds\n","Epoch: 1 batch_num: 51 val_rmse_target: 0.5417 val_rmse_stderror: 0.9787\n","Still best_val_rmse: 0.5403 (from epoch 1)\n","\n","16 steps took 8.99 seconds\n","Epoch: 1 batch_num: 67 val_rmse_target: 0.5441 val_rmse_stderror: 0.9856\n","Still best_val_rmse: 0.5403 (from epoch 1)\n","\n","16 steps took 8.99 seconds\n","Epoch: 1 batch_num: 83 val_rmse_target: 0.5503 val_rmse_stderror: 0.9856\n","Still best_val_rmse: 0.5403 (from epoch 1)\n","\n","16 steps took 8.99 seconds\n","Epoch: 1 batch_num: 99 val_rmse_target: 0.5189 val_rmse_stderror: 0.9727\n","New best_val_rmse: 0.5189\n","\n","16 steps took 9.0 seconds\n","Epoch: 1 batch_num: 115 val_rmse_target: 0.4861 val_rmse_stderror: 0.9714\n","New best_val_rmse: 0.4861\n","\n","4 steps took 2.25 seconds\n","Epoch: 1 batch_num: 119 val_rmse_target: 0.5019 val_rmse_stderror: 0.9688\n","Still best_val_rmse: 0.4861 (from epoch 1)\n","\n","16 steps took 8.99 seconds\n","Epoch: 1 batch_num: 135 val_rmse_target: 0.5168 val_rmse_stderror: 0.9819\n","Still best_val_rmse: 0.4861 (from epoch 1)\n","\n","16 steps took 9.11 seconds\n","Epoch: 2 batch_num: 10 val_rmse_target: 0.4871 val_rmse_stderror: 0.9789\n","Still best_val_rmse: 0.4861 (from epoch 1)\n","\n","4 steps took 2.25 seconds\n","Epoch: 2 batch_num: 14 val_rmse_target: 0.4735 val_rmse_stderror: 0.9816\n","New best_val_rmse: 0.4735\n","\n","2 steps took 1.12 seconds\n","Epoch: 2 batch_num: 16 val_rmse_target: 0.4789 val_rmse_stderror: 0.9812\n","Still best_val_rmse: 0.4735 (from epoch 2)\n","\n","2 steps took 1.12 seconds\n","Epoch: 2 batch_num: 18 val_rmse_target: 0.4716 val_rmse_stderror: 0.9769\n","New best_val_rmse: 0.4716\n","\n","2 steps took 1.12 seconds\n","Epoch: 2 batch_num: 20 val_rmse_target: 0.4785 val_rmse_stderror: 0.972\n","Still best_val_rmse: 0.4716 (from epoch 2)\n","\n","2 steps took 1.12 seconds\n","Epoch: 2 batch_num: 22 val_rmse_target: 0.4849 val_rmse_stderror: 0.9697\n","Still best_val_rmse: 0.4716 (from epoch 2)\n","\n","4 steps took 2.24 seconds\n","Epoch: 2 batch_num: 26 val_rmse_target: 0.5061 val_rmse_stderror: 0.9754\n","Still best_val_rmse: 0.4716 (from epoch 2)\n","\n","16 steps took 8.99 seconds\n","Epoch: 2 batch_num: 42 val_rmse_target: 0.4887 val_rmse_stderror: 0.9812\n","Still best_val_rmse: 0.4716 (from epoch 2)\n","\n","4 steps took 2.24 seconds\n","Epoch: 2 batch_num: 46 val_rmse_target: 0.4747 val_rmse_stderror: 0.9766\n","Still best_val_rmse: 0.4716 (from epoch 2)\n","\n","2 steps took 1.12 seconds\n","Epoch: 2 batch_num: 48 val_rmse_target: 0.4735 val_rmse_stderror: 0.9738\n","Still best_val_rmse: 0.4716 (from epoch 2)\n","\n","2 steps took 1.12 seconds\n","Epoch: 2 batch_num: 50 val_rmse_target: 0.4761 val_rmse_stderror: 0.9739\n","Still best_val_rmse: 0.4716 (from epoch 2)\n","\n","2 steps took 1.12 seconds\n","Epoch: 2 batch_num: 52 val_rmse_target: 0.4737 val_rmse_stderror: 0.9744\n","Still best_val_rmse: 0.4716 (from epoch 2)\n","\n","2 steps took 1.12 seconds\n","Epoch: 2 batch_num: 54 val_rmse_target: 0.4736 val_rmse_stderror: 0.9757\n","Still best_val_rmse: 0.4716 (from epoch 2)\n","\n","2 steps took 1.12 seconds\n","Epoch: 2 batch_num: 56 val_rmse_target: 0.4913 val_rmse_stderror: 0.98\n","Still best_val_rmse: 0.4716 (from epoch 2)\n","\n","8 steps took 4.49 seconds\n","Epoch: 2 batch_num: 64 val_rmse_target: 0.488 val_rmse_stderror: 0.982\n","Still best_val_rmse: 0.4716 (from epoch 2)\n","\n","4 steps took 2.24 seconds\n","Epoch: 2 batch_num: 68 val_rmse_target: 0.508 val_rmse_stderror: 0.9844\n","Still best_val_rmse: 0.4716 (from epoch 2)\n","\n","16 steps took 8.99 seconds\n","Epoch: 2 batch_num: 84 val_rmse_target: 0.5038 val_rmse_stderror: 0.9828\n","Still best_val_rmse: 0.4716 (from epoch 2)\n","\n","16 steps took 8.99 seconds\n","Epoch: 2 batch_num: 100 val_rmse_target: 0.4941 val_rmse_stderror: 0.9871\n","Still best_val_rmse: 0.4716 (from epoch 2)\n","\n","8 steps took 4.5 seconds\n","Epoch: 2 batch_num: 108 val_rmse_target: 0.4832 val_rmse_stderror: 0.984\n","Still best_val_rmse: 0.4716 (from epoch 2)\n","\n","4 steps took 2.24 seconds\n","Epoch: 2 batch_num: 112 val_rmse_target: 0.4833 val_rmse_stderror: 0.9828\n","Still best_val_rmse: 0.4716 (from epoch 2)\n","\n","4 steps took 2.25 seconds\n","Epoch: 2 batch_num: 116 val_rmse_target: 0.4919 val_rmse_stderror: 0.9794\n","Still best_val_rmse: 0.4716 (from epoch 2)\n","\n","8 steps took 4.5 seconds\n","Epoch: 2 batch_num: 124 val_rmse_target: 0.5034 val_rmse_stderror: 0.9695\n","Still best_val_rmse: 0.4716 (from epoch 2)\n","\n","16 steps took 8.98 seconds\n","Epoch: 2 batch_num: 140 val_rmse_target: 0.4811 val_rmse_stderror: 0.9831\n","Still best_val_rmse: 0.4716 (from epoch 2)\n","\n","4 steps took 2.37 seconds\n","Epoch: 3 batch_num: 3 val_rmse_target: 0.475 val_rmse_stderror: 0.9854\n","Still best_val_rmse: 0.4716 (from epoch 2)\n","\n","2 steps took 1.12 seconds\n","Epoch: 3 batch_num: 5 val_rmse_target: 0.4762 val_rmse_stderror: 0.9866\n","Still best_val_rmse: 0.4716 (from epoch 2)\n","\n","2 steps took 1.12 seconds\n","Epoch: 3 batch_num: 7 val_rmse_target: 0.4727 val_rmse_stderror: 0.986\n","Still best_val_rmse: 0.4716 (from epoch 2)\n","\n","2 steps took 1.12 seconds\n","Epoch: 3 batch_num: 9 val_rmse_target: 0.4715 val_rmse_stderror: 0.985\n","New best_val_rmse: 0.4715\n","\n","2 steps took 1.13 seconds\n","Epoch: 3 batch_num: 11 val_rmse_target: 0.4745 val_rmse_stderror: 0.9843\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 3 batch_num: 13 val_rmse_target: 0.4821 val_rmse_stderror: 0.9833\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","4 steps took 2.25 seconds\n","Epoch: 3 batch_num: 17 val_rmse_target: 0.4867 val_rmse_stderror: 0.9782\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","4 steps took 2.24 seconds\n","Epoch: 3 batch_num: 21 val_rmse_target: 0.4911 val_rmse_stderror: 0.9775\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","8 steps took 4.5 seconds\n","Epoch: 3 batch_num: 29 val_rmse_target: 0.4832 val_rmse_stderror: 0.9836\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","4 steps took 2.24 seconds\n","Epoch: 3 batch_num: 33 val_rmse_target: 0.4784 val_rmse_stderror: 0.9833\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 3 batch_num: 35 val_rmse_target: 0.4879 val_rmse_stderror: 0.9845\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","4 steps took 2.24 seconds\n","Epoch: 3 batch_num: 39 val_rmse_target: 0.4827 val_rmse_stderror: 0.9827\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","4 steps took 2.24 seconds\n","Epoch: 3 batch_num: 43 val_rmse_target: 0.4783 val_rmse_stderror: 0.981\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 3 batch_num: 45 val_rmse_target: 0.4859 val_rmse_stderror: 0.9824\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","4 steps took 2.24 seconds\n","Epoch: 3 batch_num: 49 val_rmse_target: 0.4777 val_rmse_stderror: 0.9822\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 3 batch_num: 51 val_rmse_target: 0.4772 val_rmse_stderror: 0.982\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 3 batch_num: 53 val_rmse_target: 0.4783 val_rmse_stderror: 0.9821\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 3 batch_num: 55 val_rmse_target: 0.4821 val_rmse_stderror: 0.9832\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","4 steps took 2.25 seconds\n","Epoch: 3 batch_num: 59 val_rmse_target: 0.4798 val_rmse_stderror: 0.9845\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 3 batch_num: 61 val_rmse_target: 0.4792 val_rmse_stderror: 0.9848\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 3 batch_num: 63 val_rmse_target: 0.4772 val_rmse_stderror: 0.9846\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 3 batch_num: 65 val_rmse_target: 0.4745 val_rmse_stderror: 0.9836\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 3 batch_num: 67 val_rmse_target: 0.4743 val_rmse_stderror: 0.9831\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 3 batch_num: 69 val_rmse_target: 0.4746 val_rmse_stderror: 0.983\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 3 batch_num: 71 val_rmse_target: 0.4774 val_rmse_stderror: 0.9845\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 3 batch_num: 73 val_rmse_target: 0.4809 val_rmse_stderror: 0.9851\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","4 steps took 2.24 seconds\n","Epoch: 3 batch_num: 77 val_rmse_target: 0.4865 val_rmse_stderror: 0.9845\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","4 steps took 2.24 seconds\n","Epoch: 3 batch_num: 81 val_rmse_target: 0.4826 val_rmse_stderror: 0.9822\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","4 steps took 2.24 seconds\n","Epoch: 3 batch_num: 85 val_rmse_target: 0.4829 val_rmse_stderror: 0.9819\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","4 steps took 2.24 seconds\n","Epoch: 3 batch_num: 89 val_rmse_target: 0.4849 val_rmse_stderror: 0.981\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","4 steps took 2.24 seconds\n","Epoch: 3 batch_num: 93 val_rmse_target: 0.4865 val_rmse_stderror: 0.9827\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","4 steps took 2.25 seconds\n","Epoch: 3 batch_num: 97 val_rmse_target: 0.4869 val_rmse_stderror: 0.9825\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","4 steps took 2.24 seconds\n","Epoch: 3 batch_num: 101 val_rmse_target: 0.481 val_rmse_stderror: 0.9816\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","4 steps took 2.24 seconds\n","Epoch: 3 batch_num: 105 val_rmse_target: 0.4786 val_rmse_stderror: 0.9811\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 3 batch_num: 107 val_rmse_target: 0.4775 val_rmse_stderror: 0.9814\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 3 batch_num: 109 val_rmse_target: 0.4776 val_rmse_stderror: 0.9815\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 3 batch_num: 111 val_rmse_target: 0.4812 val_rmse_stderror: 0.982\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","4 steps took 2.24 seconds\n","Epoch: 3 batch_num: 115 val_rmse_target: 0.4796 val_rmse_stderror: 0.982\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 3 batch_num: 117 val_rmse_target: 0.4766 val_rmse_stderror: 0.982\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 3 batch_num: 119 val_rmse_target: 0.4755 val_rmse_stderror: 0.9822\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 3 batch_num: 121 val_rmse_target: 0.4752 val_rmse_stderror: 0.9826\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 3 batch_num: 123 val_rmse_target: 0.4755 val_rmse_stderror: 0.9826\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 3 batch_num: 125 val_rmse_target: 0.4772 val_rmse_stderror: 0.9829\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 3 batch_num: 127 val_rmse_target: 0.4783 val_rmse_stderror: 0.983\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 3 batch_num: 129 val_rmse_target: 0.4785 val_rmse_stderror: 0.9827\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 3 batch_num: 131 val_rmse_target: 0.4774 val_rmse_stderror: 0.9823\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 3 batch_num: 133 val_rmse_target: 0.4779 val_rmse_stderror: 0.9824\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 3 batch_num: 135 val_rmse_target: 0.4803 val_rmse_stderror: 0.9826\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","4 steps took 2.24 seconds\n","Epoch: 3 batch_num: 139 val_rmse_target: 0.4812 val_rmse_stderror: 0.9824\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","4 steps took 2.37 seconds\n","Epoch: 4 batch_num: 2 val_rmse_target: 0.476 val_rmse_stderror: 0.9811\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 4 val_rmse_target: 0.4746 val_rmse_stderror: 0.9803\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 6 val_rmse_target: 0.4741 val_rmse_stderror: 0.98\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 8 val_rmse_target: 0.4745 val_rmse_stderror: 0.9799\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 10 val_rmse_target: 0.4753 val_rmse_stderror: 0.9797\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 12 val_rmse_target: 0.4755 val_rmse_stderror: 0.9793\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 14 val_rmse_target: 0.4763 val_rmse_stderror: 0.9787\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 16 val_rmse_target: 0.4778 val_rmse_stderror: 0.9784\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.13 seconds\n","Epoch: 4 batch_num: 18 val_rmse_target: 0.4789 val_rmse_stderror: 0.9783\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 20 val_rmse_target: 0.4804 val_rmse_stderror: 0.9785\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","4 steps took 2.24 seconds\n","Epoch: 4 batch_num: 24 val_rmse_target: 0.485 val_rmse_stderror: 0.9797\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","4 steps took 2.25 seconds\n","Epoch: 4 batch_num: 28 val_rmse_target: 0.4821 val_rmse_stderror: 0.9803\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","4 steps took 2.24 seconds\n","Epoch: 4 batch_num: 32 val_rmse_target: 0.4795 val_rmse_stderror: 0.9809\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 34 val_rmse_target: 0.4794 val_rmse_stderror: 0.9815\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 36 val_rmse_target: 0.4793 val_rmse_stderror: 0.9821\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 38 val_rmse_target: 0.4796 val_rmse_stderror: 0.9828\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 40 val_rmse_target: 0.4789 val_rmse_stderror: 0.9831\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 42 val_rmse_target: 0.4777 val_rmse_stderror: 0.9832\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 44 val_rmse_target: 0.4772 val_rmse_stderror: 0.9832\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 46 val_rmse_target: 0.4773 val_rmse_stderror: 0.9833\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 48 val_rmse_target: 0.4781 val_rmse_stderror: 0.9835\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 50 val_rmse_target: 0.4796 val_rmse_stderror: 0.9839\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 52 val_rmse_target: 0.4813 val_rmse_stderror: 0.9841\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","4 steps took 2.25 seconds\n","Epoch: 4 batch_num: 56 val_rmse_target: 0.4813 val_rmse_stderror: 0.9838\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","4 steps took 2.24 seconds\n","Epoch: 4 batch_num: 60 val_rmse_target: 0.4816 val_rmse_stderror: 0.9835\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","4 steps took 2.24 seconds\n","Epoch: 4 batch_num: 64 val_rmse_target: 0.4816 val_rmse_stderror: 0.9832\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","4 steps took 2.24 seconds\n","Epoch: 4 batch_num: 68 val_rmse_target: 0.4809 val_rmse_stderror: 0.9829\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","4 steps took 2.24 seconds\n","Epoch: 4 batch_num: 72 val_rmse_target: 0.4791 val_rmse_stderror: 0.9824\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 74 val_rmse_target: 0.4786 val_rmse_stderror: 0.9823\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 76 val_rmse_target: 0.478 val_rmse_stderror: 0.9822\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 78 val_rmse_target: 0.4779 val_rmse_stderror: 0.9822\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 80 val_rmse_target: 0.4777 val_rmse_stderror: 0.9822\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 82 val_rmse_target: 0.4777 val_rmse_stderror: 0.9822\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 84 val_rmse_target: 0.4777 val_rmse_stderror: 0.9822\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 86 val_rmse_target: 0.4775 val_rmse_stderror: 0.9822\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 88 val_rmse_target: 0.4774 val_rmse_stderror: 0.9823\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 90 val_rmse_target: 0.4774 val_rmse_stderror: 0.9824\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 92 val_rmse_target: 0.4774 val_rmse_stderror: 0.9824\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 94 val_rmse_target: 0.4772 val_rmse_stderror: 0.9824\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 96 val_rmse_target: 0.4772 val_rmse_stderror: 0.9825\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.13 seconds\n","Epoch: 4 batch_num: 98 val_rmse_target: 0.4771 val_rmse_stderror: 0.9825\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 100 val_rmse_target: 0.477 val_rmse_stderror: 0.9825\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 102 val_rmse_target: 0.4771 val_rmse_stderror: 0.9825\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 104 val_rmse_target: 0.4772 val_rmse_stderror: 0.9826\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 106 val_rmse_target: 0.4773 val_rmse_stderror: 0.9826\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 108 val_rmse_target: 0.4775 val_rmse_stderror: 0.9826\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 110 val_rmse_target: 0.4776 val_rmse_stderror: 0.9826\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 112 val_rmse_target: 0.4778 val_rmse_stderror: 0.9826\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 114 val_rmse_target: 0.4779 val_rmse_stderror: 0.9826\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 116 val_rmse_target: 0.4779 val_rmse_stderror: 0.9826\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 118 val_rmse_target: 0.4779 val_rmse_stderror: 0.9826\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 120 val_rmse_target: 0.4779 val_rmse_stderror: 0.9826\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 122 val_rmse_target: 0.4779 val_rmse_stderror: 0.9826\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 124 val_rmse_target: 0.4778 val_rmse_stderror: 0.9826\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 126 val_rmse_target: 0.4778 val_rmse_stderror: 0.9826\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 128 val_rmse_target: 0.4778 val_rmse_stderror: 0.9826\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 130 val_rmse_target: 0.4778 val_rmse_stderror: 0.9826\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 132 val_rmse_target: 0.4778 val_rmse_stderror: 0.9826\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 134 val_rmse_target: 0.4778 val_rmse_stderror: 0.9826\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 136 val_rmse_target: 0.4778 val_rmse_stderror: 0.9826\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 138 val_rmse_target: 0.4778 val_rmse_stderror: 0.9826\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","2 steps took 1.12 seconds\n","Epoch: 4 batch_num: 140 val_rmse_target: 0.4778 val_rmse_stderror: 0.9826\n","Still best_val_rmse: 0.4715 (from epoch 3)\n","\n","Performance estimates:\n","[0.4715036928208487]\n","Mean: 0.4715036928208487\n","\n","Fold 2/5\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"stream","text":["\n","16 steps took 9.17 seconds\n","Epoch: 0 batch_num: 16 val_rmse_target: 1.18 val_rmse_stderror: 1.039\n","New best_val_rmse: 1.18\n","\n","16 steps took 8.7 seconds\n","Epoch: 0 batch_num: 32 val_rmse_target: 1.037 val_rmse_stderror: 0.9823\n","New best_val_rmse: 1.037\n","\n","16 steps took 8.69 seconds\n","Epoch: 0 batch_num: 48 val_rmse_target: 0.7729 val_rmse_stderror: 0.9647\n","New best_val_rmse: 0.7729\n","\n","16 steps took 8.69 seconds\n","Epoch: 0 batch_num: 64 val_rmse_target: 0.6309 val_rmse_stderror: 0.9522\n","New best_val_rmse: 0.6309\n","\n","16 steps took 8.69 seconds\n","Epoch: 0 batch_num: 80 val_rmse_target: 0.5838 val_rmse_stderror: 0.9791\n","New best_val_rmse: 0.5838\n","\n","16 steps took 8.68 seconds\n","Epoch: 0 batch_num: 96 val_rmse_target: 0.6214 val_rmse_stderror: 0.9777\n","Still best_val_rmse: 0.5838 (from epoch 0)\n","\n","16 steps took 8.68 seconds\n","Epoch: 0 batch_num: 112 val_rmse_target: 0.5761 val_rmse_stderror: 0.987\n","New best_val_rmse: 0.5761\n","\n","16 steps took 8.69 seconds\n","Epoch: 0 batch_num: 128 val_rmse_target: 0.5713 val_rmse_stderror: 0.9885\n","New best_val_rmse: 0.5713\n","\n","16 steps took 8.81 seconds\n","Epoch: 1 batch_num: 3 val_rmse_target: 0.5695 val_rmse_stderror: 0.9609\n","New best_val_rmse: 0.5695\n","\n","16 steps took 8.69 seconds\n","Epoch: 1 batch_num: 19 val_rmse_target: 0.6537 val_rmse_stderror: 0.9819\n","Still best_val_rmse: 0.5695 (from epoch 1)\n","\n","16 steps took 8.69 seconds\n","Epoch: 1 batch_num: 35 val_rmse_target: 0.5441 val_rmse_stderror: 0.9818\n","New best_val_rmse: 0.5441\n","\n","16 steps took 8.69 seconds\n","Epoch: 1 batch_num: 51 val_rmse_target: 0.5251 val_rmse_stderror: 0.9874\n","New best_val_rmse: 0.5251\n","\n","16 steps took 8.7 seconds\n","Epoch: 1 batch_num: 67 val_rmse_target: 0.5428 val_rmse_stderror: 0.9829\n","Still best_val_rmse: 0.5251 (from epoch 1)\n","\n","16 steps took 8.69 seconds\n","Epoch: 1 batch_num: 83 val_rmse_target: 0.5651 val_rmse_stderror: 0.9796\n","Still best_val_rmse: 0.5251 (from epoch 1)\n","\n","16 steps took 8.7 seconds\n","Epoch: 1 batch_num: 99 val_rmse_target: 0.5186 val_rmse_stderror: 0.983\n","New best_val_rmse: 0.5186\n","\n","16 steps took 8.7 seconds\n","Epoch: 1 batch_num: 115 val_rmse_target: 0.541 val_rmse_stderror: 0.9739\n","Still best_val_rmse: 0.5186 (from epoch 1)\n","\n","16 steps took 8.69 seconds\n","Epoch: 1 batch_num: 131 val_rmse_target: 0.5311 val_rmse_stderror: 0.9869\n","Still best_val_rmse: 0.5186 (from epoch 1)\n","\n","16 steps took 8.82 seconds\n","Epoch: 2 batch_num: 6 val_rmse_target: 0.511 val_rmse_stderror: 0.9841\n","New best_val_rmse: 0.511\n","\n","16 steps took 8.69 seconds\n","Epoch: 2 batch_num: 22 val_rmse_target: 0.5389 val_rmse_stderror: 0.9809\n","Still best_val_rmse: 0.511 (from epoch 2)\n","\n","16 steps took 8.69 seconds\n","Epoch: 2 batch_num: 38 val_rmse_target: 0.4988 val_rmse_stderror: 0.982\n","New best_val_rmse: 0.4988\n","\n","8 steps took 4.34 seconds\n","Epoch: 2 batch_num: 46 val_rmse_target: 0.5224 val_rmse_stderror: 0.9812\n","Still best_val_rmse: 0.4988 (from epoch 2)\n","\n","16 steps took 8.69 seconds\n","Epoch: 2 batch_num: 62 val_rmse_target: 0.5778 val_rmse_stderror: 0.9912\n","Still best_val_rmse: 0.4988 (from epoch 2)\n","\n","16 steps took 8.69 seconds\n","Epoch: 2 batch_num: 78 val_rmse_target: 0.5188 val_rmse_stderror: 0.9824\n","Still best_val_rmse: 0.4988 (from epoch 2)\n","\n","16 steps took 8.69 seconds\n","Epoch: 2 batch_num: 94 val_rmse_target: 0.5727 val_rmse_stderror: 0.9872\n","Still best_val_rmse: 0.4988 (from epoch 2)\n","\n","16 steps took 8.69 seconds\n","Epoch: 2 batch_num: 110 val_rmse_target: 0.5318 val_rmse_stderror: 0.9856\n","Still best_val_rmse: 0.4988 (from epoch 2)\n","\n","16 steps took 8.69 seconds\n","Epoch: 2 batch_num: 126 val_rmse_target: 0.5567 val_rmse_stderror: 0.9962\n","Still best_val_rmse: 0.4988 (from epoch 2)\n","\n","16 steps took 8.82 seconds\n","Epoch: 3 batch_num: 1 val_rmse_target: 0.504 val_rmse_stderror: 0.9781\n","Still best_val_rmse: 0.4988 (from epoch 2)\n","\n","16 steps took 8.69 seconds\n","Epoch: 3 batch_num: 17 val_rmse_target: 0.5043 val_rmse_stderror: 0.9846\n","Still best_val_rmse: 0.4988 (from epoch 2)\n","\n","16 steps took 8.69 seconds\n","Epoch: 3 batch_num: 33 val_rmse_target: 0.5024 val_rmse_stderror: 0.9841\n","Still best_val_rmse: 0.4988 (from epoch 2)\n","\n","16 steps took 8.68 seconds\n","Epoch: 3 batch_num: 49 val_rmse_target: 0.4993 val_rmse_stderror: 0.9825\n","Still best_val_rmse: 0.4988 (from epoch 2)\n","\n","8 steps took 4.34 seconds\n","Epoch: 3 batch_num: 57 val_rmse_target: 0.5171 val_rmse_stderror: 0.9801\n","Still best_val_rmse: 0.4988 (from epoch 2)\n","\n","16 steps took 8.69 seconds\n","Epoch: 3 batch_num: 73 val_rmse_target: 0.5047 val_rmse_stderror: 0.9875\n","Still best_val_rmse: 0.4988 (from epoch 2)\n","\n","16 steps took 8.69 seconds\n","Epoch: 3 batch_num: 89 val_rmse_target: 0.501 val_rmse_stderror: 0.9844\n","Still best_val_rmse: 0.4988 (from epoch 2)\n","\n","16 steps took 8.69 seconds\n","Epoch: 3 batch_num: 105 val_rmse_target: 0.4986 val_rmse_stderror: 0.9854\n","New best_val_rmse: 0.4986\n","\n","8 steps took 4.34 seconds\n","Epoch: 3 batch_num: 113 val_rmse_target: 0.5165 val_rmse_stderror: 0.9871\n","Still best_val_rmse: 0.4986 (from epoch 3)\n","\n","16 steps took 8.68 seconds\n","Epoch: 3 batch_num: 129 val_rmse_target: 0.5115 val_rmse_stderror: 0.9835\n","Still best_val_rmse: 0.4986 (from epoch 3)\n","\n","16 steps took 8.82 seconds\n","Epoch: 4 batch_num: 4 val_rmse_target: 0.5031 val_rmse_stderror: 0.9849\n","Still best_val_rmse: 0.4986 (from epoch 3)\n","\n","16 steps took 8.68 seconds\n","Epoch: 4 batch_num: 20 val_rmse_target: 0.5011 val_rmse_stderror: 0.9841\n","Still best_val_rmse: 0.4986 (from epoch 3)\n","\n","16 steps took 8.69 seconds\n","Epoch: 4 batch_num: 36 val_rmse_target: 0.5044 val_rmse_stderror: 0.9861\n","Still best_val_rmse: 0.4986 (from epoch 3)\n","\n","16 steps took 8.69 seconds\n","Epoch: 4 batch_num: 52 val_rmse_target: 0.5031 val_rmse_stderror: 0.986\n","Still best_val_rmse: 0.4986 (from epoch 3)\n","\n","16 steps took 8.69 seconds\n","Epoch: 4 batch_num: 68 val_rmse_target: 0.503 val_rmse_stderror: 0.9858\n","Still best_val_rmse: 0.4986 (from epoch 3)\n","\n","16 steps took 8.71 seconds\n","Epoch: 4 batch_num: 84 val_rmse_target: 0.4997 val_rmse_stderror: 0.9855\n","Still best_val_rmse: 0.4986 (from epoch 3)\n","\n","8 steps took 4.34 seconds\n","Epoch: 4 batch_num: 92 val_rmse_target: 0.5 val_rmse_stderror: 0.9857\n","Still best_val_rmse: 0.4986 (from epoch 3)\n","\n","8 steps took 4.34 seconds\n","Epoch: 4 batch_num: 100 val_rmse_target: 0.5008 val_rmse_stderror: 0.9858\n","Still best_val_rmse: 0.4986 (from epoch 3)\n","\n","16 steps took 8.69 seconds\n","Epoch: 4 batch_num: 116 val_rmse_target: 0.5028 val_rmse_stderror: 0.9861\n","Still best_val_rmse: 0.4986 (from epoch 3)\n","\n","16 steps took 8.68 seconds\n","Epoch: 4 batch_num: 132 val_rmse_target: 0.5031 val_rmse_stderror: 0.9862\n","Still best_val_rmse: 0.4986 (from epoch 3)\n","\n","Performance estimates:\n","[0.4715036928208487, 0.4985938457861796]\n","Mean: 0.48504876930351415\n","\n","Fold 3/5\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"stream","text":["\n","16 steps took 9.11 seconds\n","Epoch: 0 batch_num: 16 val_rmse_target: 1.33 val_rmse_stderror: 2.649\n","New best_val_rmse: 1.33\n","\n","16 steps took 8.61 seconds\n","Epoch: 0 batch_num: 32 val_rmse_target: 1.05 val_rmse_stderror: 2.161\n","New best_val_rmse: 1.05\n","\n","16 steps took 8.62 seconds\n","Epoch: 0 batch_num: 48 val_rmse_target: 0.8249 val_rmse_stderror: 2.151\n","New best_val_rmse: 0.8249\n","\n","16 steps took 8.62 seconds\n","Epoch: 0 batch_num: 64 val_rmse_target: 0.7802 val_rmse_stderror: 2.17\n","New best_val_rmse: 0.7802\n","\n","16 steps took 8.61 seconds\n","Epoch: 0 batch_num: 80 val_rmse_target: 0.7089 val_rmse_stderror: 2.204\n","New best_val_rmse: 0.7089\n","\n","16 steps took 8.61 seconds\n","Epoch: 0 batch_num: 96 val_rmse_target: 0.6428 val_rmse_stderror: 2.173\n","New best_val_rmse: 0.6428\n","\n","16 steps took 8.61 seconds\n","Epoch: 0 batch_num: 112 val_rmse_target: 0.5632 val_rmse_stderror: 2.196\n","New best_val_rmse: 0.5632\n","\n","16 steps took 8.62 seconds\n","Epoch: 0 batch_num: 128 val_rmse_target: 0.5738 val_rmse_stderror: 2.171\n","Still best_val_rmse: 0.5632 (from epoch 0)\n","\n","16 steps took 8.75 seconds\n","Epoch: 1 batch_num: 3 val_rmse_target: 0.6755 val_rmse_stderror: 2.182\n","Still best_val_rmse: 0.5632 (from epoch 0)\n","\n","16 steps took 8.61 seconds\n","Epoch: 1 batch_num: 19 val_rmse_target: 0.5318 val_rmse_stderror: 2.198\n","New best_val_rmse: 0.5318\n","\n","16 steps took 8.62 seconds\n","Epoch: 1 batch_num: 35 val_rmse_target: 0.5548 val_rmse_stderror: 2.168\n","Still best_val_rmse: 0.5318 (from epoch 1)\n","\n","16 steps took 8.61 seconds\n","Epoch: 1 batch_num: 51 val_rmse_target: 0.5666 val_rmse_stderror: 2.19\n","Still best_val_rmse: 0.5318 (from epoch 1)\n","\n","16 steps took 8.62 seconds\n","Epoch: 1 batch_num: 67 val_rmse_target: 0.4984 val_rmse_stderror: 2.179\n","New best_val_rmse: 0.4984\n","\n","8 steps took 4.3 seconds\n","Epoch: 1 batch_num: 75 val_rmse_target: 0.547 val_rmse_stderror: 2.183\n","Still best_val_rmse: 0.4984 (from epoch 1)\n","\n","16 steps took 8.63 seconds\n","Epoch: 1 batch_num: 91 val_rmse_target: 0.5388 val_rmse_stderror: 2.172\n","Still best_val_rmse: 0.4984 (from epoch 1)\n","\n","16 steps took 8.61 seconds\n","Epoch: 1 batch_num: 107 val_rmse_target: 0.5053 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4984 (from epoch 1)\n","\n","16 steps took 8.61 seconds\n","Epoch: 1 batch_num: 123 val_rmse_target: 0.461 val_rmse_stderror: 2.206\n","New best_val_rmse: 0.461\n","\n","1 steps took 0.535 seconds\n","Epoch: 1 batch_num: 124 val_rmse_target: 0.4706 val_rmse_stderror: 2.207\n","Still best_val_rmse: 0.461 (from epoch 1)\n","\n","2 steps took 1.07 seconds\n","Epoch: 1 batch_num: 126 val_rmse_target: 0.4899 val_rmse_stderror: 2.203\n","Still best_val_rmse: 0.461 (from epoch 1)\n","\n","4 steps took 2.15 seconds\n","Epoch: 1 batch_num: 130 val_rmse_target: 0.4725 val_rmse_stderror: 2.189\n","Still best_val_rmse: 0.461 (from epoch 1)\n","\n","2 steps took 1.07 seconds\n","Epoch: 1 batch_num: 132 val_rmse_target: 0.4608 val_rmse_stderror: 2.184\n","New best_val_rmse: 0.4608\n","\n","1 steps took 0.534 seconds\n","Epoch: 1 batch_num: 133 val_rmse_target: 0.4734 val_rmse_stderror: 2.181\n","Still best_val_rmse: 0.4608 (from epoch 1)\n","\n","2 steps took 1.07 seconds\n","Epoch: 1 batch_num: 135 val_rmse_target: 0.4612 val_rmse_stderror: 2.18\n","Still best_val_rmse: 0.4608 (from epoch 1)\n","\n","1 steps took 0.532 seconds\n","Epoch: 1 batch_num: 136 val_rmse_target: 0.4642 val_rmse_stderror: 2.18\n","Still best_val_rmse: 0.4608 (from epoch 1)\n","\n","1 steps took 0.534 seconds\n","Epoch: 1 batch_num: 137 val_rmse_target: 0.4634 val_rmse_stderror: 2.182\n","Still best_val_rmse: 0.4608 (from epoch 1)\n","\n","1 steps took 0.533 seconds\n","Epoch: 1 batch_num: 138 val_rmse_target: 0.4628 val_rmse_stderror: 2.184\n","Still best_val_rmse: 0.4608 (from epoch 1)\n","\n","1 steps took 0.534 seconds\n","Epoch: 1 batch_num: 139 val_rmse_target: 0.4643 val_rmse_stderror: 2.187\n","Still best_val_rmse: 0.4608 (from epoch 1)\n","\n","1 steps took 0.533 seconds\n","Epoch: 1 batch_num: 140 val_rmse_target: 0.4652 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4608 (from epoch 1)\n","\n","1 steps took 0.673 seconds\n","Epoch: 2 batch_num: 0 val_rmse_target: 0.5236 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4608 (from epoch 1)\n","\n","16 steps took 8.61 seconds\n","Epoch: 2 batch_num: 16 val_rmse_target: 0.4648 val_rmse_stderror: 2.171\n","Still best_val_rmse: 0.4608 (from epoch 1)\n","\n","1 steps took 0.532 seconds\n","Epoch: 2 batch_num: 17 val_rmse_target: 0.4635 val_rmse_stderror: 2.17\n","Still best_val_rmse: 0.4608 (from epoch 1)\n","\n","1 steps took 0.533 seconds\n","Epoch: 2 batch_num: 18 val_rmse_target: 0.4711 val_rmse_stderror: 2.171\n","Still best_val_rmse: 0.4608 (from epoch 1)\n","\n","2 steps took 1.07 seconds\n","Epoch: 2 batch_num: 20 val_rmse_target: 0.4999 val_rmse_stderror: 2.173\n","Still best_val_rmse: 0.4608 (from epoch 1)\n","\n","8 steps took 4.3 seconds\n","Epoch: 2 batch_num: 28 val_rmse_target: 0.4935 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4608 (from epoch 1)\n","\n","8 steps took 4.3 seconds\n","Epoch: 2 batch_num: 36 val_rmse_target: 0.5261 val_rmse_stderror: 2.196\n","Still best_val_rmse: 0.4608 (from epoch 1)\n","\n","16 steps took 8.62 seconds\n","Epoch: 2 batch_num: 52 val_rmse_target: 0.4746 val_rmse_stderror: 2.204\n","Still best_val_rmse: 0.4608 (from epoch 1)\n","\n","2 steps took 1.07 seconds\n","Epoch: 2 batch_num: 54 val_rmse_target: 0.4903 val_rmse_stderror: 2.2\n","Still best_val_rmse: 0.4608 (from epoch 1)\n","\n","8 steps took 4.3 seconds\n","Epoch: 2 batch_num: 62 val_rmse_target: 0.4548 val_rmse_stderror: 2.189\n","New best_val_rmse: 0.4548\n","\n","1 steps took 0.538 seconds\n","Epoch: 2 batch_num: 63 val_rmse_target: 0.4559 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.534 seconds\n","Epoch: 2 batch_num: 64 val_rmse_target: 0.483 val_rmse_stderror: 2.182\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","4 steps took 2.15 seconds\n","Epoch: 2 batch_num: 68 val_rmse_target: 0.5051 val_rmse_stderror: 2.175\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","16 steps took 8.61 seconds\n","Epoch: 2 batch_num: 84 val_rmse_target: 0.4567 val_rmse_stderror: 2.185\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.534 seconds\n","Epoch: 2 batch_num: 85 val_rmse_target: 0.467 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.532 seconds\n","Epoch: 2 batch_num: 86 val_rmse_target: 0.4606 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.533 seconds\n","Epoch: 2 batch_num: 87 val_rmse_target: 0.4566 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.534 seconds\n","Epoch: 2 batch_num: 88 val_rmse_target: 0.4602 val_rmse_stderror: 2.185\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.534 seconds\n","Epoch: 2 batch_num: 89 val_rmse_target: 0.4806 val_rmse_stderror: 2.185\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","4 steps took 2.15 seconds\n","Epoch: 2 batch_num: 93 val_rmse_target: 0.4748 val_rmse_stderror: 2.185\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 2 batch_num: 95 val_rmse_target: 0.4719 val_rmse_stderror: 2.188\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 2 batch_num: 97 val_rmse_target: 0.4761 val_rmse_stderror: 2.188\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 2 batch_num: 99 val_rmse_target: 0.4596 val_rmse_stderror: 2.184\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.534 seconds\n","Epoch: 2 batch_num: 100 val_rmse_target: 0.4761 val_rmse_stderror: 2.183\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 2 batch_num: 102 val_rmse_target: 0.5061 val_rmse_stderror: 2.181\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","16 steps took 8.61 seconds\n","Epoch: 2 batch_num: 118 val_rmse_target: 0.4745 val_rmse_stderror: 2.197\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.08 seconds\n","Epoch: 2 batch_num: 120 val_rmse_target: 0.4885 val_rmse_stderror: 2.193\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","4 steps took 2.15 seconds\n","Epoch: 2 batch_num: 124 val_rmse_target: 0.4693 val_rmse_stderror: 2.192\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.533 seconds\n","Epoch: 2 batch_num: 125 val_rmse_target: 0.4588 val_rmse_stderror: 2.191\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.533 seconds\n","Epoch: 2 batch_num: 126 val_rmse_target: 0.4579 val_rmse_stderror: 2.19\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.532 seconds\n","Epoch: 2 batch_num: 127 val_rmse_target: 0.4563 val_rmse_stderror: 2.187\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.535 seconds\n","Epoch: 2 batch_num: 128 val_rmse_target: 0.4572 val_rmse_stderror: 2.185\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.534 seconds\n","Epoch: 2 batch_num: 129 val_rmse_target: 0.4713 val_rmse_stderror: 2.183\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 2 batch_num: 131 val_rmse_target: 0.4845 val_rmse_stderror: 2.179\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","4 steps took 2.15 seconds\n","Epoch: 2 batch_num: 135 val_rmse_target: 0.4581 val_rmse_stderror: 2.179\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.533 seconds\n","Epoch: 2 batch_num: 136 val_rmse_target: 0.4575 val_rmse_stderror: 2.18\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.532 seconds\n","Epoch: 2 batch_num: 137 val_rmse_target: 0.4602 val_rmse_stderror: 2.181\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.534 seconds\n","Epoch: 2 batch_num: 138 val_rmse_target: 0.463 val_rmse_stderror: 2.182\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.535 seconds\n","Epoch: 2 batch_num: 139 val_rmse_target: 0.4641 val_rmse_stderror: 2.183\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.534 seconds\n","Epoch: 2 batch_num: 140 val_rmse_target: 0.4692 val_rmse_stderror: 2.183\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.666 seconds\n","Epoch: 3 batch_num: 0 val_rmse_target: 0.4704 val_rmse_stderror: 2.184\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 3 batch_num: 2 val_rmse_target: 0.465 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.533 seconds\n","Epoch: 3 batch_num: 3 val_rmse_target: 0.4646 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.531 seconds\n","Epoch: 3 batch_num: 4 val_rmse_target: 0.4718 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 3 batch_num: 6 val_rmse_target: 0.477 val_rmse_stderror: 2.187\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 3 batch_num: 8 val_rmse_target: 0.4677 val_rmse_stderror: 2.187\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.535 seconds\n","Epoch: 3 batch_num: 9 val_rmse_target: 0.4658 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.534 seconds\n","Epoch: 3 batch_num: 10 val_rmse_target: 0.467 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.534 seconds\n","Epoch: 3 batch_num: 11 val_rmse_target: 0.4732 val_rmse_stderror: 2.185\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 3 batch_num: 13 val_rmse_target: 0.4911 val_rmse_stderror: 2.182\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","8 steps took 4.3 seconds\n","Epoch: 3 batch_num: 21 val_rmse_target: 0.4618 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.534 seconds\n","Epoch: 3 batch_num: 22 val_rmse_target: 0.4662 val_rmse_stderror: 2.188\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.534 seconds\n","Epoch: 3 batch_num: 23 val_rmse_target: 0.4758 val_rmse_stderror: 2.19\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 3 batch_num: 25 val_rmse_target: 0.4779 val_rmse_stderror: 2.195\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 3 batch_num: 27 val_rmse_target: 0.4731 val_rmse_stderror: 2.2\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 3 batch_num: 29 val_rmse_target: 0.4802 val_rmse_stderror: 2.204\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","4 steps took 2.15 seconds\n","Epoch: 3 batch_num: 33 val_rmse_target: 0.4712 val_rmse_stderror: 2.198\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 3 batch_num: 35 val_rmse_target: 0.4652 val_rmse_stderror: 2.195\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.534 seconds\n","Epoch: 3 batch_num: 36 val_rmse_target: 0.4645 val_rmse_stderror: 2.194\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.534 seconds\n","Epoch: 3 batch_num: 37 val_rmse_target: 0.4668 val_rmse_stderror: 2.191\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.534 seconds\n","Epoch: 3 batch_num: 38 val_rmse_target: 0.4739 val_rmse_stderror: 2.188\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 3 batch_num: 40 val_rmse_target: 0.4831 val_rmse_stderror: 2.183\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","4 steps took 2.15 seconds\n","Epoch: 3 batch_num: 44 val_rmse_target: 0.4701 val_rmse_stderror: 2.18\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 3 batch_num: 46 val_rmse_target: 0.4619 val_rmse_stderror: 2.182\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.536 seconds\n","Epoch: 3 batch_num: 47 val_rmse_target: 0.4621 val_rmse_stderror: 2.184\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.534 seconds\n","Epoch: 3 batch_num: 48 val_rmse_target: 0.4627 val_rmse_stderror: 2.185\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.533 seconds\n","Epoch: 3 batch_num: 49 val_rmse_target: 0.464 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.537 seconds\n","Epoch: 3 batch_num: 50 val_rmse_target: 0.4657 val_rmse_stderror: 2.187\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.535 seconds\n","Epoch: 3 batch_num: 51 val_rmse_target: 0.4695 val_rmse_stderror: 2.188\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.533 seconds\n","Epoch: 3 batch_num: 52 val_rmse_target: 0.4711 val_rmse_stderror: 2.188\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 3 batch_num: 54 val_rmse_target: 0.4884 val_rmse_stderror: 2.188\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","4 steps took 2.15 seconds\n","Epoch: 3 batch_num: 58 val_rmse_target: 0.4697 val_rmse_stderror: 2.188\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.536 seconds\n","Epoch: 3 batch_num: 59 val_rmse_target: 0.4624 val_rmse_stderror: 2.188\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.534 seconds\n","Epoch: 3 batch_num: 60 val_rmse_target: 0.4604 val_rmse_stderror: 2.188\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.534 seconds\n","Epoch: 3 batch_num: 61 val_rmse_target: 0.4597 val_rmse_stderror: 2.187\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.534 seconds\n","Epoch: 3 batch_num: 62 val_rmse_target: 0.4614 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.534 seconds\n","Epoch: 3 batch_num: 63 val_rmse_target: 0.4665 val_rmse_stderror: 2.185\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.532 seconds\n","Epoch: 3 batch_num: 64 val_rmse_target: 0.4711 val_rmse_stderror: 2.184\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 3 batch_num: 66 val_rmse_target: 0.4826 val_rmse_stderror: 2.182\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","4 steps took 2.15 seconds\n","Epoch: 3 batch_num: 70 val_rmse_target: 0.475 val_rmse_stderror: 2.182\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 3 batch_num: 72 val_rmse_target: 0.4687 val_rmse_stderror: 2.183\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.536 seconds\n","Epoch: 3 batch_num: 73 val_rmse_target: 0.4681 val_rmse_stderror: 2.183\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.533 seconds\n","Epoch: 3 batch_num: 74 val_rmse_target: 0.4689 val_rmse_stderror: 2.184\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.533 seconds\n","Epoch: 3 batch_num: 75 val_rmse_target: 0.4712 val_rmse_stderror: 2.185\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 3 batch_num: 77 val_rmse_target: 0.4747 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 3 batch_num: 79 val_rmse_target: 0.475 val_rmse_stderror: 2.187\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 3 batch_num: 81 val_rmse_target: 0.4768 val_rmse_stderror: 2.189\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 3 batch_num: 83 val_rmse_target: 0.4757 val_rmse_stderror: 2.19\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 3 batch_num: 85 val_rmse_target: 0.469 val_rmse_stderror: 2.191\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.534 seconds\n","Epoch: 3 batch_num: 86 val_rmse_target: 0.4645 val_rmse_stderror: 2.192\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.534 seconds\n","Epoch: 3 batch_num: 87 val_rmse_target: 0.4625 val_rmse_stderror: 2.192\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.538 seconds\n","Epoch: 3 batch_num: 88 val_rmse_target: 0.4635 val_rmse_stderror: 2.192\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.532 seconds\n","Epoch: 3 batch_num: 89 val_rmse_target: 0.4674 val_rmse_stderror: 2.192\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.533 seconds\n","Epoch: 3 batch_num: 90 val_rmse_target: 0.4709 val_rmse_stderror: 2.191\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.08 seconds\n","Epoch: 3 batch_num: 92 val_rmse_target: 0.4769 val_rmse_stderror: 2.191\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 3 batch_num: 94 val_rmse_target: 0.4769 val_rmse_stderror: 2.191\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 3 batch_num: 96 val_rmse_target: 0.4737 val_rmse_stderror: 2.191\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 3 batch_num: 98 val_rmse_target: 0.4712 val_rmse_stderror: 2.19\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.08 seconds\n","Epoch: 3 batch_num: 100 val_rmse_target: 0.4676 val_rmse_stderror: 2.188\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.533 seconds\n","Epoch: 3 batch_num: 101 val_rmse_target: 0.4653 val_rmse_stderror: 2.187\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.533 seconds\n","Epoch: 3 batch_num: 102 val_rmse_target: 0.4634 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.539 seconds\n","Epoch: 3 batch_num: 103 val_rmse_target: 0.4627 val_rmse_stderror: 2.185\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.534 seconds\n","Epoch: 3 batch_num: 104 val_rmse_target: 0.4648 val_rmse_stderror: 2.184\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.535 seconds\n","Epoch: 3 batch_num: 105 val_rmse_target: 0.472 val_rmse_stderror: 2.183\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 3 batch_num: 107 val_rmse_target: 0.4852 val_rmse_stderror: 2.18\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","4 steps took 2.15 seconds\n","Epoch: 3 batch_num: 111 val_rmse_target: 0.4915 val_rmse_stderror: 2.179\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","8 steps took 4.3 seconds\n","Epoch: 3 batch_num: 119 val_rmse_target: 0.4618 val_rmse_stderror: 2.185\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.534 seconds\n","Epoch: 3 batch_num: 120 val_rmse_target: 0.4615 val_rmse_stderror: 2.185\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.533 seconds\n","Epoch: 3 batch_num: 121 val_rmse_target: 0.4611 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.533 seconds\n","Epoch: 3 batch_num: 122 val_rmse_target: 0.4606 val_rmse_stderror: 2.187\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.532 seconds\n","Epoch: 3 batch_num: 123 val_rmse_target: 0.4616 val_rmse_stderror: 2.187\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.535 seconds\n","Epoch: 3 batch_num: 124 val_rmse_target: 0.4623 val_rmse_stderror: 2.188\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.534 seconds\n","Epoch: 3 batch_num: 125 val_rmse_target: 0.4621 val_rmse_stderror: 2.188\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.535 seconds\n","Epoch: 3 batch_num: 126 val_rmse_target: 0.4612 val_rmse_stderror: 2.189\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.532 seconds\n","Epoch: 3 batch_num: 127 val_rmse_target: 0.4607 val_rmse_stderror: 2.189\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.534 seconds\n","Epoch: 3 batch_num: 128 val_rmse_target: 0.4598 val_rmse_stderror: 2.19\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.536 seconds\n","Epoch: 3 batch_num: 129 val_rmse_target: 0.4596 val_rmse_stderror: 2.19\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.537 seconds\n","Epoch: 3 batch_num: 130 val_rmse_target: 0.4599 val_rmse_stderror: 2.19\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.534 seconds\n","Epoch: 3 batch_num: 131 val_rmse_target: 0.4599 val_rmse_stderror: 2.19\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.533 seconds\n","Epoch: 3 batch_num: 132 val_rmse_target: 0.4608 val_rmse_stderror: 2.189\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.533 seconds\n","Epoch: 3 batch_num: 133 val_rmse_target: 0.4624 val_rmse_stderror: 2.189\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.535 seconds\n","Epoch: 3 batch_num: 134 val_rmse_target: 0.4654 val_rmse_stderror: 2.188\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.532 seconds\n","Epoch: 3 batch_num: 135 val_rmse_target: 0.4692 val_rmse_stderror: 2.187\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.536 seconds\n","Epoch: 3 batch_num: 136 val_rmse_target: 0.4728 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 3 batch_num: 138 val_rmse_target: 0.4764 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 3 batch_num: 140 val_rmse_target: 0.4753 val_rmse_stderror: 2.185\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.19 seconds\n","Epoch: 4 batch_num: 1 val_rmse_target: 0.4768 val_rmse_stderror: 2.185\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 4 batch_num: 3 val_rmse_target: 0.4764 val_rmse_stderror: 2.184\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 4 batch_num: 5 val_rmse_target: 0.4688 val_rmse_stderror: 2.183\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.533 seconds\n","Epoch: 4 batch_num: 6 val_rmse_target: 0.4642 val_rmse_stderror: 2.183\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.536 seconds\n","Epoch: 4 batch_num: 7 val_rmse_target: 0.4615 val_rmse_stderror: 2.183\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.533 seconds\n","Epoch: 4 batch_num: 8 val_rmse_target: 0.4597 val_rmse_stderror: 2.183\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.534 seconds\n","Epoch: 4 batch_num: 9 val_rmse_target: 0.4595 val_rmse_stderror: 2.183\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.532 seconds\n","Epoch: 4 batch_num: 10 val_rmse_target: 0.4613 val_rmse_stderror: 2.182\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.534 seconds\n","Epoch: 4 batch_num: 11 val_rmse_target: 0.4642 val_rmse_stderror: 2.182\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.532 seconds\n","Epoch: 4 batch_num: 12 val_rmse_target: 0.4666 val_rmse_stderror: 2.182\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.533 seconds\n","Epoch: 4 batch_num: 13 val_rmse_target: 0.4691 val_rmse_stderror: 2.182\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.534 seconds\n","Epoch: 4 batch_num: 14 val_rmse_target: 0.4711 val_rmse_stderror: 2.182\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 4 batch_num: 16 val_rmse_target: 0.4712 val_rmse_stderror: 2.182\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 4 batch_num: 18 val_rmse_target: 0.4731 val_rmse_stderror: 2.183\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 4 batch_num: 20 val_rmse_target: 0.4756 val_rmse_stderror: 2.183\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 4 batch_num: 22 val_rmse_target: 0.4761 val_rmse_stderror: 2.183\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 4 batch_num: 24 val_rmse_target: 0.4776 val_rmse_stderror: 2.184\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 4 batch_num: 26 val_rmse_target: 0.4786 val_rmse_stderror: 2.184\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 4 batch_num: 28 val_rmse_target: 0.4794 val_rmse_stderror: 2.184\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 4 batch_num: 30 val_rmse_target: 0.4767 val_rmse_stderror: 2.185\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 4 batch_num: 32 val_rmse_target: 0.4707 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 4 batch_num: 34 val_rmse_target: 0.4676 val_rmse_stderror: 2.185\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.535 seconds\n","Epoch: 4 batch_num: 35 val_rmse_target: 0.4674 val_rmse_stderror: 2.185\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.534 seconds\n","Epoch: 4 batch_num: 36 val_rmse_target: 0.4677 val_rmse_stderror: 2.185\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.534 seconds\n","Epoch: 4 batch_num: 37 val_rmse_target: 0.4672 val_rmse_stderror: 2.185\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.535 seconds\n","Epoch: 4 batch_num: 38 val_rmse_target: 0.4659 val_rmse_stderror: 2.185\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.537 seconds\n","Epoch: 4 batch_num: 39 val_rmse_target: 0.4649 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.533 seconds\n","Epoch: 4 batch_num: 40 val_rmse_target: 0.4644 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.533 seconds\n","Epoch: 4 batch_num: 41 val_rmse_target: 0.4644 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.534 seconds\n","Epoch: 4 batch_num: 42 val_rmse_target: 0.4654 val_rmse_stderror: 2.185\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.533 seconds\n","Epoch: 4 batch_num: 43 val_rmse_target: 0.4661 val_rmse_stderror: 2.185\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.535 seconds\n","Epoch: 4 batch_num: 44 val_rmse_target: 0.4662 val_rmse_stderror: 2.185\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.534 seconds\n","Epoch: 4 batch_num: 45 val_rmse_target: 0.4666 val_rmse_stderror: 2.185\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.533 seconds\n","Epoch: 4 batch_num: 46 val_rmse_target: 0.4672 val_rmse_stderror: 2.185\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.533 seconds\n","Epoch: 4 batch_num: 47 val_rmse_target: 0.4675 val_rmse_stderror: 2.185\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.533 seconds\n","Epoch: 4 batch_num: 48 val_rmse_target: 0.4682 val_rmse_stderror: 2.185\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.536 seconds\n","Epoch: 4 batch_num: 49 val_rmse_target: 0.4689 val_rmse_stderror: 2.185\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.533 seconds\n","Epoch: 4 batch_num: 50 val_rmse_target: 0.4694 val_rmse_stderror: 2.185\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.531 seconds\n","Epoch: 4 batch_num: 51 val_rmse_target: 0.4701 val_rmse_stderror: 2.185\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 4 batch_num: 53 val_rmse_target: 0.4707 val_rmse_stderror: 2.185\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 4 batch_num: 55 val_rmse_target: 0.4703 val_rmse_stderror: 2.185\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 4 batch_num: 57 val_rmse_target: 0.469 val_rmse_stderror: 2.185\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.533 seconds\n","Epoch: 4 batch_num: 58 val_rmse_target: 0.4686 val_rmse_stderror: 2.185\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.534 seconds\n","Epoch: 4 batch_num: 59 val_rmse_target: 0.4685 val_rmse_stderror: 2.185\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.533 seconds\n","Epoch: 4 batch_num: 60 val_rmse_target: 0.4689 val_rmse_stderror: 2.185\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.533 seconds\n","Epoch: 4 batch_num: 61 val_rmse_target: 0.469 val_rmse_stderror: 2.185\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.533 seconds\n","Epoch: 4 batch_num: 62 val_rmse_target: 0.4692 val_rmse_stderror: 2.185\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.535 seconds\n","Epoch: 4 batch_num: 63 val_rmse_target: 0.4693 val_rmse_stderror: 2.185\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.538 seconds\n","Epoch: 4 batch_num: 64 val_rmse_target: 0.4684 val_rmse_stderror: 2.185\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.535 seconds\n","Epoch: 4 batch_num: 65 val_rmse_target: 0.467 val_rmse_stderror: 2.185\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.533 seconds\n","Epoch: 4 batch_num: 66 val_rmse_target: 0.4653 val_rmse_stderror: 2.185\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.534 seconds\n","Epoch: 4 batch_num: 67 val_rmse_target: 0.4638 val_rmse_stderror: 2.185\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.532 seconds\n","Epoch: 4 batch_num: 68 val_rmse_target: 0.4626 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.535 seconds\n","Epoch: 4 batch_num: 69 val_rmse_target: 0.4616 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.535 seconds\n","Epoch: 4 batch_num: 70 val_rmse_target: 0.4611 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.535 seconds\n","Epoch: 4 batch_num: 71 val_rmse_target: 0.4609 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.533 seconds\n","Epoch: 4 batch_num: 72 val_rmse_target: 0.4608 val_rmse_stderror: 2.187\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.53 seconds\n","Epoch: 4 batch_num: 73 val_rmse_target: 0.4606 val_rmse_stderror: 2.187\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.538 seconds\n","Epoch: 4 batch_num: 74 val_rmse_target: 0.4607 val_rmse_stderror: 2.187\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.533 seconds\n","Epoch: 4 batch_num: 75 val_rmse_target: 0.4606 val_rmse_stderror: 2.187\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.536 seconds\n","Epoch: 4 batch_num: 76 val_rmse_target: 0.4607 val_rmse_stderror: 2.187\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.533 seconds\n","Epoch: 4 batch_num: 77 val_rmse_target: 0.4607 val_rmse_stderror: 2.187\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.535 seconds\n","Epoch: 4 batch_num: 78 val_rmse_target: 0.4606 val_rmse_stderror: 2.187\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.538 seconds\n","Epoch: 4 batch_num: 79 val_rmse_target: 0.4604 val_rmse_stderror: 2.188\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.536 seconds\n","Epoch: 4 batch_num: 80 val_rmse_target: 0.4603 val_rmse_stderror: 2.188\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.533 seconds\n","Epoch: 4 batch_num: 81 val_rmse_target: 0.4603 val_rmse_stderror: 2.188\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.534 seconds\n","Epoch: 4 batch_num: 82 val_rmse_target: 0.4606 val_rmse_stderror: 2.188\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.533 seconds\n","Epoch: 4 batch_num: 83 val_rmse_target: 0.461 val_rmse_stderror: 2.188\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.535 seconds\n","Epoch: 4 batch_num: 84 val_rmse_target: 0.4615 val_rmse_stderror: 2.188\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.533 seconds\n","Epoch: 4 batch_num: 85 val_rmse_target: 0.4619 val_rmse_stderror: 2.188\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.534 seconds\n","Epoch: 4 batch_num: 86 val_rmse_target: 0.4623 val_rmse_stderror: 2.188\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.534 seconds\n","Epoch: 4 batch_num: 87 val_rmse_target: 0.4624 val_rmse_stderror: 2.188\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.535 seconds\n","Epoch: 4 batch_num: 88 val_rmse_target: 0.4626 val_rmse_stderror: 2.188\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.533 seconds\n","Epoch: 4 batch_num: 89 val_rmse_target: 0.4626 val_rmse_stderror: 2.188\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.535 seconds\n","Epoch: 4 batch_num: 90 val_rmse_target: 0.4628 val_rmse_stderror: 2.188\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.535 seconds\n","Epoch: 4 batch_num: 91 val_rmse_target: 0.4631 val_rmse_stderror: 2.188\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.534 seconds\n","Epoch: 4 batch_num: 92 val_rmse_target: 0.4634 val_rmse_stderror: 2.188\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.532 seconds\n","Epoch: 4 batch_num: 93 val_rmse_target: 0.4639 val_rmse_stderror: 2.188\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.533 seconds\n","Epoch: 4 batch_num: 94 val_rmse_target: 0.4643 val_rmse_stderror: 2.187\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.532 seconds\n","Epoch: 4 batch_num: 95 val_rmse_target: 0.4647 val_rmse_stderror: 2.187\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.531 seconds\n","Epoch: 4 batch_num: 96 val_rmse_target: 0.4653 val_rmse_stderror: 2.187\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.534 seconds\n","Epoch: 4 batch_num: 97 val_rmse_target: 0.4659 val_rmse_stderror: 2.187\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.532 seconds\n","Epoch: 4 batch_num: 98 val_rmse_target: 0.4666 val_rmse_stderror: 2.187\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.534 seconds\n","Epoch: 4 batch_num: 99 val_rmse_target: 0.4675 val_rmse_stderror: 2.187\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.535 seconds\n","Epoch: 4 batch_num: 100 val_rmse_target: 0.4683 val_rmse_stderror: 2.187\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.533 seconds\n","Epoch: 4 batch_num: 101 val_rmse_target: 0.4691 val_rmse_stderror: 2.187\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.533 seconds\n","Epoch: 4 batch_num: 102 val_rmse_target: 0.4699 val_rmse_stderror: 2.187\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","1 steps took 0.533 seconds\n","Epoch: 4 batch_num: 103 val_rmse_target: 0.4706 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 4 batch_num: 105 val_rmse_target: 0.4717 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 4 batch_num: 107 val_rmse_target: 0.4722 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 4 batch_num: 109 val_rmse_target: 0.4726 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 4 batch_num: 111 val_rmse_target: 0.4728 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 4 batch_num: 113 val_rmse_target: 0.4728 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 4 batch_num: 115 val_rmse_target: 0.4729 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 4 batch_num: 117 val_rmse_target: 0.4727 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 4 batch_num: 119 val_rmse_target: 0.4725 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 4 batch_num: 121 val_rmse_target: 0.4722 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 4 batch_num: 123 val_rmse_target: 0.472 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 4 batch_num: 125 val_rmse_target: 0.4718 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 4 batch_num: 127 val_rmse_target: 0.4718 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 4 batch_num: 129 val_rmse_target: 0.4717 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 4 batch_num: 131 val_rmse_target: 0.4716 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 4 batch_num: 133 val_rmse_target: 0.4716 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 4 batch_num: 135 val_rmse_target: 0.4716 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 4 batch_num: 137 val_rmse_target: 0.4716 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","2 steps took 1.07 seconds\n","Epoch: 4 batch_num: 139 val_rmse_target: 0.4715 val_rmse_stderror: 2.186\n","Still best_val_rmse: 0.4548 (from epoch 2)\n","\n","Performance estimates:\n","[0.4715036928208487, 0.4985938457861796, 0.45480021516657915]\n","Mean: 0.4749659179245358\n","\n","Fold 4/5\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"stream","text":["\n","16 steps took 8.89 seconds\n","Epoch: 0 batch_num: 16 val_rmse_target: 1.153 val_rmse_stderror: 1.32\n","New best_val_rmse: 1.153\n","\n","16 steps took 8.38 seconds\n","Epoch: 0 batch_num: 32 val_rmse_target: 1.072 val_rmse_stderror: 1.331\n","New best_val_rmse: 1.072\n","\n","16 steps took 8.4 seconds\n","Epoch: 0 batch_num: 48 val_rmse_target: 0.7558 val_rmse_stderror: 1.285\n","New best_val_rmse: 0.7558\n","\n","16 steps took 8.38 seconds\n","Epoch: 0 batch_num: 64 val_rmse_target: 0.7411 val_rmse_stderror: 1.364\n","New best_val_rmse: 0.7411\n","\n","16 steps took 8.4 seconds\n","Epoch: 0 batch_num: 80 val_rmse_target: 0.7133 val_rmse_stderror: 1.282\n","New best_val_rmse: 0.7133\n","\n","16 steps took 8.39 seconds\n","Epoch: 0 batch_num: 96 val_rmse_target: 0.5766 val_rmse_stderror: 1.274\n","New best_val_rmse: 0.5766\n","\n","16 steps took 8.4 seconds\n","Epoch: 0 batch_num: 112 val_rmse_target: 0.6333 val_rmse_stderror: 1.288\n","Still best_val_rmse: 0.5766 (from epoch 0)\n","\n","16 steps took 8.39 seconds\n","Epoch: 0 batch_num: 128 val_rmse_target: 0.6696 val_rmse_stderror: 1.273\n","Still best_val_rmse: 0.5766 (from epoch 0)\n","\n","16 steps took 8.51 seconds\n","Epoch: 1 batch_num: 3 val_rmse_target: 0.5606 val_rmse_stderror: 1.284\n","New best_val_rmse: 0.5606\n","\n","16 steps took 8.4 seconds\n","Epoch: 1 batch_num: 19 val_rmse_target: 0.5508 val_rmse_stderror: 1.257\n","New best_val_rmse: 0.5508\n","\n","16 steps took 8.39 seconds\n","Epoch: 1 batch_num: 35 val_rmse_target: 0.5335 val_rmse_stderror: 1.293\n","New best_val_rmse: 0.5335\n","\n","16 steps took 8.38 seconds\n","Epoch: 1 batch_num: 51 val_rmse_target: 0.5089 val_rmse_stderror: 1.259\n","New best_val_rmse: 0.5089\n","\n","16 steps took 8.39 seconds\n","Epoch: 1 batch_num: 67 val_rmse_target: 0.5307 val_rmse_stderror: 1.288\n","Still best_val_rmse: 0.5089 (from epoch 1)\n","\n","16 steps took 8.38 seconds\n","Epoch: 1 batch_num: 83 val_rmse_target: 0.4957 val_rmse_stderror: 1.301\n","New best_val_rmse: 0.4957\n","\n","8 steps took 4.2 seconds\n","Epoch: 1 batch_num: 91 val_rmse_target: 0.502 val_rmse_stderror: 1.303\n","Still best_val_rmse: 0.4957 (from epoch 1)\n","\n","16 steps took 8.38 seconds\n","Epoch: 1 batch_num: 107 val_rmse_target: 0.5197 val_rmse_stderror: 1.268\n","Still best_val_rmse: 0.4957 (from epoch 1)\n","\n","16 steps took 8.38 seconds\n","Epoch: 1 batch_num: 123 val_rmse_target: 0.5069 val_rmse_stderror: 1.306\n","Still best_val_rmse: 0.4957 (from epoch 1)\n","\n","16 steps took 8.37 seconds\n","Epoch: 1 batch_num: 139 val_rmse_target: 0.5543 val_rmse_stderror: 1.265\n","Still best_val_rmse: 0.4957 (from epoch 1)\n","\n","16 steps took 8.52 seconds\n","Epoch: 2 batch_num: 14 val_rmse_target: 0.5208 val_rmse_stderror: 1.293\n","Still best_val_rmse: 0.4957 (from epoch 1)\n","\n","16 steps took 8.38 seconds\n","Epoch: 2 batch_num: 30 val_rmse_target: 0.5204 val_rmse_stderror: 1.298\n","Still best_val_rmse: 0.4957 (from epoch 1)\n","\n","16 steps took 8.37 seconds\n","Epoch: 2 batch_num: 46 val_rmse_target: 0.4806 val_rmse_stderror: 1.293\n","New best_val_rmse: 0.4806\n","\n","4 steps took 2.09 seconds\n","Epoch: 2 batch_num: 50 val_rmse_target: 0.4991 val_rmse_stderror: 1.275\n","Still best_val_rmse: 0.4806 (from epoch 2)\n","\n","8 steps took 4.19 seconds\n","Epoch: 2 batch_num: 58 val_rmse_target: 0.4845 val_rmse_stderror: 1.276\n","Still best_val_rmse: 0.4806 (from epoch 2)\n","\n","4 steps took 2.09 seconds\n","Epoch: 2 batch_num: 62 val_rmse_target: 0.4781 val_rmse_stderror: 1.277\n","New best_val_rmse: 0.4781\n","\n","2 steps took 1.04 seconds\n","Epoch: 2 batch_num: 64 val_rmse_target: 0.4808 val_rmse_stderror: 1.285\n","Still best_val_rmse: 0.4781 (from epoch 2)\n","\n","4 steps took 2.09 seconds\n","Epoch: 2 batch_num: 68 val_rmse_target: 0.4786 val_rmse_stderror: 1.295\n","Still best_val_rmse: 0.4781 (from epoch 2)\n","\n","2 steps took 1.05 seconds\n","Epoch: 2 batch_num: 70 val_rmse_target: 0.485 val_rmse_stderror: 1.294\n","Still best_val_rmse: 0.4781 (from epoch 2)\n","\n","4 steps took 2.09 seconds\n","Epoch: 2 batch_num: 74 val_rmse_target: 0.4796 val_rmse_stderror: 1.283\n","Still best_val_rmse: 0.4781 (from epoch 2)\n","\n","2 steps took 1.04 seconds\n","Epoch: 2 batch_num: 76 val_rmse_target: 0.4825 val_rmse_stderror: 1.278\n","Still best_val_rmse: 0.4781 (from epoch 2)\n","\n","4 steps took 2.09 seconds\n","Epoch: 2 batch_num: 80 val_rmse_target: 0.4791 val_rmse_stderror: 1.282\n","Still best_val_rmse: 0.4781 (from epoch 2)\n","\n","2 steps took 1.04 seconds\n","Epoch: 2 batch_num: 82 val_rmse_target: 0.4766 val_rmse_stderror: 1.286\n","New best_val_rmse: 0.4766\n","\n","2 steps took 1.04 seconds\n","Epoch: 2 batch_num: 84 val_rmse_target: 0.4825 val_rmse_stderror: 1.282\n","Still best_val_rmse: 0.4766 (from epoch 2)\n","\n","4 steps took 2.09 seconds\n","Epoch: 2 batch_num: 88 val_rmse_target: 0.4736 val_rmse_stderror: 1.274\n","New best_val_rmse: 0.4736\n","\n","2 steps took 1.04 seconds\n","Epoch: 2 batch_num: 90 val_rmse_target: 0.4829 val_rmse_stderror: 1.278\n","Still best_val_rmse: 0.4736 (from epoch 2)\n","\n","4 steps took 2.09 seconds\n","Epoch: 2 batch_num: 94 val_rmse_target: 0.492 val_rmse_stderror: 1.287\n","Still best_val_rmse: 0.4736 (from epoch 2)\n","\n","8 steps took 4.19 seconds\n","Epoch: 2 batch_num: 102 val_rmse_target: 0.4939 val_rmse_stderror: 1.28\n","Still best_val_rmse: 0.4736 (from epoch 2)\n","\n","8 steps took 4.19 seconds\n","Epoch: 2 batch_num: 110 val_rmse_target: 0.496 val_rmse_stderror: 1.287\n","Still best_val_rmse: 0.4736 (from epoch 2)\n","\n","8 steps took 4.18 seconds\n","Epoch: 2 batch_num: 118 val_rmse_target: 0.489 val_rmse_stderror: 1.276\n","Still best_val_rmse: 0.4736 (from epoch 2)\n","\n","4 steps took 2.09 seconds\n","Epoch: 2 batch_num: 122 val_rmse_target: 0.4786 val_rmse_stderror: 1.292\n","Still best_val_rmse: 0.4736 (from epoch 2)\n","\n","2 steps took 1.04 seconds\n","Epoch: 2 batch_num: 124 val_rmse_target: 0.4854 val_rmse_stderror: 1.301\n","Still best_val_rmse: 0.4736 (from epoch 2)\n","\n","4 steps took 2.09 seconds\n","Epoch: 2 batch_num: 128 val_rmse_target: 0.4891 val_rmse_stderror: 1.293\n","Still best_val_rmse: 0.4736 (from epoch 2)\n","\n","4 steps took 2.09 seconds\n","Epoch: 2 batch_num: 132 val_rmse_target: 0.4892 val_rmse_stderror: 1.278\n","Still best_val_rmse: 0.4736 (from epoch 2)\n","\n","4 steps took 2.09 seconds\n","Epoch: 2 batch_num: 136 val_rmse_target: 0.4857 val_rmse_stderror: 1.292\n","Still best_val_rmse: 0.4736 (from epoch 2)\n","\n","4 steps took 2.09 seconds\n","Epoch: 2 batch_num: 140 val_rmse_target: 0.4929 val_rmse_stderror: 1.295\n","Still best_val_rmse: 0.4736 (from epoch 2)\n","\n","8 steps took 4.34 seconds\n","Epoch: 3 batch_num: 7 val_rmse_target: 0.4809 val_rmse_stderror: 1.284\n","Still best_val_rmse: 0.4736 (from epoch 2)\n","\n","4 steps took 2.09 seconds\n","Epoch: 3 batch_num: 11 val_rmse_target: 0.4766 val_rmse_stderror: 1.298\n","Still best_val_rmse: 0.4736 (from epoch 2)\n","\n","2 steps took 1.04 seconds\n","Epoch: 3 batch_num: 13 val_rmse_target: 0.4782 val_rmse_stderror: 1.29\n","Still best_val_rmse: 0.4736 (from epoch 2)\n","\n","2 steps took 1.04 seconds\n","Epoch: 3 batch_num: 15 val_rmse_target: 0.476 val_rmse_stderror: 1.282\n","Still best_val_rmse: 0.4736 (from epoch 2)\n","\n","2 steps took 1.04 seconds\n","Epoch: 3 batch_num: 17 val_rmse_target: 0.4764 val_rmse_stderror: 1.277\n","Still best_val_rmse: 0.4736 (from epoch 2)\n","\n","2 steps took 1.04 seconds\n","Epoch: 3 batch_num: 19 val_rmse_target: 0.4791 val_rmse_stderror: 1.278\n","Still best_val_rmse: 0.4736 (from epoch 2)\n","\n","2 steps took 1.04 seconds\n","Epoch: 3 batch_num: 21 val_rmse_target: 0.4812 val_rmse_stderror: 1.282\n","Still best_val_rmse: 0.4736 (from epoch 2)\n","\n","4 steps took 2.09 seconds\n","Epoch: 3 batch_num: 25 val_rmse_target: 0.4778 val_rmse_stderror: 1.291\n","Still best_val_rmse: 0.4736 (from epoch 2)\n","\n","2 steps took 1.04 seconds\n","Epoch: 3 batch_num: 27 val_rmse_target: 0.4746 val_rmse_stderror: 1.29\n","Still best_val_rmse: 0.4736 (from epoch 2)\n","\n","2 steps took 1.04 seconds\n","Epoch: 3 batch_num: 29 val_rmse_target: 0.4737 val_rmse_stderror: 1.284\n","Still best_val_rmse: 0.4736 (from epoch 2)\n","\n","2 steps took 1.05 seconds\n","Epoch: 3 batch_num: 31 val_rmse_target: 0.4749 val_rmse_stderror: 1.279\n","Still best_val_rmse: 0.4736 (from epoch 2)\n","\n","2 steps took 1.04 seconds\n","Epoch: 3 batch_num: 33 val_rmse_target: 0.4732 val_rmse_stderror: 1.277\n","New best_val_rmse: 0.4732\n","\n","2 steps took 1.04 seconds\n","Epoch: 3 batch_num: 35 val_rmse_target: 0.4732 val_rmse_stderror: 1.277\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 3 batch_num: 37 val_rmse_target: 0.4745 val_rmse_stderror: 1.282\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 3 batch_num: 39 val_rmse_target: 0.4762 val_rmse_stderror: 1.287\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 3 batch_num: 41 val_rmse_target: 0.4786 val_rmse_stderror: 1.288\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 3 batch_num: 43 val_rmse_target: 0.4775 val_rmse_stderror: 1.289\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 3 batch_num: 45 val_rmse_target: 0.4745 val_rmse_stderror: 1.288\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 3 batch_num: 47 val_rmse_target: 0.477 val_rmse_stderror: 1.286\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 3 batch_num: 49 val_rmse_target: 0.4752 val_rmse_stderror: 1.288\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 3 batch_num: 51 val_rmse_target: 0.476 val_rmse_stderror: 1.292\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 3 batch_num: 53 val_rmse_target: 0.4966 val_rmse_stderror: 1.296\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","8 steps took 4.19 seconds\n","Epoch: 3 batch_num: 61 val_rmse_target: 0.4771 val_rmse_stderror: 1.282\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 3 batch_num: 63 val_rmse_target: 0.4784 val_rmse_stderror: 1.28\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 3 batch_num: 65 val_rmse_target: 0.4784 val_rmse_stderror: 1.281\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 3 batch_num: 67 val_rmse_target: 0.4788 val_rmse_stderror: 1.283\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 3 batch_num: 69 val_rmse_target: 0.479 val_rmse_stderror: 1.285\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.05 seconds\n","Epoch: 3 batch_num: 71 val_rmse_target: 0.4776 val_rmse_stderror: 1.284\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.05 seconds\n","Epoch: 3 batch_num: 73 val_rmse_target: 0.475 val_rmse_stderror: 1.28\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 3 batch_num: 75 val_rmse_target: 0.4748 val_rmse_stderror: 1.281\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 3 batch_num: 77 val_rmse_target: 0.4764 val_rmse_stderror: 1.282\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 3 batch_num: 79 val_rmse_target: 0.4758 val_rmse_stderror: 1.281\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 3 batch_num: 81 val_rmse_target: 0.4755 val_rmse_stderror: 1.281\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.05 seconds\n","Epoch: 3 batch_num: 83 val_rmse_target: 0.4763 val_rmse_stderror: 1.282\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 3 batch_num: 85 val_rmse_target: 0.4787 val_rmse_stderror: 1.282\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 3 batch_num: 87 val_rmse_target: 0.4802 val_rmse_stderror: 1.28\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","4 steps took 2.09 seconds\n","Epoch: 3 batch_num: 91 val_rmse_target: 0.4805 val_rmse_stderror: 1.282\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","4 steps took 2.09 seconds\n","Epoch: 3 batch_num: 95 val_rmse_target: 0.4872 val_rmse_stderror: 1.291\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","4 steps took 2.09 seconds\n","Epoch: 3 batch_num: 99 val_rmse_target: 0.4842 val_rmse_stderror: 1.288\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","4 steps took 2.09 seconds\n","Epoch: 3 batch_num: 103 val_rmse_target: 0.48 val_rmse_stderror: 1.281\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","4 steps took 2.09 seconds\n","Epoch: 3 batch_num: 107 val_rmse_target: 0.4808 val_rmse_stderror: 1.285\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","4 steps took 2.09 seconds\n","Epoch: 3 batch_num: 111 val_rmse_target: 0.4917 val_rmse_stderror: 1.292\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","8 steps took 4.18 seconds\n","Epoch: 3 batch_num: 119 val_rmse_target: 0.4732 val_rmse_stderror: 1.282\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 3 batch_num: 121 val_rmse_target: 0.4739 val_rmse_stderror: 1.277\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 3 batch_num: 123 val_rmse_target: 0.4773 val_rmse_stderror: 1.275\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 3 batch_num: 125 val_rmse_target: 0.4779 val_rmse_stderror: 1.275\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 3 batch_num: 127 val_rmse_target: 0.474 val_rmse_stderror: 1.278\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 3 batch_num: 129 val_rmse_target: 0.4754 val_rmse_stderror: 1.283\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.05 seconds\n","Epoch: 3 batch_num: 131 val_rmse_target: 0.4825 val_rmse_stderror: 1.287\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","4 steps took 2.09 seconds\n","Epoch: 3 batch_num: 135 val_rmse_target: 0.4801 val_rmse_stderror: 1.288\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","4 steps took 2.09 seconds\n","Epoch: 3 batch_num: 139 val_rmse_target: 0.4753 val_rmse_stderror: 1.283\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.18 seconds\n","Epoch: 4 batch_num: 0 val_rmse_target: 0.4759 val_rmse_stderror: 1.28\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.05 seconds\n","Epoch: 4 batch_num: 2 val_rmse_target: 0.4769 val_rmse_stderror: 1.28\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 4 batch_num: 4 val_rmse_target: 0.4763 val_rmse_stderror: 1.281\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 4 batch_num: 6 val_rmse_target: 0.475 val_rmse_stderror: 1.285\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.05 seconds\n","Epoch: 4 batch_num: 8 val_rmse_target: 0.4769 val_rmse_stderror: 1.289\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 4 batch_num: 10 val_rmse_target: 0.4805 val_rmse_stderror: 1.291\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","4 steps took 2.09 seconds\n","Epoch: 4 batch_num: 14 val_rmse_target: 0.4823 val_rmse_stderror: 1.291\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","4 steps took 2.09 seconds\n","Epoch: 4 batch_num: 18 val_rmse_target: 0.4775 val_rmse_stderror: 1.286\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 4 batch_num: 20 val_rmse_target: 0.4761 val_rmse_stderror: 1.283\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 4 batch_num: 22 val_rmse_target: 0.4774 val_rmse_stderror: 1.281\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.05 seconds\n","Epoch: 4 batch_num: 24 val_rmse_target: 0.4796 val_rmse_stderror: 1.28\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 4 batch_num: 26 val_rmse_target: 0.4804 val_rmse_stderror: 1.279\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","4 steps took 2.09 seconds\n","Epoch: 4 batch_num: 30 val_rmse_target: 0.4792 val_rmse_stderror: 1.281\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.05 seconds\n","Epoch: 4 batch_num: 32 val_rmse_target: 0.4787 val_rmse_stderror: 1.282\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 4 batch_num: 34 val_rmse_target: 0.4796 val_rmse_stderror: 1.284\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 4 batch_num: 36 val_rmse_target: 0.4822 val_rmse_stderror: 1.286\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","4 steps took 2.09 seconds\n","Epoch: 4 batch_num: 40 val_rmse_target: 0.4834 val_rmse_stderror: 1.286\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","4 steps took 2.09 seconds\n","Epoch: 4 batch_num: 44 val_rmse_target: 0.4804 val_rmse_stderror: 1.284\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","4 steps took 2.09 seconds\n","Epoch: 4 batch_num: 48 val_rmse_target: 0.4786 val_rmse_stderror: 1.284\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.05 seconds\n","Epoch: 4 batch_num: 50 val_rmse_target: 0.478 val_rmse_stderror: 1.284\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 4 batch_num: 52 val_rmse_target: 0.4782 val_rmse_stderror: 1.285\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 4 batch_num: 54 val_rmse_target: 0.4783 val_rmse_stderror: 1.284\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 4 batch_num: 56 val_rmse_target: 0.4781 val_rmse_stderror: 1.284\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.05 seconds\n","Epoch: 4 batch_num: 58 val_rmse_target: 0.4778 val_rmse_stderror: 1.284\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 4 batch_num: 60 val_rmse_target: 0.4777 val_rmse_stderror: 1.284\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 4 batch_num: 62 val_rmse_target: 0.478 val_rmse_stderror: 1.284\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 4 batch_num: 64 val_rmse_target: 0.4782 val_rmse_stderror: 1.285\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 4 batch_num: 66 val_rmse_target: 0.4785 val_rmse_stderror: 1.285\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 4 batch_num: 68 val_rmse_target: 0.4787 val_rmse_stderror: 1.285\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 4 batch_num: 70 val_rmse_target: 0.4789 val_rmse_stderror: 1.285\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 4 batch_num: 72 val_rmse_target: 0.479 val_rmse_stderror: 1.286\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 4 batch_num: 74 val_rmse_target: 0.4789 val_rmse_stderror: 1.286\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.05 seconds\n","Epoch: 4 batch_num: 76 val_rmse_target: 0.4783 val_rmse_stderror: 1.286\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 4 batch_num: 78 val_rmse_target: 0.4778 val_rmse_stderror: 1.286\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 4 batch_num: 80 val_rmse_target: 0.4772 val_rmse_stderror: 1.286\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.05 seconds\n","Epoch: 4 batch_num: 82 val_rmse_target: 0.4767 val_rmse_stderror: 1.286\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.05 seconds\n","Epoch: 4 batch_num: 84 val_rmse_target: 0.4764 val_rmse_stderror: 1.286\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 4 batch_num: 86 val_rmse_target: 0.4762 val_rmse_stderror: 1.286\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 4 batch_num: 88 val_rmse_target: 0.476 val_rmse_stderror: 1.286\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 4 batch_num: 90 val_rmse_target: 0.476 val_rmse_stderror: 1.286\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 4 batch_num: 92 val_rmse_target: 0.476 val_rmse_stderror: 1.286\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 4 batch_num: 94 val_rmse_target: 0.476 val_rmse_stderror: 1.285\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 4 batch_num: 96 val_rmse_target: 0.4759 val_rmse_stderror: 1.285\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 4 batch_num: 98 val_rmse_target: 0.4757 val_rmse_stderror: 1.285\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 4 batch_num: 100 val_rmse_target: 0.4756 val_rmse_stderror: 1.285\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 4 batch_num: 102 val_rmse_target: 0.4755 val_rmse_stderror: 1.285\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 4 batch_num: 104 val_rmse_target: 0.4755 val_rmse_stderror: 1.284\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.05 seconds\n","Epoch: 4 batch_num: 106 val_rmse_target: 0.4755 val_rmse_stderror: 1.284\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 4 batch_num: 108 val_rmse_target: 0.4755 val_rmse_stderror: 1.285\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.05 seconds\n","Epoch: 4 batch_num: 110 val_rmse_target: 0.4756 val_rmse_stderror: 1.285\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.05 seconds\n","Epoch: 4 batch_num: 112 val_rmse_target: 0.4756 val_rmse_stderror: 1.285\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 4 batch_num: 114 val_rmse_target: 0.4756 val_rmse_stderror: 1.285\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 4 batch_num: 116 val_rmse_target: 0.4756 val_rmse_stderror: 1.285\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 4 batch_num: 118 val_rmse_target: 0.4756 val_rmse_stderror: 1.285\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.05 seconds\n","Epoch: 4 batch_num: 120 val_rmse_target: 0.4756 val_rmse_stderror: 1.285\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 4 batch_num: 122 val_rmse_target: 0.4756 val_rmse_stderror: 1.285\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.05 seconds\n","Epoch: 4 batch_num: 124 val_rmse_target: 0.4756 val_rmse_stderror: 1.285\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 4 batch_num: 126 val_rmse_target: 0.4756 val_rmse_stderror: 1.285\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 4 batch_num: 128 val_rmse_target: 0.4756 val_rmse_stderror: 1.285\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 4 batch_num: 130 val_rmse_target: 0.4756 val_rmse_stderror: 1.285\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 4 batch_num: 132 val_rmse_target: 0.4756 val_rmse_stderror: 1.285\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 4 batch_num: 134 val_rmse_target: 0.4756 val_rmse_stderror: 1.285\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 4 batch_num: 136 val_rmse_target: 0.4756 val_rmse_stderror: 1.285\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 4 batch_num: 138 val_rmse_target: 0.4756 val_rmse_stderror: 1.285\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","2 steps took 1.04 seconds\n","Epoch: 4 batch_num: 140 val_rmse_target: 0.4756 val_rmse_stderror: 1.285\n","Still best_val_rmse: 0.4732 (from epoch 3)\n","\n","Performance estimates:\n","[0.4715036928208487, 0.4985938457861796, 0.45480021516657915, 0.4731537771199186]\n","Mean: 0.4745128827233815\n","\n","Fold 5/5\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"stream","text":["\n","16 steps took 8.71 seconds\n","Epoch: 0 batch_num: 16 val_rmse_target: 0.9344 val_rmse_stderror: 0.9963\n","New best_val_rmse: 0.9344\n","\n","16 steps took 8.23 seconds\n","Epoch: 0 batch_num: 32 val_rmse_target: 0.7823 val_rmse_stderror: 0.9671\n","New best_val_rmse: 0.7823\n","\n","16 steps took 8.22 seconds\n","Epoch: 0 batch_num: 48 val_rmse_target: 0.6935 val_rmse_stderror: 0.9711\n","New best_val_rmse: 0.6935\n","\n","16 steps took 8.22 seconds\n","Epoch: 0 batch_num: 64 val_rmse_target: 0.7316 val_rmse_stderror: 1.003\n","Still best_val_rmse: 0.6935 (from epoch 0)\n","\n","16 steps took 8.22 seconds\n","Epoch: 0 batch_num: 80 val_rmse_target: 0.7086 val_rmse_stderror: 1.001\n","Still best_val_rmse: 0.6935 (from epoch 0)\n","\n","16 steps took 8.22 seconds\n","Epoch: 0 batch_num: 96 val_rmse_target: 0.6042 val_rmse_stderror: 1.012\n","New best_val_rmse: 0.6042\n","\n","16 steps took 8.23 seconds\n","Epoch: 0 batch_num: 112 val_rmse_target: 0.5802 val_rmse_stderror: 1.02\n","New best_val_rmse: 0.5802\n","\n","16 steps took 8.21 seconds\n","Epoch: 0 batch_num: 128 val_rmse_target: 0.552 val_rmse_stderror: 1.008\n","New best_val_rmse: 0.552\n","\n","16 steps took 8.35 seconds\n","Epoch: 1 batch_num: 3 val_rmse_target: 0.5514 val_rmse_stderror: 1.002\n","New best_val_rmse: 0.5514\n","\n","16 steps took 8.22 seconds\n","Epoch: 1 batch_num: 19 val_rmse_target: 0.5398 val_rmse_stderror: 1.014\n","New best_val_rmse: 0.5398\n","\n","16 steps took 8.23 seconds\n","Epoch: 1 batch_num: 35 val_rmse_target: 0.5612 val_rmse_stderror: 1.0\n","Still best_val_rmse: 0.5398 (from epoch 1)\n","\n","16 steps took 8.22 seconds\n","Epoch: 1 batch_num: 51 val_rmse_target: 0.5438 val_rmse_stderror: 1.016\n","Still best_val_rmse: 0.5398 (from epoch 1)\n","\n","16 steps took 8.21 seconds\n","Epoch: 1 batch_num: 67 val_rmse_target: 0.5638 val_rmse_stderror: 1.002\n","Still best_val_rmse: 0.5398 (from epoch 1)\n","\n","16 steps took 8.22 seconds\n","Epoch: 1 batch_num: 83 val_rmse_target: 0.5352 val_rmse_stderror: 1.005\n","New best_val_rmse: 0.5352\n","\n","16 steps took 8.21 seconds\n","Epoch: 1 batch_num: 99 val_rmse_target: 0.5622 val_rmse_stderror: 0.9992\n","Still best_val_rmse: 0.5352 (from epoch 1)\n","\n","16 steps took 8.22 seconds\n","Epoch: 1 batch_num: 115 val_rmse_target: 0.513 val_rmse_stderror: 1.002\n","New best_val_rmse: 0.513\n","\n","16 steps took 8.21 seconds\n","Epoch: 1 batch_num: 131 val_rmse_target: 0.5035 val_rmse_stderror: 0.9969\n","New best_val_rmse: 0.5035\n","\n","16 steps took 8.36 seconds\n","Epoch: 2 batch_num: 6 val_rmse_target: 0.5032 val_rmse_stderror: 1.001\n","New best_val_rmse: 0.5032\n","\n","16 steps took 8.23 seconds\n","Epoch: 2 batch_num: 22 val_rmse_target: 0.5088 val_rmse_stderror: 1.016\n","Still best_val_rmse: 0.5032 (from epoch 2)\n","\n","16 steps took 8.22 seconds\n","Epoch: 2 batch_num: 38 val_rmse_target: 0.5088 val_rmse_stderror: 1.016\n","Still best_val_rmse: 0.5032 (from epoch 2)\n","\n","16 steps took 8.21 seconds\n","Epoch: 2 batch_num: 54 val_rmse_target: 0.5134 val_rmse_stderror: 1.015\n","Still best_val_rmse: 0.5032 (from epoch 2)\n","\n","16 steps took 8.22 seconds\n","Epoch: 2 batch_num: 70 val_rmse_target: 0.541 val_rmse_stderror: 1.01\n","Still best_val_rmse: 0.5032 (from epoch 2)\n","\n","16 steps took 8.21 seconds\n","Epoch: 2 batch_num: 86 val_rmse_target: 0.5019 val_rmse_stderror: 1.004\n","New best_val_rmse: 0.5019\n","\n","16 steps took 8.23 seconds\n","Epoch: 2 batch_num: 102 val_rmse_target: 0.5098 val_rmse_stderror: 1.01\n","Still best_val_rmse: 0.5019 (from epoch 2)\n","\n","16 steps took 8.21 seconds\n","Epoch: 2 batch_num: 118 val_rmse_target: 0.5166 val_rmse_stderror: 1.016\n","Still best_val_rmse: 0.5019 (from epoch 2)\n","\n","16 steps took 8.21 seconds\n","Epoch: 2 batch_num: 134 val_rmse_target: 0.5209 val_rmse_stderror: 1.006\n","Still best_val_rmse: 0.5019 (from epoch 2)\n","\n","16 steps took 8.38 seconds\n","Epoch: 3 batch_num: 9 val_rmse_target: 0.5066 val_rmse_stderror: 1.005\n","Still best_val_rmse: 0.5019 (from epoch 2)\n","\n","16 steps took 8.23 seconds\n","Epoch: 3 batch_num: 25 val_rmse_target: 0.5039 val_rmse_stderror: 1.013\n","Still best_val_rmse: 0.5019 (from epoch 2)\n","\n","16 steps took 8.24 seconds\n","Epoch: 3 batch_num: 41 val_rmse_target: 0.5065 val_rmse_stderror: 1.005\n","Still best_val_rmse: 0.5019 (from epoch 2)\n","\n","16 steps took 8.24 seconds\n","Epoch: 3 batch_num: 57 val_rmse_target: 0.5024 val_rmse_stderror: 1.006\n","Still best_val_rmse: 0.5019 (from epoch 2)\n","\n","16 steps took 8.22 seconds\n","Epoch: 3 batch_num: 73 val_rmse_target: 0.5017 val_rmse_stderror: 1.01\n","New best_val_rmse: 0.5017\n","\n","16 steps took 8.22 seconds\n","Epoch: 3 batch_num: 89 val_rmse_target: 0.4986 val_rmse_stderror: 1.003\n","New best_val_rmse: 0.4986\n","\n","8 steps took 4.11 seconds\n","Epoch: 3 batch_num: 97 val_rmse_target: 0.499 val_rmse_stderror: 1.011\n","Still best_val_rmse: 0.4986 (from epoch 3)\n","\n","8 steps took 4.1 seconds\n","Epoch: 3 batch_num: 105 val_rmse_target: 0.4978 val_rmse_stderror: 1.009\n","New best_val_rmse: 0.4978\n","\n","8 steps took 4.1 seconds\n","Epoch: 3 batch_num: 113 val_rmse_target: 0.4998 val_rmse_stderror: 1.003\n","Still best_val_rmse: 0.4978 (from epoch 3)\n","\n","8 steps took 4.1 seconds\n","Epoch: 3 batch_num: 121 val_rmse_target: 0.5012 val_rmse_stderror: 1.009\n","Still best_val_rmse: 0.4978 (from epoch 3)\n","\n","16 steps took 8.21 seconds\n","Epoch: 3 batch_num: 137 val_rmse_target: 0.5012 val_rmse_stderror: 1.009\n","Still best_val_rmse: 0.4978 (from epoch 3)\n","\n","16 steps took 8.35 seconds\n","Epoch: 4 batch_num: 12 val_rmse_target: 0.5009 val_rmse_stderror: 1.006\n","Still best_val_rmse: 0.4978 (from epoch 3)\n","\n","16 steps took 8.21 seconds\n","Epoch: 4 batch_num: 28 val_rmse_target: 0.5013 val_rmse_stderror: 1.008\n","Still best_val_rmse: 0.4978 (from epoch 3)\n","\n","16 steps took 8.22 seconds\n","Epoch: 4 batch_num: 44 val_rmse_target: 0.5003 val_rmse_stderror: 1.007\n","Still best_val_rmse: 0.4978 (from epoch 3)\n","\n","16 steps took 8.21 seconds\n","Epoch: 4 batch_num: 60 val_rmse_target: 0.5004 val_rmse_stderror: 1.007\n","Still best_val_rmse: 0.4978 (from epoch 3)\n","\n","16 steps took 8.21 seconds\n","Epoch: 4 batch_num: 76 val_rmse_target: 0.4996 val_rmse_stderror: 1.008\n","Still best_val_rmse: 0.4978 (from epoch 3)\n","\n","8 steps took 4.11 seconds\n","Epoch: 4 batch_num: 84 val_rmse_target: 0.5002 val_rmse_stderror: 1.008\n","Still best_val_rmse: 0.4978 (from epoch 3)\n","\n","16 steps took 8.22 seconds\n","Epoch: 4 batch_num: 100 val_rmse_target: 0.501 val_rmse_stderror: 1.008\n","Still best_val_rmse: 0.4978 (from epoch 3)\n","\n","16 steps took 8.23 seconds\n","Epoch: 4 batch_num: 116 val_rmse_target: 0.5012 val_rmse_stderror: 1.008\n","Still best_val_rmse: 0.4978 (from epoch 3)\n","\n","16 steps took 8.21 seconds\n","Epoch: 4 batch_num: 132 val_rmse_target: 0.5012 val_rmse_stderror: 1.008\n","Still best_val_rmse: 0.4978 (from epoch 3)\n","\n","Performance estimates:\n","[0.4715036928208487, 0.4985938457861796, 0.45480021516657915, 0.4731537771199186, 0.497774381223485]\n","Mean: 0.4791651824234022\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"m4v-cGx-Mv7S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626322873338,"user_tz":-540,"elapsed":29,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"ecfdf9c6-cc70-45c3-fae4-556115c8030b"},"source":["print(list_val_rmse)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[0.4715036928208487, 0.4985938457861796, 0.45480021516657915, 0.4731537771199186, 0.497774381223485]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"q2CdCMuIKDMP"},"source":["#rep = MemReporter(model)\n","#rep.report()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eLl1yDOOKIe7"},"source":["#rep = MemReporter(model.roberta)\n","#rep.report()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7qkqnknA_m9D"},"source":["#gpuinfo()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PwrqSMdYA6Pu"},"source":["#del model\n","#del optimizer \n","#del train_loader\n","#del val_loader\n","#del scheduler \n","#del list_val_rmse\n","#del train_indices\n","#del val_indices\n","#del tokenizer\n","#torch.cuda.empty_cache()\n","#gpuinfo()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wXcHyUSJXecL"},"source":["# Inference"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YIV6UllSIGoa","executionInfo":{"status":"ok","timestamp":1626322885188,"user_tz":-540,"elapsed":11866,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"f8f086c8-c2c5-4462-a570-3f62f6eb4501"},"source":["%cd\n","!mkdir .kaggle\n","!mkdir /content/model\n","!cp /content/drive/MyDrive/Colab_Files/kaggle-api/kaggle.json .kaggle/\n","\n","!cp -r /content/model_1.pth /content/model/model_1.pth\n","!cp -r /content/model_2.pth /content/model/model_2.pth\n","!cp -r /content/model_3.pth /content/model/model_3.pth\n","!cp -r /content/model_4.pth /content/model/model_4.pth\n","!cp -r /content/model_5.pth /content/model/model_5.pth"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/root\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"14ddOZH4IMam","executionInfo":{"status":"ok","timestamp":1626322941810,"user_tz":-540,"elapsed":56637,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"36ff26d7-a32a-4f34-e675-020e9f519bb1"},"source":["\n","\n","def dataset_upload():\n","    import json\n","    from kaggle.api.kaggle_api_extended import KaggleApi\n","\n","    id = f'{USERID}/{EX_NO}'\n","\n","    dataset_metadata = {}\n","    dataset_metadata['id'] = id\n","    dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n","    dataset_metadata['title'] = f'{EX_NO}'\n","\n","    with open(UPLOAD_DIR / 'dataset-metadata.json', 'w') as f:\n","        json.dump(dataset_metadata, f, indent=4)\n","\n","    api = KaggleApi()\n","    api.authenticate()\n","\n","    # データセットがない場合\n","    if f'{USERID}/{EX_NO}' not in [str(d) for d in api.dataset_list(user=USERID, search=f'\"{EX_NO}\"')]:\n","        api.dataset_create_new(folder=UPLOAD_DIR,\n","                               convert_to_csv=False,\n","                               dir_mode='skip')\n","    # データセットがある場合\n","    else:\n","        api.dataset_create_version(folder=UPLOAD_DIR,\n","                                   version_notes='update',\n","                                   convert_to_csv=False,\n","                                   delete_old_versions=True,\n","                                   dir_mode='skip')\n","dataset_upload()\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\r  0%|          | 0.00/477M [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Starting upload for file model_2.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 477M/477M [00:10<00:00, 49.4MB/s]\n","  0%|          | 0.00/477M [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_2.pth (477MB)\n","Starting upload for file model_3.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 477M/477M [00:09<00:00, 50.7MB/s]\n","  0%|          | 0.00/477M [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_3.pth (477MB)\n","Starting upload for file model_5.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 477M/477M [00:09<00:00, 50.8MB/s]\n","  0%|          | 0.00/477M [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_5.pth (477MB)\n","Starting upload for file model_4.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 477M/477M [00:10<00:00, 47.3MB/s]\n","  0%|          | 0.00/477M [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_4.pth (477MB)\n","Starting upload for file model_1.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 477M/477M [00:09<00:00, 51.6MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_1.pth (477MB)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"huJwVMSAPuDO"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0zzuBPobmLFu"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wpc8ro9hmNci"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ceDI72NumT5-"},"source":[""],"execution_count":null,"outputs":[]}]}