{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"048-train-02.ipynb","provenance":[{"file_id":"17V-_oEoc7G-20Mk78qNMJWU1Of9PfFTH","timestamp":1626946997184},{"file_id":"17a4F4aC9L0QBqU8BRTrdqPn0WwJ0b08b","timestamp":1626746992716},{"file_id":"1G_W9irFTrEmDeHR0S6_u0bjpk8nxipXW","timestamp":1626689695352},{"file_id":"1bhhkorT--y8XXaVLM8hibVgC-tLqZ16P","timestamp":1626358153868},{"file_id":"1WtT2hX6O9Qbt_hb9sF50nM2QmDXFi-XA","timestamp":1626338366006},{"file_id":"1k_p5wftcUeo711Xho1-T5an2Xkneau-J","timestamp":1626323813472},{"file_id":"1Vz2GB2BNTWuefEFkCSh3TBPEIel7KG1t","timestamp":1626317426487},{"file_id":"1djoMWojeaIPopG5tS1jNMohn8ineblRh","timestamp":1626306831897},{"file_id":"1-6tlDO8158Pi6TpptIF884oFaEiT4Uxb","timestamp":1626276420047},{"file_id":"1js8eA3mDNS8mwSpCiHuzPeARFlUPAVrg","timestamp":1626272452526},{"file_id":"1yhcPgulwJtjJKUK9IuRKmNMhJ-4YXGol","timestamp":1626267205517},{"file_id":"1mnnSv0Pofn1QxArywV81VYqnZPB8uUWN","timestamp":1626180468522},{"file_id":"1RRdjt_UAeHmr5QQBAMyC82Fq1s31OWdK","timestamp":1625833136005},{"file_id":"1JPgg44HFemzwk8VSCXih3PejL0idy-C4","timestamp":1625825483466},{"file_id":"1Ye6wqVX71xAAAhmjXkw9IpRvTqeUyJDA","timestamp":1625812137500}],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":120},"id":"Z6yRwt-PXtbP","executionInfo":{"status":"ok","timestamp":1626953585455,"user_tz":-540,"elapsed":343,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"47e2d1f9-0ce9-4579-d70b-31560608a06c"},"source":["\"\"\"\n","if 'google.colab' in sys.modules:  # colab環境特有の処理_初回のみ\n","  # Google Driveのマウント\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","\n","  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules' \\\n","   -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/requirements.txt' \\\n","   --ignore-installed\n","\n","  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules' \\\n","   transformers -U\n","  !pip install gensim==4.0.1 --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\n","  !pip install pytorch_memlab --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\n","\"\"\""],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\nif 'google.colab' in sys.modules:  # colab環境特有の処理_初回のみ\\n  # Google Driveのマウント\\n  from google.colab import drive\\n  drive.mount('/content/drive')\\n\\n  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'    -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/requirements.txt'    --ignore-installed\\n\\n  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'    transformers -U\\n  !pip install gensim==4.0.1 --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\\n  !pip install pytorch_memlab --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\\n\""]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ucCbvGD1XvG7","executionInfo":{"status":"ok","timestamp":1626953863527,"user_tz":-540,"elapsed":277593,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"b94e395b-f94f-4b06-dcfa-996a1a7cfff9"},"source":["import sys\n","if 'google.colab' in sys.modules:  # colab特有の処理_2回目以降\n","  # Google Driveのマウント\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","\n","  # データセットをDriveから取得\n","  !mkdir -p 'input'\n","  !cp -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/00_input/commonlitreadabilityprize/' '/content/input'\n","  !cp -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/97_pre_trained/clrp_pretrained_manish_epoch5' '/content/clrp-roberta-large'\n","  # ライブラリのパス指定\n","  sys.path.append('/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules')\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"N6kqvVoPrnpj","executionInfo":{"status":"ok","timestamp":1626953863529,"user_tz":-540,"elapsed":40,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"7d6fd039-fce1-4ccb-e28b-5cd05fac419a"},"source":["\"\"\"\n","%cd\n","!mkdir .kaggle\n","!mkdir /content/model\n","!cp /content/drive/MyDrive/Colab_Files/kaggle-api/kaggle.json .kaggle/\n","\"\"\""],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\n%cd\\n!mkdir .kaggle\\n!mkdir /content/model\\n!cp /content/drive/MyDrive/Colab_Files/kaggle-api/kaggle.json .kaggle/\\n'"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":69},"id":"Axihy1acGjie","executionInfo":{"status":"ok","timestamp":1626953863530,"user_tz":-540,"elapsed":23,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"6d596cc3-3975-488c-c2dd-fc2a16fcbcae"},"source":["\"\"\"\n","!mkdir /content/pre-trained-roberta\n","!kaggle datasets download -p /content/pre-trained-roberta clrprobertalarge --unzip\n","!cp -r /content/pre-trained-roberta/ /content/drive/MyDrive/Colab_Files/kaggle/commonlit/97_pre_trained/clrp_pretrained_manish_epoch5\n","\"\"\""],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\n!mkdir /content/pre-trained-roberta\\n!kaggle datasets download -p /content/pre-trained-roberta clrprobertalarge --unzip\\n!cp -r /content/pre-trained-roberta/ /content/drive/MyDrive/Colab_Files/kaggle/commonlit/97_pre_trained/clrp_pretrained_manish_epoch5\\n'"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"RV9-VwbpZLZ9","executionInfo":{"status":"ok","timestamp":1626953863531,"user_tz":-540,"elapsed":21,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["from pathlib import Path\n","\n","# input\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    DATA_DIR = Path('../input/commonlitreadabilityprize/')\n","\n","elif 'google.colab' in sys.modules: # Colab環境\n","    DATA_DIR = Path('/content/input/commonlitreadabilityprize')\n","\n","else:\n","    DATA_DIR = Path('../00_input/commonlitreadabilityprize/')"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"x5difyXe00UV","executionInfo":{"status":"ok","timestamp":1626954101773,"user_tz":-540,"elapsed":341,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["from pathlib import Path\n","\n","# tokenizer\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    TOKENIZER_DIR = '../input/roberta-transformers-pytorch/roberta-large'\n","elif 'google.colab' in sys.modules: # Colab環境\n","    TOKENIZER_DIR = '/content/clrp-roberta-large/clrp_pretrained_manish_epoch5/pre-trained-roberta/clrp_roberta_large' # 仮で、毎回DLする想定のモデル名を指定。あとで変更予定。\n","else:\n","    TOKENIZER_DIR = 'roberta-large'"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"tKjsUxnOeDYl","executionInfo":{"status":"ok","timestamp":1626954103074,"user_tz":-540,"elapsed":4,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["from pathlib import Path\n","\n","# pre-trained model\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    PRE_TRAINED_MODEL_DIR = '../input/roberta-transformers-pytorch/roberta-large'\n","elif 'google.colab' in sys.modules: # Colab環境\n","    PRE_TRAINED_MODEL_DIR = '/content/clrp-roberta-large/clrp_pretrained_manish_epoch5/pre-trained-roberta/clrp_roberta_large' # 仮で、毎回DLする想定のモデル名を指定。あとで変更予定。\n","else:\n","    PRE_TRAINED_MODEL_DIR = 'roberta-large'"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZLaT2V0ReoAZ","executionInfo":{"status":"ok","timestamp":1626954113706,"user_tz":-540,"elapsed":538,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["UPLOAD_DIR = Path('/content/model')\n","EX_NO = '048-train-02'  # 実験番号などを入れる、folderのpathにする\n","USERID = 'calpis10000'"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"hOGjAb4pAJ0F","executionInfo":{"status":"ok","timestamp":1626954116385,"user_tz":-540,"elapsed":510,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["import subprocess\n","import shlex\n","\n","def gpuinfo():\n","    \"\"\"\n","    Returns size of total GPU RAM and used GPU RAM.\n","\n","    Parameters\n","    ----------\n","    None\n","\n","    Returns\n","    -------\n","    info : dict\n","        Total GPU RAM in integer for key 'total_MiB'.\n","        Used GPU RAM in integer for key 'used_MiB'.\n","    \"\"\"\n","\n","    command = 'nvidia-smi -q -d MEMORY | sed -n \"/FB Memory Usage/,/Free/p\" | sed -e \"1d\" -e \"4d\" -e \"s/ MiB//g\" | cut -d \":\" -f 2 | cut -c2-'\n","    commands = [shlex.split(part) for part in command.split(' | ')]\n","    for i, cmd in enumerate(commands):\n","        if i==0:\n","            res = subprocess.Popen(cmd, stdout=subprocess.PIPE)\n","        else:\n","            res = subprocess.Popen(cmd, stdin=res.stdout, stdout=subprocess.PIPE)\n","    total, used = map(int, res.communicate()[0].decode('utf-8').strip().split('\\n'))\n","    info = {'total_MiB':total, 'used_MiB':used}\n","    return info\n"],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g3-6m5MKXecB"},"source":["# Overview\n","This nb is based on copy from https://www.kaggle.com/andretugan/lightweight-roberta-solution-in-pytorch .\n","\n","Acknowledgments(from base nb): \n","some ideas were taken from kernels by [Torch](https://www.kaggle.com/rhtsingh) and [Maunish](https://www.kaggle.com/maunish)."]},{"cell_type":"code","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-04T06:26:32.834365Z","iopub.execute_input":"2021-07-04T06:26:32.834903Z","iopub.status.idle":"2021-07-04T06:26:40.143740Z","shell.execute_reply.started":"2021-07-04T06:26:32.834785Z","shell.execute_reply":"2021-07-04T06:26:40.142864Z"},"trusted":true,"id":"HRsRZ06WXecD","executionInfo":{"status":"ok","timestamp":1626954118333,"user_tz":-540,"elapsed":409,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["import os\n","import math\n","import random\n","import time\n","\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","\n","from transformers import AdamW # optimizer\n","from transformers import AutoTokenizer\n","from transformers import AutoModel\n","from transformers import AutoConfig\n","from transformers import get_cosine_schedule_with_warmup # scheduler\n","from pytorch_memlab import profile\n","import pytorch_memlab\n","from pytorch_memlab import MemReporter\n","\n","from sklearn.model_selection import KFold, StratifiedKFold\n","\n","import gc\n","gc.enable()"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.145217Z","iopub.execute_input":"2021-07-04T06:26:40.145539Z","iopub.status.idle":"2021-07-04T06:26:40.201326Z","shell.execute_reply.started":"2021-07-04T06:26:40.145504Z","shell.execute_reply":"2021-07-04T06:26:40.200136Z"},"trusted":true,"id":"omBfwshTXecE","executionInfo":{"status":"ok","timestamp":1626954120092,"user_tz":-540,"elapsed":4,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["NUM_FOLDS = 5 # K Fold\n","NUM_EPOCHS = 5 # Epochs\n","BATCH_SIZE = 12 # Batch Size\n","MAX_LEN = 248 # ベクトル長\n","EVAL_SCHEDULE = [(0.55, 64), (0.50, 32), (0.49, 16), (0.48, 8), (0.47, 4), (0.46, 2), (-1., 1)] # schedulerの何らかの設定？\n","ROBERTA_PATH = PRE_TRAINED_MODEL_DIR # roberta pre-trainedモデル(モデルとして指定)\n","TOKENIZER_PATH = TOKENIZER_DIR # roberta pre-trainedモデル(Tokenizerとして指定)\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\" # cudaがなければcpuを使えばいいじゃない"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.203398Z","iopub.execute_input":"2021-07-04T06:26:40.204055Z","iopub.status.idle":"2021-07-04T06:26:40.211572Z","shell.execute_reply.started":"2021-07-04T06:26:40.204015Z","shell.execute_reply":"2021-07-04T06:26:40.210762Z"},"trusted":true,"id":"4qcuXqwtXecF","executionInfo":{"status":"ok","timestamp":1626954120431,"user_tz":-540,"elapsed":3,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["def set_random_seed(random_seed):\n","    random.seed(random_seed)\n","    np.random.seed(random_seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(random_seed)\n","\n","    torch.manual_seed(random_seed)\n","    torch.cuda.manual_seed(random_seed)\n","    torch.cuda.manual_seed_all(random_seed)\n","\n","    torch.backends.cudnn.deterministic = True# cudnnによる最適化で結果が変わらないためのおまじない "],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.214188Z","iopub.execute_input":"2021-07-04T06:26:40.214809Z","iopub.status.idle":"2021-07-04T06:26:40.309744Z","shell.execute_reply.started":"2021-07-04T06:26:40.214769Z","shell.execute_reply":"2021-07-04T06:26:40.308926Z"},"trusted":true,"id":"70PyLsJTXecF","executionInfo":{"status":"ok","timestamp":1626954121331,"user_tz":-540,"elapsed":414,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# train, testを読む\n","train_df = pd.read_csv(DATA_DIR/\"train.csv\")\n","\n","# Remove incomplete entries if any.\n","train_df.drop(train_df[(train_df.target == 0) & (train_df.standard_error == 0)].index,\n","              inplace=True)\n","train_df.reset_index(drop=True, inplace=True)\n","\n","test_df = pd.read_csv(DATA_DIR/\"test.csv\")\n","submission_df = pd.read_csv(DATA_DIR/\"sample_submission.csv\")"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"9ZYOB59L8qtA","executionInfo":{"status":"ok","timestamp":1626954121332,"user_tz":-540,"elapsed":9,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"6224406d-7cea-43d7-cb94-cc6b81471411"},"source":["train_df.head()\n"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>url_legal</th>\n","      <th>license</th>\n","      <th>excerpt</th>\n","      <th>target</th>\n","      <th>standard_error</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>c12129c31</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>When the young people returned to the ballroom...</td>\n","      <td>-0.340259</td>\n","      <td>0.464009</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>85aa80a4c</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>All through dinner time, Mrs. Fayre was somewh...</td>\n","      <td>-0.315372</td>\n","      <td>0.480805</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>b69ac6792</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>As Roger had predicted, the snow departed as q...</td>\n","      <td>-0.580118</td>\n","      <td>0.476676</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>dd1000b26</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>And outside before the palace a great garden w...</td>\n","      <td>-1.054013</td>\n","      <td>0.450007</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>37c1b32fb</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Once upon a time there were Three Bears who li...</td>\n","      <td>0.247197</td>\n","      <td>0.510845</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          id url_legal  ...    target standard_error\n","0  c12129c31       NaN  ... -0.340259       0.464009\n","1  85aa80a4c       NaN  ... -0.315372       0.480805\n","2  b69ac6792       NaN  ... -0.580118       0.476676\n","3  dd1000b26       NaN  ... -1.054013       0.450007\n","4  37c1b32fb       NaN  ...  0.247197       0.510845\n","\n","[5 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.311021Z","iopub.execute_input":"2021-07-04T06:26:40.311347Z","iopub.status.idle":"2021-07-04T06:26:40.624393Z","shell.execute_reply.started":"2021-07-04T06:26:40.311314Z","shell.execute_reply":"2021-07-04T06:26:40.623347Z"},"trusted":true,"id":"xf0662k4XecF","executionInfo":{"status":"ok","timestamp":1626954122548,"user_tz":-540,"elapsed":633,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# tokenizerを指定\n","tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N6aaghNkXecG"},"source":["# Dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IJ2N6JcvmyD2","executionInfo":{"status":"ok","timestamp":1626954129054,"user_tz":-540,"elapsed":3308,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"8227f726-1ad5-421d-bd75-0245a21a5460"},"source":["# 前処理用\n","import string\n","import re\n","# ローカルの場合、stopwordsをダウンロード\n","import nltk\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    pass\n","else:\n","    import nltk\n","    nltk.download('stopwords')\n","    nltk.download('averaged_perceptron_tagger')\n","    os.listdir(os.path.expanduser('~/nltk_data/corpora/stopwords/'))\n","\n","# テキスト前処理\n","# https://www.kaggle.com/alaasedeeq/commonlit-readability-eda\n","\n","#filtering the unwanted symbols, spaces, ....etc\n","to_replace_by_space = re.compile('[/(){}\\[\\]|@,;]')\n","punctuation = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n","bad_symbols = re.compile('[^0-9a-z #+_]')\n","stopwords = set(nltk.corpus.stopwords.words('english'))\n","\n","def text_prepare(text):\n","    '''\n","    text: a string\n","    returna modified version of the string\n","    '''\n","    text = text.lower() # lowercase text\n","    text = re.sub(punctuation, '',text)\n","    text = re.sub(to_replace_by_space, \" \", text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n","    text = re.sub(bad_symbols, \"\", text)         # delete symbols which are in BAD_SYMBOLS_RE from text\n","    text = \" \".join([word for word in text.split(\" \") if word not in stopwords]) # delete stopwords from text\n","    text = re.sub(' +', ' ', text)\n","    return text\n","\n","def text_normalization(s:pd.Series):\n","    x = s.apply(text_prepare)\n","    return x\n","\n","# Counterオブジェクトを取得\n","def get_counter(text:str):\n","    text_list = [wrd for wrd in text.split(\" \") if wrd not in ('', '\\n')]\n","    counter = collections.Counter(text_list)\n","    return counter\n"],"execution_count":26,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.628883Z","iopub.execute_input":"2021-07-04T06:26:40.629347Z","iopub.status.idle":"2021-07-04T06:26:40.644338Z","shell.execute_reply.started":"2021-07-04T06:26:40.629309Z","shell.execute_reply":"2021-07-04T06:26:40.643336Z"},"trusted":true,"id":"zkopT0U1XecG","executionInfo":{"status":"ok","timestamp":1626954130522,"user_tz":-540,"elapsed":4,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# Dataset用のClass。おそらく、trainとtestでインスタンスを生成し、DataFrameと同じように扱えるような思想。\n","class LitDataset(Dataset):\n","    def __init__(self, df, inference_only=False):\n","        super().__init__()\n","\n","        self.df = df        \n","        self.inference_only = inference_only # Testデータ用フラグ\n","        self.text = df.excerpt.tolist() # 分析対象カラムをlistにする。(分かち書きではなく、Seriesをlistへ変換するような処理)\n","        #self.text = [text.replace(\"\\n\", \" \") for text in self.text] # 単語単位で分かち書きする場合\n","        self.text_len = text_normalization(df.excerpt).map(lambda x: [0 if i >= len(x.split(' ')) else len(x.split(' ')[i]) for i in range(132)])\n","\n","        if not self.inference_only:\n","            self.target = torch.tensor(df.target.values, dtype=torch.float32) # trainのみ、targetをtensorに変換\n","            self.standard_error = torch.tensor(df.standard_error.values, dtype=torch.float32) \n","\n","        self.encoded = tokenizer.batch_encode_plus( # textをtokenize\n","            self.text,\n","            padding = 'max_length',            \n","            max_length = MAX_LEN,\n","            truncation = True, # 最大長を超える文字は切り捨て\n","            return_attention_mask=True\n","        )        \n"," \n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    \n","    def __getitem__(self, index): # 変換結果を返す\n","        input_ids = torch.tensor(self.encoded['input_ids'][index])\n","        attention_mask = torch.tensor(self.encoded['attention_mask'][index])\n","        input_len = torch.tensor(self.text_len.iloc[index], dtype=torch.float32)\n","\n","        if self.inference_only:\n","            return (input_ids, attention_mask, input_len)            \n","        else:\n","            target = self.target[index]\n","            standard_error = self.standard_error[index]\n","            return (input_ids, attention_mask, input_len, target, standard_error)"],"execution_count":27,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KKtdy32wXecG"},"source":["# Model\n","The model is inspired by the one from [Maunish](https://www.kaggle.com/maunish/clrp-roberta-svm)."]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.649629Z","iopub.execute_input":"2021-07-04T06:26:40.650066Z","iopub.status.idle":"2021-07-04T06:26:40.666374Z","shell.execute_reply.started":"2021-07-04T06:26:40.650002Z","shell.execute_reply":"2021-07-04T06:26:40.665211Z"},"trusted":true,"id":"BpkxjXEUXecH","executionInfo":{"status":"ok","timestamp":1626954132323,"user_tz":-540,"elapsed":3,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["class LitModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        config = AutoConfig.from_pretrained(ROBERTA_PATH) # pretrainedからconfigを読み込み\n","        config.update({\"output_hidden_states\":True, # config更新: embedding層を抽出\n","                       \"hidden_dropout_prob\": 0.0, # config更新: dropoutしない\n","                       \"layer_norm_eps\": 1e-7}) # config更新: layer normalizationのepsilon                      \n","        \n","        self.roberta = AutoModel.from_pretrained(ROBERTA_PATH, config=config) # cpuで処理する\n","            \n","        self.attention = nn.Sequential(# attentionレイヤー            \n","            nn.Linear(config.hidden_size, 512),      \n","            nn.Tanh(),                       \n","            nn.Linear(512, 1),\n","            nn.Softmax(dim=1)\n","        )\n","\n","        self.conv1_layers = nn.Sequential(\n","            nn.Conv1d(1, 16, kernel_size=3, stride=1),\n","            nn.BatchNorm1d(16),\n","            nn.ReLU(),\n","            nn.MaxPool1d(kernel_size=3, stride=2),\n","\n","            nn.Conv1d(16, 64, kernel_size=3, stride=1),\n","            nn.BatchNorm1d(64),\n","            nn.Conv1d(64, 256, kernel_size=3, stride=1),\n","            nn.AdaptiveAvgPool1d(1)\n","        )\n","\n","        self.regressor = nn.Sequential( # 出力レイヤー                    \n","            nn.Linear(config.hidden_size + 256, 2)                        \n","        )\n","\n","    def forward(self, input_ids, attention_mask, input_len):\n","        roberta_output = self.roberta(input_ids=input_ids, # robertaに入力データを流し、出力としてrobertaモデル(layerの複合体)を得る\n","                                      attention_mask=attention_mask)     \n","        # attention_pooling\n","        last_hidden_state = roberta_output.hidden_states[-1] # robertaモデルの最後のlayerを得る\n","        weights = self.attention(last_hidden_state) # robertaの最後のlayerをattentionへ入力し、出力として重みを得る                \n","        context_vector = torch.sum(weights * last_hidden_state, dim=1) # 重み×最後の層を足し合わせて文書ベクトルとする。\n","\n","        # word_length_conv1d\n","        input_chnl = input_len.unsqueeze(1)\n","        conv1_layers = self.conv1_layers(input_chnl)\n","        conv1_layers_v = conv1_layers.view(conv1_layers.size(0),-1)\n","\n","        # concat_embeddings\n","        cat_embeddings = torch.cat([context_vector, conv1_layers_v], dim=1)\n","        \n","        return self.regressor(cat_embeddings) # 文書ベクトルを線形層に入力し、targetを出力する\n","\n","        # https://www.kaggle.com/rhtsingh/utilizing-transformer-representations-efficiently\n","        #last_hidden_state = roberta_output[0]\n","        #input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        #sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        #sum_mask = input_mask_expanded.sum(1)\n","        #sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        #mean_embeddings = sum_embeddings / sum_mask\n","\n","        \n","        # Now we reduce the context vector to the prediction score.\n","        #return self.regressor(mean_embeddings) # 文書ベクトルを線形層に入力し、targetを出力する"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.672515Z","iopub.execute_input":"2021-07-04T06:26:40.672944Z","iopub.status.idle":"2021-07-04T06:26:40.684593Z","shell.execute_reply.started":"2021-07-04T06:26:40.672908Z","shell.execute_reply":"2021-07-04T06:26:40.683569Z"},"trusted":true,"id":"bB4jvQTxXecH","executionInfo":{"status":"ok","timestamp":1626954132868,"user_tz":-540,"elapsed":3,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 評価指標(MSE)の計算。最終的に、ルートしてRMSEにすると思われる。\n","def eval_mse(model, data_loader):\n","    \"\"\"Evaluates the mean squared error of the |model| on |data_loader|\"\"\"\n","    model.eval() # evalモードを選択。Batch Normとかdropoutをしなくなる           \n","    mse_mean_sum = 0\n","    mse_std_sum = 0\n","\n","    with torch.no_grad(): # 勾配の計算をしないBlock\n","        for batch_num, (input_ids, attention_mask, input_len, target, standard_error) in enumerate(data_loader): # data_loaderからinput, attentin_mask, targetをbatchごとに取り出す\n","            input_ids = input_ids.to(DEVICE)   \n","            attention_mask = attention_mask.to(DEVICE)  \n","            input_len = input_len.to(DEVICE) \n","            target = target.to(DEVICE)      \n","            standard_error = standard_error.to(DEVICE) \n","            \n","            output = model(input_ids, attention_mask, input_len) # 取得した値をモデルへ入力し、出力として予測値を得る。\n","\n","            mse_mean_sum += nn.MSELoss(reduction=\"sum\")(output[:,0].flatten(), target).item() # 誤差の合計を得る(Batchごとに計算した誤差を足し上げる)\n","            mse_std_sum += nn.MSELoss(reduction=\"sum\")(output[:,1].flatten(), target).item() # 誤差の合計を得る(Batchごとに計算した誤差を足し上げる)\n","\n","    del input_ids\n","    del attention_mask\n","    del target\n","\n","    mse_mean_result = mse_mean_sum / len(data_loader.dataset)\n","    mse_std_result = mse_std_sum / len(data_loader.dataset)\n","  \n","    return mse_mean_result, mse_std_result # 誤差の合計をdataset長で除し、mseを取得＆返す"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.690155Z","iopub.execute_input":"2021-07-04T06:26:40.692530Z","iopub.status.idle":"2021-07-04T06:26:40.703425Z","shell.execute_reply.started":"2021-07-04T06:26:40.692488Z","shell.execute_reply":"2021-07-04T06:26:40.702366Z"},"trusted":true,"id":"47bDno_LXecI","executionInfo":{"status":"ok","timestamp":1626954132868,"user_tz":-540,"elapsed":3,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 推論結果を返す\n","def predict(model, data_loader):\n","    \"\"\"Returns an np.array with predictions of the |model| on |data_loader|\"\"\"\n","    model.eval() # evalモード(dropout, batch_normしない)\n","\n","    result = np.zeros(len(data_loader.dataset)) # 結果をdataset長のzero配列として用意\n","    index = 0\n","    \n","    with torch.no_grad(): # 勾配の計算をしないblock(inputすると、現状の重みによる推論結果を返す)\n","        for batch_num, (input_ids, attention_mask, input_len) in enumerate(data_loader): # data_loaderからbatchごとにinputを得る\n","            input_ids = input_ids.to(DEVICE)\n","            attention_mask = attention_mask.to(DEVICE)\n","            input_len = input_len.to(DEVICE)\n","                        \n","            output = model(input_ids, attention_mask, input_len) # modelにinputを入力し、予測結果を得る。\n","\n","            result[index : index + output[:,0].shape[0]] = output[:,0].flatten().to(\"cpu\") # result[index ~ predの長さ]へ、予測結果を格納\n","            index += pred.shape[0] # indexを更新\n","\n","    return result # 全batchで推論が終わったら、結果を返す"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.708605Z","iopub.execute_input":"2021-07-04T06:26:40.709024Z","iopub.status.idle":"2021-07-04T06:26:40.730675Z","shell.execute_reply.started":"2021-07-04T06:26:40.708983Z","shell.execute_reply":"2021-07-04T06:26:40.729705Z"},"trusted":true,"id":"oInneuAmXecI","executionInfo":{"status":"ok","timestamp":1626954133933,"user_tz":-540,"elapsed":560,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 学習\n","def train(model, # モデル\n","          model_path, # モデルのアウトプット先\n","          train_loader, # train-setのdata_loader\n","          val_loader, # valid-setのdata_loader\n","          optimizer, # optimizer\n","          scheduler=None, # scheduler, デフォルトはNone\n","          num_epochs=NUM_EPOCHS # epoch数、notebook冒頭で指定した値\n","         ):    \n","    \n","    best_val_rmse = None\n","    best_epoch = 0\n","    step = 0\n","    last_eval_step = 0\n","    eval_period = EVAL_SCHEDULE[0][1] # eval期間(って何？) 冒頭で決めたEVAL_SCHEDULEの最初のtupleの[1]を取得\n","\n","    start = time.time() # 時間計測用\n","\n","    for epoch in range(num_epochs): # 指定したEpoch数だけ繰り返し\n","        val_rmse = None         \n","\n","        for batch_num, (input_ids, attention_mask, input_len, target, standard_error) in enumerate(train_loader): # train_loaderからinput, targetを取得\n","            input_ids = input_ids.to(DEVICE) # inputをDEVICEへ突っ込む\n","            attention_mask = attention_mask.to(DEVICE)   \n","            input_len = input_len.to(DEVICE)\n","            target = target.to(DEVICE)\n","            standard_error = standard_error.to(DEVICE)  \n","\n","            optimizer.zero_grad() # 勾配を初期化            \n","            model.train() # 学習モード開始\n","\n","            # https://www.kaggle.com/c/commonlitreadabilityprize/discussion/239421\n","            output = model(input_ids, attention_mask, input_len) # input,attention_maskを入力し、予測結果を得る\n","            p = torch.distributions.Normal(output[:,0], torch.sqrt(output[:,1]**2))\n","            q = torch.distributions.Normal(target, standard_error)\n","            kl_vector = torch.distributions.kl_divergence(p, q)\n","            loss = kl_vector.mean()\n","\n","            loss.backward() # 誤差逆伝播法により勾配を得る\n","            optimizer.step() # 重みを更新する\n","\n","            if scheduler:\n","                scheduler.step() # schedulerが与えられた場合は、schedulerの学習率更新\n","            \n","            if step >= last_eval_step + eval_period: # batchを回すごとにstepを増やしていって、「前回evalしたstep + eval_period(16)」を超えたら実行。\n","                # Evaluate the model on val_loader.\n","                elapsed_seconds = time.time() - start # 経過時間\n","                num_steps = step - last_eval_step # 経過ステップ数\n","                print(f\"\\n{num_steps} steps took {elapsed_seconds:0.3} seconds\")\n","                last_eval_step = step # 前回stepの更新\n","                \n","                # valid-setによるrmse計算\n","                train_mean_mse = nn.MSELoss(reduction=\"mean\")(output[:,0].flatten(), target) \n","                train_std_mse = nn.MSELoss(reduction=\"mean\")(torch.sqrt(output[:,1]**2).flatten(), standard_error) \n","\n","                train_mean_rmse = math.sqrt(train_mean_mse)\n","                train_std_rmse = math.sqrt(train_std_mse)\n","\n","                val_mean_mse, val_std_mse = eval_mse(model, val_loader)\n","                val_mean_rmse = math.sqrt(val_mean_mse)                            \n","                val_std_rmse = math.sqrt(val_std_mse)                            \n","\n","                print(f\"Epoch: {epoch} batch_num: {batch_num}\")\n","                print(f\"train_rmse_target: {train_mean_rmse:0.4}\",\n","                      f\"train_rmse_stderror: {train_std_rmse:0.4}\",\n","                      f\"train_kl_div: {loss:0.4}\",\n","                      )\n","                print(f\"val_rmse_target: {val_mean_rmse:0.4}\",\n","                      f\"val_rmse_stderror: {val_std_rmse:0.4}\"\n","                      )\n","\n","                for rmse, period in EVAL_SCHEDULE: # eval_periodをvalid-rmseで切り替える処理\n","                    if val_mean_rmse >= rmse: # valid rmseをEVAL_SCHEDULEと比較し、0項 > valid rmseとなるまで回す : EVAL_SCHEDULE = [(0.50, 16), (0.49, 8), (0.48, 4), (0.47, 2), (-1., 1)]\n","                        eval_period = period # eval_periodを更新\n","                        break                               \n","\n","                if not best_val_rmse or val_mean_rmse < best_val_rmse: # 初回(best_val_rmse==None), またはbest_val_rmseを更新したらモデルを保存する\n","                    best_val_rmse = val_mean_rmse\n","                    best_epoch = epoch\n","                    torch.save(model.state_dict(), model_path) # 最高の自分を保存\n","                    print(f\"New best_val_rmse: {best_val_rmse:0.4}\")\n","                else:       \n","                    print(f\"Still best_val_rmse: {best_val_rmse:0.4}\", # 更新されない場合は、元のスコアを表示\n","                          f\"(from epoch {best_epoch})\")      \n","                                                  \n","                start = time.time()\n","            \n","            # batchごとにメモリ解放\n","            del input_ids\n","            del attention_mask\n","            del target\n","            torch.cuda.empty_cache()                                            \n","            step += 1\n","    \n","    return best_val_rmse"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7RGA6hWForlI","executionInfo":{"status":"ok","timestamp":1626954157034,"user_tz":-540,"elapsed":23105,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"fc1be1ec-9a43-43f3-a961-be8fdaf73ae1"},"source":["model = LitModel()"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-roberta-large/clrp_pretrained_manish_epoch5/pre-trained-roberta/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-roberta-large/clrp_pretrained_manish_epoch5/pre-trained-roberta/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aV9i6viKouG0","executionInfo":{"status":"ok","timestamp":1626954157035,"user_tz":-540,"elapsed":10,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"d5669084-b12a-4a88-8e91-81e61206880e"},"source":["list(model.conv1_layers.named_parameters())"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('0.weight', Parameter containing:\n","  tensor([[[ 0.5347,  0.5405,  0.1111]],\n","  \n","          [[ 0.4445, -0.0755,  0.3954]],\n","  \n","          [[-0.3700,  0.4156,  0.2489]],\n","  \n","          [[-0.4004,  0.0544,  0.3169]],\n","  \n","          [[ 0.4928,  0.4009,  0.0931]],\n","  \n","          [[ 0.3404,  0.5599,  0.5071]],\n","  \n","          [[ 0.4287, -0.3406,  0.5498]],\n","  \n","          [[ 0.3402, -0.4250,  0.3389]],\n","  \n","          [[ 0.0522, -0.0968,  0.2488]],\n","  \n","          [[-0.5174,  0.4211,  0.5160]],\n","  \n","          [[-0.0967, -0.2791, -0.2843]],\n","  \n","          [[ 0.1505,  0.3263,  0.4104]],\n","  \n","          [[ 0.3440,  0.4251, -0.1591]],\n","  \n","          [[ 0.1941, -0.0958,  0.1804]],\n","  \n","          [[-0.0225, -0.3241,  0.1665]],\n","  \n","          [[ 0.3054,  0.4358,  0.1943]]], requires_grad=True)),\n"," ('0.bias', Parameter containing:\n","  tensor([-0.4409, -0.0972, -0.4537,  0.4673,  0.2311,  0.1901, -0.0704,  0.0271,\n","           0.1471, -0.1120, -0.4712,  0.2886, -0.0899,  0.0664, -0.3075, -0.3576],\n","         requires_grad=True)),\n"," ('1.weight', Parameter containing:\n","  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n","         requires_grad=True)),\n"," ('1.bias', Parameter containing:\n","  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","         requires_grad=True)),\n"," ('4.weight', Parameter containing:\n","  tensor([[[ 0.0161, -0.0283,  0.0090],\n","           [ 0.1029, -0.0458, -0.1093],\n","           [ 0.1042, -0.1420, -0.0055],\n","           ...,\n","           [ 0.1111, -0.0395, -0.0749],\n","           [-0.0153,  0.0276,  0.1042],\n","           [ 0.1397,  0.0673, -0.0020]],\n","  \n","          [[ 0.0061,  0.0245, -0.0266],\n","           [-0.0847,  0.1039, -0.0218],\n","           [-0.0914, -0.0508, -0.1237],\n","           ...,\n","           [ 0.1400,  0.0929, -0.1169],\n","           [-0.1030, -0.0063,  0.0704],\n","           [ 0.0536,  0.1030, -0.0469]],\n","  \n","          [[ 0.0035, -0.0828,  0.0716],\n","           [ 0.0380, -0.0907, -0.0700],\n","           [-0.0352,  0.0787,  0.0131],\n","           ...,\n","           [-0.0517, -0.1394,  0.0302],\n","           [ 0.0535, -0.1098, -0.0176],\n","           [ 0.1284, -0.0040,  0.0661]],\n","  \n","          ...,\n","  \n","          [[ 0.0630,  0.0885, -0.0854],\n","           [ 0.0069,  0.0343, -0.0153],\n","           [ 0.0432, -0.0830,  0.0632],\n","           ...,\n","           [-0.1069,  0.0087, -0.0675],\n","           [-0.0167,  0.1202, -0.0734],\n","           [ 0.0959,  0.0384,  0.1124]],\n","  \n","          [[ 0.1096, -0.0238, -0.0458],\n","           [ 0.0338, -0.0415,  0.0319],\n","           [-0.1274, -0.0701,  0.1155],\n","           ...,\n","           [-0.0507, -0.0219, -0.0664],\n","           [ 0.1199, -0.1411,  0.0792],\n","           [ 0.0427,  0.0210, -0.0373]],\n","  \n","          [[-0.0012,  0.1311, -0.0330],\n","           [ 0.1329,  0.1228, -0.0028],\n","           [ 0.0584, -0.0765,  0.1312],\n","           ...,\n","           [ 0.0338,  0.0161,  0.1338],\n","           [ 0.1202, -0.1413, -0.1352],\n","           [-0.0510,  0.1203, -0.1284]]], requires_grad=True)),\n"," ('4.bias', Parameter containing:\n","  tensor([ 0.0719, -0.0200,  0.1024,  0.0389,  0.1179,  0.0864, -0.0009,  0.0015,\n","          -0.0645, -0.0947, -0.1192,  0.0575, -0.1316,  0.0033,  0.1152, -0.0415,\n","           0.0697,  0.1192,  0.0032,  0.0621, -0.0788,  0.1188, -0.0278,  0.0476,\n","          -0.1359, -0.0103,  0.0157,  0.0908,  0.0271,  0.0038,  0.1189,  0.0685,\n","          -0.0973, -0.1171,  0.0825,  0.0408, -0.0462, -0.0968,  0.1234, -0.0092,\n","           0.1114,  0.0412,  0.1165,  0.0242,  0.0058,  0.0489, -0.0716,  0.0926,\n","           0.0821, -0.1317, -0.1354, -0.1152, -0.0187,  0.1334,  0.0199, -0.0114,\n","          -0.0128,  0.0546, -0.0295,  0.0927, -0.0356,  0.0441,  0.0961, -0.0648],\n","         requires_grad=True)),\n"," ('5.weight', Parameter containing:\n","  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","          1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)),\n"," ('5.bias', Parameter containing:\n","  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","         requires_grad=True)),\n"," ('6.weight', Parameter containing:\n","  tensor([[[-0.0244,  0.0191, -0.0304],\n","           [-0.0403,  0.0505, -0.0411],\n","           [ 0.0272, -0.0588,  0.0566],\n","           ...,\n","           [ 0.0451,  0.0566, -0.0320],\n","           [-0.0201,  0.0543,  0.0636],\n","           [-0.0480, -0.0184,  0.0699]],\n","  \n","          [[ 0.0273,  0.0206, -0.0696],\n","           [ 0.0290,  0.0021, -0.0594],\n","           [ 0.0367,  0.0704,  0.0285],\n","           ...,\n","           [-0.0512, -0.0364, -0.0324],\n","           [-0.0548,  0.0584, -0.0141],\n","           [-0.0441, -0.0033,  0.0060]],\n","  \n","          [[ 0.0674,  0.0002,  0.0479],\n","           [ 0.0535,  0.0585, -0.0170],\n","           [ 0.0337, -0.0660,  0.0165],\n","           ...,\n","           [ 0.0008,  0.0053,  0.0566],\n","           [-0.0475,  0.0611, -0.0077],\n","           [-0.0044,  0.0220, -0.0633]],\n","  \n","          ...,\n","  \n","          [[ 0.0268,  0.0650,  0.0137],\n","           [-0.0230,  0.0218,  0.0375],\n","           [-0.0263,  0.0262, -0.0323],\n","           ...,\n","           [-0.0245, -0.0712, -0.0649],\n","           [-0.0589,  0.0602,  0.0636],\n","           [ 0.0279, -0.0685, -0.0226]],\n","  \n","          [[-0.0136,  0.0676, -0.0064],\n","           [-0.0141,  0.0152, -0.0516],\n","           [-0.0158,  0.0069, -0.0305],\n","           ...,\n","           [ 0.0255,  0.0067, -0.0685],\n","           [ 0.0317, -0.0101, -0.0716],\n","           [-0.0132,  0.0602,  0.0686]],\n","  \n","          [[-0.0120,  0.0354,  0.0464],\n","           [-0.0339, -0.0224, -0.0537],\n","           [-0.0319,  0.0032,  0.0388],\n","           ...,\n","           [-0.0313, -0.0432,  0.0075],\n","           [ 0.0320, -0.0476,  0.0391],\n","           [ 0.0669,  0.0042,  0.0618]]], requires_grad=True)),\n"," ('6.bias', Parameter containing:\n","  tensor([ 0.0632, -0.0671,  0.0624,  0.0639, -0.0720,  0.0225,  0.0337,  0.0221,\n","           0.0516,  0.0721, -0.0458,  0.0506,  0.0484,  0.0419, -0.0255, -0.0206,\n","           0.0324, -0.0709,  0.0594,  0.0633,  0.0643, -0.0440, -0.0640,  0.0100,\n","          -0.0491,  0.0580, -0.0139,  0.0082,  0.0717, -0.0339,  0.0710,  0.0248,\n","           0.0335, -0.0589,  0.0313,  0.0059,  0.0421, -0.0248, -0.0603, -0.0685,\n","           0.0165, -0.0172,  0.0181, -0.0275,  0.0571, -0.0576,  0.0565, -0.0172,\n","           0.0600, -0.0288, -0.0595,  0.0002, -0.0712, -0.0703, -0.0048, -0.0387,\n","          -0.0451, -0.0292, -0.0345, -0.0031, -0.0238, -0.0630,  0.0539, -0.0488,\n","           0.0144, -0.0569, -0.0052,  0.0356,  0.0615, -0.0319,  0.0394,  0.0182,\n","          -0.0550,  0.0354,  0.0718, -0.0401,  0.0258,  0.0391,  0.0481, -0.0291,\n","          -0.0611,  0.0230,  0.0602,  0.0690,  0.0579, -0.0264,  0.0410, -0.0716,\n","          -0.0479,  0.0038, -0.0170, -0.0420,  0.0614, -0.0123, -0.0591,  0.0140,\n","          -0.0383,  0.0071,  0.0638, -0.0030,  0.0450, -0.0192,  0.0582, -0.0219,\n","          -0.0643, -0.0072, -0.0454, -0.0341,  0.0327,  0.0635,  0.0284, -0.0378,\n","          -0.0172,  0.0157,  0.0342, -0.0567, -0.0199, -0.0478, -0.0208, -0.0282,\n","           0.0452, -0.0447, -0.0451, -0.0607, -0.0575, -0.0714,  0.0516,  0.0665,\n","           0.0624, -0.0196, -0.0689,  0.0228, -0.0465, -0.0501, -0.0452,  0.0219,\n","           0.0052, -0.0323,  0.0455,  0.0616,  0.0349, -0.0247, -0.0318,  0.0432,\n","          -0.0214, -0.0310,  0.0577, -0.0714,  0.0629, -0.0507,  0.0555,  0.0353,\n","          -0.0607, -0.0712, -0.0265,  0.0495, -0.0565, -0.0210, -0.0112, -0.0011,\n","          -0.0300, -0.0024, -0.0310, -0.0639, -0.0617, -0.0329,  0.0589,  0.0704,\n","          -0.0665, -0.0459,  0.0657, -0.0583, -0.0363,  0.0090,  0.0297,  0.0422,\n","          -0.0102,  0.0569,  0.0433,  0.0656, -0.0197,  0.0172,  0.0327,  0.0321,\n","           0.0469,  0.0641,  0.0169,  0.0022,  0.0195,  0.0690,  0.0613, -0.0698,\n","          -0.0696, -0.0034,  0.0121,  0.0501, -0.0181,  0.0405,  0.0528,  0.0613,\n","          -0.0598, -0.0653,  0.0006, -0.0289,  0.0047, -0.0092, -0.0191,  0.0704,\n","           0.0382,  0.0597,  0.0721,  0.0169,  0.0144,  0.0323,  0.0391, -0.0462,\n","          -0.0447,  0.0721, -0.0052, -0.0619,  0.0019, -0.0202,  0.0583,  0.0676,\n","          -0.0699,  0.0521,  0.0115,  0.0425, -0.0215, -0.0421,  0.0598, -0.0397,\n","           0.0177, -0.0477, -0.0375,  0.0522,  0.0391, -0.0176, -0.0378, -0.0312,\n","          -0.0418,  0.0203,  0.0283,  0.0676, -0.0433,  0.0055, -0.0081, -0.0233,\n","           0.0581, -0.0707, -0.0674,  0.0661,  0.0499,  0.0097,  0.0078, -0.0542],\n","         requires_grad=True))]"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.735798Z","iopub.execute_input":"2021-07-04T06:26:40.738398Z","iopub.status.idle":"2021-07-04T06:26:40.750876Z","shell.execute_reply.started":"2021-07-04T06:26:40.738356Z","shell.execute_reply":"2021-07-04T06:26:40.749635Z"},"trusted":true,"id":"rMY0fjXwXecJ","executionInfo":{"status":"ok","timestamp":1626954157035,"user_tz":-540,"elapsed":5,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# optimizerの作成\n","def create_optimizer(model):\n","    named_parameters = list(model.named_parameters()) # モデルパラメータの取得\n","    \n","    roberta_parameters = list(model.roberta.named_parameters())[:-2] # パラメータをroberta用、attention用、regressor用に格納。(直接引っ張ってくる形式に変更)\n","    attention_parameters = list(model.attention.named_parameters())\n","    conv1d_parameters = list(model.conv1_layers.named_parameters())\n","    regressor_parameters = list(model.regressor.named_parameters())\n","        \n","    attention_group = [params for (name, params) in attention_parameters] # attention用パラメータをリストとして取得\n","    conv1d_group = [params for (name, params) in conv1d_parameters]\n","    regressor_group = [params for (name, params) in regressor_parameters] # reg用パラメータをリストとして取得\n","\n","    parameters = []\n","    parameters.append({\"params\": attention_group}) # パラメータをリストに辞書として格納していく\n","    parameters.append({\"params\": conv1d_group})\n","    parameters.append({\"params\": regressor_group})\n","\n","    for layer_num, (name, params) in enumerate(roberta_parameters): # レイヤーごとにname, paramsを取得していろんな処理\n","        weight_decay = 0.0 if \"bias\" in name else 0.01\n","\n","        lr = 8e-6\n","\n","        if layer_num >= 69:        \n","            lr = 2e-5\n","\n","        if layer_num >= 133:\n","            lr = 4e-5\n","\n","        parameters.append({\"params\": params,\n","                           \"weight_decay\": weight_decay,\n","                           \"lr\": lr})\n","\n","    return AdamW(parameters) # 最終的に、AdamWにパラメータを入力する。\n"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"kbCfVXbjpdZw","executionInfo":{"status":"ok","timestamp":1626954157489,"user_tz":-540,"elapsed":459,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["opt = create_optimizer(model)"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"id":"EbaJojz0Zjif","executionInfo":{"status":"ok","timestamp":1626954157489,"user_tz":-540,"elapsed":4,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# https://www.kaggle.com/abhishek/step-1-create-folds\n","def create_folds(data, num_splits, SEED, return_df=False):\n","    # we create a new column called kfold and fill it with -1\n","    data[\"kfold\"] = -1\n","    \n","    # the next step is to randomize the rows of the data\n","    data = data.sample(frac=1).reset_index(drop=True)\n","\n","    # calculate number of bins by Sturge's rule\n","    # I take the floor of the value, you can also\n","    # just round it\n","    num_bins = int(np.floor(1 + np.log2(len(data))))\n","    \n","    # bin targets\n","    data.loc[:, \"bins_tg\"] = pd.cut(\n","        data[\"target\"], bins=num_bins, labels=False\n","    ).map(lambda x: str(x))\n","\n","    # bin standard_error\n","    data.loc[:, \"bins_std\"] = pd.cut(\n","        data[\"standard_error\"], bins=num_bins, labels=False\n","    )\n","\n","    # bins\n","    data.loc[:, \"bins\"] = data['bins_tg'].map(lambda x: str(x)) + data['bins_std'].map(lambda x: str(x))\n","\n","    # initiate the kfold class from model_selection module\n","    kf = StratifiedKFold(n_splits=5, random_state=SEED, shuffle=True)\n","\n","    # note that, instead of targets, we use bins!\n","    if return_df:\n","      for f, (t_, v_) in enumerate(kf.split(X=data, y=data.bins.values)):\n","        data.loc[v_, 'kfold'] = f\n","      return data\n","    else:\n","      return kf.split(X=data, y=data.bins.values)"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"id":"4PLKHwvKtNBn","executionInfo":{"status":"ok","timestamp":1626954157490,"user_tz":-540,"elapsed":5,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["def train_and_save_model(train_indices, val_indices, model_path):\n","    train_dataset = LitDataset(train_df.loc[train_indices]) # train, validのDataset\n","    val_dataset = LitDataset(train_df.loc[val_indices])\n","        \n","    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n","                              drop_last=True, shuffle=True, num_workers=2) # train, validのDataLoader\n","    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n","                            drop_last=False, shuffle=False, num_workers=2)    \n","\n","    model = LitModel().to(DEVICE) # modelをDEVICEへぶち込む\n","    optimizer = create_optimizer(model) # optimizerをモデルから作成\n","    scheduler = get_cosine_schedule_with_warmup( # schedulerを作成\n","        optimizer,\n","        num_training_steps=NUM_EPOCHS * len(train_loader),\n","        num_warmup_steps=50)    \n","    rmse = train(model, model_path, train_loader, val_loader, optimizer, scheduler=scheduler)\n","\n","    del train_dataset\n","    del val_dataset\n","    del train_loader\n","    del val_loader\n","    del model\n","    del optimizer\n","    del scheduler\n","    gc.collect() \n","    torch.cuda.empty_cache()\n","    return rmse"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.755813Z","iopub.execute_input":"2021-07-04T06:26:40.758373Z","iopub.status.idle":"2021-07-04T06:27:12.493221Z","shell.execute_reply.started":"2021-07-04T06:26:40.758265Z","shell.execute_reply":"2021-07-04T06:27:12.490139Z"},"trusted":true,"id":"k2LGJD3XXecK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626968371502,"user_tz":-540,"elapsed":14214016,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"b56660cb-fc15-4f88-ea22-91009c33128d"},"source":["# 実行処理。 KFold & 学習\n","SEED = 1000\n","list_val_rmse = []\n","\n","#kfold = KFold(n_splits=NUM_FOLDS, random_state=SEED, shuffle=True)\n","kfold = create_folds(train_df, 5, SEED=SEED, return_df=False) # binsで切る場合\n","\n","for fold, (train_indices, val_indices) in enumerate(kfold):    \n","    print(f\"\\nFold {fold + 1}/{NUM_FOLDS}\")\n","    print(gpuinfo())\n","    model_path = f\"model_{fold + 1}.pth\" # model_fold数_.pth\n","    set_random_seed(SEED + fold) # SEEDはfold別に変わるようにする\n","    list_val_rmse.append(train_and_save_model(train_indices, val_indices, model_path))\n","\n","    print(\"\\nPerformance estimates:\")\n","    print(list_val_rmse)\n","    print(\"Mean:\", np.array(list_val_rmse).mean())\n","    print(gpuinfo())"],"execution_count":38,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  % (min_groups, self.n_splits)), UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Fold 1/5\n","{'total_MiB': 16280, 'used_MiB': 2}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-roberta-large/clrp_pretrained_manish_epoch5/pre-trained-roberta/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-roberta-large/clrp_pretrained_manish_epoch5/pre-trained-roberta/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 82.1 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.5399 train_rmse_stderror: 0.06492 train_kl_div: 0.6304\n","val_rmse_target: 0.5983 val_rmse_stderror: 1.05\n","New best_val_rmse: 0.5983\n","\n","64 steps took 80.9 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.7003 train_rmse_stderror: 0.05013 train_kl_div: 0.9843\n","val_rmse_target: 0.5409 val_rmse_stderror: 1.096\n","New best_val_rmse: 0.5409\n","\n","32 steps took 40.5 seconds\n","Epoch: 0 batch_num: 160\n","train_rmse_target: 0.3487 train_rmse_stderror: 0.0359 train_kl_div: 0.2846\n","val_rmse_target: 0.5284 val_rmse_stderror: 1.09\n","New best_val_rmse: 0.5284\n","\n","32 steps took 40.7 seconds\n","Epoch: 1 batch_num: 4\n","train_rmse_target: 0.2836 train_rmse_stderror: 0.0325 train_kl_div: 0.1961\n","val_rmse_target: 0.4913 val_rmse_stderror: 1.088\n","New best_val_rmse: 0.4913\n","\n","16 steps took 20.3 seconds\n","Epoch: 1 batch_num: 20\n","train_rmse_target: 0.7707 train_rmse_stderror: 0.04263 train_kl_div: 1.284\n","val_rmse_target: 0.4931 val_rmse_stderror: 1.082\n","Still best_val_rmse: 0.4913 (from epoch 1)\n","\n","16 steps took 20.2 seconds\n","Epoch: 1 batch_num: 36\n","train_rmse_target: 0.5235 train_rmse_stderror: 0.02987 train_kl_div: 0.5977\n","val_rmse_target: 0.5349 val_rmse_stderror: 1.083\n","Still best_val_rmse: 0.4913 (from epoch 1)\n","\n","32 steps took 40.5 seconds\n","Epoch: 1 batch_num: 68\n","train_rmse_target: 0.5383 train_rmse_stderror: 0.03189 train_kl_div: 0.6185\n","val_rmse_target: 0.4726 val_rmse_stderror: 1.073\n","New best_val_rmse: 0.4726\n","\n","4 steps took 5.07 seconds\n","Epoch: 1 batch_num: 72\n","train_rmse_target: 0.4771 train_rmse_stderror: 0.02878 train_kl_div: 0.4831\n","val_rmse_target: 0.5265 val_rmse_stderror: 1.088\n","Still best_val_rmse: 0.4726 (from epoch 1)\n","\n","32 steps took 40.5 seconds\n","Epoch: 1 batch_num: 104\n","train_rmse_target: 0.4566 train_rmse_stderror: 0.03869 train_kl_div: 0.474\n","val_rmse_target: 0.4965 val_rmse_stderror: 1.072\n","Still best_val_rmse: 0.4726 (from epoch 1)\n","\n","16 steps took 20.2 seconds\n","Epoch: 1 batch_num: 120\n","train_rmse_target: 0.3565 train_rmse_stderror: 0.0303 train_kl_div: 0.2959\n","val_rmse_target: 0.5381 val_rmse_stderror: 1.085\n","Still best_val_rmse: 0.4726 (from epoch 1)\n","\n","32 steps took 40.5 seconds\n","Epoch: 1 batch_num: 152\n","train_rmse_target: 0.4491 train_rmse_stderror: 0.03094 train_kl_div: 0.4152\n","val_rmse_target: 0.4917 val_rmse_stderror: 1.086\n","Still best_val_rmse: 0.4726 (from epoch 1)\n","\n","16 steps took 20.3 seconds\n","Epoch: 1 batch_num: 168\n","train_rmse_target: 0.5072 train_rmse_stderror: 0.04587 train_kl_div: 0.3993\n","val_rmse_target: 0.5074 val_rmse_stderror: 1.086\n","Still best_val_rmse: 0.4726 (from epoch 1)\n","\n","32 steps took 40.7 seconds\n","Epoch: 2 batch_num: 12\n","train_rmse_target: 0.2507 train_rmse_stderror: 0.01667 train_kl_div: 0.1416\n","val_rmse_target: 0.4631 val_rmse_stderror: 1.092\n","New best_val_rmse: 0.4631\n","\n","2 steps took 2.53 seconds\n","Epoch: 2 batch_num: 14\n","train_rmse_target: 0.2787 train_rmse_stderror: 0.03129 train_kl_div: 0.1622\n","val_rmse_target: 0.4608 val_rmse_stderror: 1.093\n","New best_val_rmse: 0.4608\n","\n","2 steps took 2.52 seconds\n","Epoch: 2 batch_num: 16\n","train_rmse_target: 0.2079 train_rmse_stderror: 0.03094 train_kl_div: 0.08938\n","val_rmse_target: 0.4705 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.4608 (from epoch 2)\n","\n","4 steps took 5.05 seconds\n","Epoch: 2 batch_num: 20\n","train_rmse_target: 0.2993 train_rmse_stderror: 0.03127 train_kl_div: 0.1878\n","val_rmse_target: 0.4902 val_rmse_stderror: 1.075\n","Still best_val_rmse: 0.4608 (from epoch 2)\n","\n","16 steps took 20.2 seconds\n","Epoch: 2 batch_num: 36\n","train_rmse_target: 0.156 train_rmse_stderror: 0.03124 train_kl_div: 0.05821\n","val_rmse_target: 0.4733 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.4608 (from epoch 2)\n","\n","4 steps took 5.04 seconds\n","Epoch: 2 batch_num: 40\n","train_rmse_target: 0.2134 train_rmse_stderror: 0.0235 train_kl_div: 0.09602\n","val_rmse_target: 0.4688 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.4608 (from epoch 2)\n","\n","2 steps took 2.51 seconds\n","Epoch: 2 batch_num: 42\n","train_rmse_target: 0.235 train_rmse_stderror: 0.0243 train_kl_div: 0.116\n","val_rmse_target: 0.4783 val_rmse_stderror: 1.086\n","Still best_val_rmse: 0.4608 (from epoch 2)\n","\n","4 steps took 5.05 seconds\n","Epoch: 2 batch_num: 46\n","train_rmse_target: 0.255 train_rmse_stderror: 0.03244 train_kl_div: 0.1363\n","val_rmse_target: 0.4675 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.4608 (from epoch 2)\n","\n","2 steps took 2.52 seconds\n","Epoch: 2 batch_num: 48\n","train_rmse_target: 0.3661 train_rmse_stderror: 0.02838 train_kl_div: 0.2351\n","val_rmse_target: 0.4714 val_rmse_stderror: 1.092\n","Still best_val_rmse: 0.4608 (from epoch 2)\n","\n","4 steps took 5.04 seconds\n","Epoch: 2 batch_num: 52\n","train_rmse_target: 0.2386 train_rmse_stderror: 0.03817 train_kl_div: 0.1172\n","val_rmse_target: 0.4863 val_rmse_stderror: 1.093\n","Still best_val_rmse: 0.4608 (from epoch 2)\n","\n","8 steps took 10.1 seconds\n","Epoch: 2 batch_num: 60\n","train_rmse_target: 0.3431 train_rmse_stderror: 0.02503 train_kl_div: 0.2509\n","val_rmse_target: 0.4652 val_rmse_stderror: 1.084\n","Still best_val_rmse: 0.4608 (from epoch 2)\n","\n","2 steps took 2.52 seconds\n","Epoch: 2 batch_num: 62\n","train_rmse_target: 0.2506 train_rmse_stderror: 0.02892 train_kl_div: 0.1353\n","val_rmse_target: 0.4809 val_rmse_stderror: 1.093\n","Still best_val_rmse: 0.4608 (from epoch 2)\n","\n","8 steps took 10.1 seconds\n","Epoch: 2 batch_num: 70\n","train_rmse_target: 0.2765 train_rmse_stderror: 0.02873 train_kl_div: 0.1716\n","val_rmse_target: 0.4653 val_rmse_stderror: 1.088\n","Still best_val_rmse: 0.4608 (from epoch 2)\n","\n","2 steps took 2.52 seconds\n","Epoch: 2 batch_num: 72\n","train_rmse_target: 0.1773 train_rmse_stderror: 0.0375 train_kl_div: 0.07663\n","val_rmse_target: 0.4776 val_rmse_stderror: 1.085\n","Still best_val_rmse: 0.4608 (from epoch 2)\n","\n","4 steps took 5.06 seconds\n","Epoch: 2 batch_num: 76\n","train_rmse_target: 0.2209 train_rmse_stderror: 0.02773 train_kl_div: 0.09986\n","val_rmse_target: 0.4658 val_rmse_stderror: 1.093\n","Still best_val_rmse: 0.4608 (from epoch 2)\n","\n","2 steps took 2.52 seconds\n","Epoch: 2 batch_num: 78\n","train_rmse_target: 0.2576 train_rmse_stderror: 0.034 train_kl_div: 0.1339\n","val_rmse_target: 0.4744 val_rmse_stderror: 1.088\n","Still best_val_rmse: 0.4608 (from epoch 2)\n","\n","4 steps took 5.04 seconds\n","Epoch: 2 batch_num: 82\n","train_rmse_target: 0.2614 train_rmse_stderror: 0.03301 train_kl_div: 0.1463\n","val_rmse_target: 0.4691 val_rmse_stderror: 1.077\n","Still best_val_rmse: 0.4608 (from epoch 2)\n","\n","2 steps took 2.52 seconds\n","Epoch: 2 batch_num: 84\n","train_rmse_target: 0.2688 train_rmse_stderror: 0.01632 train_kl_div: 0.1513\n","val_rmse_target: 0.4692 val_rmse_stderror: 1.083\n","Still best_val_rmse: 0.4608 (from epoch 2)\n","\n","2 steps took 2.52 seconds\n","Epoch: 2 batch_num: 86\n","train_rmse_target: 0.2639 train_rmse_stderror: 0.02751 train_kl_div: 0.154\n","val_rmse_target: 0.473 val_rmse_stderror: 1.086\n","Still best_val_rmse: 0.4608 (from epoch 2)\n","\n","4 steps took 5.05 seconds\n","Epoch: 2 batch_num: 90\n","train_rmse_target: 0.2559 train_rmse_stderror: 0.02922 train_kl_div: 0.1084\n","val_rmse_target: 0.4735 val_rmse_stderror: 1.085\n","Still best_val_rmse: 0.4608 (from epoch 2)\n","\n","4 steps took 5.04 seconds\n","Epoch: 2 batch_num: 94\n","train_rmse_target: 0.1809 train_rmse_stderror: 0.03258 train_kl_div: 0.08319\n","val_rmse_target: 0.4796 val_rmse_stderror: 1.095\n","Still best_val_rmse: 0.4608 (from epoch 2)\n","\n","4 steps took 5.04 seconds\n","Epoch: 2 batch_num: 98\n","train_rmse_target: 0.2391 train_rmse_stderror: 0.02054 train_kl_div: 0.1201\n","val_rmse_target: 0.4682 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.4608 (from epoch 2)\n","\n","2 steps took 2.52 seconds\n","Epoch: 2 batch_num: 100\n","train_rmse_target: 0.2647 train_rmse_stderror: 0.01725 train_kl_div: 0.1584\n","val_rmse_target: 0.4683 val_rmse_stderror: 1.084\n","Still best_val_rmse: 0.4608 (from epoch 2)\n","\n","2 steps took 2.52 seconds\n","Epoch: 2 batch_num: 102\n","train_rmse_target: 0.2229 train_rmse_stderror: 0.0342 train_kl_div: 0.09569\n","val_rmse_target: 0.4654 val_rmse_stderror: 1.088\n","Still best_val_rmse: 0.4608 (from epoch 2)\n","\n","2 steps took 2.52 seconds\n","Epoch: 2 batch_num: 104\n","train_rmse_target: 0.2422 train_rmse_stderror: 0.04034 train_kl_div: 0.1183\n","val_rmse_target: 0.4829 val_rmse_stderror: 1.09\n","Still best_val_rmse: 0.4608 (from epoch 2)\n","\n","8 steps took 10.1 seconds\n","Epoch: 2 batch_num: 112\n","train_rmse_target: 0.1714 train_rmse_stderror: 0.03056 train_kl_div: 0.06086\n","val_rmse_target: 0.4848 val_rmse_stderror: 1.088\n","Still best_val_rmse: 0.4608 (from epoch 2)\n","\n","8 steps took 10.1 seconds\n","Epoch: 2 batch_num: 120\n","train_rmse_target: 0.2296 train_rmse_stderror: 0.03312 train_kl_div: 0.1094\n","val_rmse_target: 0.4775 val_rmse_stderror: 1.092\n","Still best_val_rmse: 0.4608 (from epoch 2)\n","\n","4 steps took 5.04 seconds\n","Epoch: 2 batch_num: 124\n","train_rmse_target: 0.235 train_rmse_stderror: 0.03208 train_kl_div: 0.1115\n","val_rmse_target: 0.47 val_rmse_stderror: 1.083\n","Still best_val_rmse: 0.4608 (from epoch 2)\n","\n","4 steps took 5.05 seconds\n","Epoch: 2 batch_num: 128\n","train_rmse_target: 0.3198 train_rmse_stderror: 0.03251 train_kl_div: 0.2041\n","val_rmse_target: 0.4693 val_rmse_stderror: 1.09\n","Still best_val_rmse: 0.4608 (from epoch 2)\n","\n","2 steps took 2.52 seconds\n","Epoch: 2 batch_num: 130\n","train_rmse_target: 0.307 train_rmse_stderror: 0.03355 train_kl_div: 0.1927\n","val_rmse_target: 0.4907 val_rmse_stderror: 1.093\n","Still best_val_rmse: 0.4608 (from epoch 2)\n","\n","16 steps took 20.2 seconds\n","Epoch: 2 batch_num: 146\n","train_rmse_target: 0.407 train_rmse_stderror: 0.04569 train_kl_div: 0.2547\n","val_rmse_target: 0.4759 val_rmse_stderror: 1.1\n","Still best_val_rmse: 0.4608 (from epoch 2)\n","\n","4 steps took 5.06 seconds\n","Epoch: 2 batch_num: 150\n","train_rmse_target: 0.278 train_rmse_stderror: 0.01994 train_kl_div: 0.1503\n","val_rmse_target: 0.4738 val_rmse_stderror: 1.093\n","Still best_val_rmse: 0.4608 (from epoch 2)\n","\n","4 steps took 5.05 seconds\n","Epoch: 2 batch_num: 154\n","train_rmse_target: 0.2405 train_rmse_stderror: 0.0369 train_kl_div: 0.1267\n","val_rmse_target: 0.4573 val_rmse_stderror: 1.088\n","New best_val_rmse: 0.4573\n","\n","1 steps took 1.27 seconds\n","Epoch: 2 batch_num: 155\n","train_rmse_target: 0.2628 train_rmse_stderror: 0.02759 train_kl_div: 0.1215\n","val_rmse_target: 0.4587 val_rmse_stderror: 1.088\n","Still best_val_rmse: 0.4573 (from epoch 2)\n","\n","1 steps took 1.25 seconds\n","Epoch: 2 batch_num: 156\n","train_rmse_target: 0.2766 train_rmse_stderror: 0.03376 train_kl_div: 0.1479\n","val_rmse_target: 0.4616 val_rmse_stderror: 1.085\n","Still best_val_rmse: 0.4573 (from epoch 2)\n","\n","2 steps took 2.52 seconds\n","Epoch: 2 batch_num: 158\n","train_rmse_target: 0.1706 train_rmse_stderror: 0.01932 train_kl_div: 0.06372\n","val_rmse_target: 0.4632 val_rmse_stderror: 1.084\n","Still best_val_rmse: 0.4573 (from epoch 2)\n","\n","2 steps took 2.52 seconds\n","Epoch: 2 batch_num: 160\n","train_rmse_target: 0.3139 train_rmse_stderror: 0.02665 train_kl_div: 0.1823\n","val_rmse_target: 0.4591 val_rmse_stderror: 1.083\n","Still best_val_rmse: 0.4573 (from epoch 2)\n","\n","1 steps took 1.25 seconds\n","Epoch: 2 batch_num: 161\n","train_rmse_target: 0.2526 train_rmse_stderror: 0.02001 train_kl_div: 0.1438\n","val_rmse_target: 0.4566 val_rmse_stderror: 1.084\n","New best_val_rmse: 0.4566\n","\n","1 steps took 1.27 seconds\n","Epoch: 2 batch_num: 162\n","train_rmse_target: 0.2319 train_rmse_stderror: 0.03968 train_kl_div: 0.1163\n","val_rmse_target: 0.4566 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.4566 (from epoch 2)\n","\n","1 steps took 1.25 seconds\n","Epoch: 2 batch_num: 163\n","train_rmse_target: 0.1948 train_rmse_stderror: 0.02052 train_kl_div: 0.07411\n","val_rmse_target: 0.456 val_rmse_stderror: 1.089\n","New best_val_rmse: 0.456\n","\n","1 steps took 1.25 seconds\n","Epoch: 2 batch_num: 164\n","train_rmse_target: 0.283 train_rmse_stderror: 0.02204 train_kl_div: 0.1798\n","val_rmse_target: 0.4566 val_rmse_stderror: 1.09\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","1 steps took 1.25 seconds\n","Epoch: 2 batch_num: 165\n","train_rmse_target: 0.2538 train_rmse_stderror: 0.02205 train_kl_div: 0.1455\n","val_rmse_target: 0.4565 val_rmse_stderror: 1.091\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","1 steps took 1.25 seconds\n","Epoch: 2 batch_num: 166\n","train_rmse_target: 0.3054 train_rmse_stderror: 0.03315 train_kl_div: 0.1786\n","val_rmse_target: 0.4583 val_rmse_stderror: 1.092\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","1 steps took 1.25 seconds\n","Epoch: 2 batch_num: 167\n","train_rmse_target: 0.3118 train_rmse_stderror: 0.03068 train_kl_div: 0.1994\n","val_rmse_target: 0.4602 val_rmse_stderror: 1.091\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","2 steps took 2.52 seconds\n","Epoch: 2 batch_num: 169\n","train_rmse_target: 0.3021 train_rmse_stderror: 0.02524 train_kl_div: 0.202\n","val_rmse_target: 0.4605 val_rmse_stderror: 1.088\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","2 steps took 2.52 seconds\n","Epoch: 2 batch_num: 171\n","train_rmse_target: 0.277 train_rmse_stderror: 0.03187 train_kl_div: 0.1612\n","val_rmse_target: 0.4581 val_rmse_stderror: 1.085\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","1 steps took 1.25 seconds\n","Epoch: 2 batch_num: 172\n","train_rmse_target: 0.1976 train_rmse_stderror: 0.02313 train_kl_div: 0.08763\n","val_rmse_target: 0.4585 val_rmse_stderror: 1.085\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","1 steps took 1.26 seconds\n","Epoch: 2 batch_num: 173\n","train_rmse_target: 0.3 train_rmse_stderror: 0.02681 train_kl_div: 0.1788\n","val_rmse_target: 0.4602 val_rmse_stderror: 1.086\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","2 steps took 2.52 seconds\n","Epoch: 2 batch_num: 175\n","train_rmse_target: 0.2464 train_rmse_stderror: 0.02914 train_kl_div: 0.1224\n","val_rmse_target: 0.4635 val_rmse_stderror: 1.091\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","2 steps took 2.51 seconds\n","Epoch: 2 batch_num: 177\n","train_rmse_target: 0.1472 train_rmse_stderror: 0.02814 train_kl_div: 0.05026\n","val_rmse_target: 0.4696 val_rmse_stderror: 1.097\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","2 steps took 2.51 seconds\n","Epoch: 2 batch_num: 179\n","train_rmse_target: 0.223 train_rmse_stderror: 0.02656 train_kl_div: 0.108\n","val_rmse_target: 0.4832 val_rmse_stderror: 1.096\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","8 steps took 10.1 seconds\n","Epoch: 2 batch_num: 187\n","train_rmse_target: 0.3157 train_rmse_stderror: 0.02615 train_kl_div: 0.2024\n","val_rmse_target: 0.4806 val_rmse_stderror: 1.085\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","8 steps took 10.3 seconds\n","Epoch: 3 batch_num: 7\n","train_rmse_target: 0.1804 train_rmse_stderror: 0.02043 train_kl_div: 0.06989\n","val_rmse_target: 0.4708 val_rmse_stderror: 1.096\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","4 steps took 5.06 seconds\n","Epoch: 3 batch_num: 11\n","train_rmse_target: 0.1627 train_rmse_stderror: 0.01901 train_kl_div: 0.0571\n","val_rmse_target: 0.4597 val_rmse_stderror: 1.091\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 12\n","train_rmse_target: 0.0974 train_rmse_stderror: 0.02314 train_kl_div: 0.02128\n","val_rmse_target: 0.4592 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","1 steps took 1.26 seconds\n","Epoch: 3 batch_num: 13\n","train_rmse_target: 0.1428 train_rmse_stderror: 0.02816 train_kl_div: 0.04336\n","val_rmse_target: 0.459 val_rmse_stderror: 1.086\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","1 steps took 1.26 seconds\n","Epoch: 3 batch_num: 14\n","train_rmse_target: 0.2244 train_rmse_stderror: 0.03092 train_kl_div: 0.09876\n","val_rmse_target: 0.4571 val_rmse_stderror: 1.084\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 15\n","train_rmse_target: 0.1353 train_rmse_stderror: 0.02284 train_kl_div: 0.04045\n","val_rmse_target: 0.4564 val_rmse_stderror: 1.083\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 16\n","train_rmse_target: 0.1779 train_rmse_stderror: 0.01693 train_kl_div: 0.06661\n","val_rmse_target: 0.4578 val_rmse_stderror: 1.084\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","1 steps took 1.26 seconds\n","Epoch: 3 batch_num: 17\n","train_rmse_target: 0.1659 train_rmse_stderror: 0.02657 train_kl_div: 0.05997\n","val_rmse_target: 0.4616 val_rmse_stderror: 1.086\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","2 steps took 2.52 seconds\n","Epoch: 3 batch_num: 19\n","train_rmse_target: 0.1711 train_rmse_stderror: 0.02461 train_kl_div: 0.0615\n","val_rmse_target: 0.4703 val_rmse_stderror: 1.09\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","4 steps took 5.05 seconds\n","Epoch: 3 batch_num: 23\n","train_rmse_target: 0.1183 train_rmse_stderror: 0.02231 train_kl_div: 0.03156\n","val_rmse_target: 0.4594 val_rmse_stderror: 1.097\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 24\n","train_rmse_target: 0.1499 train_rmse_stderror: 0.01608 train_kl_div: 0.05258\n","val_rmse_target: 0.4586 val_rmse_stderror: 1.097\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 25\n","train_rmse_target: 0.1412 train_rmse_stderror: 0.008716 train_kl_div: 0.0467\n","val_rmse_target: 0.4598 val_rmse_stderror: 1.097\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","1 steps took 1.26 seconds\n","Epoch: 3 batch_num: 26\n","train_rmse_target: 0.2375 train_rmse_stderror: 0.03946 train_kl_div: 0.1081\n","val_rmse_target: 0.4621 val_rmse_stderror: 1.096\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","2 steps took 2.52 seconds\n","Epoch: 3 batch_num: 28\n","train_rmse_target: 0.1676 train_rmse_stderror: 0.02776 train_kl_div: 0.05926\n","val_rmse_target: 0.4646 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","2 steps took 2.52 seconds\n","Epoch: 3 batch_num: 30\n","train_rmse_target: 0.1901 train_rmse_stderror: 0.02351 train_kl_div: 0.07316\n","val_rmse_target: 0.46 val_rmse_stderror: 1.085\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 31\n","train_rmse_target: 0.2053 train_rmse_stderror: 0.02485 train_kl_div: 0.06775\n","val_rmse_target: 0.4593 val_rmse_stderror: 1.084\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 32\n","train_rmse_target: 0.1106 train_rmse_stderror: 0.01757 train_kl_div: 0.02921\n","val_rmse_target: 0.4596 val_rmse_stderror: 1.083\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 33\n","train_rmse_target: 0.216 train_rmse_stderror: 0.02282 train_kl_div: 0.101\n","val_rmse_target: 0.4618 val_rmse_stderror: 1.083\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","2 steps took 2.52 seconds\n","Epoch: 3 batch_num: 35\n","train_rmse_target: 0.1957 train_rmse_stderror: 0.02108 train_kl_div: 0.08477\n","val_rmse_target: 0.4632 val_rmse_stderror: 1.085\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","2 steps took 2.52 seconds\n","Epoch: 3 batch_num: 37\n","train_rmse_target: 0.1886 train_rmse_stderror: 0.03278 train_kl_div: 0.06708\n","val_rmse_target: 0.4579 val_rmse_stderror: 1.083\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 38\n","train_rmse_target: 0.1205 train_rmse_stderror: 0.0174 train_kl_div: 0.03181\n","val_rmse_target: 0.4572 val_rmse_stderror: 1.083\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 39\n","train_rmse_target: 0.1993 train_rmse_stderror: 0.02018 train_kl_div: 0.08247\n","val_rmse_target: 0.4563 val_rmse_stderror: 1.083\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 40\n","train_rmse_target: 0.09749 train_rmse_stderror: 0.02878 train_kl_div: 0.02398\n","val_rmse_target: 0.4567 val_rmse_stderror: 1.084\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 41\n","train_rmse_target: 0.1158 train_rmse_stderror: 0.01655 train_kl_div: 0.02872\n","val_rmse_target: 0.4573 val_rmse_stderror: 1.085\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 42\n","train_rmse_target: 0.2232 train_rmse_stderror: 0.03284 train_kl_div: 0.08513\n","val_rmse_target: 0.4569 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 43\n","train_rmse_target: 0.2212 train_rmse_stderror: 0.0237 train_kl_div: 0.09337\n","val_rmse_target: 0.4567 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 44\n","train_rmse_target: 0.1782 train_rmse_stderror: 0.02791 train_kl_div: 0.0749\n","val_rmse_target: 0.4574 val_rmse_stderror: 1.091\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 45\n","train_rmse_target: 0.1408 train_rmse_stderror: 0.01904 train_kl_div: 0.04063\n","val_rmse_target: 0.4601 val_rmse_stderror: 1.093\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","2 steps took 2.51 seconds\n","Epoch: 3 batch_num: 47\n","train_rmse_target: 0.1782 train_rmse_stderror: 0.03372 train_kl_div: 0.06121\n","val_rmse_target: 0.4627 val_rmse_stderror: 1.093\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","2 steps took 2.52 seconds\n","Epoch: 3 batch_num: 49\n","train_rmse_target: 0.1438 train_rmse_stderror: 0.01757 train_kl_div: 0.04326\n","val_rmse_target: 0.4599 val_rmse_stderror: 1.09\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","1 steps took 1.26 seconds\n","Epoch: 3 batch_num: 50\n","train_rmse_target: 0.1513 train_rmse_stderror: 0.01597 train_kl_div: 0.05124\n","val_rmse_target: 0.4579 val_rmse_stderror: 1.088\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 51\n","train_rmse_target: 0.1709 train_rmse_stderror: 0.02264 train_kl_div: 0.06032\n","val_rmse_target: 0.4577 val_rmse_stderror: 1.086\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 52\n","train_rmse_target: 0.1945 train_rmse_stderror: 0.02686 train_kl_div: 0.089\n","val_rmse_target: 0.4582 val_rmse_stderror: 1.085\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","1 steps took 1.26 seconds\n","Epoch: 3 batch_num: 53\n","train_rmse_target: 0.1833 train_rmse_stderror: 0.02145 train_kl_div: 0.06256\n","val_rmse_target: 0.4589 val_rmse_stderror: 1.085\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 54\n","train_rmse_target: 0.1334 train_rmse_stderror: 0.02075 train_kl_div: 0.04144\n","val_rmse_target: 0.4586 val_rmse_stderror: 1.086\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","1 steps took 1.26 seconds\n","Epoch: 3 batch_num: 55\n","train_rmse_target: 0.1624 train_rmse_stderror: 0.0297 train_kl_div: 0.05732\n","val_rmse_target: 0.4574 val_rmse_stderror: 1.088\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 56\n","train_rmse_target: 0.1815 train_rmse_stderror: 0.02592 train_kl_div: 0.06706\n","val_rmse_target: 0.4561 val_rmse_stderror: 1.091\n","Still best_val_rmse: 0.456 (from epoch 2)\n","\n","1 steps took 1.26 seconds\n","Epoch: 3 batch_num: 57\n","train_rmse_target: 0.1164 train_rmse_stderror: 0.02703 train_kl_div: 0.03025\n","val_rmse_target: 0.4556 val_rmse_stderror: 1.094\n","New best_val_rmse: 0.4556\n","\n","1 steps took 1.26 seconds\n","Epoch: 3 batch_num: 58\n","train_rmse_target: 0.1382 train_rmse_stderror: 0.03072 train_kl_div: 0.04107\n","val_rmse_target: 0.4563 val_rmse_stderror: 1.096\n","Still best_val_rmse: 0.4556 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 59\n","train_rmse_target: 0.1134 train_rmse_stderror: 0.03239 train_kl_div: 0.03103\n","val_rmse_target: 0.4574 val_rmse_stderror: 1.099\n","Still best_val_rmse: 0.4556 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 60\n","train_rmse_target: 0.1661 train_rmse_stderror: 0.03057 train_kl_div: 0.05384\n","val_rmse_target: 0.4606 val_rmse_stderror: 1.101\n","Still best_val_rmse: 0.4556 (from epoch 3)\n","\n","2 steps took 2.52 seconds\n","Epoch: 3 batch_num: 62\n","train_rmse_target: 0.2146 train_rmse_stderror: 0.0583 train_kl_div: 0.08018\n","val_rmse_target: 0.4643 val_rmse_stderror: 1.098\n","Still best_val_rmse: 0.4556 (from epoch 3)\n","\n","2 steps took 2.52 seconds\n","Epoch: 3 batch_num: 64\n","train_rmse_target: 0.1686 train_rmse_stderror: 0.03206 train_kl_div: 0.06448\n","val_rmse_target: 0.4563 val_rmse_stderror: 1.091\n","Still best_val_rmse: 0.4556 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 65\n","train_rmse_target: 0.1412 train_rmse_stderror: 0.01638 train_kl_div: 0.04562\n","val_rmse_target: 0.4545 val_rmse_stderror: 1.088\n","New best_val_rmse: 0.4545\n","\n","1 steps took 1.27 seconds\n","Epoch: 3 batch_num: 66\n","train_rmse_target: 0.123 train_rmse_stderror: 0.0227 train_kl_div: 0.0343\n","val_rmse_target: 0.4553 val_rmse_stderror: 1.086\n","Still best_val_rmse: 0.4545 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 3 batch_num: 67\n","train_rmse_target: 0.1371 train_rmse_stderror: 0.02188 train_kl_div: 0.04254\n","val_rmse_target: 0.4573 val_rmse_stderror: 1.084\n","Still best_val_rmse: 0.4545 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 3 batch_num: 68\n","train_rmse_target: 0.1535 train_rmse_stderror: 0.01983 train_kl_div: 0.04941\n","val_rmse_target: 0.4576 val_rmse_stderror: 1.083\n","Still best_val_rmse: 0.4545 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 69\n","train_rmse_target: 0.2391 train_rmse_stderror: 0.0372 train_kl_div: 0.1178\n","val_rmse_target: 0.4566 val_rmse_stderror: 1.082\n","Still best_val_rmse: 0.4545 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 70\n","train_rmse_target: 0.1902 train_rmse_stderror: 0.01373 train_kl_div: 0.07785\n","val_rmse_target: 0.4544 val_rmse_stderror: 1.083\n","New best_val_rmse: 0.4544\n","\n","1 steps took 1.27 seconds\n","Epoch: 3 batch_num: 71\n","train_rmse_target: 0.2177 train_rmse_stderror: 0.02541 train_kl_div: 0.1038\n","val_rmse_target: 0.4538 val_rmse_stderror: 1.084\n","New best_val_rmse: 0.4538\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 72\n","train_rmse_target: 0.1208 train_rmse_stderror: 0.03352 train_kl_div: 0.035\n","val_rmse_target: 0.4542 val_rmse_stderror: 1.085\n","Still best_val_rmse: 0.4538 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 73\n","train_rmse_target: 0.1377 train_rmse_stderror: 0.03095 train_kl_div: 0.04689\n","val_rmse_target: 0.4552 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.4538 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 74\n","train_rmse_target: 0.111 train_rmse_stderror: 0.02704 train_kl_div: 0.02913\n","val_rmse_target: 0.4574 val_rmse_stderror: 1.088\n","Still best_val_rmse: 0.4538 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 75\n","train_rmse_target: 0.2027 train_rmse_stderror: 0.02591 train_kl_div: 0.09452\n","val_rmse_target: 0.4589 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.4538 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 76\n","train_rmse_target: 0.1559 train_rmse_stderror: 0.02994 train_kl_div: 0.0561\n","val_rmse_target: 0.4604 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.4538 (from epoch 3)\n","\n","2 steps took 2.52 seconds\n","Epoch: 3 batch_num: 78\n","train_rmse_target: 0.1563 train_rmse_stderror: 0.01893 train_kl_div: 0.05376\n","val_rmse_target: 0.4588 val_rmse_stderror: 1.09\n","Still best_val_rmse: 0.4538 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 3 batch_num: 79\n","train_rmse_target: 0.1761 train_rmse_stderror: 0.03284 train_kl_div: 0.06094\n","val_rmse_target: 0.4561 val_rmse_stderror: 1.088\n","Still best_val_rmse: 0.4538 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 80\n","train_rmse_target: 0.154 train_rmse_stderror: 0.02237 train_kl_div: 0.04517\n","val_rmse_target: 0.4535 val_rmse_stderror: 1.086\n","New best_val_rmse: 0.4535\n","\n","1 steps took 1.27 seconds\n","Epoch: 3 batch_num: 81\n","train_rmse_target: 0.1395 train_rmse_stderror: 0.02634 train_kl_div: 0.04546\n","val_rmse_target: 0.4527 val_rmse_stderror: 1.086\n","New best_val_rmse: 0.4527\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 82\n","train_rmse_target: 0.1844 train_rmse_stderror: 0.02098 train_kl_div: 0.07052\n","val_rmse_target: 0.4529 val_rmse_stderror: 1.085\n","Still best_val_rmse: 0.4527 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 3 batch_num: 83\n","train_rmse_target: 0.2877 train_rmse_stderror: 0.02818 train_kl_div: 0.1715\n","val_rmse_target: 0.4524 val_rmse_stderror: 1.086\n","New best_val_rmse: 0.4524\n","\n","1 steps took 1.27 seconds\n","Epoch: 3 batch_num: 84\n","train_rmse_target: 0.2104 train_rmse_stderror: 0.02867 train_kl_div: 0.08606\n","val_rmse_target: 0.4516 val_rmse_stderror: 1.085\n","New best_val_rmse: 0.4516\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 85\n","train_rmse_target: 0.1197 train_rmse_stderror: 0.02563 train_kl_div: 0.03347\n","val_rmse_target: 0.451 val_rmse_stderror: 1.086\n","New best_val_rmse: 0.451\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 86\n","train_rmse_target: 0.187 train_rmse_stderror: 0.02666 train_kl_div: 0.07464\n","val_rmse_target: 0.451 val_rmse_stderror: 1.086\n","New best_val_rmse: 0.451\n","\n","1 steps took 1.27 seconds\n","Epoch: 3 batch_num: 87\n","train_rmse_target: 0.1685 train_rmse_stderror: 0.02349 train_kl_div: 0.06299\n","val_rmse_target: 0.4511 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 88\n","train_rmse_target: 0.1614 train_rmse_stderror: 0.02451 train_kl_div: 0.05872\n","val_rmse_target: 0.4511 val_rmse_stderror: 1.088\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 3 batch_num: 89\n","train_rmse_target: 0.1347 train_rmse_stderror: 0.0216 train_kl_div: 0.04019\n","val_rmse_target: 0.451 val_rmse_stderror: 1.09\n","New best_val_rmse: 0.451\n","\n","1 steps took 1.26 seconds\n","Epoch: 3 batch_num: 90\n","train_rmse_target: 0.139 train_rmse_stderror: 0.02334 train_kl_div: 0.04331\n","val_rmse_target: 0.4511 val_rmse_stderror: 1.092\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 91\n","train_rmse_target: 0.1709 train_rmse_stderror: 0.01276 train_kl_div: 0.06529\n","val_rmse_target: 0.451 val_rmse_stderror: 1.093\n","New best_val_rmse: 0.451\n","\n","1 steps took 1.26 seconds\n","Epoch: 3 batch_num: 92\n","train_rmse_target: 0.1386 train_rmse_stderror: 0.02241 train_kl_div: 0.04239\n","val_rmse_target: 0.451 val_rmse_stderror: 1.095\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 3 batch_num: 93\n","train_rmse_target: 0.1551 train_rmse_stderror: 0.02717 train_kl_div: 0.05424\n","val_rmse_target: 0.4513 val_rmse_stderror: 1.095\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 3 batch_num: 94\n","train_rmse_target: 0.1514 train_rmse_stderror: 0.03591 train_kl_div: 0.0527\n","val_rmse_target: 0.4512 val_rmse_stderror: 1.093\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 95\n","train_rmse_target: 0.1391 train_rmse_stderror: 0.0201 train_kl_div: 0.04272\n","val_rmse_target: 0.4515 val_rmse_stderror: 1.091\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 3 batch_num: 96\n","train_rmse_target: 0.1088 train_rmse_stderror: 0.01357 train_kl_div: 0.02347\n","val_rmse_target: 0.4517 val_rmse_stderror: 1.09\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 97\n","train_rmse_target: 0.1914 train_rmse_stderror: 0.02268 train_kl_div: 0.08159\n","val_rmse_target: 0.4521 val_rmse_stderror: 1.088\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 98\n","train_rmse_target: 0.1503 train_rmse_stderror: 0.01699 train_kl_div: 0.0483\n","val_rmse_target: 0.4527 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 99\n","train_rmse_target: 0.1185 train_rmse_stderror: 0.01822 train_kl_div: 0.03238\n","val_rmse_target: 0.4529 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 100\n","train_rmse_target: 0.2285 train_rmse_stderror: 0.05045 train_kl_div: 0.08272\n","val_rmse_target: 0.453 val_rmse_stderror: 1.085\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 101\n","train_rmse_target: 0.175 train_rmse_stderror: 0.03277 train_kl_div: 0.06912\n","val_rmse_target: 0.4531 val_rmse_stderror: 1.084\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 3 batch_num: 102\n","train_rmse_target: 0.1896 train_rmse_stderror: 0.0257 train_kl_div: 0.07971\n","val_rmse_target: 0.4525 val_rmse_stderror: 1.084\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 3 batch_num: 103\n","train_rmse_target: 0.2356 train_rmse_stderror: 0.0345 train_kl_div: 0.09503\n","val_rmse_target: 0.4516 val_rmse_stderror: 1.084\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 104\n","train_rmse_target: 0.1298 train_rmse_stderror: 0.02129 train_kl_div: 0.03574\n","val_rmse_target: 0.4515 val_rmse_stderror: 1.084\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 105\n","train_rmse_target: 0.1256 train_rmse_stderror: 0.02615 train_kl_div: 0.03419\n","val_rmse_target: 0.452 val_rmse_stderror: 1.085\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 3 batch_num: 106\n","train_rmse_target: 0.1324 train_rmse_stderror: 0.03779 train_kl_div: 0.04013\n","val_rmse_target: 0.4526 val_rmse_stderror: 1.086\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 107\n","train_rmse_target: 0.1079 train_rmse_stderror: 0.02311 train_kl_div: 0.02544\n","val_rmse_target: 0.4538 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 3 batch_num: 108\n","train_rmse_target: 0.1337 train_rmse_stderror: 0.02214 train_kl_div: 0.03743\n","val_rmse_target: 0.4548 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 109\n","train_rmse_target: 0.2021 train_rmse_stderror: 0.0194 train_kl_div: 0.08808\n","val_rmse_target: 0.4557 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 110\n","train_rmse_target: 0.1428 train_rmse_stderror: 0.02728 train_kl_div: 0.04663\n","val_rmse_target: 0.456 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 3 batch_num: 111\n","train_rmse_target: 0.1306 train_rmse_stderror: 0.02302 train_kl_div: 0.03653\n","val_rmse_target: 0.4558 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 112\n","train_rmse_target: 0.1869 train_rmse_stderror: 0.02906 train_kl_div: 0.07023\n","val_rmse_target: 0.4554 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 113\n","train_rmse_target: 0.1601 train_rmse_stderror: 0.01569 train_kl_div: 0.05577\n","val_rmse_target: 0.4545 val_rmse_stderror: 1.088\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 3 batch_num: 114\n","train_rmse_target: 0.1431 train_rmse_stderror: 0.02402 train_kl_div: 0.04885\n","val_rmse_target: 0.4532 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 115\n","train_rmse_target: 0.113 train_rmse_stderror: 0.02471 train_kl_div: 0.03062\n","val_rmse_target: 0.4524 val_rmse_stderror: 1.09\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 3 batch_num: 116\n","train_rmse_target: 0.1854 train_rmse_stderror: 0.0178 train_kl_div: 0.07778\n","val_rmse_target: 0.4525 val_rmse_stderror: 1.091\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 3 batch_num: 117\n","train_rmse_target: 0.1529 train_rmse_stderror: 0.02513 train_kl_div: 0.05252\n","val_rmse_target: 0.4527 val_rmse_stderror: 1.092\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 118\n","train_rmse_target: 0.171 train_rmse_stderror: 0.02927 train_kl_div: 0.06259\n","val_rmse_target: 0.4527 val_rmse_stderror: 1.093\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 119\n","train_rmse_target: 0.1909 train_rmse_stderror: 0.02111 train_kl_div: 0.08206\n","val_rmse_target: 0.4522 val_rmse_stderror: 1.093\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 3 batch_num: 120\n","train_rmse_target: 0.09843 train_rmse_stderror: 0.01657 train_kl_div: 0.02302\n","val_rmse_target: 0.4519 val_rmse_stderror: 1.093\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 121\n","train_rmse_target: 0.1281 train_rmse_stderror: 0.0243 train_kl_div: 0.0382\n","val_rmse_target: 0.4521 val_rmse_stderror: 1.093\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 3 batch_num: 122\n","train_rmse_target: 0.1355 train_rmse_stderror: 0.0231 train_kl_div: 0.03786\n","val_rmse_target: 0.4523 val_rmse_stderror: 1.093\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 123\n","train_rmse_target: 0.1174 train_rmse_stderror: 0.02413 train_kl_div: 0.03344\n","val_rmse_target: 0.4526 val_rmse_stderror: 1.092\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 124\n","train_rmse_target: 0.1396 train_rmse_stderror: 0.02388 train_kl_div: 0.04255\n","val_rmse_target: 0.453 val_rmse_stderror: 1.091\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 3 batch_num: 125\n","train_rmse_target: 0.1132 train_rmse_stderror: 0.01297 train_kl_div: 0.02721\n","val_rmse_target: 0.4533 val_rmse_stderror: 1.09\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 3 batch_num: 126\n","train_rmse_target: 0.166 train_rmse_stderror: 0.01236 train_kl_div: 0.05657\n","val_rmse_target: 0.454 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 127\n","train_rmse_target: 0.1353 train_rmse_stderror: 0.02854 train_kl_div: 0.03532\n","val_rmse_target: 0.4552 val_rmse_stderror: 1.088\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 3 batch_num: 128\n","train_rmse_target: 0.1583 train_rmse_stderror: 0.01764 train_kl_div: 0.05532\n","val_rmse_target: 0.4568 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 3 batch_num: 129\n","train_rmse_target: 0.1048 train_rmse_stderror: 0.01324 train_kl_div: 0.02252\n","val_rmse_target: 0.4581 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 130\n","train_rmse_target: 0.1085 train_rmse_stderror: 0.02578 train_kl_div: 0.02561\n","val_rmse_target: 0.4594 val_rmse_stderror: 1.086\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 131\n","train_rmse_target: 0.1341 train_rmse_stderror: 0.02139 train_kl_div: 0.04015\n","val_rmse_target: 0.4606 val_rmse_stderror: 1.085\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","2 steps took 2.52 seconds\n","Epoch: 3 batch_num: 133\n","train_rmse_target: 0.1401 train_rmse_stderror: 0.02365 train_kl_div: 0.03781\n","val_rmse_target: 0.463 val_rmse_stderror: 1.086\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","2 steps took 2.52 seconds\n","Epoch: 3 batch_num: 135\n","train_rmse_target: 0.1207 train_rmse_stderror: 0.02398 train_kl_div: 0.03159\n","val_rmse_target: 0.4625 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","2 steps took 2.52 seconds\n","Epoch: 3 batch_num: 137\n","train_rmse_target: 0.1372 train_rmse_stderror: 0.02314 train_kl_div: 0.04118\n","val_rmse_target: 0.4574 val_rmse_stderror: 1.088\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 138\n","train_rmse_target: 0.1749 train_rmse_stderror: 0.01419 train_kl_div: 0.06473\n","val_rmse_target: 0.4551 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 139\n","train_rmse_target: 0.1575 train_rmse_stderror: 0.01746 train_kl_div: 0.053\n","val_rmse_target: 0.4537 val_rmse_stderror: 1.09\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 140\n","train_rmse_target: 0.1814 train_rmse_stderror: 0.0265 train_kl_div: 0.07243\n","val_rmse_target: 0.453 val_rmse_stderror: 1.091\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 3 batch_num: 141\n","train_rmse_target: 0.2466 train_rmse_stderror: 0.03014 train_kl_div: 0.09456\n","val_rmse_target: 0.452 val_rmse_stderror: 1.092\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 142\n","train_rmse_target: 0.1733 train_rmse_stderror: 0.02461 train_kl_div: 0.06478\n","val_rmse_target: 0.4515 val_rmse_stderror: 1.093\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 143\n","train_rmse_target: 0.1768 train_rmse_stderror: 0.02345 train_kl_div: 0.07059\n","val_rmse_target: 0.4514 val_rmse_stderror: 1.092\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 144\n","train_rmse_target: 0.1086 train_rmse_stderror: 0.02892 train_kl_div: 0.0277\n","val_rmse_target: 0.4516 val_rmse_stderror: 1.092\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 3 batch_num: 145\n","train_rmse_target: 0.1265 train_rmse_stderror: 0.0332 train_kl_div: 0.0361\n","val_rmse_target: 0.4516 val_rmse_stderror: 1.091\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 3 batch_num: 146\n","train_rmse_target: 0.1098 train_rmse_stderror: 0.02697 train_kl_div: 0.02767\n","val_rmse_target: 0.4514 val_rmse_stderror: 1.091\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 147\n","train_rmse_target: 0.1079 train_rmse_stderror: 0.01566 train_kl_div: 0.02701\n","val_rmse_target: 0.4512 val_rmse_stderror: 1.091\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 148\n","train_rmse_target: 0.1233 train_rmse_stderror: 0.02765 train_kl_div: 0.03794\n","val_rmse_target: 0.4512 val_rmse_stderror: 1.091\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 149\n","train_rmse_target: 0.1472 train_rmse_stderror: 0.03449 train_kl_div: 0.04136\n","val_rmse_target: 0.4514 val_rmse_stderror: 1.09\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 150\n","train_rmse_target: 0.2141 train_rmse_stderror: 0.03013 train_kl_div: 0.09834\n","val_rmse_target: 0.4521 val_rmse_stderror: 1.088\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 151\n","train_rmse_target: 0.2122 train_rmse_stderror: 0.01867 train_kl_div: 0.09295\n","val_rmse_target: 0.4532 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 152\n","train_rmse_target: 0.1144 train_rmse_stderror: 0.02579 train_kl_div: 0.03168\n","val_rmse_target: 0.4548 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 153\n","train_rmse_target: 0.1334 train_rmse_stderror: 0.02688 train_kl_div: 0.04134\n","val_rmse_target: 0.4557 val_rmse_stderror: 1.086\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 154\n","train_rmse_target: 0.1522 train_rmse_stderror: 0.019 train_kl_div: 0.03989\n","val_rmse_target: 0.4567 val_rmse_stderror: 1.085\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 155\n","train_rmse_target: 0.1462 train_rmse_stderror: 0.02227 train_kl_div: 0.04923\n","val_rmse_target: 0.4567 val_rmse_stderror: 1.085\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 156\n","train_rmse_target: 0.17 train_rmse_stderror: 0.02187 train_kl_div: 0.06022\n","val_rmse_target: 0.4553 val_rmse_stderror: 1.085\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 3 batch_num: 157\n","train_rmse_target: 0.1787 train_rmse_stderror: 0.03138 train_kl_div: 0.07102\n","val_rmse_target: 0.4541 val_rmse_stderror: 1.084\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 158\n","train_rmse_target: 0.1133 train_rmse_stderror: 0.02454 train_kl_div: 0.02945\n","val_rmse_target: 0.4531 val_rmse_stderror: 1.084\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 3 batch_num: 159\n","train_rmse_target: 0.188 train_rmse_stderror: 0.01794 train_kl_div: 0.07416\n","val_rmse_target: 0.4526 val_rmse_stderror: 1.084\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 160\n","train_rmse_target: 0.2101 train_rmse_stderror: 0.02116 train_kl_div: 0.08494\n","val_rmse_target: 0.4527 val_rmse_stderror: 1.084\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 161\n","train_rmse_target: 0.159 train_rmse_stderror: 0.02333 train_kl_div: 0.05074\n","val_rmse_target: 0.4529 val_rmse_stderror: 1.084\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 162\n","train_rmse_target: 0.1475 train_rmse_stderror: 0.02602 train_kl_div: 0.04856\n","val_rmse_target: 0.4531 val_rmse_stderror: 1.085\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 163\n","train_rmse_target: 0.112 train_rmse_stderror: 0.02249 train_kl_div: 0.02898\n","val_rmse_target: 0.4533 val_rmse_stderror: 1.086\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 164\n","train_rmse_target: 0.126 train_rmse_stderror: 0.02228 train_kl_div: 0.03657\n","val_rmse_target: 0.4534 val_rmse_stderror: 1.088\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 165\n","train_rmse_target: 0.1907 train_rmse_stderror: 0.02295 train_kl_div: 0.07053\n","val_rmse_target: 0.4535 val_rmse_stderror: 1.088\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 166\n","train_rmse_target: 0.1076 train_rmse_stderror: 0.02292 train_kl_div: 0.02575\n","val_rmse_target: 0.4538 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 3 batch_num: 167\n","train_rmse_target: 0.2082 train_rmse_stderror: 0.0421 train_kl_div: 0.08077\n","val_rmse_target: 0.454 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 168\n","train_rmse_target: 0.1028 train_rmse_stderror: 0.02244 train_kl_div: 0.02405\n","val_rmse_target: 0.4544 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 169\n","train_rmse_target: 0.1806 train_rmse_stderror: 0.02386 train_kl_div: 0.06283\n","val_rmse_target: 0.455 val_rmse_stderror: 1.09\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 170\n","train_rmse_target: 0.2291 train_rmse_stderror: 0.03197 train_kl_div: 0.09666\n","val_rmse_target: 0.455 val_rmse_stderror: 1.09\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 3 batch_num: 171\n","train_rmse_target: 0.1872 train_rmse_stderror: 0.02459 train_kl_div: 0.06974\n","val_rmse_target: 0.4554 val_rmse_stderror: 1.09\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 172\n","train_rmse_target: 0.1334 train_rmse_stderror: 0.01825 train_kl_div: 0.03904\n","val_rmse_target: 0.4558 val_rmse_stderror: 1.091\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 173\n","train_rmse_target: 0.1559 train_rmse_stderror: 0.02384 train_kl_div: 0.05262\n","val_rmse_target: 0.4565 val_rmse_stderror: 1.092\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 3 batch_num: 174\n","train_rmse_target: 0.1584 train_rmse_stderror: 0.02061 train_kl_div: 0.05147\n","val_rmse_target: 0.457 val_rmse_stderror: 1.092\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 175\n","train_rmse_target: 0.1564 train_rmse_stderror: 0.02487 train_kl_div: 0.0566\n","val_rmse_target: 0.457 val_rmse_stderror: 1.093\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 176\n","train_rmse_target: 0.3247 train_rmse_stderror: 0.03936 train_kl_div: 0.1739\n","val_rmse_target: 0.4568 val_rmse_stderror: 1.093\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 3 batch_num: 177\n","train_rmse_target: 0.124 train_rmse_stderror: 0.01569 train_kl_div: 0.0317\n","val_rmse_target: 0.4563 val_rmse_stderror: 1.093\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 178\n","train_rmse_target: 0.1733 train_rmse_stderror: 0.02079 train_kl_div: 0.05471\n","val_rmse_target: 0.4557 val_rmse_stderror: 1.092\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 179\n","train_rmse_target: 0.1609 train_rmse_stderror: 0.0202 train_kl_div: 0.05454\n","val_rmse_target: 0.4551 val_rmse_stderror: 1.091\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 180\n","train_rmse_target: 0.1612 train_rmse_stderror: 0.02044 train_kl_div: 0.05318\n","val_rmse_target: 0.4543 val_rmse_stderror: 1.091\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 181\n","train_rmse_target: 0.1219 train_rmse_stderror: 0.02353 train_kl_div: 0.03624\n","val_rmse_target: 0.4537 val_rmse_stderror: 1.09\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 3 batch_num: 182\n","train_rmse_target: 0.1735 train_rmse_stderror: 0.02124 train_kl_div: 0.06511\n","val_rmse_target: 0.4532 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 183\n","train_rmse_target: 0.1723 train_rmse_stderror: 0.01852 train_kl_div: 0.06232\n","val_rmse_target: 0.4529 val_rmse_stderror: 1.088\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 184\n","train_rmse_target: 0.1878 train_rmse_stderror: 0.02206 train_kl_div: 0.06676\n","val_rmse_target: 0.4529 val_rmse_stderror: 1.088\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 3 batch_num: 185\n","train_rmse_target: 0.2153 train_rmse_stderror: 0.01916 train_kl_div: 0.09631\n","val_rmse_target: 0.4529 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 186\n","train_rmse_target: 0.1636 train_rmse_stderror: 0.03612 train_kl_div: 0.04249\n","val_rmse_target: 0.4529 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 3 batch_num: 187\n","train_rmse_target: 0.2066 train_rmse_stderror: 0.02504 train_kl_div: 0.09188\n","val_rmse_target: 0.4529 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.49 seconds\n","Epoch: 4 batch_num: 0\n","train_rmse_target: 0.1209 train_rmse_stderror: 0.02418 train_kl_div: 0.03311\n","val_rmse_target: 0.4528 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 1\n","train_rmse_target: 0.09694 train_rmse_stderror: 0.02393 train_kl_div: 0.02029\n","val_rmse_target: 0.4528 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 2\n","train_rmse_target: 0.1199 train_rmse_stderror: 0.0177 train_kl_div: 0.03289\n","val_rmse_target: 0.4528 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 3\n","train_rmse_target: 0.1219 train_rmse_stderror: 0.0207 train_kl_div: 0.03259\n","val_rmse_target: 0.4528 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 4\n","train_rmse_target: 0.09157 train_rmse_stderror: 0.02858 train_kl_div: 0.02094\n","val_rmse_target: 0.4528 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 5\n","train_rmse_target: 0.07214 train_rmse_stderror: 0.02496 train_kl_div: 0.01211\n","val_rmse_target: 0.4529 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 6\n","train_rmse_target: 0.1133 train_rmse_stderror: 0.0191 train_kl_div: 0.03022\n","val_rmse_target: 0.4529 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 7\n","train_rmse_target: 0.1241 train_rmse_stderror: 0.0221 train_kl_div: 0.03415\n","val_rmse_target: 0.4531 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 8\n","train_rmse_target: 0.1068 train_rmse_stderror: 0.0228 train_kl_div: 0.02517\n","val_rmse_target: 0.4534 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 9\n","train_rmse_target: 0.1275 train_rmse_stderror: 0.01611 train_kl_div: 0.03532\n","val_rmse_target: 0.454 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 10\n","train_rmse_target: 0.1143 train_rmse_stderror: 0.01873 train_kl_div: 0.0306\n","val_rmse_target: 0.4542 val_rmse_stderror: 1.088\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 11\n","train_rmse_target: 0.07309 train_rmse_stderror: 0.01583 train_kl_div: 0.01338\n","val_rmse_target: 0.4547 val_rmse_stderror: 1.088\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 12\n","train_rmse_target: 0.1198 train_rmse_stderror: 0.01597 train_kl_div: 0.03257\n","val_rmse_target: 0.455 val_rmse_stderror: 1.088\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 13\n","train_rmse_target: 0.0983 train_rmse_stderror: 0.01955 train_kl_div: 0.02333\n","val_rmse_target: 0.4552 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 14\n","train_rmse_target: 0.123 train_rmse_stderror: 0.02324 train_kl_div: 0.03168\n","val_rmse_target: 0.4556 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 15\n","train_rmse_target: 0.1263 train_rmse_stderror: 0.03365 train_kl_div: 0.03314\n","val_rmse_target: 0.4555 val_rmse_stderror: 1.09\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 16\n","train_rmse_target: 0.1243 train_rmse_stderror: 0.02574 train_kl_div: 0.03504\n","val_rmse_target: 0.4552 val_rmse_stderror: 1.091\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 17\n","train_rmse_target: 0.09622 train_rmse_stderror: 0.01852 train_kl_div: 0.02132\n","val_rmse_target: 0.4548 val_rmse_stderror: 1.091\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 18\n","train_rmse_target: 0.07997 train_rmse_stderror: 0.01462 train_kl_div: 0.01355\n","val_rmse_target: 0.4544 val_rmse_stderror: 1.091\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 19\n","train_rmse_target: 0.09659 train_rmse_stderror: 0.01917 train_kl_div: 0.02037\n","val_rmse_target: 0.4542 val_rmse_stderror: 1.091\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 20\n","train_rmse_target: 0.1427 train_rmse_stderror: 0.01755 train_kl_div: 0.04072\n","val_rmse_target: 0.4541 val_rmse_stderror: 1.091\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 21\n","train_rmse_target: 0.1073 train_rmse_stderror: 0.02261 train_kl_div: 0.02618\n","val_rmse_target: 0.454 val_rmse_stderror: 1.091\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 22\n","train_rmse_target: 0.09561 train_rmse_stderror: 0.01744 train_kl_div: 0.02031\n","val_rmse_target: 0.4539 val_rmse_stderror: 1.091\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 23\n","train_rmse_target: 0.09289 train_rmse_stderror: 0.02455 train_kl_div: 0.02013\n","val_rmse_target: 0.4539 val_rmse_stderror: 1.091\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 24\n","train_rmse_target: 0.06438 train_rmse_stderror: 0.02099 train_kl_div: 0.009611\n","val_rmse_target: 0.4539 val_rmse_stderror: 1.091\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 25\n","train_rmse_target: 0.1195 train_rmse_stderror: 0.02084 train_kl_div: 0.03163\n","val_rmse_target: 0.4539 val_rmse_stderror: 1.09\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 26\n","train_rmse_target: 0.07179 train_rmse_stderror: 0.02241 train_kl_div: 0.0126\n","val_rmse_target: 0.4538 val_rmse_stderror: 1.09\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 27\n","train_rmse_target: 0.09698 train_rmse_stderror: 0.01782 train_kl_div: 0.02136\n","val_rmse_target: 0.4539 val_rmse_stderror: 1.09\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 28\n","train_rmse_target: 0.1624 train_rmse_stderror: 0.03091 train_kl_div: 0.04474\n","val_rmse_target: 0.4538 val_rmse_stderror: 1.09\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 29\n","train_rmse_target: 0.1523 train_rmse_stderror: 0.01956 train_kl_div: 0.04705\n","val_rmse_target: 0.4536 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 30\n","train_rmse_target: 0.136 train_rmse_stderror: 0.02308 train_kl_div: 0.0392\n","val_rmse_target: 0.4535 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 31\n","train_rmse_target: 0.09436 train_rmse_stderror: 0.02623 train_kl_div: 0.0203\n","val_rmse_target: 0.4533 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 32\n","train_rmse_target: 0.1043 train_rmse_stderror: 0.02461 train_kl_div: 0.02533\n","val_rmse_target: 0.4534 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 33\n","train_rmse_target: 0.1022 train_rmse_stderror: 0.01913 train_kl_div: 0.02511\n","val_rmse_target: 0.4536 val_rmse_stderror: 1.09\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 34\n","train_rmse_target: 0.09573 train_rmse_stderror: 0.01984 train_kl_div: 0.02136\n","val_rmse_target: 0.4536 val_rmse_stderror: 1.09\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 35\n","train_rmse_target: 0.1084 train_rmse_stderror: 0.01704 train_kl_div: 0.02339\n","val_rmse_target: 0.4538 val_rmse_stderror: 1.09\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 36\n","train_rmse_target: 0.07881 train_rmse_stderror: 0.01404 train_kl_div: 0.01373\n","val_rmse_target: 0.4536 val_rmse_stderror: 1.091\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 37\n","train_rmse_target: 0.06861 train_rmse_stderror: 0.02088 train_kl_div: 0.01112\n","val_rmse_target: 0.4536 val_rmse_stderror: 1.091\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 38\n","train_rmse_target: 0.09165 train_rmse_stderror: 0.02659 train_kl_div: 0.01916\n","val_rmse_target: 0.4537 val_rmse_stderror: 1.09\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 39\n","train_rmse_target: 0.1018 train_rmse_stderror: 0.0185 train_kl_div: 0.0234\n","val_rmse_target: 0.4537 val_rmse_stderror: 1.09\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 40\n","train_rmse_target: 0.09164 train_rmse_stderror: 0.01934 train_kl_div: 0.01971\n","val_rmse_target: 0.4539 val_rmse_stderror: 1.09\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 41\n","train_rmse_target: 0.1303 train_rmse_stderror: 0.03778 train_kl_div: 0.03434\n","val_rmse_target: 0.454 val_rmse_stderror: 1.09\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 42\n","train_rmse_target: 0.1233 train_rmse_stderror: 0.01582 train_kl_div: 0.03445\n","val_rmse_target: 0.4543 val_rmse_stderror: 1.09\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 43\n","train_rmse_target: 0.1727 train_rmse_stderror: 0.02547 train_kl_div: 0.05268\n","val_rmse_target: 0.4546 val_rmse_stderror: 1.09\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 44\n","train_rmse_target: 0.115 train_rmse_stderror: 0.01966 train_kl_div: 0.03017\n","val_rmse_target: 0.4547 val_rmse_stderror: 1.09\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 45\n","train_rmse_target: 0.08128 train_rmse_stderror: 0.01081 train_kl_div: 0.0139\n","val_rmse_target: 0.4546 val_rmse_stderror: 1.09\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 46\n","train_rmse_target: 0.1355 train_rmse_stderror: 0.02419 train_kl_div: 0.03859\n","val_rmse_target: 0.4544 val_rmse_stderror: 1.09\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 47\n","train_rmse_target: 0.09111 train_rmse_stderror: 0.01965 train_kl_div: 0.01748\n","val_rmse_target: 0.4541 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 48\n","train_rmse_target: 0.1034 train_rmse_stderror: 0.02737 train_kl_div: 0.02552\n","val_rmse_target: 0.4544 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 49\n","train_rmse_target: 0.1392 train_rmse_stderror: 0.0218 train_kl_div: 0.03816\n","val_rmse_target: 0.4538 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 50\n","train_rmse_target: 0.05082 train_rmse_stderror: 0.02692 train_kl_div: 0.007735\n","val_rmse_target: 0.4536 val_rmse_stderror: 1.088\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 51\n","train_rmse_target: 0.1219 train_rmse_stderror: 0.01813 train_kl_div: 0.03018\n","val_rmse_target: 0.4534 val_rmse_stderror: 1.088\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 52\n","train_rmse_target: 0.08707 train_rmse_stderror: 0.03 train_kl_div: 0.01612\n","val_rmse_target: 0.4534 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 53\n","train_rmse_target: 0.1088 train_rmse_stderror: 0.02954 train_kl_div: 0.02984\n","val_rmse_target: 0.4528 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 54\n","train_rmse_target: 0.1104 train_rmse_stderror: 0.02491 train_kl_div: 0.02837\n","val_rmse_target: 0.4526 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 55\n","train_rmse_target: 0.1044 train_rmse_stderror: 0.02417 train_kl_div: 0.02559\n","val_rmse_target: 0.4525 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 56\n","train_rmse_target: 0.1902 train_rmse_stderror: 0.02685 train_kl_div: 0.07151\n","val_rmse_target: 0.4524 val_rmse_stderror: 1.086\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 57\n","train_rmse_target: 0.152 train_rmse_stderror: 0.03461 train_kl_div: 0.03776\n","val_rmse_target: 0.4525 val_rmse_stderror: 1.086\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 58\n","train_rmse_target: 0.08906 train_rmse_stderror: 0.0275 train_kl_div: 0.01746\n","val_rmse_target: 0.4525 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 59\n","train_rmse_target: 0.1229 train_rmse_stderror: 0.01287 train_kl_div: 0.033\n","val_rmse_target: 0.4527 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 60\n","train_rmse_target: 0.1128 train_rmse_stderror: 0.02506 train_kl_div: 0.03042\n","val_rmse_target: 0.4528 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 61\n","train_rmse_target: 0.1044 train_rmse_stderror: 0.02105 train_kl_div: 0.02491\n","val_rmse_target: 0.4531 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 62\n","train_rmse_target: 0.0995 train_rmse_stderror: 0.01937 train_kl_div: 0.02098\n","val_rmse_target: 0.4531 val_rmse_stderror: 1.088\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 63\n","train_rmse_target: 0.07296 train_rmse_stderror: 0.02161 train_kl_div: 0.0127\n","val_rmse_target: 0.4528 val_rmse_stderror: 1.088\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 64\n","train_rmse_target: 0.07415 train_rmse_stderror: 0.01601 train_kl_div: 0.01187\n","val_rmse_target: 0.4529 val_rmse_stderror: 1.088\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 65\n","train_rmse_target: 0.1042 train_rmse_stderror: 0.01632 train_kl_div: 0.02379\n","val_rmse_target: 0.4529 val_rmse_stderror: 1.088\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 66\n","train_rmse_target: 0.05771 train_rmse_stderror: 0.02021 train_kl_div: 0.007952\n","val_rmse_target: 0.4529 val_rmse_stderror: 1.088\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 67\n","train_rmse_target: 0.1577 train_rmse_stderror: 0.04363 train_kl_div: 0.04691\n","val_rmse_target: 0.453 val_rmse_stderror: 1.088\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 68\n","train_rmse_target: 0.08014 train_rmse_stderror: 0.01819 train_kl_div: 0.01566\n","val_rmse_target: 0.4529 val_rmse_stderror: 1.088\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 69\n","train_rmse_target: 0.09469 train_rmse_stderror: 0.01743 train_kl_div: 0.02074\n","val_rmse_target: 0.4529 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 70\n","train_rmse_target: 0.09384 train_rmse_stderror: 0.01852 train_kl_div: 0.01942\n","val_rmse_target: 0.4529 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 71\n","train_rmse_target: 0.1059 train_rmse_stderror: 0.01806 train_kl_div: 0.02413\n","val_rmse_target: 0.453 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 72\n","train_rmse_target: 0.06278 train_rmse_stderror: 0.01698 train_kl_div: 0.009586\n","val_rmse_target: 0.4531 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 73\n","train_rmse_target: 0.1146 train_rmse_stderror: 0.02915 train_kl_div: 0.03168\n","val_rmse_target: 0.4532 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 74\n","train_rmse_target: 0.1001 train_rmse_stderror: 0.02503 train_kl_div: 0.02253\n","val_rmse_target: 0.4532 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 75\n","train_rmse_target: 0.13 train_rmse_stderror: 0.02458 train_kl_div: 0.03769\n","val_rmse_target: 0.4534 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 76\n","train_rmse_target: 0.1233 train_rmse_stderror: 0.0235 train_kl_div: 0.03199\n","val_rmse_target: 0.4532 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 77\n","train_rmse_target: 0.111 train_rmse_stderror: 0.02427 train_kl_div: 0.02845\n","val_rmse_target: 0.4531 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 78\n","train_rmse_target: 0.05477 train_rmse_stderror: 0.02038 train_kl_div: 0.008296\n","val_rmse_target: 0.4534 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 79\n","train_rmse_target: 0.1381 train_rmse_stderror: 0.02778 train_kl_div: 0.0419\n","val_rmse_target: 0.4537 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 80\n","train_rmse_target: 0.09208 train_rmse_stderror: 0.018 train_kl_div: 0.0181\n","val_rmse_target: 0.4538 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 81\n","train_rmse_target: 0.07654 train_rmse_stderror: 0.02207 train_kl_div: 0.01378\n","val_rmse_target: 0.4535 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 82\n","train_rmse_target: 0.1747 train_rmse_stderror: 0.0272 train_kl_div: 0.05982\n","val_rmse_target: 0.4535 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 83\n","train_rmse_target: 0.1256 train_rmse_stderror: 0.03042 train_kl_div: 0.0354\n","val_rmse_target: 0.4537 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 84\n","train_rmse_target: 0.1364 train_rmse_stderror: 0.04194 train_kl_div: 0.03087\n","val_rmse_target: 0.4535 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 85\n","train_rmse_target: 0.1154 train_rmse_stderror: 0.02501 train_kl_div: 0.03012\n","val_rmse_target: 0.4534 val_rmse_stderror: 1.088\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 86\n","train_rmse_target: 0.1264 train_rmse_stderror: 0.01724 train_kl_div: 0.03341\n","val_rmse_target: 0.4535 val_rmse_stderror: 1.088\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 87\n","train_rmse_target: 0.1087 train_rmse_stderror: 0.01416 train_kl_div: 0.02326\n","val_rmse_target: 0.4535 val_rmse_stderror: 1.088\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 88\n","train_rmse_target: 0.1243 train_rmse_stderror: 0.01988 train_kl_div: 0.03219\n","val_rmse_target: 0.4533 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 89\n","train_rmse_target: 0.1342 train_rmse_stderror: 0.02701 train_kl_div: 0.04099\n","val_rmse_target: 0.4531 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 90\n","train_rmse_target: 0.08128 train_rmse_stderror: 0.01802 train_kl_div: 0.01609\n","val_rmse_target: 0.453 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 91\n","train_rmse_target: 0.08572 train_rmse_stderror: 0.01979 train_kl_div: 0.01724\n","val_rmse_target: 0.4532 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 92\n","train_rmse_target: 0.09794 train_rmse_stderror: 0.01961 train_kl_div: 0.02184\n","val_rmse_target: 0.4532 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 93\n","train_rmse_target: 0.0979 train_rmse_stderror: 0.0193 train_kl_div: 0.02318\n","val_rmse_target: 0.453 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 94\n","train_rmse_target: 0.148 train_rmse_stderror: 0.03288 train_kl_div: 0.04806\n","val_rmse_target: 0.4532 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 95\n","train_rmse_target: 0.1261 train_rmse_stderror: 0.0279 train_kl_div: 0.03516\n","val_rmse_target: 0.4531 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 96\n","train_rmse_target: 0.08039 train_rmse_stderror: 0.01608 train_kl_div: 0.01504\n","val_rmse_target: 0.4532 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 97\n","train_rmse_target: 0.1185 train_rmse_stderror: 0.02819 train_kl_div: 0.03037\n","val_rmse_target: 0.4531 val_rmse_stderror: 1.086\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 98\n","train_rmse_target: 0.0792 train_rmse_stderror: 0.02545 train_kl_div: 0.01695\n","val_rmse_target: 0.453 val_rmse_stderror: 1.086\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 99\n","train_rmse_target: 0.1183 train_rmse_stderror: 0.01904 train_kl_div: 0.0277\n","val_rmse_target: 0.453 val_rmse_stderror: 1.086\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 100\n","train_rmse_target: 0.1518 train_rmse_stderror: 0.02669 train_kl_div: 0.04091\n","val_rmse_target: 0.4531 val_rmse_stderror: 1.086\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 101\n","train_rmse_target: 0.08512 train_rmse_stderror: 0.02335 train_kl_div: 0.01756\n","val_rmse_target: 0.4532 val_rmse_stderror: 1.086\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 102\n","train_rmse_target: 0.08921 train_rmse_stderror: 0.02067 train_kl_div: 0.0185\n","val_rmse_target: 0.4529 val_rmse_stderror: 1.086\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 103\n","train_rmse_target: 0.08765 train_rmse_stderror: 0.01967 train_kl_div: 0.01772\n","val_rmse_target: 0.453 val_rmse_stderror: 1.086\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 104\n","train_rmse_target: 0.1123 train_rmse_stderror: 0.02134 train_kl_div: 0.02651\n","val_rmse_target: 0.453 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 105\n","train_rmse_target: 0.143 train_rmse_stderror: 0.01388 train_kl_div: 0.04373\n","val_rmse_target: 0.4531 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 106\n","train_rmse_target: 0.08925 train_rmse_stderror: 0.01665 train_kl_div: 0.01772\n","val_rmse_target: 0.453 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 107\n","train_rmse_target: 0.09959 train_rmse_stderror: 0.03 train_kl_div: 0.02548\n","val_rmse_target: 0.4528 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 108\n","train_rmse_target: 0.09291 train_rmse_stderror: 0.02035 train_kl_div: 0.02009\n","val_rmse_target: 0.4528 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 109\n","train_rmse_target: 0.0817 train_rmse_stderror: 0.02061 train_kl_div: 0.01576\n","val_rmse_target: 0.4527 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 110\n","train_rmse_target: 0.1157 train_rmse_stderror: 0.02134 train_kl_div: 0.02922\n","val_rmse_target: 0.4528 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 111\n","train_rmse_target: 0.1016 train_rmse_stderror: 0.02968 train_kl_div: 0.02304\n","val_rmse_target: 0.4529 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 112\n","train_rmse_target: 0.07111 train_rmse_stderror: 0.02027 train_kl_div: 0.01217\n","val_rmse_target: 0.4529 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 113\n","train_rmse_target: 0.1726 train_rmse_stderror: 0.03157 train_kl_div: 0.05635\n","val_rmse_target: 0.4531 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 114\n","train_rmse_target: 0.1004 train_rmse_stderror: 0.01714 train_kl_div: 0.02463\n","val_rmse_target: 0.4527 val_rmse_stderror: 1.087\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 115\n","train_rmse_target: 0.113 train_rmse_stderror: 0.03106 train_kl_div: 0.02895\n","val_rmse_target: 0.4529 val_rmse_stderror: 1.088\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 116\n","train_rmse_target: 0.1097 train_rmse_stderror: 0.01662 train_kl_div: 0.02616\n","val_rmse_target: 0.4528 val_rmse_stderror: 1.088\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 117\n","train_rmse_target: 0.08276 train_rmse_stderror: 0.02296 train_kl_div: 0.01672\n","val_rmse_target: 0.4527 val_rmse_stderror: 1.088\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 118\n","train_rmse_target: 0.1165 train_rmse_stderror: 0.02261 train_kl_div: 0.02836\n","val_rmse_target: 0.4528 val_rmse_stderror: 1.088\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 119\n","train_rmse_target: 0.07666 train_rmse_stderror: 0.01158 train_kl_div: 0.01347\n","val_rmse_target: 0.4526 val_rmse_stderror: 1.088\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 120\n","train_rmse_target: 0.09071 train_rmse_stderror: 0.02294 train_kl_div: 0.01831\n","val_rmse_target: 0.4527 val_rmse_stderror: 1.088\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 121\n","train_rmse_target: 0.1404 train_rmse_stderror: 0.0217 train_kl_div: 0.03702\n","val_rmse_target: 0.4527 val_rmse_stderror: 1.088\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 122\n","train_rmse_target: 0.1391 train_rmse_stderror: 0.02123 train_kl_div: 0.04328\n","val_rmse_target: 0.4525 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 123\n","train_rmse_target: 0.1032 train_rmse_stderror: 0.02942 train_kl_div: 0.0197\n","val_rmse_target: 0.4526 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 124\n","train_rmse_target: 0.1189 train_rmse_stderror: 0.01389 train_kl_div: 0.03195\n","val_rmse_target: 0.4526 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 125\n","train_rmse_target: 0.1137 train_rmse_stderror: 0.03572 train_kl_div: 0.02894\n","val_rmse_target: 0.4526 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 126\n","train_rmse_target: 0.07047 train_rmse_stderror: 0.02191 train_kl_div: 0.01308\n","val_rmse_target: 0.4525 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 127\n","train_rmse_target: 0.0575 train_rmse_stderror: 0.01905 train_kl_div: 0.008264\n","val_rmse_target: 0.4525 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 128\n","train_rmse_target: 0.1008 train_rmse_stderror: 0.01682 train_kl_div: 0.02077\n","val_rmse_target: 0.4526 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 129\n","train_rmse_target: 0.08802 train_rmse_stderror: 0.02236 train_kl_div: 0.01925\n","val_rmse_target: 0.4525 val_rmse_stderror: 1.09\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 130\n","train_rmse_target: 0.1115 train_rmse_stderror: 0.02116 train_kl_div: 0.0275\n","val_rmse_target: 0.4525 val_rmse_stderror: 1.09\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 131\n","train_rmse_target: 0.144 train_rmse_stderror: 0.02256 train_kl_div: 0.04685\n","val_rmse_target: 0.4526 val_rmse_stderror: 1.09\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 132\n","train_rmse_target: 0.1081 train_rmse_stderror: 0.0191 train_kl_div: 0.02426\n","val_rmse_target: 0.4525 val_rmse_stderror: 1.09\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 133\n","train_rmse_target: 0.09774 train_rmse_stderror: 0.0108 train_kl_div: 0.01963\n","val_rmse_target: 0.4525 val_rmse_stderror: 1.09\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 134\n","train_rmse_target: 0.08535 train_rmse_stderror: 0.01728 train_kl_div: 0.01653\n","val_rmse_target: 0.4525 val_rmse_stderror: 1.09\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 135\n","train_rmse_target: 0.1275 train_rmse_stderror: 0.02175 train_kl_div: 0.03444\n","val_rmse_target: 0.4526 val_rmse_stderror: 1.09\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 136\n","train_rmse_target: 0.1533 train_rmse_stderror: 0.02457 train_kl_div: 0.04575\n","val_rmse_target: 0.4525 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 137\n","train_rmse_target: 0.1139 train_rmse_stderror: 0.008461 train_kl_div: 0.02612\n","val_rmse_target: 0.4526 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 138\n","train_rmse_target: 0.08925 train_rmse_stderror: 0.02476 train_kl_div: 0.01818\n","val_rmse_target: 0.4526 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 139\n","train_rmse_target: 0.06408 train_rmse_stderror: 0.02553 train_kl_div: 0.01138\n","val_rmse_target: 0.4526 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 140\n","train_rmse_target: 0.1246 train_rmse_stderror: 0.01855 train_kl_div: 0.03142\n","val_rmse_target: 0.4525 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 141\n","train_rmse_target: 0.09158 train_rmse_stderror: 0.01241 train_kl_div: 0.01953\n","val_rmse_target: 0.4525 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 142\n","train_rmse_target: 0.07878 train_rmse_stderror: 0.01705 train_kl_div: 0.01433\n","val_rmse_target: 0.4525 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 143\n","train_rmse_target: 0.1408 train_rmse_stderror: 0.02214 train_kl_div: 0.03507\n","val_rmse_target: 0.4525 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 144\n","train_rmse_target: 0.09326 train_rmse_stderror: 0.01893 train_kl_div: 0.01924\n","val_rmse_target: 0.4527 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 145\n","train_rmse_target: 0.1884 train_rmse_stderror: 0.02665 train_kl_div: 0.05494\n","val_rmse_target: 0.4527 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 146\n","train_rmse_target: 0.1043 train_rmse_stderror: 0.0155 train_kl_div: 0.02409\n","val_rmse_target: 0.4527 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 147\n","train_rmse_target: 0.0419 train_rmse_stderror: 0.01903 train_kl_div: 0.005348\n","val_rmse_target: 0.4526 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 148\n","train_rmse_target: 0.0635 train_rmse_stderror: 0.02083 train_kl_div: 0.01027\n","val_rmse_target: 0.4526 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 149\n","train_rmse_target: 0.1079 train_rmse_stderror: 0.0211 train_kl_div: 0.02584\n","val_rmse_target: 0.4526 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 150\n","train_rmse_target: 0.1261 train_rmse_stderror: 0.02052 train_kl_div: 0.0347\n","val_rmse_target: 0.4526 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 151\n","train_rmse_target: 0.1212 train_rmse_stderror: 0.02972 train_kl_div: 0.03236\n","val_rmse_target: 0.4526 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 152\n","train_rmse_target: 0.0719 train_rmse_stderror: 0.02247 train_kl_div: 0.01253\n","val_rmse_target: 0.4527 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 153\n","train_rmse_target: 0.2561 train_rmse_stderror: 0.03469 train_kl_div: 0.1081\n","val_rmse_target: 0.4528 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 154\n","train_rmse_target: 0.08844 train_rmse_stderror: 0.01417 train_kl_div: 0.01779\n","val_rmse_target: 0.4527 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 155\n","train_rmse_target: 0.06723 train_rmse_stderror: 0.02074 train_kl_div: 0.01111\n","val_rmse_target: 0.4527 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 156\n","train_rmse_target: 0.09892 train_rmse_stderror: 0.01858 train_kl_div: 0.02302\n","val_rmse_target: 0.4526 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 157\n","train_rmse_target: 0.1265 train_rmse_stderror: 0.02295 train_kl_div: 0.03473\n","val_rmse_target: 0.4526 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 158\n","train_rmse_target: 0.09042 train_rmse_stderror: 0.0216 train_kl_div: 0.01945\n","val_rmse_target: 0.4526 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 159\n","train_rmse_target: 0.1016 train_rmse_stderror: 0.02863 train_kl_div: 0.02551\n","val_rmse_target: 0.4525 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 160\n","train_rmse_target: 0.1104 train_rmse_stderror: 0.01422 train_kl_div: 0.02832\n","val_rmse_target: 0.4525 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 161\n","train_rmse_target: 0.08437 train_rmse_stderror: 0.01846 train_kl_div: 0.01751\n","val_rmse_target: 0.4526 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 162\n","train_rmse_target: 0.06958 train_rmse_stderror: 0.02168 train_kl_div: 0.011\n","val_rmse_target: 0.4525 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 163\n","train_rmse_target: 0.07045 train_rmse_stderror: 0.02399 train_kl_div: 0.0114\n","val_rmse_target: 0.4527 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 164\n","train_rmse_target: 0.08724 train_rmse_stderror: 0.02688 train_kl_div: 0.01712\n","val_rmse_target: 0.4527 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 165\n","train_rmse_target: 0.06146 train_rmse_stderror: 0.02279 train_kl_div: 0.01071\n","val_rmse_target: 0.4528 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 166\n","train_rmse_target: 0.1067 train_rmse_stderror: 0.02496 train_kl_div: 0.02605\n","val_rmse_target: 0.4526 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 167\n","train_rmse_target: 0.09395 train_rmse_stderror: 0.02222 train_kl_div: 0.02175\n","val_rmse_target: 0.4526 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 168\n","train_rmse_target: 0.1013 train_rmse_stderror: 0.01366 train_kl_div: 0.0228\n","val_rmse_target: 0.4527 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 169\n","train_rmse_target: 0.1282 train_rmse_stderror: 0.02045 train_kl_div: 0.03527\n","val_rmse_target: 0.4527 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 170\n","train_rmse_target: 0.1437 train_rmse_stderror: 0.02275 train_kl_div: 0.03975\n","val_rmse_target: 0.4527 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 171\n","train_rmse_target: 0.08829 train_rmse_stderror: 0.02291 train_kl_div: 0.01762\n","val_rmse_target: 0.4528 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 172\n","train_rmse_target: 0.09949 train_rmse_stderror: 0.0362 train_kl_div: 0.02477\n","val_rmse_target: 0.4528 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 173\n","train_rmse_target: 0.1351 train_rmse_stderror: 0.02332 train_kl_div: 0.03187\n","val_rmse_target: 0.4527 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 174\n","train_rmse_target: 0.1294 train_rmse_stderror: 0.0205 train_kl_div: 0.03902\n","val_rmse_target: 0.4526 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 175\n","train_rmse_target: 0.08157 train_rmse_stderror: 0.02234 train_kl_div: 0.01624\n","val_rmse_target: 0.4526 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 176\n","train_rmse_target: 0.1254 train_rmse_stderror: 0.02364 train_kl_div: 0.03211\n","val_rmse_target: 0.4525 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 177\n","train_rmse_target: 0.1506 train_rmse_stderror: 0.02544 train_kl_div: 0.03882\n","val_rmse_target: 0.4525 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 178\n","train_rmse_target: 0.1014 train_rmse_stderror: 0.02908 train_kl_div: 0.02567\n","val_rmse_target: 0.4525 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 179\n","train_rmse_target: 0.1458 train_rmse_stderror: 0.0234 train_kl_div: 0.04428\n","val_rmse_target: 0.4524 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 180\n","train_rmse_target: 0.1155 train_rmse_stderror: 0.02005 train_kl_div: 0.02782\n","val_rmse_target: 0.4525 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 181\n","train_rmse_target: 0.07942 train_rmse_stderror: 0.02233 train_kl_div: 0.01657\n","val_rmse_target: 0.4525 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 182\n","train_rmse_target: 0.1219 train_rmse_stderror: 0.01876 train_kl_div: 0.03148\n","val_rmse_target: 0.4526 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 183\n","train_rmse_target: 0.1665 train_rmse_stderror: 0.01274 train_kl_div: 0.05575\n","val_rmse_target: 0.4525 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 184\n","train_rmse_target: 0.09795 train_rmse_stderror: 0.01375 train_kl_div: 0.02111\n","val_rmse_target: 0.4526 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 185\n","train_rmse_target: 0.07612 train_rmse_stderror: 0.01679 train_kl_div: 0.01266\n","val_rmse_target: 0.4526 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.25 seconds\n","Epoch: 4 batch_num: 186\n","train_rmse_target: 0.111 train_rmse_stderror: 0.01882 train_kl_div: 0.03018\n","val_rmse_target: 0.4527 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","1 steps took 1.26 seconds\n","Epoch: 4 batch_num: 187\n","train_rmse_target: 0.06598 train_rmse_stderror: 0.01924 train_kl_div: 0.01042\n","val_rmse_target: 0.4529 val_rmse_stderror: 1.089\n","Still best_val_rmse: 0.451 (from epoch 3)\n","\n","Performance estimates:\n","[0.45098122503459925]\n","Mean: 0.45098122503459925\n","{'total_MiB': 16280, 'used_MiB': 945}\n","\n","Fold 2/5\n","{'total_MiB': 16280, 'used_MiB': 945}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-roberta-large/clrp_pretrained_manish_epoch5/pre-trained-roberta/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-roberta-large/clrp_pretrained_manish_epoch5/pre-trained-roberta/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 82.1 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.6712 train_rmse_stderror: 0.3022 train_kl_div: 1.401\n","val_rmse_target: 0.7052 val_rmse_stderror: 1.988\n","New best_val_rmse: 0.7052\n","\n","64 steps took 81.0 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.7034 train_rmse_stderror: 0.05006 train_kl_div: 0.9755\n","val_rmse_target: 0.6072 val_rmse_stderror: 1.852\n","New best_val_rmse: 0.6072\n","\n","64 steps took 81.3 seconds\n","Epoch: 1 batch_num: 4\n","train_rmse_target: 0.5346 train_rmse_stderror: 0.07337 train_kl_div: 0.4645\n","val_rmse_target: 0.6272 val_rmse_stderror: 1.823\n","Still best_val_rmse: 0.6072 (from epoch 0)\n","\n","64 steps took 81.0 seconds\n","Epoch: 1 batch_num: 68\n","train_rmse_target: 0.7959 train_rmse_stderror: 0.04375 train_kl_div: 1.233\n","val_rmse_target: 0.5462 val_rmse_stderror: 1.803\n","New best_val_rmse: 0.5462\n","\n","32 steps took 40.5 seconds\n","Epoch: 1 batch_num: 100\n","train_rmse_target: 0.7134 train_rmse_stderror: 0.04023 train_kl_div: 1.069\n","val_rmse_target: 0.5513 val_rmse_stderror: 1.808\n","Still best_val_rmse: 0.5462 (from epoch 1)\n","\n","64 steps took 81.0 seconds\n","Epoch: 1 batch_num: 164\n","train_rmse_target: 0.5515 train_rmse_stderror: 0.07321 train_kl_div: 0.6863\n","val_rmse_target: 0.5597 val_rmse_stderror: 1.817\n","Still best_val_rmse: 0.5462 (from epoch 1)\n","\n","64 steps took 81.3 seconds\n","Epoch: 2 batch_num: 40\n","train_rmse_target: 0.3625 train_rmse_stderror: 0.04315 train_kl_div: 0.2788\n","val_rmse_target: 0.539 val_rmse_stderror: 1.814\n","New best_val_rmse: 0.539\n","\n","32 steps took 40.5 seconds\n","Epoch: 2 batch_num: 72\n","train_rmse_target: 0.2938 train_rmse_stderror: 0.04374 train_kl_div: 0.1838\n","val_rmse_target: 0.5613 val_rmse_stderror: 1.791\n","Still best_val_rmse: 0.539 (from epoch 2)\n","\n","64 steps took 81.0 seconds\n","Epoch: 2 batch_num: 136\n","train_rmse_target: 0.3989 train_rmse_stderror: 0.03035 train_kl_div: 0.3292\n","val_rmse_target: 0.5061 val_rmse_stderror: 1.806\n","New best_val_rmse: 0.5061\n","\n","32 steps took 40.5 seconds\n","Epoch: 2 batch_num: 168\n","train_rmse_target: 0.5476 train_rmse_stderror: 0.04904 train_kl_div: 0.6169\n","val_rmse_target: 0.515 val_rmse_stderror: 1.797\n","Still best_val_rmse: 0.5061 (from epoch 2)\n","\n","32 steps took 40.7 seconds\n","Epoch: 3 batch_num: 12\n","train_rmse_target: 0.5213 train_rmse_stderror: 0.04371 train_kl_div: 0.5428\n","val_rmse_target: 0.4924 val_rmse_stderror: 1.811\n","New best_val_rmse: 0.4924\n","\n","16 steps took 20.3 seconds\n","Epoch: 3 batch_num: 28\n","train_rmse_target: 0.2146 train_rmse_stderror: 0.03575 train_kl_div: 0.08944\n","val_rmse_target: 0.5062 val_rmse_stderror: 1.805\n","Still best_val_rmse: 0.4924 (from epoch 3)\n","\n","32 steps took 40.5 seconds\n","Epoch: 3 batch_num: 60\n","train_rmse_target: 0.3521 train_rmse_stderror: 0.04733 train_kl_div: 0.241\n","val_rmse_target: 0.5009 val_rmse_stderror: 1.801\n","Still best_val_rmse: 0.4924 (from epoch 3)\n","\n","32 steps took 40.5 seconds\n","Epoch: 3 batch_num: 92\n","train_rmse_target: 0.408 train_rmse_stderror: 0.05708 train_kl_div: 0.3529\n","val_rmse_target: 0.4979 val_rmse_stderror: 1.812\n","Still best_val_rmse: 0.4924 (from epoch 3)\n","\n","16 steps took 20.3 seconds\n","Epoch: 3 batch_num: 108\n","train_rmse_target: 0.3478 train_rmse_stderror: 0.02742 train_kl_div: 0.2658\n","val_rmse_target: 0.5144 val_rmse_stderror: 1.801\n","Still best_val_rmse: 0.4924 (from epoch 3)\n","\n","32 steps took 40.5 seconds\n","Epoch: 3 batch_num: 140\n","train_rmse_target: 0.4439 train_rmse_stderror: 0.04686 train_kl_div: 0.4036\n","val_rmse_target: 0.5518 val_rmse_stderror: 1.803\n","Still best_val_rmse: 0.4924 (from epoch 3)\n","\n","64 steps took 81.2 seconds\n","Epoch: 4 batch_num: 16\n","train_rmse_target: 0.2815 train_rmse_stderror: 0.05142 train_kl_div: 0.1601\n","val_rmse_target: 0.4925 val_rmse_stderror: 1.808\n","Still best_val_rmse: 0.4924 (from epoch 3)\n","\n","16 steps took 20.3 seconds\n","Epoch: 4 batch_num: 32\n","train_rmse_target: 0.2749 train_rmse_stderror: 0.03827 train_kl_div: 0.1631\n","val_rmse_target: 0.4963 val_rmse_stderror: 1.806\n","Still best_val_rmse: 0.4924 (from epoch 3)\n","\n","16 steps took 20.3 seconds\n","Epoch: 4 batch_num: 48\n","train_rmse_target: 0.2501 train_rmse_stderror: 0.03488 train_kl_div: 0.1206\n","val_rmse_target: 0.5005 val_rmse_stderror: 1.806\n","Still best_val_rmse: 0.4924 (from epoch 3)\n","\n","32 steps took 40.5 seconds\n","Epoch: 4 batch_num: 80\n","train_rmse_target: 0.3509 train_rmse_stderror: 0.04381 train_kl_div: 0.2092\n","val_rmse_target: 0.5256 val_rmse_stderror: 1.799\n","Still best_val_rmse: 0.4924 (from epoch 3)\n","\n","32 steps took 40.5 seconds\n","Epoch: 4 batch_num: 112\n","train_rmse_target: 0.2354 train_rmse_stderror: 0.03394 train_kl_div: 0.1134\n","val_rmse_target: 0.5004 val_rmse_stderror: 1.804\n","Still best_val_rmse: 0.4924 (from epoch 3)\n","\n","32 steps took 40.5 seconds\n","Epoch: 4 batch_num: 144\n","train_rmse_target: 0.2048 train_rmse_stderror: 0.07439 train_kl_div: 0.1128\n","val_rmse_target: 0.5013 val_rmse_stderror: 1.805\n","Still best_val_rmse: 0.4924 (from epoch 3)\n","\n","32 steps took 40.5 seconds\n","Epoch: 4 batch_num: 176\n","train_rmse_target: 0.2338 train_rmse_stderror: 0.03054 train_kl_div: 0.1253\n","val_rmse_target: 0.5018 val_rmse_stderror: 1.804\n","Still best_val_rmse: 0.4924 (from epoch 3)\n","\n","Performance estimates:\n","[0.45098122503459925, 0.49243304423428724]\n","Mean: 0.47170713463444325\n","{'total_MiB': 16280, 'used_MiB': 945}\n","\n","Fold 3/5\n","{'total_MiB': 16280, 'used_MiB': 945}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-roberta-large/clrp_pretrained_manish_epoch5/pre-trained-roberta/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-roberta-large/clrp_pretrained_manish_epoch5/pre-trained-roberta/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 82.0 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.49 train_rmse_stderror: 0.1377 train_kl_div: 0.5644\n","val_rmse_target: 0.8565 val_rmse_stderror: 1.25\n","New best_val_rmse: 0.8565\n","\n","64 steps took 81.0 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.6814 train_rmse_stderror: 0.04658 train_kl_div: 0.9285\n","val_rmse_target: 0.6379 val_rmse_stderror: 1.182\n","New best_val_rmse: 0.6379\n","\n","64 steps took 81.3 seconds\n","Epoch: 1 batch_num: 4\n","train_rmse_target: 0.5404 train_rmse_stderror: 0.05594 train_kl_div: 0.6087\n","val_rmse_target: 0.5442 val_rmse_stderror: 1.178\n","New best_val_rmse: 0.5442\n","\n","32 steps took 40.6 seconds\n","Epoch: 1 batch_num: 36\n","train_rmse_target: 0.4669 train_rmse_stderror: 0.03954 train_kl_div: 0.4526\n","val_rmse_target: 0.5399 val_rmse_stderror: 1.173\n","New best_val_rmse: 0.5399\n","\n","32 steps took 40.5 seconds\n","Epoch: 1 batch_num: 68\n","train_rmse_target: 0.4656 train_rmse_stderror: 0.03258 train_kl_div: 0.4643\n","val_rmse_target: 0.5676 val_rmse_stderror: 1.173\n","Still best_val_rmse: 0.5399 (from epoch 1)\n","\n","64 steps took 81.0 seconds\n","Epoch: 1 batch_num: 132\n","train_rmse_target: 0.5006 train_rmse_stderror: 0.0322 train_kl_div: 0.5389\n","val_rmse_target: 0.549 val_rmse_stderror: 1.188\n","Still best_val_rmse: 0.5399 (from epoch 1)\n","\n","32 steps took 40.5 seconds\n","Epoch: 1 batch_num: 164\n","train_rmse_target: 0.6202 train_rmse_stderror: 0.04379 train_kl_div: 0.6749\n","val_rmse_target: 0.5441 val_rmse_stderror: 1.184\n","Still best_val_rmse: 0.5399 (from epoch 1)\n","\n","32 steps took 40.8 seconds\n","Epoch: 2 batch_num: 8\n","train_rmse_target: 0.4941 train_rmse_stderror: 0.05177 train_kl_div: 0.4168\n","val_rmse_target: 0.5636 val_rmse_stderror: 1.184\n","Still best_val_rmse: 0.5399 (from epoch 1)\n","\n","64 steps took 81.0 seconds\n","Epoch: 2 batch_num: 72\n","train_rmse_target: 0.2848 train_rmse_stderror: 0.04722 train_kl_div: 0.1883\n","val_rmse_target: 0.5309 val_rmse_stderror: 1.177\n","New best_val_rmse: 0.5309\n","\n","32 steps took 40.5 seconds\n","Epoch: 2 batch_num: 104\n","train_rmse_target: 0.4039 train_rmse_stderror: 0.03036 train_kl_div: 0.3564\n","val_rmse_target: 0.5909 val_rmse_stderror: 1.181\n","Still best_val_rmse: 0.5309 (from epoch 2)\n","\n","64 steps took 81.0 seconds\n","Epoch: 2 batch_num: 168\n","train_rmse_target: 0.2402 train_rmse_stderror: 0.05118 train_kl_div: 0.1304\n","val_rmse_target: 0.5669 val_rmse_stderror: 1.184\n","Still best_val_rmse: 0.5309 (from epoch 2)\n","\n","64 steps took 81.3 seconds\n","Epoch: 3 batch_num: 44\n","train_rmse_target: 0.2257 train_rmse_stderror: 0.02836 train_kl_div: 0.1216\n","val_rmse_target: 0.5043 val_rmse_stderror: 1.182\n","New best_val_rmse: 0.5043\n","\n","32 steps took 40.5 seconds\n","Epoch: 3 batch_num: 76\n","train_rmse_target: 0.1408 train_rmse_stderror: 0.03881 train_kl_div: 0.05151\n","val_rmse_target: 0.5061 val_rmse_stderror: 1.175\n","Still best_val_rmse: 0.5043 (from epoch 3)\n","\n","32 steps took 40.5 seconds\n","Epoch: 3 batch_num: 108\n","train_rmse_target: 0.2174 train_rmse_stderror: 0.03333 train_kl_div: 0.09644\n","val_rmse_target: 0.5017 val_rmse_stderror: 1.177\n","New best_val_rmse: 0.5017\n","\n","32 steps took 40.5 seconds\n","Epoch: 3 batch_num: 140\n","train_rmse_target: 0.1416 train_rmse_stderror: 0.03348 train_kl_div: 0.04649\n","val_rmse_target: 0.5137 val_rmse_stderror: 1.181\n","Still best_val_rmse: 0.5017 (from epoch 3)\n","\n","32 steps took 40.5 seconds\n","Epoch: 3 batch_num: 172\n","train_rmse_target: 0.2731 train_rmse_stderror: 0.03633 train_kl_div: 0.1616\n","val_rmse_target: 0.5085 val_rmse_stderror: 1.177\n","Still best_val_rmse: 0.5017 (from epoch 3)\n","\n","32 steps took 40.7 seconds\n","Epoch: 4 batch_num: 16\n","train_rmse_target: 0.1555 train_rmse_stderror: 0.0284 train_kl_div: 0.05335\n","val_rmse_target: 0.5118 val_rmse_stderror: 1.179\n","Still best_val_rmse: 0.5017 (from epoch 3)\n","\n","32 steps took 40.5 seconds\n","Epoch: 4 batch_num: 48\n","train_rmse_target: 0.1109 train_rmse_stderror: 0.02839 train_kl_div: 0.0292\n","val_rmse_target: 0.5109 val_rmse_stderror: 1.18\n","Still best_val_rmse: 0.5017 (from epoch 3)\n","\n","32 steps took 40.5 seconds\n","Epoch: 4 batch_num: 80\n","train_rmse_target: 0.07739 train_rmse_stderror: 0.03372 train_kl_div: 0.01771\n","val_rmse_target: 0.504 val_rmse_stderror: 1.18\n","Still best_val_rmse: 0.5017 (from epoch 3)\n","\n","32 steps took 40.5 seconds\n","Epoch: 4 batch_num: 112\n","train_rmse_target: 0.169 train_rmse_stderror: 0.04736 train_kl_div: 0.06558\n","val_rmse_target: 0.508 val_rmse_stderror: 1.179\n","Still best_val_rmse: 0.5017 (from epoch 3)\n","\n","32 steps took 40.5 seconds\n","Epoch: 4 batch_num: 144\n","train_rmse_target: 0.1126 train_rmse_stderror: 0.03076 train_kl_div: 0.03298\n","val_rmse_target: 0.5108 val_rmse_stderror: 1.179\n","Still best_val_rmse: 0.5017 (from epoch 3)\n","\n","32 steps took 40.5 seconds\n","Epoch: 4 batch_num: 176\n","train_rmse_target: 0.1239 train_rmse_stderror: 0.03667 train_kl_div: 0.03465\n","val_rmse_target: 0.5102 val_rmse_stderror: 1.179\n","Still best_val_rmse: 0.5017 (from epoch 3)\n","\n","Performance estimates:\n","[0.45098122503459925, 0.49243304423428724, 0.501725707273907]\n","Mean: 0.4817133255142645\n","{'total_MiB': 16280, 'used_MiB': 945}\n","\n","Fold 4/5\n","{'total_MiB': 16280, 'used_MiB': 945}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-roberta-large/clrp_pretrained_manish_epoch5/pre-trained-roberta/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-roberta-large/clrp_pretrained_manish_epoch5/pre-trained-roberta/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 82.1 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.5312 train_rmse_stderror: 0.0562 train_kl_div: 0.4958\n","val_rmse_target: 0.8225 val_rmse_stderror: 1.764\n","New best_val_rmse: 0.8225\n","\n","64 steps took 81.0 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.5925 train_rmse_stderror: 0.03526 train_kl_div: 0.7474\n","val_rmse_target: 0.6417 val_rmse_stderror: 1.739\n","New best_val_rmse: 0.6417\n","\n","64 steps took 81.3 seconds\n","Epoch: 1 batch_num: 4\n","train_rmse_target: 0.3908 train_rmse_stderror: 0.04783 train_kl_div: 0.2841\n","val_rmse_target: 0.5558 val_rmse_stderror: 1.778\n","New best_val_rmse: 0.5558\n","\n","64 steps took 81.0 seconds\n","Epoch: 1 batch_num: 68\n","train_rmse_target: 0.4604 train_rmse_stderror: 0.04201 train_kl_div: 0.4623\n","val_rmse_target: 0.513 val_rmse_stderror: 1.762\n","New best_val_rmse: 0.513\n","\n","32 steps took 40.6 seconds\n","Epoch: 1 batch_num: 100\n","train_rmse_target: 0.5346 train_rmse_stderror: 0.03543 train_kl_div: 0.6466\n","val_rmse_target: 0.5458 val_rmse_stderror: 1.743\n","Still best_val_rmse: 0.513 (from epoch 1)\n","\n","32 steps took 40.5 seconds\n","Epoch: 1 batch_num: 132\n","train_rmse_target: 0.5098 train_rmse_stderror: 0.04661 train_kl_div: 0.5361\n","val_rmse_target: 0.614 val_rmse_stderror: 1.776\n","Still best_val_rmse: 0.513 (from epoch 1)\n","\n","64 steps took 81.2 seconds\n","Epoch: 2 batch_num: 8\n","train_rmse_target: 0.1714 train_rmse_stderror: 0.02695 train_kl_div: 0.06717\n","val_rmse_target: 0.519 val_rmse_stderror: 1.763\n","Still best_val_rmse: 0.513 (from epoch 1)\n","\n","32 steps took 40.5 seconds\n","Epoch: 2 batch_num: 40\n","train_rmse_target: 0.3731 train_rmse_stderror: 0.03869 train_kl_div: 0.2989\n","val_rmse_target: 0.5496 val_rmse_stderror: 1.746\n","Still best_val_rmse: 0.513 (from epoch 1)\n","\n","32 steps took 40.5 seconds\n","Epoch: 2 batch_num: 72\n","train_rmse_target: 0.3226 train_rmse_stderror: 0.02421 train_kl_div: 0.214\n","val_rmse_target: 0.4921 val_rmse_stderror: 1.77\n","New best_val_rmse: 0.4921\n","\n","16 steps took 20.3 seconds\n","Epoch: 2 batch_num: 88\n","train_rmse_target: 0.3609 train_rmse_stderror: 0.02621 train_kl_div: 0.2778\n","val_rmse_target: 0.5091 val_rmse_stderror: 1.755\n","Still best_val_rmse: 0.4921 (from epoch 2)\n","\n","32 steps took 40.5 seconds\n","Epoch: 2 batch_num: 120\n","train_rmse_target: 0.4029 train_rmse_stderror: 0.03214 train_kl_div: 0.3524\n","val_rmse_target: 0.5048 val_rmse_stderror: 1.772\n","Still best_val_rmse: 0.4921 (from epoch 2)\n","\n","32 steps took 40.4 seconds\n","Epoch: 2 batch_num: 152\n","train_rmse_target: 0.387 train_rmse_stderror: 0.03301 train_kl_div: 0.3214\n","val_rmse_target: 0.5127 val_rmse_stderror: 1.751\n","Still best_val_rmse: 0.4921 (from epoch 2)\n","\n","32 steps took 40.5 seconds\n","Epoch: 2 batch_num: 184\n","train_rmse_target: 0.2425 train_rmse_stderror: 0.02077 train_kl_div: 0.1236\n","val_rmse_target: 0.5088 val_rmse_stderror: 1.754\n","Still best_val_rmse: 0.4921 (from epoch 2)\n","\n","32 steps took 40.7 seconds\n","Epoch: 3 batch_num: 28\n","train_rmse_target: 0.1985 train_rmse_stderror: 0.023 train_kl_div: 0.08633\n","val_rmse_target: 0.5293 val_rmse_stderror: 1.77\n","Still best_val_rmse: 0.4921 (from epoch 2)\n","\n","32 steps took 40.5 seconds\n","Epoch: 3 batch_num: 60\n","train_rmse_target: 0.1581 train_rmse_stderror: 0.02039 train_kl_div: 0.0574\n","val_rmse_target: 0.5107 val_rmse_stderror: 1.759\n","Still best_val_rmse: 0.4921 (from epoch 2)\n","\n","32 steps took 40.5 seconds\n","Epoch: 3 batch_num: 92\n","train_rmse_target: 0.2698 train_rmse_stderror: 0.04162 train_kl_div: 0.1203\n","val_rmse_target: 0.5149 val_rmse_stderror: 1.756\n","Still best_val_rmse: 0.4921 (from epoch 2)\n","\n","32 steps took 40.5 seconds\n","Epoch: 3 batch_num: 124\n","train_rmse_target: 0.1867 train_rmse_stderror: 0.02315 train_kl_div: 0.07395\n","val_rmse_target: 0.5133 val_rmse_stderror: 1.761\n","Still best_val_rmse: 0.4921 (from epoch 2)\n","\n","32 steps took 40.5 seconds\n","Epoch: 3 batch_num: 156\n","train_rmse_target: 0.1122 train_rmse_stderror: 0.02063 train_kl_div: 0.02651\n","val_rmse_target: 0.5056 val_rmse_stderror: 1.755\n","Still best_val_rmse: 0.4921 (from epoch 2)\n","\n","32 steps took 40.7 seconds\n","Epoch: 4 batch_num: 0\n","train_rmse_target: 0.1415 train_rmse_stderror: 0.02908 train_kl_div: 0.04437\n","val_rmse_target: 0.5097 val_rmse_stderror: 1.76\n","Still best_val_rmse: 0.4921 (from epoch 2)\n","\n","32 steps took 40.5 seconds\n","Epoch: 4 batch_num: 32\n","train_rmse_target: 0.169 train_rmse_stderror: 0.01623 train_kl_div: 0.05848\n","val_rmse_target: 0.5096 val_rmse_stderror: 1.758\n","Still best_val_rmse: 0.4921 (from epoch 2)\n","\n","32 steps took 40.5 seconds\n","Epoch: 4 batch_num: 64\n","train_rmse_target: 0.1135 train_rmse_stderror: 0.01642 train_kl_div: 0.02451\n","val_rmse_target: 0.506 val_rmse_stderror: 1.76\n","Still best_val_rmse: 0.4921 (from epoch 2)\n","\n","32 steps took 40.5 seconds\n","Epoch: 4 batch_num: 96\n","train_rmse_target: 0.1494 train_rmse_stderror: 0.01692 train_kl_div: 0.05204\n","val_rmse_target: 0.505 val_rmse_stderror: 1.758\n","Still best_val_rmse: 0.4921 (from epoch 2)\n","\n","32 steps took 40.5 seconds\n","Epoch: 4 batch_num: 128\n","train_rmse_target: 0.08201 train_rmse_stderror: 0.0156 train_kl_div: 0.0164\n","val_rmse_target: 0.5017 val_rmse_stderror: 1.76\n","Still best_val_rmse: 0.4921 (from epoch 2)\n","\n","32 steps took 40.5 seconds\n","Epoch: 4 batch_num: 160\n","train_rmse_target: 0.1377 train_rmse_stderror: 0.02982 train_kl_div: 0.04221\n","val_rmse_target: 0.5023 val_rmse_stderror: 1.759\n","Still best_val_rmse: 0.4921 (from epoch 2)\n","\n","Performance estimates:\n","[0.45098122503459925, 0.49243304423428724, 0.501725707273907, 0.49213581026671677]\n","Mean: 0.4843189467023776\n","{'total_MiB': 16280, 'used_MiB': 945}\n","\n","Fold 5/5\n","{'total_MiB': 16280, 'used_MiB': 945}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-roberta-large/clrp_pretrained_manish_epoch5/pre-trained-roberta/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-roberta-large/clrp_pretrained_manish_epoch5/pre-trained-roberta/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 82.3 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.8071 train_rmse_stderror: 0.05243 train_kl_div: 1.269\n","val_rmse_target: 0.7002 val_rmse_stderror: 1.151\n","New best_val_rmse: 0.7002\n","\n","64 steps took 81.1 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.5158 train_rmse_stderror: 0.04194 train_kl_div: 0.5996\n","val_rmse_target: 0.6066 val_rmse_stderror: 1.146\n","New best_val_rmse: 0.6066\n","\n","64 steps took 81.3 seconds\n","Epoch: 1 batch_num: 4\n","train_rmse_target: 0.4832 train_rmse_stderror: 0.02355 train_kl_div: 0.5017\n","val_rmse_target: 0.5504 val_rmse_stderror: 1.138\n","New best_val_rmse: 0.5504\n","\n","64 steps took 81.0 seconds\n","Epoch: 1 batch_num: 68\n","train_rmse_target: 0.2372 train_rmse_stderror: 0.02897 train_kl_div: 0.1295\n","val_rmse_target: 0.5042 val_rmse_stderror: 1.146\n","New best_val_rmse: 0.5042\n","\n","32 steps took 40.5 seconds\n","Epoch: 1 batch_num: 100\n","train_rmse_target: 0.3241 train_rmse_stderror: 0.03684 train_kl_div: 0.2259\n","val_rmse_target: 0.5172 val_rmse_stderror: 1.135\n","Still best_val_rmse: 0.5042 (from epoch 1)\n","\n","32 steps took 40.6 seconds\n","Epoch: 1 batch_num: 132\n","train_rmse_target: 0.5028 train_rmse_stderror: 0.02762 train_kl_div: 0.4978\n","val_rmse_target: 0.494 val_rmse_stderror: 1.156\n","New best_val_rmse: 0.494\n","\n","16 steps took 20.3 seconds\n","Epoch: 1 batch_num: 148\n","train_rmse_target: 0.3198 train_rmse_stderror: 0.02831 train_kl_div: 0.2105\n","val_rmse_target: 0.5168 val_rmse_stderror: 1.148\n","Still best_val_rmse: 0.494 (from epoch 1)\n","\n","32 steps took 40.5 seconds\n","Epoch: 1 batch_num: 180\n","train_rmse_target: 0.5329 train_rmse_stderror: 0.04022 train_kl_div: 0.5072\n","val_rmse_target: 0.5136 val_rmse_stderror: 1.155\n","Still best_val_rmse: 0.494 (from epoch 1)\n","\n","32 steps took 40.8 seconds\n","Epoch: 2 batch_num: 24\n","train_rmse_target: 0.2501 train_rmse_stderror: 0.02856 train_kl_div: 0.1404\n","val_rmse_target: 0.5004 val_rmse_stderror: 1.147\n","Still best_val_rmse: 0.494 (from epoch 1)\n","\n","32 steps took 40.5 seconds\n","Epoch: 2 batch_num: 56\n","train_rmse_target: 0.2465 train_rmse_stderror: 0.03306 train_kl_div: 0.1332\n","val_rmse_target: 0.5558 val_rmse_stderror: 1.151\n","Still best_val_rmse: 0.494 (from epoch 1)\n","\n","64 steps took 81.1 seconds\n","Epoch: 2 batch_num: 120\n","train_rmse_target: 0.1791 train_rmse_stderror: 0.02565 train_kl_div: 0.07185\n","val_rmse_target: 0.4958 val_rmse_stderror: 1.148\n","Still best_val_rmse: 0.494 (from epoch 1)\n","\n","16 steps took 20.3 seconds\n","Epoch: 2 batch_num: 136\n","train_rmse_target: 0.2338 train_rmse_stderror: 0.02829 train_kl_div: 0.1162\n","val_rmse_target: 0.5109 val_rmse_stderror: 1.135\n","Still best_val_rmse: 0.494 (from epoch 1)\n","\n","32 steps took 40.5 seconds\n","Epoch: 2 batch_num: 168\n","train_rmse_target: 0.3025 train_rmse_stderror: 0.02917 train_kl_div: 0.1972\n","val_rmse_target: 0.4934 val_rmse_stderror: 1.142\n","New best_val_rmse: 0.4934\n","\n","16 steps took 20.3 seconds\n","Epoch: 2 batch_num: 184\n","train_rmse_target: 0.193 train_rmse_stderror: 0.03078 train_kl_div: 0.08145\n","val_rmse_target: 0.495 val_rmse_stderror: 1.141\n","Still best_val_rmse: 0.4934 (from epoch 2)\n","\n","16 steps took 20.5 seconds\n","Epoch: 3 batch_num: 12\n","train_rmse_target: 0.1906 train_rmse_stderror: 0.02528 train_kl_div: 0.07849\n","val_rmse_target: 0.4978 val_rmse_stderror: 1.145\n","Still best_val_rmse: 0.4934 (from epoch 2)\n","\n","16 steps took 20.2 seconds\n","Epoch: 3 batch_num: 28\n","train_rmse_target: 0.1305 train_rmse_stderror: 0.02837 train_kl_div: 0.03735\n","val_rmse_target: 0.4911 val_rmse_stderror: 1.144\n","New best_val_rmse: 0.4911\n","\n","16 steps took 20.3 seconds\n","Epoch: 3 batch_num: 44\n","train_rmse_target: 0.1653 train_rmse_stderror: 0.01381 train_kl_div: 0.05014\n","val_rmse_target: 0.4894 val_rmse_stderror: 1.139\n","New best_val_rmse: 0.4894\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 52\n","train_rmse_target: 0.1901 train_rmse_stderror: 0.02628 train_kl_div: 0.08264\n","val_rmse_target: 0.5007 val_rmse_stderror: 1.145\n","Still best_val_rmse: 0.4894 (from epoch 3)\n","\n","32 steps took 40.5 seconds\n","Epoch: 3 batch_num: 84\n","train_rmse_target: 0.1362 train_rmse_stderror: 0.02002 train_kl_div: 0.03986\n","val_rmse_target: 0.4864 val_rmse_stderror: 1.144\n","New best_val_rmse: 0.4864\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 92\n","train_rmse_target: 0.1393 train_rmse_stderror: 0.02032 train_kl_div: 0.04316\n","val_rmse_target: 0.4965 val_rmse_stderror: 1.148\n","Still best_val_rmse: 0.4864 (from epoch 3)\n","\n","16 steps took 20.3 seconds\n","Epoch: 3 batch_num: 108\n","train_rmse_target: 0.126 train_rmse_stderror: 0.0228 train_kl_div: 0.03682\n","val_rmse_target: 0.4872 val_rmse_stderror: 1.147\n","Still best_val_rmse: 0.4864 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 116\n","train_rmse_target: 0.1045 train_rmse_stderror: 0.02623 train_kl_div: 0.02414\n","val_rmse_target: 0.4885 val_rmse_stderror: 1.139\n","Still best_val_rmse: 0.4864 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 124\n","train_rmse_target: 0.2433 train_rmse_stderror: 0.0318 train_kl_div: 0.1179\n","val_rmse_target: 0.4977 val_rmse_stderror: 1.146\n","Still best_val_rmse: 0.4864 (from epoch 3)\n","\n","16 steps took 20.3 seconds\n","Epoch: 3 batch_num: 140\n","train_rmse_target: 0.2594 train_rmse_stderror: 0.03412 train_kl_div: 0.1588\n","val_rmse_target: 0.4898 val_rmse_stderror: 1.148\n","Still best_val_rmse: 0.4864 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 148\n","train_rmse_target: 0.1308 train_rmse_stderror: 0.02316 train_kl_div: 0.03758\n","val_rmse_target: 0.5045 val_rmse_stderror: 1.146\n","Still best_val_rmse: 0.4864 (from epoch 3)\n","\n","32 steps took 40.5 seconds\n","Epoch: 3 batch_num: 180\n","train_rmse_target: 0.1462 train_rmse_stderror: 0.02842 train_kl_div: 0.04502\n","val_rmse_target: 0.4944 val_rmse_stderror: 1.149\n","Still best_val_rmse: 0.4864 (from epoch 3)\n","\n","16 steps took 20.5 seconds\n","Epoch: 4 batch_num: 8\n","train_rmse_target: 0.1104 train_rmse_stderror: 0.02149 train_kl_div: 0.02709\n","val_rmse_target: 0.4902 val_rmse_stderror: 1.141\n","Still best_val_rmse: 0.4864 (from epoch 3)\n","\n","16 steps took 20.3 seconds\n","Epoch: 4 batch_num: 24\n","train_rmse_target: 0.1282 train_rmse_stderror: 0.02999 train_kl_div: 0.03201\n","val_rmse_target: 0.4937 val_rmse_stderror: 1.144\n","Still best_val_rmse: 0.4864 (from epoch 3)\n","\n","16 steps took 20.2 seconds\n","Epoch: 4 batch_num: 40\n","train_rmse_target: 0.09538 train_rmse_stderror: 0.02254 train_kl_div: 0.02165\n","val_rmse_target: 0.4922 val_rmse_stderror: 1.145\n","Still best_val_rmse: 0.4864 (from epoch 3)\n","\n","16 steps took 20.3 seconds\n","Epoch: 4 batch_num: 56\n","train_rmse_target: 0.1259 train_rmse_stderror: 0.02078 train_kl_div: 0.03601\n","val_rmse_target: 0.4909 val_rmse_stderror: 1.143\n","Still best_val_rmse: 0.4864 (from epoch 3)\n","\n","16 steps took 20.2 seconds\n","Epoch: 4 batch_num: 72\n","train_rmse_target: 0.08423 train_rmse_stderror: 0.03968 train_kl_div: 0.01521\n","val_rmse_target: 0.4923 val_rmse_stderror: 1.146\n","Still best_val_rmse: 0.4864 (from epoch 3)\n","\n","16 steps took 20.3 seconds\n","Epoch: 4 batch_num: 88\n","train_rmse_target: 0.1093 train_rmse_stderror: 0.02402 train_kl_div: 0.02603\n","val_rmse_target: 0.4928 val_rmse_stderror: 1.144\n","Still best_val_rmse: 0.4864 (from epoch 3)\n","\n","16 steps took 20.2 seconds\n","Epoch: 4 batch_num: 104\n","train_rmse_target: 0.1024 train_rmse_stderror: 0.01787 train_kl_div: 0.02359\n","val_rmse_target: 0.4907 val_rmse_stderror: 1.144\n","Still best_val_rmse: 0.4864 (from epoch 3)\n","\n","16 steps took 20.2 seconds\n","Epoch: 4 batch_num: 120\n","train_rmse_target: 0.1156 train_rmse_stderror: 0.01972 train_kl_div: 0.03027\n","val_rmse_target: 0.4909 val_rmse_stderror: 1.146\n","Still best_val_rmse: 0.4864 (from epoch 3)\n","\n","16 steps took 20.2 seconds\n","Epoch: 4 batch_num: 136\n","train_rmse_target: 0.07644 train_rmse_stderror: 0.01007 train_kl_div: 0.01325\n","val_rmse_target: 0.491 val_rmse_stderror: 1.146\n","Still best_val_rmse: 0.4864 (from epoch 3)\n","\n","16 steps took 20.2 seconds\n","Epoch: 4 batch_num: 152\n","train_rmse_target: 0.07183 train_rmse_stderror: 0.01292 train_kl_div: 0.01203\n","val_rmse_target: 0.4916 val_rmse_stderror: 1.146\n","Still best_val_rmse: 0.4864 (from epoch 3)\n","\n","16 steps took 20.3 seconds\n","Epoch: 4 batch_num: 168\n","train_rmse_target: 0.1463 train_rmse_stderror: 0.01265 train_kl_div: 0.03645\n","val_rmse_target: 0.4916 val_rmse_stderror: 1.146\n","Still best_val_rmse: 0.4864 (from epoch 3)\n","\n","16 steps took 20.3 seconds\n","Epoch: 4 batch_num: 184\n","train_rmse_target: 0.1027 train_rmse_stderror: 0.01962 train_kl_div: 0.02341\n","val_rmse_target: 0.4915 val_rmse_stderror: 1.146\n","Still best_val_rmse: 0.4864 (from epoch 3)\n","\n","Performance estimates:\n","[0.45098122503459925, 0.49243304423428724, 0.501725707273907, 0.49213581026671677, 0.4863717478883462]\n","Mean: 0.4847295069395713\n","{'total_MiB': 16280, 'used_MiB': 945}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"m4v-cGx-Mv7S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626968371504,"user_tz":-540,"elapsed":36,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"043ba7be-a826-4251-9981-ca4179a23672"},"source":["print(list_val_rmse)"],"execution_count":39,"outputs":[{"output_type":"stream","text":["[0.45098122503459925, 0.49243304423428724, 0.501725707273907, 0.49213581026671677, 0.4863717478883462]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"q2CdCMuIKDMP","executionInfo":{"status":"ok","timestamp":1626968371505,"user_tz":-540,"elapsed":24,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#rep = MemReporter(model)\n","#rep.report()"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"id":"eLl1yDOOKIe7","executionInfo":{"status":"ok","timestamp":1626968371505,"user_tz":-540,"elapsed":23,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#rep = MemReporter(model.roberta)\n","#rep.report()"],"execution_count":41,"outputs":[]},{"cell_type":"code","metadata":{"id":"7qkqnknA_m9D","executionInfo":{"status":"ok","timestamp":1626968371506,"user_tz":-540,"elapsed":24,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#gpuinfo()"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"id":"PwrqSMdYA6Pu","executionInfo":{"status":"ok","timestamp":1626968371507,"user_tz":-540,"elapsed":24,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#del model\n","#del optimizer \n","#del train_loader\n","#del val_loader\n","#del scheduler \n","#del list_val_rmse\n","#del train_indices\n","#del val_indices\n","#del tokenizer\n","#torch.cuda.empty_cache()\n","#gpuinfo()"],"execution_count":43,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wXcHyUSJXecL"},"source":["# upload models"]},{"cell_type":"code","metadata":{"id":"YIV6UllSIGoa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626968486984,"user_tz":-540,"elapsed":115501,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"ff36f2c8-14e4-4506-fc0d-ec0f85da4f24"},"source":["%cd\n","!mkdir .kaggle\n","!mkdir /content/model\n","!cp /content/drive/MyDrive/Colab_Files/kaggle-api/kaggle.json .kaggle/\n","\n","!cp -r /content/model_1.pth /content/model/model_1.pth\n","!cp -r /content/model_2.pth /content/model/model_2.pth\n","!cp -r /content/model_3.pth /content/model/model_3.pth\n","!cp -r /content/model_4.pth /content/model/model_4.pth\n","!cp -r /content/model_5.pth /content/model/model_5.pth"],"execution_count":44,"outputs":[{"output_type":"stream","text":["/root\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"14ddOZH4IMam","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626968744948,"user_tz":-540,"elapsed":257979,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"088cec35-ddf7-43e4-9221-f2fe11feea0a"},"source":["def dataset_upload():\n","    import json\n","    from kaggle.api.kaggle_api_extended import KaggleApi\n","\n","    id = f'{USERID}/{EX_NO}'\n","\n","    dataset_metadata = {}\n","    dataset_metadata['id'] = id\n","    dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n","    dataset_metadata['title'] = f'{EX_NO}'\n","\n","    with open(UPLOAD_DIR / 'dataset-metadata.json', 'w') as f:\n","        json.dump(dataset_metadata, f, indent=4)\n","\n","    api = KaggleApi()\n","    api.authenticate()\n","\n","    # データセットがない場合\n","    if f'{USERID}/{EX_NO}' not in [str(d) for d in api.dataset_list(user=USERID, search=f'\"{EX_NO}\"')]:\n","        api.dataset_create_new(folder=UPLOAD_DIR,\n","                               convert_to_csv=False,\n","                               dir_mode='skip')\n","    # データセットがある場合\n","    else:\n","        api.dataset_create_version(folder=UPLOAD_DIR,\n","                                   version_notes='update',\n","                                   convert_to_csv=False,\n","                                   delete_old_versions=True,\n","                                   dir_mode='skip')\n","dataset_upload()\n","\n"],"execution_count":45,"outputs":[{"output_type":"stream","text":["\r  0%|          | 0.00/1.33G [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Starting upload for file model_2.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [00:50<00:00, 28.5MB/s]\n","  0%|          | 0.00/1.33G [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_2.pth (1GB)\n","Starting upload for file model_3.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [00:49<00:00, 28.6MB/s]\n","  0%|          | 0.00/1.33G [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_3.pth (1GB)\n","Starting upload for file model_4.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [00:50<00:00, 28.4MB/s]\n","  0%|          | 0.00/1.33G [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_4.pth (1GB)\n","Starting upload for file model_5.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [00:50<00:00, 28.1MB/s]\n","  0%|          | 0.00/1.33G [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_5.pth (1GB)\n","Starting upload for file model_1.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [00:52<00:00, 27.1MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_1.pth (1GB)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"huJwVMSAPuDO","executionInfo":{"status":"ok","timestamp":1626968744951,"user_tz":-540,"elapsed":16,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"id":"0zzuBPobmLFu","executionInfo":{"status":"ok","timestamp":1626968744952,"user_tz":-540,"elapsed":15,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wpc8ro9hmNci","executionInfo":{"status":"ok","timestamp":1626968744952,"user_tz":-540,"elapsed":14,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"id":"ceDI72NumT5-","executionInfo":{"status":"ok","timestamp":1626968744953,"user_tz":-540,"elapsed":14,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"id":"PvRi_JQgwcKI","executionInfo":{"status":"aborted","timestamp":1626954023608,"user_tz":-540,"elapsed":44,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":null,"outputs":[]}]}