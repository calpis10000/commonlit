{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"057-051-train-08-03.ipynb","provenance":[{"file_id":"1pEE-6E2ELbcFyJXynHh8bDmDpPd2ERY4","timestamp":1627781507819},{"file_id":"1KpIMgxWzyzcuIwriE2LXfXX57EzcFk10","timestamp":1627731049342},{"file_id":"17BUK8yRF7SDX0khlOXoHcFRTEFffkvRb","timestamp":1627488927996},{"file_id":"1wNpTEKAuuKP7ivTcm1f9j0sdmYU1RyzA","timestamp":1627306793279},{"file_id":"1uE__yBR1oxeYaUIrUTMEOffmeyuJBRAU","timestamp":1627305921964},{"file_id":"1PbEPh6kL5p5cdH5HC8iHoMVCIzA0MqvB","timestamp":1627284576770},{"file_id":"1TlxQ4e-ZX1Zy51dKLuhNdrBWg1qhojqP","timestamp":1627273765934},{"file_id":"17a4F4aC9L0QBqU8BRTrdqPn0WwJ0b08b","timestamp":1626746992716},{"file_id":"1G_W9irFTrEmDeHR0S6_u0bjpk8nxipXW","timestamp":1626689695352},{"file_id":"1bhhkorT--y8XXaVLM8hibVgC-tLqZ16P","timestamp":1626358153868},{"file_id":"1WtT2hX6O9Qbt_hb9sF50nM2QmDXFi-XA","timestamp":1626338366006},{"file_id":"1k_p5wftcUeo711Xho1-T5an2Xkneau-J","timestamp":1626323813472},{"file_id":"1Vz2GB2BNTWuefEFkCSh3TBPEIel7KG1t","timestamp":1626317426487},{"file_id":"1djoMWojeaIPopG5tS1jNMohn8ineblRh","timestamp":1626306831897},{"file_id":"1-6tlDO8158Pi6TpptIF884oFaEiT4Uxb","timestamp":1626276420047},{"file_id":"1js8eA3mDNS8mwSpCiHuzPeARFlUPAVrg","timestamp":1626272452526},{"file_id":"1yhcPgulwJtjJKUK9IuRKmNMhJ-4YXGol","timestamp":1626267205517},{"file_id":"1mnnSv0Pofn1QxArywV81VYqnZPB8uUWN","timestamp":1626180468522},{"file_id":"1RRdjt_UAeHmr5QQBAMyC82Fq1s31OWdK","timestamp":1625833136005},{"file_id":"1JPgg44HFemzwk8VSCXih3PejL0idy-C4","timestamp":1625825483466},{"file_id":"1Ye6wqVX71xAAAhmjXkw9IpRvTqeUyJDA","timestamp":1625812137500}],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ucCbvGD1XvG7","executionInfo":{"status":"ok","timestamp":1627782914202,"user_tz":-540,"elapsed":361,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"646fd09b-1ef8-4435-8558-5055d7311f8b"},"source":["import sys\n","if 'google.colab' in sys.modules:  # colab特有の処理_2回目以降\n","  # Google Driveのマウント\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","\n","  # ライブラリのパス指定\n","  sys.path.append('/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules')\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nj4Ygf894sik","executionInfo":{"status":"ok","timestamp":1627782914930,"user_tz":-540,"elapsed":338,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"fda36b6c-49c8-4dba-93ce-6490dfff3c2d"},"source":["!nvidia-smi"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Sun Aug  1 01:55:14 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   69C    P0    48W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FACwJ6icpxrR","executionInfo":{"status":"ok","timestamp":1627782919905,"user_tz":-540,"elapsed":4980,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# データセットをDriveから取得\n","!mkdir -p 'input'\n","!mkdir -p 'clrp-pre-trained'\n","\n","!cp -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/00_input/commonlitreadabilityprize/' '/content/input'\n","!cp -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/97_pre_trained/clrp_pretrained_manish_epoch5/pre-trained-roberta/clrp_roberta_large/' '/content/clrp-pre-trained'"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"RV9-VwbpZLZ9","executionInfo":{"status":"ok","timestamp":1627782919906,"user_tz":-540,"elapsed":15,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["from pathlib import Path\n","\n","# input\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    DATA_DIR = Path('../input/commonlitreadabilityprize/')\n","\n","elif 'google.colab' in sys.modules: # Colab環境\n","    DATA_DIR = Path('/content/input/commonlitreadabilityprize')\n","\n","else:\n","    DATA_DIR = Path('../00_input/commonlitreadabilityprize/')"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"x5difyXe00UV","executionInfo":{"status":"ok","timestamp":1627782919906,"user_tz":-540,"elapsed":9,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["from pathlib import Path\n","\n","# tokenizer\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    TOKENIZER_DIR = '../input/roberta-transformers-pytorch/roberta-large'\n","elif 'google.colab' in sys.modules: # Colab環境\n","    TOKENIZER_DIR = '/content/clrp-pre-trained/clrp_roberta_large' # 仮で、毎回DLする想定のモデル名を指定。あとで変更予定。\n","else:\n","    TOKENIZER_DIR = 'roberta-large'"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"tKjsUxnOeDYl","executionInfo":{"status":"ok","timestamp":1627782919907,"user_tz":-540,"elapsed":10,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["from pathlib import Path\n","\n","# pre-trained model\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    PRE_TRAINED_MODEL_DIR = '../input/roberta-transformers-pytorch/roberta-large'\n","elif 'google.colab' in sys.modules: # Colab環境\n","    PRE_TRAINED_MODEL_DIR = '/content/clrp-pre-trained/clrp_roberta_large' # 仮で、毎回DLする想定のモデル名を指定。あとで変更予定。\n","else:\n","    PRE_TRAINED_MODEL_DIR = 'roberta-large'"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZLaT2V0ReoAZ","executionInfo":{"status":"ok","timestamp":1627782919908,"user_tz":-540,"elapsed":10,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["UPLOAD_DIR = Path('/content/model')\n","EX_NO = '057-051-train-08-03'  # 実験番号などを入れる、folderのpathにする\n","USERID = 'calpis10000'"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"hOGjAb4pAJ0F","executionInfo":{"status":"ok","timestamp":1627782919909,"user_tz":-540,"elapsed":10,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["import subprocess\n","import shlex\n","\n","def gpuinfo():\n","    \"\"\"\n","    Returns size of total GPU RAM and used GPU RAM.\n","\n","    Parameters\n","    ----------\n","    None\n","\n","    Returns\n","    -------\n","    info : dict\n","        Total GPU RAM in integer for key 'total_MiB'.\n","        Used GPU RAM in integer for key 'used_MiB'.\n","    \"\"\"\n","\n","    command = 'nvidia-smi -q -d MEMORY | sed -n \"/FB Memory Usage/,/Free/p\" | sed -e \"1d\" -e \"4d\" -e \"s/ MiB//g\" | cut -d \":\" -f 2 | cut -c2-'\n","    commands = [shlex.split(part) for part in command.split(' | ')]\n","    for i, cmd in enumerate(commands):\n","        if i==0:\n","            res = subprocess.Popen(cmd, stdout=subprocess.PIPE)\n","        else:\n","            res = subprocess.Popen(cmd, stdin=res.stdout, stdout=subprocess.PIPE)\n","    total, used = map(int, res.communicate()[0].decode('utf-8').strip().split('\\n'))\n","    info = {'total_MiB':total, 'used_MiB':used}\n","    return info\n"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g3-6m5MKXecB"},"source":["# Overview\n","This nb is based on copy from https://www.kaggle.com/andretugan/lightweight-roberta-solution-in-pytorch .\n","\n","Acknowledgments(from base nb): \n","some ideas were taken from kernels by [Torch](https://www.kaggle.com/rhtsingh) and [Maunish](https://www.kaggle.com/maunish)."]},{"cell_type":"code","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-04T06:26:32.834365Z","iopub.execute_input":"2021-07-04T06:26:32.834903Z","iopub.status.idle":"2021-07-04T06:26:40.143740Z","shell.execute_reply.started":"2021-07-04T06:26:32.834785Z","shell.execute_reply":"2021-07-04T06:26:40.142864Z"},"trusted":true,"id":"HRsRZ06WXecD","executionInfo":{"status":"ok","timestamp":1627782924417,"user_tz":-540,"elapsed":4517,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["import os\n","import math\n","import random\n","import time\n","\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","\n","from transformers import AdamW # optimizer\n","from transformers import AutoTokenizer\n","from transformers import AutoModel\n","from transformers import AutoConfig\n","from transformers import get_cosine_schedule_with_warmup # scheduler\n","from pytorch_memlab import profile\n","import pytorch_memlab\n","from pytorch_memlab import MemReporter\n","\n","from sklearn.model_selection import KFold, StratifiedKFold\n","\n","import gc\n","gc.enable()"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.145217Z","iopub.execute_input":"2021-07-04T06:26:40.145539Z","iopub.status.idle":"2021-07-04T06:26:40.201326Z","shell.execute_reply.started":"2021-07-04T06:26:40.145504Z","shell.execute_reply":"2021-07-04T06:26:40.200136Z"},"trusted":true,"id":"omBfwshTXecE","executionInfo":{"status":"ok","timestamp":1627782924419,"user_tz":-540,"elapsed":44,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["NUM_FOLDS = 5 # K Fold\n","NUM_EPOCHS = 6 # Epochs\n","BATCH_SIZE = 8 # Batch Size\n","MAX_LEN = 248 # ベクトル長\n","EVAL_SCHEDULE = [(0.55, 64), (-1., 32)] # schedulerの何らかの設定？\n","ROBERTA_PATH = PRE_TRAINED_MODEL_DIR # roberta pre-trainedモデル(モデルとして指定)\n","TOKENIZER_PATH = TOKENIZER_DIR # roberta pre-trainedモデル(Tokenizerとして指定)\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\" # cudaがなければcpuを使えばいいじゃない"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.203398Z","iopub.execute_input":"2021-07-04T06:26:40.204055Z","iopub.status.idle":"2021-07-04T06:26:40.211572Z","shell.execute_reply.started":"2021-07-04T06:26:40.204015Z","shell.execute_reply":"2021-07-04T06:26:40.210762Z"},"trusted":true,"id":"4qcuXqwtXecF","executionInfo":{"status":"ok","timestamp":1627782924421,"user_tz":-540,"elapsed":43,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["def set_random_seed(random_seed):\n","    random.seed(random_seed)\n","    np.random.seed(random_seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(random_seed)\n","\n","    torch.manual_seed(random_seed)\n","    torch.cuda.manual_seed(random_seed)\n","    torch.cuda.manual_seed_all(random_seed)\n","\n","    torch.backends.cudnn.deterministic = True# cudnnによる最適化で結果が変わらないためのおまじない "],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.214188Z","iopub.execute_input":"2021-07-04T06:26:40.214809Z","iopub.status.idle":"2021-07-04T06:26:40.309744Z","shell.execute_reply.started":"2021-07-04T06:26:40.214769Z","shell.execute_reply":"2021-07-04T06:26:40.308926Z"},"trusted":true,"id":"70PyLsJTXecF","executionInfo":{"status":"ok","timestamp":1627782924422,"user_tz":-540,"elapsed":42,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# read train_df(kfold)\n","train_kf_df = pd.read_csv(DATA_DIR/\"train_kfold.csv\")"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.311021Z","iopub.execute_input":"2021-07-04T06:26:40.311347Z","iopub.status.idle":"2021-07-04T06:26:40.624393Z","shell.execute_reply.started":"2021-07-04T06:26:40.311314Z","shell.execute_reply":"2021-07-04T06:26:40.623347Z"},"trusted":true,"id":"xf0662k4XecF","executionInfo":{"status":"ok","timestamp":1627782924423,"user_tz":-540,"elapsed":42,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# tokenizerを指定\n","tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N6aaghNkXecG"},"source":["# Dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":289},"id":"aFgGq3wB5D_q","executionInfo":{"status":"ok","timestamp":1627782924425,"user_tz":-540,"elapsed":43,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"f243a181-0e1d-45d6-b294-0c8ab4b5ac80"},"source":["train_kf_df.head()"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>url_legal</th>\n","      <th>license</th>\n","      <th>excerpt</th>\n","      <th>target</th>\n","      <th>standard_error</th>\n","      <th>kfold</th>\n","      <th>bins_tg</th>\n","      <th>bins_std</th>\n","      <th>bins</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>822c5d421</td>\n","      <td>https://www.commonlit.org/texts/the-1972-andes...</td>\n","      <td>CC BY-NC-SA 2.0</td>\n","      <td>Search parties from three countries looked for...</td>\n","      <td>-0.279952</td>\n","      <td>0.465558</td>\n","      <td>4</td>\n","      <td>7</td>\n","      <td>2</td>\n","      <td>72</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>fa84dbf46</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>With trembling hands the lad took the shavings...</td>\n","      <td>0.088148</td>\n","      <td>0.499267</td>\n","      <td>1</td>\n","      <td>8</td>\n","      <td>3</td>\n","      <td>83</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>cf48c7441</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Rhea which is also known under the name of ram...</td>\n","      <td>-1.198192</td>\n","      <td>0.472505</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>52</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>d9eb41f75</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Ditson had fawned around Browning a great deal...</td>\n","      <td>-1.199957</td>\n","      <td>0.468701</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>52</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>bd3d86f22</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>The Old Lady lived \"away back at the old Lloyd...</td>\n","      <td>-0.956118</td>\n","      <td>0.503286</td>\n","      <td>3</td>\n","      <td>6</td>\n","      <td>4</td>\n","      <td>64</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          id                                          url_legal  ... bins_std bins\n","0  822c5d421  https://www.commonlit.org/texts/the-1972-andes...  ...        2   72\n","1  fa84dbf46                                                NaN  ...        3   83\n","2  cf48c7441                                                NaN  ...        2   52\n","3  d9eb41f75                                                NaN  ...        2   52\n","4  bd3d86f22                                                NaN  ...        4   64\n","\n","[5 rows x 10 columns]"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0KtQ6i-H5D9k","executionInfo":{"status":"ok","timestamp":1627782924425,"user_tz":-540,"elapsed":40,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"9bb2c893-b1e1-47cc-ae71-f83ed533d85f"},"source":["train_kf_df['target']"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0      -0.279952\n","1       0.088148\n","2      -1.198192\n","3      -1.199957\n","4      -0.956118\n","          ...   \n","2828   -0.528836\n","2829   -1.188881\n","2830   -3.164808\n","2831   -1.979798\n","2832   -0.422689\n","Name: target, Length: 2833, dtype: float64"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UU5uZKIcDjkV","executionInfo":{"status":"ok","timestamp":1627782924846,"user_tz":-540,"elapsed":18,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"688024b0-2a64-4d53-f47c-14539ff1ce41"},"source":["# 前処理用\n","import string\n","import re\n","# ローカルの場合、stopwordsをダウンロード\n","import nltk\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    pass\n","else:\n","    import nltk\n","    nltk.download('stopwords')\n","    nltk.download('averaged_perceptron_tagger')\n","    os.listdir(os.path.expanduser('~/nltk_data/corpora/stopwords/'))\n","\n","# テキスト前処理\n","# https://www.kaggle.com/alaasedeeq/commonlit-readability-eda\n","\n","#filtering the unwanted symbols, spaces, ....etc\n","to_replace_by_space = re.compile('[/(){}\\[\\]|@,;]')\n","punctuation = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n","bad_symbols = re.compile('[^0-9a-z #+_]')\n","stopwords = set(nltk.corpus.stopwords.words('english'))\n","\n","def text_prepare(text):\n","    '''\n","    text: a string\n","    returna modified version of the string\n","    '''\n","    text = text.lower() # lowercase text\n","    text = re.sub(punctuation, '',text)\n","    text = re.sub(to_replace_by_space, \" \", text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n","    text = re.sub(bad_symbols, \"\", text)         # delete symbols which are in BAD_SYMBOLS_RE from text\n","    text = \" \".join([word for word in text.split(\" \") if word not in stopwords]) # delete stopwords from text\n","    text = re.sub(' +', ' ', text)\n","    return text\n","\n","def text_normalization(s:pd.Series):\n","    x = s.apply(text_prepare)\n","    return x\n","\n","# Counterオブジェクトを取得\n","def get_counter(text:str):\n","    text_list = [wrd for wrd in text.split(\" \") if wrd not in ('', '\\n')]\n","    counter = collections.Counter(text_list)\n","    return counter\n"],"execution_count":16,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iAse0IDWDjho","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627782924847,"user_tz":-540,"elapsed":10,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"1f581e31-1f49-4367-8b56-46916cf95c4d"},"source":["def separete_target_sign_abs(sr_: pd.Series()):\n","  return [sr_.map(np.sign), sr_.map(np.abs)]\n","\n","class LitDataset(Dataset):\n","    def __init__(self, df, inference_only=False):\n","        super().__init__()\n","\n","        self.df = df        \n","        self.inference_only = inference_only # Testデータ用フラグ\n","        self.text = df.excerpt.tolist() # 分析対象カラムをlistにする。(分かち書きではなく、Seriesをlistへ変換するような処理)\n","        #self.text = [text.replace(\"\\n\", \" \") for text in self.text] # 単語単位で分かち書きする場合\n","        self.text_len = text_normalization(df.excerpt).map(lambda x: [0 if i >= len(x.split(' ')) else len(x.split(' ')[i]) for i in range(132)])\n","\n","        if not self.inference_only:\n","            self.target = torch.tensor(df.target.values, dtype=torch.float32) # trainのみ、targetをtensorに変換\n","            self.standard_error = torch.tensor(df.standard_error.values, dtype=torch.float32) \n","\n","            target_sep = separete_target_sign_abs(df.target)\n","            self.target_sign = torch.tensor(target_sep[0].map({-1:0, 0:0, 1:1}).values, dtype=torch.float32) # 値を変換: -1 or 1 -> 0 or 1 \n","            self.target_abs = torch.tensor(target_sep[1].values, dtype=torch.float32)\n","\n","        self.encoded = tokenizer.batch_encode_plus( # textをtokenize\n","            self.text,\n","            padding = 'max_length',            \n","            max_length = MAX_LEN,\n","            truncation = True, # 最大長を超える文字は切り捨て\n","            return_attention_mask=True\n","        )        \n"," \n","    def __len__(self):\n","        return len(self.df)\n","\n","    \n","    def __getitem__(self, index): # 変換結果を返す\n","        input_ids = torch.tensor(self.encoded['input_ids'][index])\n","        attention_mask = torch.tensor(self.encoded['attention_mask'][index])\n","        input_len = torch.tensor(self.text_len.iloc[index], dtype=torch.float32)\n","\n","        if self.inference_only:\n","            return (input_ids, attention_mask, input_len)            \n","        else:\n","            target_sign = self.target_sign[index]\n","            #target_abs = self.target_abs[index]\n","            target = self.target[index]\n","            standard_error = self.standard_error[index]\n","            return (input_ids, attention_mask, input_len, target_sign, target, standard_error)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n","  \"\"\"Entry point for launching an IPython kernel.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"pfLmJIQw_L_A","executionInfo":{"status":"ok","timestamp":1627782928174,"user_tz":-540,"elapsed":3332,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["trial_df = LitDataset(train_kf_df)\n"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jxwjXEjZRJ_X","executionInfo":{"status":"ok","timestamp":1627782928176,"user_tz":-540,"elapsed":12,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"d42c4782-c620-4137-ddc0-df26575d6bc7"},"source":["trial_df[0]"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([    0, 39954,  1799,    31,   130,   749,  1415,    13,     5,  1716,\n","          3286,     4,   635,     6,   187,     5,  3286,    21,  1104,     6,\n","            24, 25630,    11,    19,     5,  1958,     6,   442,    24,  8077,\n","         20731,    31,     5,  6360,     4,    20,  2557,  1707,    21,  9491,\n","            71,   799,   360,     4,    20,  7149,     9,     5,  2058,    56,\n","           303,    10,   650, 45573,  3188,    15,     5,  3286,     8,  5470,\n","         17006,     6,    65,     9,     5,  7149,     6,    78,  1317,     5,\n","           340,    14,     5,  1707,    21,  9491,    15,    49,   365,   212,\n","           183,    15,     5,  6485,     4, 50118, 39986,  1576,     5,   340,\n","             6,     5,  7149,   880,     7, 18769,     8, 10745,    93,    70,\n","          4682, 28377,   139, 24947,  1725,     6,    54,  1415, 27035,    62,\n","             5,  9787,    61,  1458,     7,     5,  3072,     4,    22, 13368,\n","          2786,    60,    37, 15355,     6,    22,  8585,    18,   103,   205,\n","           340,   328,   166,    95,  1317,    15,     5,  3188,     4,   252,\n","           348,   373,   160,     5,  1707,    72, 10277,     5, 11138,  3286,\n","            89,    21,  7308,     4,   287,     5, 24418,  1825,     9,    49,\n","         33487, 26526,   196,   106,     6,    51,    52,  3320,     4,    22,\n","          7608,     5,  7105,    16,    14,   205,   340,  1917,   277, 15355,\n","         30302,    23, 24947,  1725,     4,    22, 10105,    24,   839,    60,\n","         24947,  1725,    26,     6,    22,  6025,    52,   214,   164,     7,\n","           120,    66,     9,   259,    15,    84,   308,    72,    20,  9699,\n","             9,    42,    65,   313,  9464,    10, 23080,     9,   746, 21508,\n","             4, 50118,   133,  7149,    56,    10,   650,  1280,     9,   689,\n","            35,    10,   367,  7548,  5692,     6, 35987, 14967,     8,   484,\n","          9407,     9,  3984,     4,     2,     1,     1,     1]),\n"," tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 0, 0, 0]),\n"," tensor([ 6.,  7.,  5.,  9.,  6.,  7.,  5.,  7.,  5.,  5.,  5.,  7.,  4.,  6.,\n","          9.,  9.,  3.,  7.,  6.,  8.,  5.,  4.,  9.,  5.,  5.,  5., 10.,  5.,\n","          5.,  3.,  6.,  3.,  9.,  5.,  5.,  4.,  6.,  8.,  4.,  3., 12.,  7.,\n","          4.,  9.,  5.,  3.,  4.,  6.,  7.,  8.,  6.,  6.,  9.,  4.,  4.,  3.,\n","          4.,  7.,  6.,  4.,  4.,  5.,  5.,  6.,  6.,  6.,  6.,  7.,  5.,  7.,\n","         12., 11.,  9.,  4.,  4.,  4.,  4.,  7.,  7.,  7.,  8.,  5.,  8.,  4.,\n","          5.,  3.,  7.,  3.,  3.,  9.,  7.,  5., 10.,  9.,  5.,  6.,  4.,  9.,\n","          4.,  8.,  6.,  7.,  7.,  4.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n","          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n","          0.,  0.,  0.,  0.,  0.,  0.]),\n"," tensor(0.),\n"," tensor(-0.2800),\n"," tensor(0.4656))"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"KKtdy32wXecG"},"source":["# Model\n","The model is inspired by the one from [Maunish](https://www.kaggle.com/maunish/clrp-roberta-svm)."]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.649629Z","iopub.execute_input":"2021-07-04T06:26:40.650066Z","iopub.status.idle":"2021-07-04T06:26:40.666374Z","shell.execute_reply.started":"2021-07-04T06:26:40.650002Z","shell.execute_reply":"2021-07-04T06:26:40.665211Z"},"trusted":true,"id":"BpkxjXEUXecH","executionInfo":{"status":"ok","timestamp":1627782928177,"user_tz":-540,"elapsed":7,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["class LitModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        config = AutoConfig.from_pretrained(ROBERTA_PATH) # pretrainedからconfigを読み込み\n","        config.update({\"output_hidden_states\":True, # config更新: embedding層を抽出\n","                       \"hidden_dropout_prob\": 0.0, # config更新: dropoutしない\n","                       \"layer_norm_eps\": 1e-7}) # config更新: layer normalizationのepsilon                      \n","        \n","        self.roberta = AutoModel.from_pretrained(ROBERTA_PATH, config=config) # cpuで処理する\n","            \n","        self.attention = nn.Sequential(# attentionレイヤー            \n","            nn.Linear(config.hidden_size, 512),      \n","            nn.Tanh(),                       \n","            nn.Linear(512, 1),\n","            nn.Softmax(dim=1)\n","        )\n","\n","        self.mlm_layers = nn.Sequential(\n","            nn.Linear(132, 64),\n","            nn.ReLU(),\n","            nn.Linear(64, 64),\n","        )\n","\n","        self.regressor = nn.Sequential( # target、stderror                  \n","            nn.Linear(config.hidden_size + 64, 2)                        \n","        )\n","\n","        self.bin_class = nn.Sequential( # target_sign\n","            nn.Linear(config.hidden_size + 64, 1),\n","            nn.Dropout(p=0.2),\n","            nn.Sigmoid()                       \n","        )\n","\n","\n","    def forward(self, input_ids, attention_mask, input_len):\n","        roberta_output = self.roberta(input_ids=input_ids, # robertaに入力データを流し、出力としてrobertaモデル(layerの複合体)を得る\n","                                      attention_mask=attention_mask)     \n","        # attention_pooling\n","        last_hidden_state = roberta_output.hidden_states[-1] # robertaモデルの最後のlayerを得る\n","        weights = self.attention(last_hidden_state) # robertaの最後のlayerをattentionへ入力し、出力として重みを得る                \n","        context_vector = torch.sum(weights * last_hidden_state, dim=1) # 重み×最後の層を足し合わせて文書ベクトルとする。\n","\n","        # word_length_conv1d\n","        #input_chnl = input_len.unsqueeze(1)\n","        #conv1_layers = self.conv1_layers(input_chnl)\n","        #conv1_layers_v = conv1_layers.view(conv1_layers.size(0),-1)\n","\n","        # word_length_mlm\n","        mlm_layers = self.mlm_layers(input_len)\n","\n","        # https://www.kaggle.com/rhtsingh/utilizing-transformer-representations-efficiently\n","        # last_hidden_state = roberta_output[0]\n","        # input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        # sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        # sum_mask = input_mask_expanded.sum(1)\n","        # sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        # mean_embeddings = sum_embeddings / sum_mask\n","\n","        # concat_embeddings\n","        cat_embeddings = torch.cat([context_vector, mlm_layers], dim=1)\n","        regressor = self.regressor(cat_embeddings)\n","        bin_class = self.bin_class(cat_embeddings)\n","        return [regressor, bin_class]\n","        \n","        # Now we reduce the context vector to the prediction score.\n","        #return self.regressor(mean_embeddings) # 文書ベクトルを線形層に入力し、targetを出力する"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.672515Z","iopub.execute_input":"2021-07-04T06:26:40.672944Z","iopub.status.idle":"2021-07-04T06:26:40.684593Z","shell.execute_reply.started":"2021-07-04T06:26:40.672908Z","shell.execute_reply":"2021-07-04T06:26:40.683569Z"},"trusted":true,"id":"bB4jvQTxXecH","executionInfo":{"status":"ok","timestamp":1627782928177,"user_tz":-540,"elapsed":7,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["def eval_mse(model, data_loader):\n","    \"\"\"Evaluates the mean squared error of the |model| on |data_loader|\"\"\"\n","    model.eval() # evalモードを選択。Batch Normとかdropoutをしなくなる           \n","    bce_sign = 0\n","    mse_mean_sum = 0\n","    mse_std_sum = 0\n","\n","    with torch.no_grad(): # 勾配の計算をしない(予測のみ行う)\n","        for batch_num, (input_ids, attention_mask, input_len, target_sign, target, standard_error) in enumerate(data_loader): # data_loaderからinput, attentin_mask, targetをbatchごとに取り出す\n","            input_ids = input_ids.to(DEVICE)   \n","            attention_mask = attention_mask.to(DEVICE)  \n","            input_len = input_len.to(DEVICE) \n","            target_sign = target_sign.to(DEVICE)  \n","            target = target.to(DEVICE)\n","            standard_error = standard_error.to(DEVICE)\n","            \n","            output = model(input_ids, attention_mask, input_len) # 取得した値をモデルへ入力し、出力として予測値を得る。\n","\n","            bce_sign += nn.BCELoss(reduction=\"sum\")(output[1].flatten(), target_sign).item() # +-のBCE\n","            mse_mean_sum += nn.MSELoss(reduction=\"sum\")(output[0][:,0].flatten(), target).item() # 誤差の合計を得る(Batchごとに計算した誤差を足し上げる)\n","            mse_std_sum += nn.MSELoss(reduction=\"sum\")(output[0][:,1].flatten(), standard_error).item() # 誤差の合計を得る(Batchごとに計算した誤差を足し上げる)\n","\n","\n","    del input_ids\n","    del attention_mask\n","\n","    bce_sign_result = bce_sign / len(data_loader.dataset)\n","    mse_mean_result = mse_mean_sum / len(data_loader.dataset)\n","    mse_std_result = mse_std_sum / len(data_loader.dataset)\n","\n","    return bce_sign_result, mse_mean_result, mse_std_result"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.690155Z","iopub.execute_input":"2021-07-04T06:26:40.692530Z","iopub.status.idle":"2021-07-04T06:26:40.703425Z","shell.execute_reply.started":"2021-07-04T06:26:40.692488Z","shell.execute_reply":"2021-07-04T06:26:40.702366Z"},"trusted":true,"id":"47bDno_LXecI","executionInfo":{"status":"ok","timestamp":1627782928178,"user_tz":-540,"elapsed":7,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 推論結果を返す\n","def predict(model, data_loader):\n","    \"\"\"Returns an np.array with predictions of the |model| on |data_loader|\"\"\"\n","    model.eval() # evalモード(dropout, batch_normしない)\n","\n","    result = np.zeros(len(data_loader.dataset)) # 結果をdataset長のzero配列として用意\n","    index = 0\n","    \n","    with torch.no_grad(): # 勾配の計算をしないblock(inputすると、現状の重みによる推論結果を返す)\n","        for batch_num, (input_ids, attention_mask, input_len) in enumerate(data_loader): # data_loaderからbatchごとにinputを得る\n","            input_ids = input_ids.to(DEVICE)\n","            attention_mask = attention_mask.to(DEVICE)\n","            input_len = input_len.to(DEVICE)\n","                        \n","            output = model(input_ids, attention_mask, input_len) # modelにinputを入力し、予測結果を得る。\n","            output_target = output[0][:,0]\n","\n","            result[index : index + output_target.shape[0]] = output_target.flatten().to(\"cpu\") # result[index ~ predの長さ]へ、予測結果を格納\n","            index += output_target.shape[0] # indexを更新\n","\n","    return result # 全batchで推論が終わったら、結果を返す"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.708605Z","iopub.execute_input":"2021-07-04T06:26:40.709024Z","iopub.status.idle":"2021-07-04T06:26:40.730675Z","shell.execute_reply.started":"2021-07-04T06:26:40.708983Z","shell.execute_reply":"2021-07-04T06:26:40.729705Z"},"trusted":true,"id":"oInneuAmXecI","executionInfo":{"status":"ok","timestamp":1627782928178,"user_tz":-540,"elapsed":6,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 学習\n","def train(model, # モデル\n","          model_path, # モデルのアウトプット先\n","          train_loader, # train-setのdata_loader\n","          val_loader, # valid-setのdata_loader\n","          optimizer, # optimizer\n","          scheduler=None, # scheduler, デフォルトはNone\n","          num_epochs=NUM_EPOCHS # epoch数、notebook冒頭で指定した値\n","         ):    \n","    \n","    best_val_rmse = None\n","    best_val_sign_bce = None\n","    best_epoch = 0\n","    step = 0\n","    last_eval_step = 0\n","    eval_period = EVAL_SCHEDULE[0][1] # eval期間(って何？) 冒頭で決めたEVAL_SCHEDULEの最初のtupleの[1]を取得\n","\n","    start = time.time() # 時間計測用\n","\n","    for epoch in range(num_epochs): # 指定したEpoch数だけ繰り返し\n","        val_rmse = None         \n","\n","        for batch_num, (input_ids, attention_mask, input_len, target_sign, target, standard_error) in enumerate(train_loader): # train_loaderからinput, targetを取得\n","            input_ids = input_ids.to(DEVICE) # inputをDEVICEへ突っ込む\n","            attention_mask = attention_mask.to(DEVICE)   \n","            input_len = input_len.to(DEVICE)\n","            target_sign = target_sign.to(DEVICE)\n","            target = target.to(DEVICE)\n","            standard_error = standard_error.to(DEVICE)\n","\n","            optimizer.zero_grad() # 勾配を初期化            \n","            model.train() # 学習モード開始\n","\n","            # https://www.kaggle.com/c/commonlitreadabilityprize/discussion/239421\n","            output = model(input_ids, attention_mask, input_len) # input,attention_maskを入力し、予測結果を得る\n","\n","            p = torch.distributions.Normal(output[0][:,0], torch.sqrt(output[0][:,1]**2))\n","            q = torch.distributions.Normal(target, standard_error)\n","            kl_vector = torch.distributions.kl_divergence(p, q)\n","\n","            loss1 = nn.BCELoss(reduction=\"mean\")(output[1].flatten(), target_sign) # +-のBCE\n","            loss2 = kl_vector.mean()\n","\n","            #loss1.backward(retain_graph=True) \n","            loss2.backward() \n","            #loss3.backward()\n","            optimizer.step() # 重みを更新する\n","\n","            if scheduler:\n","                scheduler.step() # schedulerが与えられた場合は、schedulerの学習率更新\n","            \n","            if step >= last_eval_step + eval_period: # batchを回すごとにstepを増やしていって、「前回evalしたstep + eval_period(16)」を超えたら実行。\n","                print(gpuinfo())\n","                # Evaluate the model on val_loader.\n","                elapsed_seconds = time.time() - start # 経過時間\n","                num_steps = step - last_eval_step # 経過ステップ数\n","                print(f\"\\n{num_steps} steps took {elapsed_seconds:0.3} seconds\")\n","                last_eval_step = step # 前回stepの更新\n","                \n","                # valid-setによるrmse計算\n","                train_sign_bce = loss1\n","                train_kldiv = loss2\n","                \n","                val_sign_bce, val_mse_mean, val_mse_std = eval_mse(model, val_loader)\n","                val_rmse_mean = math.sqrt(val_mse_mean)                            \n","                val_rmse_std = math.sqrt(val_mse_std)                            \n","\n","                print(f\"Epoch: {epoch} batch_num: {batch_num}\")\n","                print(f\"train_kldiv: {train_kldiv:0.4}\",\n","                      f\"train_sign_bce: {train_sign_bce:0.4}\"\n","                      )\n","                print(f\"val_rmse_mean: {val_rmse_mean:0.4}\",\n","                      f\"val_sign_bce: {val_sign_bce:0.4}\",\n","                      f\"val_rmse_std: {val_rmse_std:0.4}\"\n","                      )\n","\n","                for rmse, period in EVAL_SCHEDULE: # eval_periodをvalid-rmseで切り替える処理\n","                    if val_rmse_mean >= rmse: # valid rmseをEVAL_SCHEDULEと比較し、0項 > valid rmseとなるまで回す : EVAL_SCHEDULE = [(0.50, 16), (0.49, 8), (0.48, 4), (0.47, 2), (-1., 1)]\n","                        eval_period = period # eval_periodを更新\n","                        break                               \n","\n","                if not best_val_rmse or val_rmse_mean < best_val_rmse: # 初回(best_val_rmse==None), またはbest_val_rmseを更新したらモデルを保存する\n","                    best_val_rmse = val_rmse_mean\n","                    best_epoch = epoch\n","                    torch.save(model.state_dict(), model_path) # 最高の自分を保存\n","                    print(f\"New best_val_rmse: {best_val_rmse:0.4}\")\n","                else:       \n","                    print(f\"Still best_val_rmse: {best_val_rmse:0.4}\", # 更新されない場合は、元のスコアを表示\n","                          f\"(from epoch {best_epoch})\")      \n","\n","                if not best_val_sign_bce or val_sign_bce < best_val_sign_bce: # 初回(best_val_rmse==None), またはbest_val_rmseを更新したらモデルを保存する\n","                    best_val_sign_bce = val_sign_bce\n","                    best_epoch_sign = epoch\n","                    torch.save(model.state_dict(), f'sign_{model_path}') # 最高の自分を保存_プラマイ\n","                    print(f\"New best_val_sign_bce: {best_val_sign_bce:0.4}\")\n","                else:       \n","                    print(f\"Still best_val_sign_bce: {best_val_sign_bce:0.4}\", # 更新されない場合は、元のスコアを表示\n","                          f\"(from epoch {best_epoch_sign})\")      \n","\n","                start = time.time()\n","            \n","            # batchごとにメモリ解放\n","            del input_ids\n","            del attention_mask\n","            torch.cuda.empty_cache()                                            \n","            step += 1\n","    \n","    return best_val_rmse"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.735798Z","iopub.execute_input":"2021-07-04T06:26:40.738398Z","iopub.status.idle":"2021-07-04T06:26:40.750876Z","shell.execute_reply.started":"2021-07-04T06:26:40.738356Z","shell.execute_reply":"2021-07-04T06:26:40.749635Z"},"trusted":true,"id":"rMY0fjXwXecJ","executionInfo":{"status":"ok","timestamp":1627782928559,"user_tz":-540,"elapsed":23,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# optimizerの作成\n","def create_optimizer(model):\n","    parameters = []\n","\n","    named_parameters = list(model.named_parameters()) # モデルパラメータの取得\n","    roberta_parameters = list(model.roberta.named_parameters())[:-2] # パラメータをroberta用、attention用、regressor用に格納。(直接引っ張ってくる形式に変更)\n","\n","    attention_parameters = list(model.attention.named_parameters())\n","    attention_group = [{'params': params, 'lr': 2e-5} for (name, params) in attention_parameters] # attention用パラメータをリストとして取得\n","    parameters += attention_group\n","\n","    #norm_parameters = list(model.layer_norm.named_parameters())\n","    #norm_group = [{'params': params, 'lr': 2e-5} for (name, params) in norm_parameters]\n","    #parameters += norm_group\n","\n","    mlm_parameters = list(model.mlm_layers.named_parameters())\n","    mlm_group = [{'params': params, 'lr': 2e-5} for (name, params) in mlm_parameters] # reg用パラメータをリストとして取得\n","    parameters += mlm_group\n","\n","    regressor_parameters = list(model.regressor.named_parameters())\n","    regressor_group = [{'params': params, 'lr': 2e-5} for (name, params) in regressor_parameters] # reg用パラメータをリストとして取得\n","    parameters += regressor_group\n","\n","    bin_class_parameters = list(model.bin_class.named_parameters())\n","    bin_class_group = [{'params': params, 'lr': 2e-5} for (name, params) in bin_class_parameters] # reg用パラメータをリストとして取得\n","    parameters += bin_class_group\n","\n","\n","    for layer_num, (name, params) in enumerate(roberta_parameters): # レイヤーごとにname, paramsを取得していろんな処理\n","        weight_decay = 0.0 if \"bias\" in name else 0.01\n","\n","        lr = 8e-6\n","\n","        if layer_num >= 69:        \n","            lr = 2e-5\n","\n","        if layer_num >= 133:\n","            lr = 4e-5\n","\n","        parameters.append({\"params\": params,\n","                           \"weight_decay\": weight_decay,\n","                           \"lr\": lr})\n","\n","    return AdamW(parameters) # 最終的に、AdamWにパラメータを入力する。\n"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"4PLKHwvKtNBn","executionInfo":{"status":"ok","timestamp":1627782928559,"user_tz":-540,"elapsed":22,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["def train_and_save_model(train_indices, val_indices, model_path):\n","    train_dataset = LitDataset(train_kf_df.loc[train_indices]) # train, validのDataset\n","    val_dataset = LitDataset(train_kf_df.loc[val_indices])\n","        \n","    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n","                              drop_last=True, shuffle=True, num_workers=2) # train, validのDataLoader\n","    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n","                            drop_last=False, shuffle=False, num_workers=2)    \n","\n","    model = LitModel().to(DEVICE) # modelをDEVICEへぶち込む\n","    optimizer = create_optimizer(model) # optimizerをモデルから作成\n","    scheduler = get_cosine_schedule_with_warmup( # schedulerを作成\n","        optimizer,\n","        num_training_steps=NUM_EPOCHS * len(train_loader),\n","        num_warmup_steps=50)    \n","    rmse = train(model, model_path, train_loader, val_loader, optimizer, scheduler=scheduler)\n","\n","    del train_dataset\n","    del val_dataset\n","    del train_loader\n","    del val_loader\n","    del model\n","    del optimizer\n","    del scheduler\n","    gc.collect() \n","    torch.cuda.empty_cache()\n","    return rmse"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.755813Z","iopub.execute_input":"2021-07-04T06:26:40.758373Z","iopub.status.idle":"2021-07-04T06:27:12.493221Z","shell.execute_reply.started":"2021-07-04T06:26:40.758265Z","shell.execute_reply":"2021-07-04T06:27:12.490139Z"},"trusted":true,"id":"k2LGJD3XXecK","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e260e62b-1f09-45ac-eba9-04123bf8d894"},"source":["# 実行処理。 KFold & 学習\n","SEED = 1000\n","list_val_rmse = []\n","\n","for fold in sorted(train_kf_df['kfold'].unique()):\n","    if fold > 100: \n","      pass\n","    else:\n","      print(f\"\\nFold {fold + 1}/{NUM_FOLDS}\")\n","      print(gpuinfo())\n","      model_path = f\"model_{fold + 1}.pth\" # model_fold数_.pth\n","      set_random_seed(SEED + fold) # SEEDはfold別に変わるようにする\n","\n","      train_indices = (train_kf_df['kfold'] != fold)\n","      val_indices = (train_kf_df['kfold'] == fold)\n","      list_val_rmse.append(train_and_save_model(train_indices, val_indices, model_path))\n","      print(\"\\nPerformance estimates:\")\n","      print(list_val_rmse)\n","      print(\"Mean:\", np.array(list_val_rmse).mean())\n","      print(gpuinfo())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Fold 1/5\n","{'total_MiB': 16280, 'used_MiB': 2}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","64 steps took 64.2 seconds\n","Epoch: 0 batch_num: 64\n","train_kldiv: 1.22 train_sign_bce: 0.7268\n","val_rmse_mean: 0.6694 val_sign_bce: 0.5444 val_rmse_std: 1.04\n","New best_val_rmse: 0.6694\n","New best_val_sign_bce: 0.5444\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","64 steps took 63.4 seconds\n","Epoch: 0 batch_num: 128\n","train_kldiv: 0.7133 train_sign_bce: 0.5605\n","val_rmse_mean: 0.6178 val_sign_bce: 0.5509 val_rmse_std: 1.005\n","New best_val_rmse: 0.6178\n","Still best_val_sign_bce: 0.5444 (from epoch 0)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","64 steps took 63.3 seconds\n","Epoch: 0 batch_num: 192\n","train_kldiv: 1.074 train_sign_bce: 0.4671\n","val_rmse_mean: 0.5726 val_sign_bce: 0.5466 val_rmse_std: 1.025\n","New best_val_rmse: 0.5726\n","Still best_val_sign_bce: 0.5444 (from epoch 0)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","64 steps took 63.4 seconds\n","Epoch: 0 batch_num: 256\n","train_kldiv: 0.5754 train_sign_bce: 0.4757\n","val_rmse_mean: 0.5723 val_sign_bce: 0.5366 val_rmse_std: 0.9637\n","New best_val_rmse: 0.5723\n","New best_val_sign_bce: 0.5366\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","64 steps took 63.6 seconds\n","Epoch: 1 batch_num: 37\n","train_kldiv: 0.9923 train_sign_bce: 0.3743\n","val_rmse_mean: 0.5623 val_sign_bce: 0.5405 val_rmse_std: 0.9772\n","New best_val_rmse: 0.5623\n","Still best_val_sign_bce: 0.5366 (from epoch 0)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","64 steps took 63.4 seconds\n","Epoch: 1 batch_num: 101\n","train_kldiv: 0.3087 train_sign_bce: 0.6388\n","val_rmse_mean: 0.5277 val_sign_bce: 0.5411 val_rmse_std: 0.9812\n","New best_val_rmse: 0.5277\n","Still best_val_sign_bce: 0.5366 (from epoch 0)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 32.1 seconds\n","Epoch: 1 batch_num: 133\n","train_kldiv: 0.3178 train_sign_bce: 0.5371\n","val_rmse_mean: 0.5795 val_sign_bce: 0.5411 val_rmse_std: 1.0\n","Still best_val_rmse: 0.5277 (from epoch 1)\n","Still best_val_sign_bce: 0.5366 (from epoch 0)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","64 steps took 63.4 seconds\n","Epoch: 1 batch_num: 197\n","train_kldiv: 0.2304 train_sign_bce: 0.4595\n","val_rmse_mean: 0.5912 val_sign_bce: 0.5363 val_rmse_std: 0.9727\n","Still best_val_rmse: 0.5277 (from epoch 1)\n","New best_val_sign_bce: 0.5363\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","64 steps took 63.4 seconds\n","Epoch: 1 batch_num: 261\n","train_kldiv: 0.5523 train_sign_bce: 0.5158\n","val_rmse_mean: 0.5177 val_sign_bce: 0.5378 val_rmse_std: 0.9944\n","New best_val_rmse: 0.5177\n","Still best_val_sign_bce: 0.5363 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 32.4 seconds\n","Epoch: 2 batch_num: 10\n","train_kldiv: 0.05298 train_sign_bce: 0.8164\n","val_rmse_mean: 0.5158 val_sign_bce: 0.5359 val_rmse_std: 0.9908\n","New best_val_rmse: 0.5158\n","New best_val_sign_bce: 0.5359\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 32.0 seconds\n","Epoch: 2 batch_num: 42\n","train_kldiv: 0.1065 train_sign_bce: 0.4899\n","val_rmse_mean: 0.5033 val_sign_bce: 0.5406 val_rmse_std: 0.9952\n","New best_val_rmse: 0.5033\n","Still best_val_sign_bce: 0.5359 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 32.0 seconds\n","Epoch: 2 batch_num: 74\n","train_kldiv: 0.07797 train_sign_bce: 0.6692\n","val_rmse_mean: 0.5148 val_sign_bce: 0.5397 val_rmse_std: 0.9778\n","Still best_val_rmse: 0.5033 (from epoch 2)\n","Still best_val_sign_bce: 0.5359 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 31.9 seconds\n","Epoch: 2 batch_num: 106\n","train_kldiv: 0.05853 train_sign_bce: 0.5083\n","val_rmse_mean: 0.5125 val_sign_bce: 0.5392 val_rmse_std: 0.9863\n","Still best_val_rmse: 0.5033 (from epoch 2)\n","Still best_val_sign_bce: 0.5359 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 31.9 seconds\n","Epoch: 2 batch_num: 138\n","train_kldiv: 0.1381 train_sign_bce: 0.7652\n","val_rmse_mean: 0.5148 val_sign_bce: 0.5389 val_rmse_std: 0.9526\n","Still best_val_rmse: 0.5033 (from epoch 2)\n","Still best_val_sign_bce: 0.5359 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 32.0 seconds\n","Epoch: 2 batch_num: 170\n","train_kldiv: 0.1465 train_sign_bce: 0.646\n","val_rmse_mean: 0.5159 val_sign_bce: 0.542 val_rmse_std: 0.9792\n","Still best_val_rmse: 0.5033 (from epoch 2)\n","Still best_val_sign_bce: 0.5359 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 31.9 seconds\n","Epoch: 2 batch_num: 202\n","train_kldiv: 0.07098 train_sign_bce: 0.6317\n","val_rmse_mean: 0.5086 val_sign_bce: 0.5415 val_rmse_std: 0.9758\n","Still best_val_rmse: 0.5033 (from epoch 2)\n","Still best_val_sign_bce: 0.5359 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 32.0 seconds\n","Epoch: 2 batch_num: 234\n","train_kldiv: 0.1195 train_sign_bce: 0.5147\n","val_rmse_mean: 0.5024 val_sign_bce: 0.5405 val_rmse_std: 0.9843\n","New best_val_rmse: 0.5024\n","Still best_val_sign_bce: 0.5359 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 32.0 seconds\n","Epoch: 2 batch_num: 266\n","train_kldiv: 0.2626 train_sign_bce: 0.414\n","val_rmse_mean: 0.5392 val_sign_bce: 0.5431 val_rmse_std: 0.9937\n","Still best_val_rmse: 0.5024 (from epoch 2)\n","Still best_val_sign_bce: 0.5359 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 32.1 seconds\n","Epoch: 3 batch_num: 15\n","train_kldiv: 0.04894 train_sign_bce: 0.4878\n","val_rmse_mean: 0.5067 val_sign_bce: 0.5417 val_rmse_std: 0.9742\n","Still best_val_rmse: 0.5024 (from epoch 2)\n","Still best_val_sign_bce: 0.5359 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 31.9 seconds\n","Epoch: 3 batch_num: 47\n","train_kldiv: 0.04569 train_sign_bce: 0.7063\n","val_rmse_mean: 0.5192 val_sign_bce: 0.5406 val_rmse_std: 0.9778\n","Still best_val_rmse: 0.5024 (from epoch 2)\n","Still best_val_sign_bce: 0.5359 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 31.9 seconds\n","Epoch: 3 batch_num: 79\n","train_kldiv: 0.04604 train_sign_bce: 0.5493\n","val_rmse_mean: 0.5092 val_sign_bce: 0.5408 val_rmse_std: 0.9882\n","Still best_val_rmse: 0.5024 (from epoch 2)\n","Still best_val_sign_bce: 0.5359 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 32.0 seconds\n","Epoch: 3 batch_num: 111\n","train_kldiv: 0.08506 train_sign_bce: 0.4609\n","val_rmse_mean: 0.494 val_sign_bce: 0.5412 val_rmse_std: 0.9927\n","New best_val_rmse: 0.494\n","Still best_val_sign_bce: 0.5359 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 32.0 seconds\n","Epoch: 3 batch_num: 143\n","train_kldiv: 0.103 train_sign_bce: 0.7325\n","val_rmse_mean: 0.4951 val_sign_bce: 0.5418 val_rmse_std: 0.9938\n","Still best_val_rmse: 0.494 (from epoch 3)\n","Still best_val_sign_bce: 0.5359 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 31.9 seconds\n","Epoch: 3 batch_num: 175\n","train_kldiv: 0.06931 train_sign_bce: 0.4711\n","val_rmse_mean: 0.4934 val_sign_bce: 0.5406 val_rmse_std: 0.9875\n","New best_val_rmse: 0.4934\n","Still best_val_sign_bce: 0.5359 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 32.0 seconds\n","Epoch: 3 batch_num: 207\n","train_kldiv: 0.0205 train_sign_bce: 0.69\n","val_rmse_mean: 0.5007 val_sign_bce: 0.5396 val_rmse_std: 0.9813\n","Still best_val_rmse: 0.4934 (from epoch 3)\n","Still best_val_sign_bce: 0.5359 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 31.9 seconds\n","Epoch: 3 batch_num: 239\n","train_kldiv: 0.167 train_sign_bce: 0.4968\n","val_rmse_mean: 0.4963 val_sign_bce: 0.5399 val_rmse_std: 0.9764\n","Still best_val_rmse: 0.4934 (from epoch 3)\n","Still best_val_sign_bce: 0.5359 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 31.9 seconds\n","Epoch: 3 batch_num: 271\n","train_kldiv: 0.07528 train_sign_bce: 0.7607\n","val_rmse_mean: 0.5008 val_sign_bce: 0.5399 val_rmse_std: 0.9811\n","Still best_val_rmse: 0.4934 (from epoch 3)\n","Still best_val_sign_bce: 0.5359 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 32.2 seconds\n","Epoch: 4 batch_num: 20\n","train_kldiv: 0.04884 train_sign_bce: 0.5019\n","val_rmse_mean: 0.4922 val_sign_bce: 0.54 val_rmse_std: 0.9733\n","New best_val_rmse: 0.4922\n","Still best_val_sign_bce: 0.5359 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 32.0 seconds\n","Epoch: 4 batch_num: 52\n","train_kldiv: 0.03958 train_sign_bce: 0.5945\n","val_rmse_mean: 0.501 val_sign_bce: 0.54 val_rmse_std: 0.9847\n","Still best_val_rmse: 0.4922 (from epoch 4)\n","Still best_val_sign_bce: 0.5359 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 31.9 seconds\n","Epoch: 4 batch_num: 84\n","train_kldiv: 0.014 train_sign_bce: 0.464\n","val_rmse_mean: 0.4958 val_sign_bce: 0.5406 val_rmse_std: 0.9853\n","Still best_val_rmse: 0.4922 (from epoch 4)\n","Still best_val_sign_bce: 0.5359 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 31.9 seconds\n","Epoch: 4 batch_num: 116\n","train_kldiv: 0.02442 train_sign_bce: 0.5067\n","val_rmse_mean: 0.4998 val_sign_bce: 0.5403 val_rmse_std: 0.9761\n","Still best_val_rmse: 0.4922 (from epoch 4)\n","Still best_val_sign_bce: 0.5359 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 31.9 seconds\n","Epoch: 4 batch_num: 148\n","train_kldiv: 0.03378 train_sign_bce: 0.5573\n","val_rmse_mean: 0.4954 val_sign_bce: 0.5407 val_rmse_std: 0.9785\n","Still best_val_rmse: 0.4922 (from epoch 4)\n","Still best_val_sign_bce: 0.5359 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 32.0 seconds\n","Epoch: 4 batch_num: 180\n","train_kldiv: 0.01779 train_sign_bce: 0.5144\n","val_rmse_mean: 0.4946 val_sign_bce: 0.5411 val_rmse_std: 0.9876\n","Still best_val_rmse: 0.4922 (from epoch 4)\n","Still best_val_sign_bce: 0.5359 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 31.9 seconds\n","Epoch: 4 batch_num: 212\n","train_kldiv: 0.02731 train_sign_bce: 0.3993\n","val_rmse_mean: 0.4975 val_sign_bce: 0.5409 val_rmse_std: 0.9712\n","Still best_val_rmse: 0.4922 (from epoch 4)\n","Still best_val_sign_bce: 0.5359 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 31.9 seconds\n","Epoch: 4 batch_num: 244\n","train_kldiv: 0.03926 train_sign_bce: 0.5958\n","val_rmse_mean: 0.4978 val_sign_bce: 0.5409 val_rmse_std: 0.9796\n","Still best_val_rmse: 0.4922 (from epoch 4)\n","Still best_val_sign_bce: 0.5359 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 32.0 seconds\n","Epoch: 4 batch_num: 276\n","train_kldiv: 0.03839 train_sign_bce: 0.4884\n","val_rmse_mean: 0.4954 val_sign_bce: 0.5409 val_rmse_std: 0.9766\n","Still best_val_rmse: 0.4922 (from epoch 4)\n","Still best_val_sign_bce: 0.5359 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 32.1 seconds\n","Epoch: 5 batch_num: 25\n","train_kldiv: 0.008173 train_sign_bce: 0.5726\n","val_rmse_mean: 0.4944 val_sign_bce: 0.5412 val_rmse_std: 0.9757\n","Still best_val_rmse: 0.4922 (from epoch 4)\n","Still best_val_sign_bce: 0.5359 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 31.9 seconds\n","Epoch: 5 batch_num: 57\n","train_kldiv: 0.01925 train_sign_bce: 0.573\n","val_rmse_mean: 0.4951 val_sign_bce: 0.5412 val_rmse_std: 0.9811\n","Still best_val_rmse: 0.4922 (from epoch 4)\n","Still best_val_sign_bce: 0.5359 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 32.0 seconds\n","Epoch: 5 batch_num: 89\n","train_kldiv: 0.01387 train_sign_bce: 0.6821\n","val_rmse_mean: 0.4959 val_sign_bce: 0.5412 val_rmse_std: 0.9808\n","Still best_val_rmse: 0.4922 (from epoch 4)\n","Still best_val_sign_bce: 0.5359 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 31.9 seconds\n","Epoch: 5 batch_num: 121\n","train_kldiv: 0.01533 train_sign_bce: 0.5605\n","val_rmse_mean: 0.4958 val_sign_bce: 0.5412 val_rmse_std: 0.9743\n","Still best_val_rmse: 0.4922 (from epoch 4)\n","Still best_val_sign_bce: 0.5359 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 31.9 seconds\n","Epoch: 5 batch_num: 153\n","train_kldiv: 0.01391 train_sign_bce: 0.5469\n","val_rmse_mean: 0.4964 val_sign_bce: 0.5411 val_rmse_std: 0.9741\n","Still best_val_rmse: 0.4922 (from epoch 4)\n","Still best_val_sign_bce: 0.5359 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 31.9 seconds\n","Epoch: 5 batch_num: 185\n","train_kldiv: 0.01715 train_sign_bce: 0.4235\n","val_rmse_mean: 0.4961 val_sign_bce: 0.5412 val_rmse_std: 0.9786\n","Still best_val_rmse: 0.4922 (from epoch 4)\n","Still best_val_sign_bce: 0.5359 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 31.9 seconds\n","Epoch: 5 batch_num: 217\n","train_kldiv: 0.02234 train_sign_bce: 0.6417\n","val_rmse_mean: 0.4964 val_sign_bce: 0.5412 val_rmse_std: 0.9791\n","Still best_val_rmse: 0.4922 (from epoch 4)\n","Still best_val_sign_bce: 0.5359 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 31.9 seconds\n","Epoch: 5 batch_num: 249\n","train_kldiv: 0.01454 train_sign_bce: 0.4536\n","val_rmse_mean: 0.4963 val_sign_bce: 0.5412 val_rmse_std: 0.979\n","Still best_val_rmse: 0.4922 (from epoch 4)\n","Still best_val_sign_bce: 0.5359 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 31.9 seconds\n","Epoch: 5 batch_num: 281\n","train_kldiv: 0.01072 train_sign_bce: 0.6556\n","val_rmse_mean: 0.4963 val_sign_bce: 0.5412 val_rmse_std: 0.979\n","Still best_val_rmse: 0.4922 (from epoch 4)\n","Still best_val_sign_bce: 0.5359 (from epoch 2)\n","\n","Performance estimates:\n","[0.4921794748243375]\n","Mean: 0.4921794748243375\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 2/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","64 steps took 64.4 seconds\n","Epoch: 0 batch_num: 64\n","train_kldiv: 0.6288 train_sign_bce: 0.7843\n","val_rmse_mean: 0.6546 val_sign_bce: 0.7883 val_rmse_std: 0.1259\n","New best_val_rmse: 0.6546\n","New best_val_sign_bce: 0.7883\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","64 steps took 63.6 seconds\n","Epoch: 0 batch_num: 128\n","train_kldiv: 1.463 train_sign_bce: 0.8007\n","val_rmse_mean: 0.7931 val_sign_bce: 0.7734 val_rmse_std: 0.1734\n","Still best_val_rmse: 0.6546 (from epoch 0)\n","New best_val_sign_bce: 0.7734\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","64 steps took 63.5 seconds\n","Epoch: 0 batch_num: 192\n","train_kldiv: 1.024 train_sign_bce: 0.7243\n","val_rmse_mean: 0.5795 val_sign_bce: 0.7743 val_rmse_std: 0.1204\n","New best_val_rmse: 0.5795\n","Still best_val_sign_bce: 0.7734 (from epoch 0)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","64 steps took 63.5 seconds\n","Epoch: 0 batch_num: 256\n","train_kldiv: 0.1793 train_sign_bce: 0.7566\n","val_rmse_mean: 0.5568 val_sign_bce: 0.7587 val_rmse_std: 0.09537\n","New best_val_rmse: 0.5568\n","New best_val_sign_bce: 0.7587\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","64 steps took 64.1 seconds\n","Epoch: 1 batch_num: 37\n","train_kldiv: 0.2253 train_sign_bce: 0.7182\n","val_rmse_mean: 0.5339 val_sign_bce: 0.7513 val_rmse_std: 0.0855\n","New best_val_rmse: 0.5339\n","New best_val_sign_bce: 0.7513\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 32.1 seconds\n","Epoch: 1 batch_num: 69\n","train_kldiv: 0.1794 train_sign_bce: 0.7501\n","val_rmse_mean: 0.5702 val_sign_bce: 0.7487 val_rmse_std: 0.08099\n","Still best_val_rmse: 0.5339 (from epoch 1)\n","New best_val_sign_bce: 0.7487\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","64 steps took 63.6 seconds\n","Epoch: 1 batch_num: 133\n","train_kldiv: 0.1249 train_sign_bce: 0.7894\n","val_rmse_mean: 0.5249 val_sign_bce: 0.7456 val_rmse_std: 0.07887\n","New best_val_rmse: 0.5249\n","New best_val_sign_bce: 0.7456\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 32.1 seconds\n","Epoch: 1 batch_num: 165\n","train_kldiv: 0.1973 train_sign_bce: 0.7563\n","val_rmse_mean: 0.5255 val_sign_bce: 0.7543 val_rmse_std: 0.07842\n","Still best_val_rmse: 0.5249 (from epoch 1)\n","Still best_val_sign_bce: 0.7456 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 32.1 seconds\n","Epoch: 1 batch_num: 197\n","train_kldiv: 0.2269 train_sign_bce: 0.7494\n","val_rmse_mean: 0.6 val_sign_bce: 0.7627 val_rmse_std: 0.07591\n","Still best_val_rmse: 0.5249 (from epoch 1)\n","Still best_val_sign_bce: 0.7456 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","64 steps took 63.7 seconds\n","Epoch: 1 batch_num: 261\n","train_kldiv: 0.1521 train_sign_bce: 0.767\n","val_rmse_mean: 0.5205 val_sign_bce: 0.7441 val_rmse_std: 0.07264\n","New best_val_rmse: 0.5205\n","New best_val_sign_bce: 0.7441\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 32.4 seconds\n","Epoch: 2 batch_num: 10\n","train_kldiv: 0.1201 train_sign_bce: 0.7478\n","val_rmse_mean: 0.4923 val_sign_bce: 0.7495 val_rmse_std: 0.07332\n","New best_val_rmse: 0.4923\n","Still best_val_sign_bce: 0.7441 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 32.2 seconds\n","Epoch: 2 batch_num: 42\n","train_kldiv: 0.04624 train_sign_bce: 0.7566\n","val_rmse_mean: 0.4848 val_sign_bce: 0.7595 val_rmse_std: 0.07082\n","New best_val_rmse: 0.4848\n","Still best_val_sign_bce: 0.7441 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 32.1 seconds\n","Epoch: 2 batch_num: 74\n","train_kldiv: 0.07208 train_sign_bce: 0.7324\n","val_rmse_mean: 0.5039 val_sign_bce: 0.7519 val_rmse_std: 0.06871\n","Still best_val_rmse: 0.4848 (from epoch 2)\n","Still best_val_sign_bce: 0.7441 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 32.1 seconds\n","Epoch: 2 batch_num: 106\n","train_kldiv: 0.1334 train_sign_bce: 0.7337\n","val_rmse_mean: 0.4899 val_sign_bce: 0.7603 val_rmse_std: 0.0738\n","Still best_val_rmse: 0.4848 (from epoch 2)\n","Still best_val_sign_bce: 0.7441 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 32.1 seconds\n","Epoch: 2 batch_num: 138\n","train_kldiv: 0.1452 train_sign_bce: 0.7541\n","val_rmse_mean: 0.4847 val_sign_bce: 0.7564 val_rmse_std: 0.07039\n","New best_val_rmse: 0.4847\n","Still best_val_sign_bce: 0.7441 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 32.1 seconds\n","Epoch: 2 batch_num: 170\n","train_kldiv: 0.07049 train_sign_bce: 0.7761\n","val_rmse_mean: 0.4972 val_sign_bce: 0.7595 val_rmse_std: 0.06936\n","Still best_val_rmse: 0.4847 (from epoch 2)\n","Still best_val_sign_bce: 0.7441 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 32.0 seconds\n","Epoch: 2 batch_num: 202\n","train_kldiv: 0.2106 train_sign_bce: 0.7186\n","val_rmse_mean: 0.5084 val_sign_bce: 0.7475 val_rmse_std: 0.06749\n","Still best_val_rmse: 0.4847 (from epoch 2)\n","Still best_val_sign_bce: 0.7441 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 32.0 seconds\n","Epoch: 2 batch_num: 234\n","train_kldiv: 0.09692 train_sign_bce: 0.7039\n","val_rmse_mean: 0.4768 val_sign_bce: 0.7546 val_rmse_std: 0.06989\n","New best_val_rmse: 0.4768\n","Still best_val_sign_bce: 0.7441 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 32.0 seconds\n","Epoch: 2 batch_num: 266\n","train_kldiv: 0.1109 train_sign_bce: 0.771\n","val_rmse_mean: 0.4765 val_sign_bce: 0.7551 val_rmse_std: 0.06798\n","New best_val_rmse: 0.4765\n","Still best_val_sign_bce: 0.7441 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 32.3 seconds\n","Epoch: 3 batch_num: 15\n","train_kldiv: 0.05416 train_sign_bce: 0.7576\n","val_rmse_mean: 0.482 val_sign_bce: 0.7562 val_rmse_std: 0.07064\n","Still best_val_rmse: 0.4765 (from epoch 2)\n","Still best_val_sign_bce: 0.7441 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 31.9 seconds\n","Epoch: 3 batch_num: 47\n","train_kldiv: 0.069 train_sign_bce: 0.7226\n","val_rmse_mean: 0.49 val_sign_bce: 0.7507 val_rmse_std: 0.06692\n","Still best_val_rmse: 0.4765 (from epoch 2)\n","Still best_val_sign_bce: 0.7441 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 32.0 seconds\n","Epoch: 3 batch_num: 79\n","train_kldiv: 0.04465 train_sign_bce: 0.726\n","val_rmse_mean: 0.4828 val_sign_bce: 0.7574 val_rmse_std: 0.06823\n","Still best_val_rmse: 0.4765 (from epoch 2)\n","Still best_val_sign_bce: 0.7441 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 31.9 seconds\n","Epoch: 3 batch_num: 111\n","train_kldiv: 0.02799 train_sign_bce: 0.7437\n","val_rmse_mean: 0.4978 val_sign_bce: 0.7508 val_rmse_std: 0.06653\n","Still best_val_rmse: 0.4765 (from epoch 2)\n","Still best_val_sign_bce: 0.7441 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 32.0 seconds\n","Epoch: 3 batch_num: 143\n","train_kldiv: 0.04375 train_sign_bce: 0.7347\n","val_rmse_mean: 0.4792 val_sign_bce: 0.7527 val_rmse_std: 0.06796\n","Still best_val_rmse: 0.4765 (from epoch 2)\n","Still best_val_sign_bce: 0.7441 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 32.0 seconds\n","Epoch: 3 batch_num: 175\n","train_kldiv: 0.03928 train_sign_bce: 0.7342\n","val_rmse_mean: 0.4819 val_sign_bce: 0.757 val_rmse_std: 0.06715\n","Still best_val_rmse: 0.4765 (from epoch 2)\n","Still best_val_sign_bce: 0.7441 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 31.9 seconds\n","Epoch: 3 batch_num: 207\n","train_kldiv: 0.03898 train_sign_bce: 0.7484\n","val_rmse_mean: 0.4827 val_sign_bce: 0.7544 val_rmse_std: 0.06651\n","Still best_val_rmse: 0.4765 (from epoch 2)\n","Still best_val_sign_bce: 0.7441 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 32.0 seconds\n","Epoch: 3 batch_num: 239\n","train_kldiv: 0.0545 train_sign_bce: 0.7594\n","val_rmse_mean: 0.4795 val_sign_bce: 0.7529 val_rmse_std: 0.06755\n","Still best_val_rmse: 0.4765 (from epoch 2)\n","Still best_val_sign_bce: 0.7441 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 32.1 seconds\n","Epoch: 3 batch_num: 271\n","train_kldiv: 0.07177 train_sign_bce: 0.7203\n","val_rmse_mean: 0.4814 val_sign_bce: 0.7544 val_rmse_std: 0.06655\n","Still best_val_rmse: 0.4765 (from epoch 2)\n","Still best_val_sign_bce: 0.7441 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 32.2 seconds\n","Epoch: 4 batch_num: 20\n","train_kldiv: 0.02287 train_sign_bce: 0.8092\n","val_rmse_mean: 0.4773 val_sign_bce: 0.7537 val_rmse_std: 0.06654\n","Still best_val_rmse: 0.4765 (from epoch 2)\n","Still best_val_sign_bce: 0.7441 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 32.0 seconds\n","Epoch: 4 batch_num: 52\n","train_kldiv: 0.02125 train_sign_bce: 0.8208\n","val_rmse_mean: 0.4747 val_sign_bce: 0.7558 val_rmse_std: 0.06704\n","New best_val_rmse: 0.4747\n","Still best_val_sign_bce: 0.7441 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 32.0 seconds\n","Epoch: 4 batch_num: 84\n","train_kldiv: 0.03021 train_sign_bce: 0.7412\n","val_rmse_mean: 0.473 val_sign_bce: 0.7563 val_rmse_std: 0.06621\n","New best_val_rmse: 0.473\n","Still best_val_sign_bce: 0.7441 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 31.9 seconds\n","Epoch: 4 batch_num: 116\n","train_kldiv: 0.01671 train_sign_bce: 0.7584\n","val_rmse_mean: 0.4745 val_sign_bce: 0.7557 val_rmse_std: 0.06868\n","Still best_val_rmse: 0.473 (from epoch 4)\n","Still best_val_sign_bce: 0.7441 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 31.9 seconds\n","Epoch: 4 batch_num: 148\n","train_kldiv: 0.01048 train_sign_bce: 0.7677\n","val_rmse_mean: 0.4739 val_sign_bce: 0.7566 val_rmse_std: 0.06802\n","Still best_val_rmse: 0.473 (from epoch 4)\n","Still best_val_sign_bce: 0.7441 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 31.9 seconds\n","Epoch: 4 batch_num: 180\n","train_kldiv: 0.01367 train_sign_bce: 0.8148\n","val_rmse_mean: 0.4769 val_sign_bce: 0.756 val_rmse_std: 0.06637\n","Still best_val_rmse: 0.473 (from epoch 4)\n","Still best_val_sign_bce: 0.7441 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 31.9 seconds\n","Epoch: 4 batch_num: 212\n","train_kldiv: 0.01611 train_sign_bce: 0.7554\n","val_rmse_mean: 0.4759 val_sign_bce: 0.7567 val_rmse_std: 0.06715\n","Still best_val_rmse: 0.473 (from epoch 4)\n","Still best_val_sign_bce: 0.7441 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 31.9 seconds\n","Epoch: 4 batch_num: 244\n","train_kldiv: 0.01676 train_sign_bce: 0.7285\n","val_rmse_mean: 0.4739 val_sign_bce: 0.756 val_rmse_std: 0.06609\n","Still best_val_rmse: 0.473 (from epoch 4)\n","Still best_val_sign_bce: 0.7441 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 31.9 seconds\n","Epoch: 4 batch_num: 276\n","train_kldiv: 0.02524 train_sign_bce: 0.8218\n","val_rmse_mean: 0.4756 val_sign_bce: 0.7556 val_rmse_std: 0.06573\n","Still best_val_rmse: 0.473 (from epoch 4)\n","Still best_val_sign_bce: 0.7441 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 32.1 seconds\n","Epoch: 5 batch_num: 25\n","train_kldiv: 0.007791 train_sign_bce: 0.776\n","val_rmse_mean: 0.4751 val_sign_bce: 0.7554 val_rmse_std: 0.06635\n","Still best_val_rmse: 0.473 (from epoch 4)\n","Still best_val_sign_bce: 0.7441 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 32.0 seconds\n","Epoch: 5 batch_num: 57\n","train_kldiv: 0.01903 train_sign_bce: 0.7597\n","val_rmse_mean: 0.4755 val_sign_bce: 0.7556 val_rmse_std: 0.06639\n","Still best_val_rmse: 0.473 (from epoch 4)\n","Still best_val_sign_bce: 0.7441 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 31.9 seconds\n","Epoch: 5 batch_num: 89\n","train_kldiv: 0.01971 train_sign_bce: 0.7502\n","val_rmse_mean: 0.4751 val_sign_bce: 0.7562 val_rmse_std: 0.0659\n","Still best_val_rmse: 0.473 (from epoch 4)\n","Still best_val_sign_bce: 0.7441 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 31.9 seconds\n","Epoch: 5 batch_num: 121\n","train_kldiv: 0.005908 train_sign_bce: 0.7958\n","val_rmse_mean: 0.4756 val_sign_bce: 0.7559 val_rmse_std: 0.06593\n","Still best_val_rmse: 0.473 (from epoch 4)\n","Still best_val_sign_bce: 0.7441 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 31.9 seconds\n","Epoch: 5 batch_num: 153\n","train_kldiv: 0.01807 train_sign_bce: 0.78\n","val_rmse_mean: 0.4755 val_sign_bce: 0.7554 val_rmse_std: 0.06594\n","Still best_val_rmse: 0.473 (from epoch 4)\n","Still best_val_sign_bce: 0.7441 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 32.0 seconds\n","Epoch: 5 batch_num: 185\n","train_kldiv: 0.01345 train_sign_bce: 0.8167\n","val_rmse_mean: 0.4755 val_sign_bce: 0.7556 val_rmse_std: 0.06654\n","Still best_val_rmse: 0.473 (from epoch 4)\n","Still best_val_sign_bce: 0.7441 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 32.0 seconds\n","Epoch: 5 batch_num: 217\n","train_kldiv: 0.003957 train_sign_bce: 0.7487\n","val_rmse_mean: 0.4755 val_sign_bce: 0.7555 val_rmse_std: 0.06609\n","Still best_val_rmse: 0.473 (from epoch 4)\n","Still best_val_sign_bce: 0.7441 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 32.0 seconds\n","Epoch: 5 batch_num: 249\n","train_kldiv: 0.01446 train_sign_bce: 0.7793\n","val_rmse_mean: 0.4754 val_sign_bce: 0.7556 val_rmse_std: 0.06596\n","Still best_val_rmse: 0.473 (from epoch 4)\n","Still best_val_sign_bce: 0.7441 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","32 steps took 31.9 seconds\n","Epoch: 5 batch_num: 281\n","train_kldiv: 0.008879 train_sign_bce: 0.7548\n","val_rmse_mean: 0.4754 val_sign_bce: 0.7556 val_rmse_std: 0.06597\n","Still best_val_rmse: 0.473 (from epoch 4)\n","Still best_val_sign_bce: 0.7441 (from epoch 1)\n","\n","Performance estimates:\n","[0.4921794748243375, 0.4730300154440002]\n","Mean: 0.48260474513416884\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 3/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","64 steps took 65.3 seconds\n","Epoch: 0 batch_num: 64\n","train_kldiv: 1.721 train_sign_bce: 0.6446\n","val_rmse_mean: 0.8184 val_sign_bce: 0.6446 val_rmse_std: 1.014\n","New best_val_rmse: 0.8184\n","New best_val_sign_bce: 0.6446\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","64 steps took 63.6 seconds\n","Epoch: 0 batch_num: 128\n","train_kldiv: 1.404 train_sign_bce: 0.6032\n","val_rmse_mean: 0.7264 val_sign_bce: 0.6559 val_rmse_std: 1.008\n","New best_val_rmse: 0.7264\n","Still best_val_sign_bce: 0.6446 (from epoch 0)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","64 steps took 63.6 seconds\n","Epoch: 0 batch_num: 192\n","train_kldiv: 0.3307 train_sign_bce: 0.6359\n","val_rmse_mean: 0.5942 val_sign_bce: 0.6467 val_rmse_std: 1.013\n","New best_val_rmse: 0.5942\n","Still best_val_sign_bce: 0.6446 (from epoch 0)\n","{'total_MiB': 16280, 'used_MiB': 12909}\n","\n","64 steps took 63.6 seconds\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"m4v-cGx-Mv7S"},"source":["print(list_val_rmse)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XU4gRXHCBEpC"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iAb99KSKBEmd"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jH0aFzWxBEkG"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q2CdCMuIKDMP"},"source":["#rep = MemReporter(model)\n","#rep.report()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eLl1yDOOKIe7"},"source":["#rep = MemReporter(model.roberta)\n","#rep.report()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7qkqnknA_m9D"},"source":["#gpuinfo()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PwrqSMdYA6Pu"},"source":["#del model\n","#del optimizer \n","#del train_loader\n","#del val_loader\n","#del scheduler \n","#del list_val_rmse\n","#del train_indices\n","#del val_indices\n","#del tokenizer\n","#torch.cuda.empty_cache()\n","#gpuinfo()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wXcHyUSJXecL"},"source":["# upload models"]},{"cell_type":"code","metadata":{"id":"YIV6UllSIGoa"},"source":["%cd\n","!mkdir .kaggle\n","!mkdir /content/model\n","!cp /content/drive/MyDrive/Colab_Files/kaggle-api/kaggle.json .kaggle/\n","\n","!cp -r /content/model_1.pth /content/model/model_1.pth\n","!cp -r /content/model_2.pth /content/model/model_2.pth\n","!cp -r /content/model_3.pth /content/model/model_3.pth\n","!cp -r /content/model_4.pth /content/model/model_4.pth\n","!cp -r /content/model_5.pth /content/model/model_5.pth\n","!cp -r /content/sign_model_1.pth /content/model/sign_model_1.pth\n","!cp -r /content/sign_model_2.pth /content/model/sign_model_2.pth\n","!cp -r /content/sign_model_3.pth /content/model/sign_model_3.pth\n","!cp -r /content/sign_model_4.pth /content/model/sign_model_4.pth\n","!cp -r /content/sign_model_5.pth /content/model/sign_model_5.pth"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"14ddOZH4IMam"},"source":["def dataset_upload():\n","    import json\n","    from kaggle.api.kaggle_api_extended import KaggleApi\n","\n","    id = f'{USERID}/{EX_NO}'\n","\n","    dataset_metadata = {}\n","    dataset_metadata['id'] = id\n","    dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n","    dataset_metadata['title'] = f'{EX_NO}'\n","\n","    with open(UPLOAD_DIR / 'dataset-metadata.json', 'w') as f:\n","        json.dump(dataset_metadata, f, indent=4)\n","\n","    api = KaggleApi()\n","    api.authenticate()\n","\n","    # データセットがない場合\n","    if f'{USERID}/{EX_NO}' not in [str(d) for d in api.dataset_list(user=USERID, search=f'\"{EX_NO}\"')]:\n","        api.dataset_create_new(folder=UPLOAD_DIR,\n","                               convert_to_csv=False,\n","                               dir_mode='skip')\n","    # データセットがある場合\n","    else:\n","        api.dataset_create_version(folder=UPLOAD_DIR,\n","                                   version_notes='update',\n","                                   convert_to_csv=False,\n","                                   delete_old_versions=True,\n","                                   dir_mode='skip')\n","dataset_upload()\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R_fC64289KmB"},"source":["%cd\n","!mkdir .kaggle\n","!mkdir /content/model\n","!cp /content/drive/MyDrive/Colab_Files/kaggle-api/kaggle.json .kaggle/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dmpsG5KIWYMi"},"source":["dir_ = f'/content/drive/MyDrive/Colab_Files/kaggle/commonlit/98_model_inf/{EX_NO}'\n","!mkdir {dir_}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c3ptt69C9Kge"},"source":["import shutil\n","model_path_out = Path('/content/model/')\n","dir_ = f'/content/drive/MyDrive/Colab_Files/kaggle/commonlit/98_model_inf/{EX_NO}'\n","!mkdir {dir_}\n","tgdir = Path(dir_)\n","\n","for file_ in list(model_path_out.iterdir()):\n","  shutil.copy(file_, tgdir)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"huJwVMSAPuDO"},"source":["# validation再実行_予測結果取得\n","all_predictions = np.zeros(len(train_kf_df)) # 推論結果について、「fold　× 推論df」のzero行列で枠を作る\n","\n","for fold_ in sorted(train_kf_df['kfold'].unique()):\n","    model_path = UPLOAD_DIR/f\"model_{fold_ + 1}.pth\" # 対応するモデルを読む\n","    print(f\"\\nUsing {model_path}\")\n","\n","    val_idx = train_kf_df['kfold'] == fold_\n","    val_df = train_kf_df[val_idx]\n","    val_dataset = LitDataset(val_df, inference_only=True) # TestのDataset(何で、もう一回作るのだろう？)\n","    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n","                          drop_last=False, shuffle=False, num_workers=2) # TestのDataLoader\n","\n","    model = LitModel()\n","    model.load_state_dict(torch.load(model_path))    # 対応するモデルから、重みを読み込む\n","    model.to(DEVICE) # モデルをDEVICEへぶち込む\n","\n","    all_predictions[val_idx] = predict(model, val_loader) # 推論結果行列の対象列に、推論結果を入力(以後、繰り返し)\n","\n","    del model\n","    gc.collect()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zCTSyr6c4SOy"},"source":["from sklearn.metrics import mean_squared_error\n","import math\n","np.sqrt(mean_squared_error(train_kf_df.target.values, all_predictions))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KHttUOS44Tgh"},"source":["train_kf_df['pred'] = all_predictions\n","fold = 0\n","tg_true = train_kf_df[train_kf_df['kfold']==fold]['target'].values\n","tg_pred = train_kf_df[train_kf_df['kfold']==fold]['pred'].values\n","np.sqrt(mean_squared_error(tg_true, tg_pred))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9QdKUkE84Hc5"},"source":["train_kf_df['pred'] = all_predictions\n","train_kf_df['diff_sq'] = (train_kf_df['target'] - train_kf_df['pred'])**2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VpkQ01Nw4KAd"},"source":["train_kf_df.plot(kind='scatter', x='target', y='diff_sq')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p03ff-c_4NIQ"},"source":["# 二乗誤差が2.0を超える列\n","thr_ = 2.0 \n","train_kf_df[train_kf_df['diff_sq'] > thr_]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"poltFCo_4Qqs"},"source":["# 二乗誤差が2.0を超える文章\n","thr_ = 2.0 \n","tmp_df = train_kf_df[train_kf_df['diff_sq'] > thr_].copy()\n","for i in tmp_df.index:\n","  print(tmp_df.loc[i].target)\n","  #print(tmp_df.loc[i].standard_error)\n","  print(tmp_df.loc[i].pred)\n","  print(tmp_df.loc[i].excerpt)\n","  print('--------------------------')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0zzuBPobmLFu"},"source":["# validation再実行_予測結果取得_sign\n","all_predictions_sign = np.zeros(len(train_kf_df)) # 推論結果について、「fold　× 推論df」のzero行列で枠を作る\n","\n","for fold_ in sorted(train_kf_df['kfold'].unique()):\n","    model_path = UPLOAD_DIR/f\"sign_model_{fold_ + 1}.pth\" # 対応するモデルを読む\n","    print(f\"\\nUsing {model_path}\")\n","\n","    val_idx = train_kf_df['kfold'] == fold_\n","    val_df = train_kf_df[val_idx]\n","    val_dataset = LitDataset(val_df, inference_only=True) # TestのDataset(何で、もう一回作るのだろう？)\n","    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n","                          drop_last=False, shuffle=False, num_workers=2) # TestのDataLoader\n","\n","    model = LitModel()\n","    model.load_state_dict(torch.load(model_path))    # 対応するモデルから、重みを読み込む\n","    model.to(DEVICE) # モデルをDEVICEへぶち込む\n","\n","    all_predictions_sign[val_idx] = predict(model, val_loader) # 推論結果行列の対象列に、推論結果を入力(以後、繰り返し)\n","\n","    del model\n","    gc.collect()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UOnzcJ8C4F0L"},"source":["np.sqrt(mean_squared_error(train_kf_df.target.values, all_predictions_sign))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wpc8ro9hmNci"},"source":["train_kf_df['pred_sign'] = all_predictions_sign\n","train_kf_df['diff_sq_sign'] = (train_kf_df['target'] - train_kf_df['pred_sign'])**2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ceDI72NumT5-"},"source":["train_kf_df.plot(kind='scatter', x='target', y='diff_sq_sign')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PvRi_JQgwcKI"},"source":["# 二乗誤差が2.0を超えるレコード\n","thr_ = 2.0 \n","train_kf_df[train_kf_df['diff_sq_sign'] > thr_]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Px0bDoDve1z"},"source":["# 二乗誤差が2.0を超える文章\n","thr_ = 2.0 \n","tmp_df = train_kf_df[train_kf_df['diff_sq_sign'] > thr_].copy()\n","for i in tmp_df.index:\n","  print(tmp_df.loc[i].target)\n","  #print(tmp_df.loc[i].standard_error)\n","  print(tmp_df.loc[i].pred)\n","  print(tmp_df.loc[i].excerpt)\n","  print('--------------------------')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"87XS4-CFDgxy"},"source":["train_kf_df['pred_sign']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sKIqdv_CDiME"},"source":["train_kf_df['pred']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SMQw4b47DkKy"},"source":["train_kf_df['target']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PlX6NuBfDopm"},"source":["np.sqrt(mean_squared_error(train_kf_df.target.values, train_kf_df['pred']*0.8 + train_kf_df['pred_sign']*0.2))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wg1pwaInDqyb"},"source":[""]},{"cell_type":"code","metadata":{"id":"ppBgGZNov7Ql"},"source":["!pip install pulp"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eNwJCmoEEKEf"},"source":["def get_rmse(true, pred): \n","  return np.sqrt(mean_squared_error(true, pred))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cd-ChsWnEVg8"},"source":["target = train_kf_df.target.values\n","pred = train_kf_df['pred']*0.8 + train_kf_df['pred_sign']*0.2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Csmm2rnzEuxo"},"source":["from sklearn.linear_model import LinearRegression"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l9G1z3TWG7pW"},"source":["linear_model = LinearRegression(fit_intercept=False)\n","X = train_kf_df[['pred', 'pred_sign']]\n","y = train_kf_df.target.values\n","\n","linear_model.fit(X,y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VXYqWO8-HOYf"},"source":["linear_model.coef_"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IA-s1C9nHSmt"},"source":["weight = linear_model.coef_\n","\n","target = train_kf_df.target.values\n","pred = train_kf_df['pred']*weight[0] + train_kf_df['pred_sign']*weight[1]\n","\n","get_rmse(target, pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M2t3vx4RIBK0"},"source":["dir_ = '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/98_model_inf/057-051-train-08-02'\n","train_kf_df['pred'].to_csv(f'{dir_}/{EX_NO}_oof_target.csv')\n","train_kf_df['pred_sign'].to_csv(f'{dir_}/{EX_NO}_oof_sign.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UP1raNndMcTi"},"source":["dir_"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HeGT35QnMhG0"},"source":[""],"execution_count":null,"outputs":[]}]}