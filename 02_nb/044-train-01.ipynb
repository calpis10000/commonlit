{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"044-train-01.ipynb","provenance":[{"file_id":"1bhhkorT--y8XXaVLM8hibVgC-tLqZ16P","timestamp":1626358153868},{"file_id":"1WtT2hX6O9Qbt_hb9sF50nM2QmDXFi-XA","timestamp":1626338366006},{"file_id":"1k_p5wftcUeo711Xho1-T5an2Xkneau-J","timestamp":1626323813472},{"file_id":"1Vz2GB2BNTWuefEFkCSh3TBPEIel7KG1t","timestamp":1626317426487},{"file_id":"1djoMWojeaIPopG5tS1jNMohn8ineblRh","timestamp":1626306831897},{"file_id":"1-6tlDO8158Pi6TpptIF884oFaEiT4Uxb","timestamp":1626276420047},{"file_id":"1js8eA3mDNS8mwSpCiHuzPeARFlUPAVrg","timestamp":1626272452526},{"file_id":"1yhcPgulwJtjJKUK9IuRKmNMhJ-4YXGol","timestamp":1626267205517},{"file_id":"1mnnSv0Pofn1QxArywV81VYqnZPB8uUWN","timestamp":1626180468522},{"file_id":"1RRdjt_UAeHmr5QQBAMyC82Fq1s31OWdK","timestamp":1625833136005},{"file_id":"1JPgg44HFemzwk8VSCXih3PejL0idy-C4","timestamp":1625825483466},{"file_id":"1Ye6wqVX71xAAAhmjXkw9IpRvTqeUyJDA","timestamp":1625812137500}],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":86},"id":"Z6yRwt-PXtbP","executionInfo":{"status":"ok","timestamp":1626407103461,"user_tz":-540,"elapsed":555,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"2bb9e424-ff34-4975-8e7b-db65cabdc444"},"source":["\"\"\"\n","if 'google.colab' in sys.modules:  # colab環境特有の処理_初回のみ\n","  # Google Driveのマウント\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","\n","  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules' \\\n","   -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/requirements.txt' \\\n","   --ignore-installed\n","\n","  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules' \\\n","   transformers -U\n","  !pip install gensim==4.0.1 --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\n","  !pip install pytorch_memlab --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\n","\"\"\""],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\nif 'google.colab' in sys.modules:  # colab環境特有の処理_初回のみ\\n  # Google Driveのマウント\\n  from google.colab import drive\\n  drive.mount('/content/drive')\\n\\n  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'    -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/requirements.txt'    --ignore-installed\\n\\n  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'    transformers -U\\n  !pip install gensim==4.0.1 --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\\n  !pip install pytorch_memlab --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\\n\""]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"m9BAZj_HyuIj","executionInfo":{"status":"ok","timestamp":1626407103462,"user_tz":-540,"elapsed":7,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kA8loJjZHY2-","executionInfo":{"status":"ok","timestamp":1626407105683,"user_tz":-540,"elapsed":2227,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"31a67004-d930-4f4d-c9be-a614392be2e6"},"source":["!pip install pytorch_memlab"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pytorch_memlab in /usr/local/lib/python3.7/dist-packages (0.2.3)\n","Requirement already satisfied: pandas>=0.18 in /usr/local/lib/python3.7/dist-packages (from pytorch_memlab) (1.1.5)\n","Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch_memlab) (1.9.0+cu102)\n","Requirement already satisfied: calmsize in /usr/local/lib/python3.7/dist-packages (from pytorch_memlab) (0.1.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytorch_memlab) (57.0.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18->pytorch_memlab) (2018.9)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18->pytorch_memlab) (1.19.5)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18->pytorch_memlab) (2.8.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->pytorch_memlab) (3.7.4.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.18->pytorch_memlab) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ucCbvGD1XvG7","executionInfo":{"status":"ok","timestamp":1626407105684,"user_tz":-540,"elapsed":12,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"5c1077d9-3941-40ff-b6ec-21db042644eb"},"source":["import sys\n","if 'google.colab' in sys.modules:  # colab特有の処理_2回目以降\n","  # Google Driveのマウント\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","\n","  # データセットをDriveから取得\n","  !mkdir -p 'input'\n","  !cp -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/00_input' '/content/input'\n","\n","  # ライブラリのパス指定\n","  sys.path.append('/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules')\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RV9-VwbpZLZ9","executionInfo":{"status":"ok","timestamp":1626407105684,"user_tz":-540,"elapsed":7,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["from pathlib import Path\n","\n","# input\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    DATA_DIR = Path('../input/commonlitreadabilityprize/')\n","\n","elif 'google.colab' in sys.modules: # Colab環境\n","    !mkdir 'input' -p\n","    !cp '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/00_input/commonlitreadabilityprize/' './input' -r\n","    DATA_DIR = Path('/content/input/commonlitreadabilityprize')\n","\n","else:\n","    DATA_DIR = Path('../00_input/commonlitreadabilityprize/')"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"8tMampUSaDo5","executionInfo":{"status":"ok","timestamp":1626407105684,"user_tz":-540,"elapsed":6,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["from pathlib import Path\n","\n","# pre-trained model\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    PRE_TRAINED_MODEL_DIR = '../input/roberta-transformers-pytorch/roberta-large'\n","elif 'google.colab' in sys.modules: # Colab環境\n","    PRE_TRAINED_MODEL_DIR = 'roberta-large' # 仮で、毎回DLする想定のモデル名を指定。あとで変更予定。\n","else:\n","    PRE_TRAINED_MODEL_DIR = 'roberta-base'"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"tKjsUxnOeDYl","executionInfo":{"status":"ok","timestamp":1626407105685,"user_tz":-540,"elapsed":6,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["from pathlib import Path\n","\n","# pre-trained model\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    PRE_TRAINED_MODEL_DIR = '../input/roberta-transformers-pytorch/roberta-large'\n","elif 'google.colab' in sys.modules: # Colab環境\n","    PRE_TRAINED_MODEL_DIR = 'roberta-large' # 仮で、毎回DLする想定のモデル名を指定。あとで変更予定。\n","else:\n","    PRE_TRAINED_MODEL_DIR = 'roberta-large'"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZLaT2V0ReoAZ","executionInfo":{"status":"ok","timestamp":1626407105685,"user_tz":-540,"elapsed":6,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["UPLOAD_DIR = Path('/content/model')\n","EX_NO = '044-train-01'  # 実験番号などを入れる、folderのpathにする\n","USERID = 'calpis10000'"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"hOGjAb4pAJ0F","executionInfo":{"status":"ok","timestamp":1626407106158,"user_tz":-540,"elapsed":5,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["import subprocess\n","import shlex\n","\n","def gpuinfo():\n","    \"\"\"\n","    Returns size of total GPU RAM and used GPU RAM.\n","\n","    Parameters\n","    ----------\n","    None\n","\n","    Returns\n","    -------\n","    info : dict\n","        Total GPU RAM in integer for key 'total_MiB'.\n","        Used GPU RAM in integer for key 'used_MiB'.\n","    \"\"\"\n","\n","    command = 'nvidia-smi -q -d MEMORY | sed -n \"/FB Memory Usage/,/Free/p\" | sed -e \"1d\" -e \"4d\" -e \"s/ MiB//g\" | cut -d \":\" -f 2 | cut -c2-'\n","    commands = [shlex.split(part) for part in command.split(' | ')]\n","    for i, cmd in enumerate(commands):\n","        if i==0:\n","            res = subprocess.Popen(cmd, stdout=subprocess.PIPE)\n","        else:\n","            res = subprocess.Popen(cmd, stdin=res.stdout, stdout=subprocess.PIPE)\n","    total, used = map(int, res.communicate()[0].decode('utf-8').strip().split('\\n'))\n","    info = {'total_MiB':total, 'used_MiB':used}\n","    return info\n"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g3-6m5MKXecB"},"source":["# Overview\n","This nb is based on copy from https://www.kaggle.com/andretugan/lightweight-roberta-solution-in-pytorch .\n","\n","Acknowledgments(from base nb): \n","some ideas were taken from kernels by [Torch](https://www.kaggle.com/rhtsingh) and [Maunish](https://www.kaggle.com/maunish)."]},{"cell_type":"code","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-04T06:26:32.834365Z","iopub.execute_input":"2021-07-04T06:26:32.834903Z","iopub.status.idle":"2021-07-04T06:26:40.143740Z","shell.execute_reply.started":"2021-07-04T06:26:32.834785Z","shell.execute_reply":"2021-07-04T06:26:40.142864Z"},"trusted":true,"id":"HRsRZ06WXecD","executionInfo":{"status":"ok","timestamp":1626407109087,"user_tz":-540,"elapsed":2931,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["import os\n","import math\n","import random\n","import time\n","\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","\n","from transformers import AdamW # optimizer\n","from transformers import AutoTokenizer\n","from transformers import AutoModel\n","from transformers import AutoConfig\n","from transformers import get_cosine_schedule_with_warmup # scheduler\n","from pytorch_memlab import profile\n","import pytorch_memlab\n","from pytorch_memlab import MemReporter\n","\n","from sklearn.model_selection import KFold, StratifiedKFold\n","\n","import gc\n","gc.enable()"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"bPh2rvoiFrUM","executionInfo":{"status":"ok","timestamp":1626407109093,"user_tz":-540,"elapsed":24,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.145217Z","iopub.execute_input":"2021-07-04T06:26:40.145539Z","iopub.status.idle":"2021-07-04T06:26:40.201326Z","shell.execute_reply.started":"2021-07-04T06:26:40.145504Z","shell.execute_reply":"2021-07-04T06:26:40.200136Z"},"trusted":true,"id":"omBfwshTXecE","executionInfo":{"status":"ok","timestamp":1626407109094,"user_tz":-540,"elapsed":23,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["NUM_FOLDS = 5 # K Fold\n","NUM_EPOCHS = 5 # Epochs\n","BATCH_SIZE = 12 # Batch Size\n","MAX_LEN = 248 # ベクトル長\n","EVAL_SCHEDULE = [(0.50, 64), (0.49, 32), (0.48, 16), (0.47, 8), (0.46, 4), (-1., 1)] # schedulerの何らかの設定？\n","ROBERTA_PATH = PRE_TRAINED_MODEL_DIR # roberta pre-trainedモデル(モデルとして指定)\n","TOKENIZER_PATH = PRE_TRAINED_MODEL_DIR # roberta pre-trainedモデル(Tokenizerとして指定)\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\" # cudaがなければcpuを使えばいいじゃない"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.203398Z","iopub.execute_input":"2021-07-04T06:26:40.204055Z","iopub.status.idle":"2021-07-04T06:26:40.211572Z","shell.execute_reply.started":"2021-07-04T06:26:40.204015Z","shell.execute_reply":"2021-07-04T06:26:40.210762Z"},"trusted":true,"id":"4qcuXqwtXecF","executionInfo":{"status":"ok","timestamp":1626407109095,"user_tz":-540,"elapsed":24,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["def set_random_seed(random_seed):\n","    random.seed(random_seed)\n","    np.random.seed(random_seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(random_seed)\n","\n","    torch.manual_seed(random_seed)\n","    torch.cuda.manual_seed(random_seed)\n","    torch.cuda.manual_seed_all(random_seed)\n","\n","    torch.backends.cudnn.deterministic = True# cudnnによる最適化で結果が変わらないためのおまじない "],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.214188Z","iopub.execute_input":"2021-07-04T06:26:40.214809Z","iopub.status.idle":"2021-07-04T06:26:40.309744Z","shell.execute_reply.started":"2021-07-04T06:26:40.214769Z","shell.execute_reply":"2021-07-04T06:26:40.308926Z"},"trusted":true,"id":"70PyLsJTXecF","executionInfo":{"status":"ok","timestamp":1626407109098,"user_tz":-540,"elapsed":26,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# train, testを読む\n","train_df = pd.read_csv(DATA_DIR/\"train.csv\")\n","\n","# Remove incomplete entries if any.\n","train_df.drop(train_df[(train_df.target == 0) & (train_df.standard_error == 0)].index,\n","              inplace=True)\n","train_df.reset_index(drop=True, inplace=True)\n","\n","test_df = pd.read_csv(DATA_DIR/\"test.csv\")\n","submission_df = pd.read_csv(DATA_DIR/\"sample_submission.csv\")"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"9ZYOB59L8qtA","executionInfo":{"status":"ok","timestamp":1626407109099,"user_tz":-540,"elapsed":27,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"c47b2ef7-59d8-4475-e6f0-1f80fbab433d"},"source":["train_df.head()\n"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>url_legal</th>\n","      <th>license</th>\n","      <th>excerpt</th>\n","      <th>target</th>\n","      <th>standard_error</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>c12129c31</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>When the young people returned to the ballroom...</td>\n","      <td>-0.340259</td>\n","      <td>0.464009</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>85aa80a4c</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>All through dinner time, Mrs. Fayre was somewh...</td>\n","      <td>-0.315372</td>\n","      <td>0.480805</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>b69ac6792</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>As Roger had predicted, the snow departed as q...</td>\n","      <td>-0.580118</td>\n","      <td>0.476676</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>dd1000b26</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>And outside before the palace a great garden w...</td>\n","      <td>-1.054013</td>\n","      <td>0.450007</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>37c1b32fb</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Once upon a time there were Three Bears who li...</td>\n","      <td>0.247197</td>\n","      <td>0.510845</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          id url_legal  ...    target standard_error\n","0  c12129c31       NaN  ... -0.340259       0.464009\n","1  85aa80a4c       NaN  ... -0.315372       0.480805\n","2  b69ac6792       NaN  ... -0.580118       0.476676\n","3  dd1000b26       NaN  ... -1.054013       0.450007\n","4  37c1b32fb       NaN  ...  0.247197       0.510845\n","\n","[5 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.311021Z","iopub.execute_input":"2021-07-04T06:26:40.311347Z","iopub.status.idle":"2021-07-04T06:26:40.624393Z","shell.execute_reply.started":"2021-07-04T06:26:40.311314Z","shell.execute_reply":"2021-07-04T06:26:40.623347Z"},"trusted":true,"id":"xf0662k4XecF","executionInfo":{"status":"ok","timestamp":1626407114514,"user_tz":-540,"elapsed":5440,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# tokenizerを指定\n","tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N6aaghNkXecG"},"source":["# Dataset"]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.628883Z","iopub.execute_input":"2021-07-04T06:26:40.629347Z","iopub.status.idle":"2021-07-04T06:26:40.644338Z","shell.execute_reply.started":"2021-07-04T06:26:40.629309Z","shell.execute_reply":"2021-07-04T06:26:40.643336Z"},"trusted":true,"id":"zkopT0U1XecG","executionInfo":{"status":"ok","timestamp":1626407114515,"user_tz":-540,"elapsed":21,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# Dataset用のClass。おそらく、trainとtestでインスタンスを生成し、DataFrameと同じように扱えるような思想。\n","class LitDataset(Dataset):\n","    def __init__(self, df, inference_only=False):\n","        super().__init__()\n","\n","        self.df = df        \n","        self.inference_only = inference_only # Testデータ用フラグ\n","        self.text = df.excerpt.tolist() # 分析対象カラムをlistにする。(分かち書きではなく、Seriesをlistへ変換するような処理)\n","        #self.text = [text.replace(\"\\n\", \" \") for text in self.text] # 単語単位で分かち書きする場合\n","        \n","        if not self.inference_only:\n","            self.target = torch.tensor(df.target.values, dtype=torch.float32) # trainのみ、targetをtensorに変換\n","            self.standard_error = torch.tensor(df.standard_error.values, dtype=torch.float32) \n","\n","        self.encoded = tokenizer.batch_encode_plus( # textをtokenize\n","            self.text,\n","            padding = 'max_length',            \n","            max_length = MAX_LEN,\n","            truncation = True, # 最大長を超える文字は切り捨て\n","            return_attention_mask=True\n","        )        \n"," \n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    \n","    def __getitem__(self, index): # 変換結果を返す\n","        input_ids = torch.tensor(self.encoded['input_ids'][index])\n","        attention_mask = torch.tensor(self.encoded['attention_mask'][index])\n","        \n","        if self.inference_only:\n","            return (input_ids, attention_mask)            \n","        else:\n","            target = self.target[index]\n","            standard_error = self.standard_error[index]\n","            return (input_ids, attention_mask, target, standard_error)"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KKtdy32wXecG"},"source":["# Model\n","The model is inspired by the one from [Maunish](https://www.kaggle.com/maunish/clrp-roberta-svm)."]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.649629Z","iopub.execute_input":"2021-07-04T06:26:40.650066Z","iopub.status.idle":"2021-07-04T06:26:40.666374Z","shell.execute_reply.started":"2021-07-04T06:26:40.650002Z","shell.execute_reply":"2021-07-04T06:26:40.665211Z"},"trusted":true,"id":"BpkxjXEUXecH","executionInfo":{"status":"ok","timestamp":1626407114516,"user_tz":-540,"elapsed":21,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["class LitModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        config = AutoConfig.from_pretrained(ROBERTA_PATH) # pretrainedからconfigを読み込み\n","        config.update({\"output_hidden_states\":True, # config更新: embedding層を抽出\n","                       \"hidden_dropout_prob\": 0.0, # config更新: dropoutしない\n","                       \"layer_norm_eps\": 1e-7}) # config更新: layer normalizationのepsilon                      \n","        \n","        self.roberta = AutoModel.from_pretrained(ROBERTA_PATH, config=config) # cpuで処理する\n","            \n","        #self.attention = nn.Sequential(# attentionレイヤー            \n","        #    nn.Linear(config.hidden_size, 512),      \n","        #    nn.Tanh(),                       \n","        #    nn.Linear(512, 1),\n","        #    nn.Softmax(dim=1)\n","        #)\n","\n","        self.regressor = nn.Sequential( # 出力レイヤー                    \n","            nn.Linear(config.hidden_size, 2)                        \n","        )\n","\n","    def forward(self, input_ids, attention_mask):\n","        roberta_output = self.roberta(input_ids=input_ids, # robertaに入力データを流し、出力としてrobertaモデル(layerの複合体)を得る\n","                                      attention_mask=attention_mask)     \n","\n","        #last_hidden_state = roberta_output.hidden_states[-1] # robertaモデルの最後のlayerを得る\n","        #weights = self.attention(last_hidden_state) # robertaの最後のlayerをattentionへ入力し、出力として重みを得る                \n","        #context_vector = torch.sum(weights * last_hidden_state, dim=1) # 重み×最後の層を足し合わせて文書ベクトルとする。\n","        #return self.regressor(context_vector) # 文書ベクトルを線形層に入力し、targetを出力する\n","\n","        # https://www.kaggle.com/rhtsingh/utilizing-transformer-representations-efficiently\n","        last_hidden_state = roberta_output[0]\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        sum_mask = input_mask_expanded.sum(1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        mean_embeddings = sum_embeddings / sum_mask\n","\n","        \n","        # Now we reduce the context vector to the prediction score.\n","        return self.regressor(mean_embeddings) # 文書ベクトルを線形層に入力し、targetを出力する"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.672515Z","iopub.execute_input":"2021-07-04T06:26:40.672944Z","iopub.status.idle":"2021-07-04T06:26:40.684593Z","shell.execute_reply.started":"2021-07-04T06:26:40.672908Z","shell.execute_reply":"2021-07-04T06:26:40.683569Z"},"trusted":true,"id":"bB4jvQTxXecH","executionInfo":{"status":"ok","timestamp":1626407114517,"user_tz":-540,"elapsed":22,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 評価指標(MSE)の計算。最終的に、ルートしてRMSEにすると思われる。\n","def eval_mse(model, data_loader):\n","    \"\"\"Evaluates the mean squared error of the |model| on |data_loader|\"\"\"\n","    model.eval() # evalモードを選択。Batch Normとかdropoutをしなくなる           \n","    mse_mean_sum = 0\n","    mse_std_sum = 0\n","\n","    with torch.no_grad(): # 勾配の計算をしないBlock\n","        for batch_num, (input_ids, attention_mask, target, standard_error) in enumerate(data_loader): # data_loaderからinput, attentin_mask, targetをbatchごとに取り出す\n","            input_ids = input_ids.to(DEVICE)   \n","            attention_mask = attention_mask.to(DEVICE)   \n","            target = target.to(DEVICE)      \n","            standard_error = standard_error.to(DEVICE) \n","            \n","            output = model(input_ids, attention_mask) # 取得した値をモデルへ入力し、出力として予測値を得る。\n","\n","            mse_mean_sum += nn.MSELoss(reduction=\"sum\")(output[:,0].flatten(), target).item() # 誤差の合計を得る(Batchごとに計算した誤差を足し上げる)\n","            mse_std_sum += nn.MSELoss(reduction=\"sum\")(output[:,1].flatten(), target).item() # 誤差の合計を得る(Batchごとに計算した誤差を足し上げる)\n","\n","    del input_ids\n","    del attention_mask\n","    del target\n","\n","    mse_mean_result = mse_mean_sum / len(data_loader.dataset)\n","    mse_std_result = mse_std_sum / len(data_loader.dataset)\n","  \n","    return mse_mean_result, mse_std_result # 誤差の合計をdataset長で除し、mseを取得＆返す"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.690155Z","iopub.execute_input":"2021-07-04T06:26:40.692530Z","iopub.status.idle":"2021-07-04T06:26:40.703425Z","shell.execute_reply.started":"2021-07-04T06:26:40.692488Z","shell.execute_reply":"2021-07-04T06:26:40.702366Z"},"trusted":true,"id":"47bDno_LXecI","executionInfo":{"status":"ok","timestamp":1626407114517,"user_tz":-540,"elapsed":21,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 推論結果を返す\n","def predict(model, data_loader):\n","    \"\"\"Returns an np.array with predictions of the |model| on |data_loader|\"\"\"\n","    model.eval() # evalモード(dropout, batch_normしない)\n","\n","    result = np.zeros(len(data_loader.dataset)) # 結果をdataset長のzero配列として用意\n","    index = 0\n","    \n","    with torch.no_grad(): # 勾配の計算をしないblock(inputすると、現状の重みによる推論結果を返す)\n","        for batch_num, (input_ids, attention_mask) in enumerate(data_loader): # data_loaderからbatchごとにinputを得る\n","            input_ids = input_ids.to(DEVICE)\n","            attention_mask = attention_mask.to(DEVICE)\n","                        \n","            output = model(input_ids, attention_mask) # modelにinputを入力し、予測結果を得る。\n","\n","            result[index : index + output[:,0].shape[0]] = output[:,0].flatten().to(\"cpu\") # result[index ~ predの長さ]へ、予測結果を格納\n","            index += pred.shape[0] # indexを更新\n","\n","    return result # 全batchで推論が終わったら、結果を返す"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.708605Z","iopub.execute_input":"2021-07-04T06:26:40.709024Z","iopub.status.idle":"2021-07-04T06:26:40.730675Z","shell.execute_reply.started":"2021-07-04T06:26:40.708983Z","shell.execute_reply":"2021-07-04T06:26:40.729705Z"},"trusted":true,"id":"oInneuAmXecI","executionInfo":{"status":"ok","timestamp":1626407114518,"user_tz":-540,"elapsed":22,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 学習\n","def train(model, # モデル\n","          model_path, # モデルのアウトプット先\n","          train_loader, # train-setのdata_loader\n","          val_loader, # valid-setのdata_loader\n","          optimizer, # optimizer\n","          scheduler=None, # scheduler, デフォルトはNone\n","          num_epochs=NUM_EPOCHS # epoch数、notebook冒頭で指定した値\n","         ):    \n","    \n","    best_val_rmse = None\n","    best_epoch = 0\n","    step = 0\n","    last_eval_step = 0\n","    eval_period = EVAL_SCHEDULE[0][1] # eval期間(って何？) 冒頭で決めたEVAL_SCHEDULEの最初のtupleの[1]を取得\n","\n","    start = time.time() # 時間計測用\n","\n","    for epoch in range(num_epochs): # 指定したEpoch数だけ繰り返し\n","        val_rmse = None         \n","\n","        for batch_num, (input_ids, attention_mask, target, standard_error) in enumerate(train_loader): # train_loaderからinput, targetを取得\n","            input_ids = input_ids.to(DEVICE) # inputをDEVICEへ突っ込む\n","            attention_mask = attention_mask.to(DEVICE)       \n","            target = target.to(DEVICE)\n","            standard_error = standard_error.to(DEVICE)  \n","\n","            optimizer.zero_grad() # 勾配を初期化            \n","            model.train() # 学習モード開始\n","\n","            # https://www.kaggle.com/c/commonlitreadabilityprize/discussion/239421\n","            output = model(input_ids, attention_mask) # input,attention_maskを入力し、予測結果を得る\n","            p = torch.distributions.Normal(output[:,0], torch.sqrt(output[:,1]**2))\n","            q = torch.distributions.Normal(target, standard_error)\n","            kl_vector = torch.distributions.kl_divergence(p, q)\n","            loss = kl_vector.mean()\n","\n","            loss.backward() # 誤差逆伝播法により勾配を得る\n","            optimizer.step() # 重みを更新する\n","\n","            if scheduler:\n","                scheduler.step() # schedulerが与えられた場合は、schedulerの学習率更新\n","            \n","            if step >= last_eval_step + eval_period: # batchを回すごとにstepを増やしていって、「前回evalしたstep + eval_period(16)」を超えたら実行。\n","                # Evaluate the model on val_loader.\n","                elapsed_seconds = time.time() - start # 経過時間\n","                num_steps = step - last_eval_step # 経過ステップ数\n","                print(f\"\\n{num_steps} steps took {elapsed_seconds:0.3} seconds\")\n","                last_eval_step = step # 前回stepの更新\n","                \n","                # valid-setによるrmse計算\n","                train_mean_mse = nn.MSELoss(reduction=\"mean\")(output[:,0].flatten(), target) \n","                train_std_mse = nn.MSELoss(reduction=\"mean\")(torch.sqrt(output[:,1]**2).flatten(), standard_error) \n","\n","                train_mean_rmse = math.sqrt(train_mean_mse)\n","                train_std_rmse = math.sqrt(train_std_mse)\n","\n","                val_mean_mse, val_std_mse = eval_mse(model, val_loader)\n","                val_mean_rmse = math.sqrt(val_mean_mse)                            \n","                val_std_rmse = math.sqrt(val_std_mse)                            \n","\n","                print(f\"Epoch: {epoch} batch_num: {batch_num}\")\n","                print(f\"train_rmse_target: {train_mean_rmse:0.4}\",\n","                      f\"train_rmse_stderror: {train_std_rmse:0.4}\",\n","                      f\"train_kl_div: {loss:0.4}\",\n","                      )\n","                print(f\"val_rmse_target: {val_mean_rmse:0.4}\",\n","                      f\"val_rmse_stderror: {val_std_rmse:0.4}\"\n","                      )\n","\n","                for rmse, period in EVAL_SCHEDULE: # eval_periodをvalid-rmseで切り替える処理\n","                    if val_mean_rmse >= rmse: # valid rmseをEVAL_SCHEDULEと比較し、0項 > valid rmseとなるまで回す : EVAL_SCHEDULE = [(0.50, 16), (0.49, 8), (0.48, 4), (0.47, 2), (-1., 1)]\n","                        eval_period = period # eval_periodを更新\n","                        break                               \n","\n","                if not best_val_rmse or val_mean_rmse < best_val_rmse: # 初回(best_val_rmse==None), またはbest_val_rmseを更新したらモデルを保存する\n","                    best_val_rmse = val_mean_rmse\n","                    best_epoch = epoch\n","                    torch.save(model.state_dict(), model_path) # 最高の自分を保存\n","                    print(f\"New best_val_rmse: {best_val_rmse:0.4}\")\n","                else:       \n","                    print(f\"Still best_val_rmse: {best_val_rmse:0.4}\", # 更新されない場合は、元のスコアを表示\n","                          f\"(from epoch {best_epoch})\")      \n","                                                  \n","                start = time.time()\n","            \n","            # batchごとにメモリ解放\n","            del input_ids\n","            del attention_mask\n","            del target\n","            torch.cuda.empty_cache()                                            \n","            step += 1\n","    \n","    return best_val_rmse"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.735798Z","iopub.execute_input":"2021-07-04T06:26:40.738398Z","iopub.status.idle":"2021-07-04T06:26:40.750876Z","shell.execute_reply.started":"2021-07-04T06:26:40.738356Z","shell.execute_reply":"2021-07-04T06:26:40.749635Z"},"trusted":true,"id":"rMY0fjXwXecJ","executionInfo":{"status":"ok","timestamp":1626407114519,"user_tz":-540,"elapsed":22,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# optimizerの作成\n","def create_optimizer(model):\n","    named_parameters = list(model.named_parameters()) # モデルパラメータの取得\n","    \n","    roberta_parameters = list(model.roberta.named_parameters())[:-2] # パラメータをroberta用、attention用、regressor用に格納。(直接引っ張ってくる形式に変更)\n","    #attention_parameters = list(model.attention.named_parameters())\n","    regressor_parameters = list(model.regressor.named_parameters())\n","        \n","    #attention_group = [params for (name, params) in attention_parameters] # attention用パラメータをリストとして取得\n","    regressor_group = [params for (name, params) in regressor_parameters] # reg用パラメータをリストとして取得\n","\n","    parameters = []\n","    #parameters.append({\"params\": attention_group}) # パラメータをリストに辞書として格納していく\n","    parameters.append({\"params\": regressor_group})\n","\n","    for layer_num, (name, params) in enumerate(roberta_parameters): # レイヤーごとにname, paramsを取得していろんな処理\n","        weight_decay = 0.0 if \"bias\" in name else 0.01\n","\n","        lr = 2e-6\n","\n","        if layer_num >= 69:        \n","            lr = 5e-6\n","\n","        if layer_num >= 133:\n","            lr = 1e-5\n","\n","        parameters.append({\"params\": params,\n","                           \"weight_decay\": weight_decay,\n","                           \"lr\": lr})\n","\n","    return AdamW(parameters) # 最終的に、AdamWにパラメータを入力する。\n"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"EbaJojz0Zjif","executionInfo":{"status":"ok","timestamp":1626407114519,"user_tz":-540,"elapsed":20,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# https://www.kaggle.com/abhishek/step-1-create-folds\n","def create_folds(data, num_splits, SEED, return_df=False):\n","    # we create a new column called kfold and fill it with -1\n","    data[\"kfold\"] = -1\n","    \n","    # the next step is to randomize the rows of the data\n","    data = data.sample(frac=1).reset_index(drop=True)\n","\n","    # calculate number of bins by Sturge's rule\n","    # I take the floor of the value, you can also\n","    # just round it\n","    num_bins = int(np.floor(1 + np.log2(len(data))))\n","    \n","    # bin targets\n","    data.loc[:, \"bins_tg\"] = pd.cut(\n","        data[\"target\"], bins=num_bins, labels=False\n","    ).map(lambda x: str(x))\n","\n","    # bin standard_error\n","    data.loc[:, \"bins_std\"] = pd.cut(\n","        data[\"standard_error\"], bins=num_bins, labels=False\n","    )\n","\n","    # bins\n","    data.loc[:, \"bins\"] = data['bins_tg'].map(lambda x: str(x)) + data['bins_std'].map(lambda x: str(x))\n","\n","    # initiate the kfold class from model_selection module\n","    kf = StratifiedKFold(n_splits=5, random_state=SEED, shuffle=True)\n","\n","    # note that, instead of targets, we use bins!\n","    if return_df:\n","      for f, (t_, v_) in enumerate(kf.split(X=data, y=data.bins.values)):\n","        data.loc[v_, 'kfold'] = f\n","      return data\n","    else:\n","      return kf.split(X=data, y=data.bins.values)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"id":"vAmhaYaylMk5","executionInfo":{"status":"ok","timestamp":1626407114522,"user_tz":-540,"elapsed":22,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"40faf838-bea0-4f0b-fd0b-8fb051b2105b"},"source":["# 検証用\n","SEED = 1000\n","st_kfold_bins_df = create_folds(train_df, num_splits=5, SEED=SEED, return_df=True)\n","st_kfold_bins_df['bins_tg'] = st_kfold_bins_df['bins_tg'].map(lambda x: float(x))\n","st_kfold_bins_df['bins_std'] = st_kfold_bins_df['bins_std'].map(lambda x: float(x))\n","st_kfold_bins_df.groupby('kfold').agg({'bins_tg': ['min', 'max', 'mean'],\n","                                    'bins_std': ['min', 'max', 'mean']})"],"execution_count":22,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  % (min_groups, self.n_splits)), UserWarning)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","\n","    .dataframe thead tr:last-of-type th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th></th>\n","      <th colspan=\"3\" halign=\"left\">bins_tg</th>\n","      <th colspan=\"3\" halign=\"left\">bins_std</th>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <th>min</th>\n","      <th>max</th>\n","      <th>mean</th>\n","      <th>min</th>\n","      <th>max</th>\n","      <th>mean</th>\n","    </tr>\n","    <tr>\n","      <th>kfold</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>5.580247</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>2.952381</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>5.562610</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>2.936508</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>5.559083</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>2.913580</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>5.519435</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>2.931095</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>5.528269</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>2.911661</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      bins_tg                 bins_std                \n","          min   max      mean      min   max      mean\n","kfold                                                 \n","0         0.0  11.0  5.580247      0.0  11.0  2.952381\n","1         0.0  11.0  5.562610      0.0  11.0  2.936508\n","2         0.0  11.0  5.559083      0.0  11.0  2.913580\n","3         0.0  11.0  5.519435      0.0  11.0  2.931095\n","4         0.0  11.0  5.528269      0.0  11.0  2.911661"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"TyjgRCu3mmqG","executionInfo":{"status":"ok","timestamp":1626407114522,"user_tz":-540,"elapsed":17,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"4PLKHwvKtNBn","executionInfo":{"status":"ok","timestamp":1626407114523,"user_tz":-540,"elapsed":18,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["def train_and_save_model(train_indices, val_indices, model_path):\n","    train_dataset = LitDataset(train_df.loc[train_indices]) # train, validのDataset\n","    val_dataset = LitDataset(train_df.loc[val_indices])\n","        \n","    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n","                              drop_last=True, shuffle=True, num_workers=2) # train, validのDataLoader\n","    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n","                            drop_last=False, shuffle=False, num_workers=2)    \n","\n","    model = LitModel().to(DEVICE) # modelをDEVICEへぶち込む\n","    optimizer = create_optimizer(model) # optimizerをモデルから作成\n","    scheduler = get_cosine_schedule_with_warmup( # schedulerを作成\n","        optimizer,\n","        num_training_steps=NUM_EPOCHS * len(train_loader),\n","        num_warmup_steps=50)    \n","    rmse = train(model, model_path, train_loader, val_loader, optimizer, scheduler=scheduler)\n","\n","    del train_dataset\n","    del val_dataset\n","    del train_loader\n","    del val_loader\n","    del model\n","    del optimizer\n","    del scheduler\n","    gc.collect() \n","    torch.cuda.empty_cache()\n","    return rmse"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.755813Z","iopub.execute_input":"2021-07-04T06:26:40.758373Z","iopub.status.idle":"2021-07-04T06:27:12.493221Z","shell.execute_reply.started":"2021-07-04T06:26:40.758265Z","shell.execute_reply":"2021-07-04T06:27:12.490139Z"},"trusted":true,"id":"k2LGJD3XXecK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626414647339,"user_tz":-540,"elapsed":7532833,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"c7fc95b6-07fc-46ad-f0bd-853119bb0523"},"source":["# 実行処理。 KFold & 学習\n","SEED = 1000\n","list_val_rmse = []\n","\n","#kfold = KFold(n_splits=NUM_FOLDS, random_state=SEED, shuffle=True)\n","kfold = create_folds(train_df, 5, SEED=SEED, return_df=False) # binsで切る場合\n","\n","for fold, (train_indices, val_indices) in enumerate(kfold):    \n","    print(f\"\\nFold {fold + 1}/{NUM_FOLDS}\")\n","    print(gpuinfo())\n","    model_path = f\"model_{fold + 1}.pth\" # model_fold数_.pth\n","    set_random_seed(SEED + fold) # SEEDはfold別に変わるようにする\n","    list_val_rmse.append(train_and_save_model(train_indices, val_indices, model_path))\n","\n","    print(\"\\nPerformance estimates:\")\n","    print(list_val_rmse)\n","    print(\"Mean:\", np.array(list_val_rmse).mean())\n","    print(gpuinfo())"],"execution_count":24,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  % (min_groups, self.n_splits)), UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Fold 1/5\n","{'total_MiB': 16280, 'used_MiB': 2}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 81.6 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.5668 train_rmse_stderror: 0.05104 train_kl_div: 0.6125\n","val_rmse_target: 0.7876 val_rmse_stderror: 1.836\n","New best_val_rmse: 0.7876\n","\n","64 steps took 81.1 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.6099 train_rmse_stderror: 0.05057 train_kl_div: 0.663\n","val_rmse_target: 0.6451 val_rmse_stderror: 1.793\n","New best_val_rmse: 0.6451\n","\n","64 steps took 80.8 seconds\n","Epoch: 1 batch_num: 4\n","train_rmse_target: 0.4034 train_rmse_stderror: 0.03709 train_kl_div: 0.3355\n","val_rmse_target: 0.5698 val_rmse_stderror: 1.803\n","New best_val_rmse: 0.5698\n","\n","64 steps took 80.7 seconds\n","Epoch: 1 batch_num: 68\n","train_rmse_target: 0.6294 train_rmse_stderror: 0.06842 train_kl_div: 0.7423\n","val_rmse_target: 0.5174 val_rmse_stderror: 1.799\n","New best_val_rmse: 0.5174\n","\n","64 steps took 80.7 seconds\n","Epoch: 1 batch_num: 132\n","train_rmse_target: 0.3483 train_rmse_stderror: 0.03973 train_kl_div: 0.2354\n","val_rmse_target: 0.5368 val_rmse_stderror: 1.795\n","Still best_val_rmse: 0.5174 (from epoch 1)\n","\n","64 steps took 80.8 seconds\n","Epoch: 2 batch_num: 8\n","train_rmse_target: 0.3995 train_rmse_stderror: 0.04972 train_kl_div: 0.3285\n","val_rmse_target: 0.5516 val_rmse_stderror: 1.8\n","Still best_val_rmse: 0.5174 (from epoch 1)\n","\n","64 steps took 80.6 seconds\n","Epoch: 2 batch_num: 72\n","train_rmse_target: 0.3021 train_rmse_stderror: 0.0297 train_kl_div: 0.1791\n","val_rmse_target: 0.5167 val_rmse_stderror: 1.805\n","New best_val_rmse: 0.5167\n","\n","64 steps took 80.7 seconds\n","Epoch: 2 batch_num: 136\n","train_rmse_target: 0.3669 train_rmse_stderror: 0.04062 train_kl_div: 0.3045\n","val_rmse_target: 0.4936 val_rmse_stderror: 1.807\n","New best_val_rmse: 0.4936\n","\n","32 steps took 40.4 seconds\n","Epoch: 2 batch_num: 168\n","train_rmse_target: 0.3313 train_rmse_stderror: 0.03573 train_kl_div: 0.206\n","val_rmse_target: 0.4933 val_rmse_stderror: 1.806\n","New best_val_rmse: 0.4933\n","\n","32 steps took 40.5 seconds\n","Epoch: 3 batch_num: 12\n","train_rmse_target: 0.2423 train_rmse_stderror: 0.02646 train_kl_div: 0.1272\n","val_rmse_target: 0.4954 val_rmse_stderror: 1.799\n","Still best_val_rmse: 0.4933 (from epoch 2)\n","\n","32 steps took 40.3 seconds\n","Epoch: 3 batch_num: 44\n","train_rmse_target: 0.23 train_rmse_stderror: 0.03408 train_kl_div: 0.1067\n","val_rmse_target: 0.5062 val_rmse_stderror: 1.803\n","Still best_val_rmse: 0.4933 (from epoch 2)\n","\n","64 steps took 80.6 seconds\n","Epoch: 3 batch_num: 108\n","train_rmse_target: 0.1597 train_rmse_stderror: 0.03013 train_kl_div: 0.05788\n","val_rmse_target: 0.5007 val_rmse_stderror: 1.8\n","Still best_val_rmse: 0.4933 (from epoch 2)\n","\n","64 steps took 80.7 seconds\n","Epoch: 3 batch_num: 172\n","train_rmse_target: 0.2345 train_rmse_stderror: 0.0349 train_kl_div: 0.1184\n","val_rmse_target: 0.5084 val_rmse_stderror: 1.801\n","Still best_val_rmse: 0.4933 (from epoch 2)\n","\n","64 steps took 80.8 seconds\n","Epoch: 4 batch_num: 48\n","train_rmse_target: 0.2569 train_rmse_stderror: 0.03679 train_kl_div: 0.1343\n","val_rmse_target: 0.5008 val_rmse_stderror: 1.802\n","Still best_val_rmse: 0.4933 (from epoch 2)\n","\n","64 steps took 80.6 seconds\n","Epoch: 4 batch_num: 112\n","train_rmse_target: 0.1878 train_rmse_stderror: 0.03438 train_kl_div: 0.08778\n","val_rmse_target: 0.4979 val_rmse_stderror: 1.799\n","Still best_val_rmse: 0.4933 (from epoch 2)\n","\n","32 steps took 40.3 seconds\n","Epoch: 4 batch_num: 144\n","train_rmse_target: 0.1209 train_rmse_stderror: 0.02513 train_kl_div: 0.02888\n","val_rmse_target: 0.503 val_rmse_stderror: 1.799\n","Still best_val_rmse: 0.4933 (from epoch 2)\n","\n","Performance estimates:\n","[0.4933007558258711]\n","Mean: 0.4933007558258711\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 2/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 81.7 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.5932 train_rmse_stderror: 0.06864 train_kl_div: 0.7786\n","val_rmse_target: 0.6273 val_rmse_stderror: 1.812\n","New best_val_rmse: 0.6273\n","\n","64 steps took 80.7 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.8244 train_rmse_stderror: 0.04107 train_kl_div: 1.387\n","val_rmse_target: 0.5857 val_rmse_stderror: 1.789\n","New best_val_rmse: 0.5857\n","\n","64 steps took 81.0 seconds\n","Epoch: 1 batch_num: 4\n","train_rmse_target: 0.2916 train_rmse_stderror: 0.04329 train_kl_div: 0.1866\n","val_rmse_target: 0.529 val_rmse_stderror: 1.791\n","New best_val_rmse: 0.529\n","\n","64 steps took 80.7 seconds\n","Epoch: 1 batch_num: 68\n","train_rmse_target: 0.6142 train_rmse_stderror: 0.03786 train_kl_div: 0.6636\n","val_rmse_target: 0.5206 val_rmse_stderror: 1.784\n","New best_val_rmse: 0.5206\n","\n","64 steps took 80.7 seconds\n","Epoch: 1 batch_num: 132\n","train_rmse_target: 0.668 train_rmse_stderror: 0.03943 train_kl_div: 0.9967\n","val_rmse_target: 0.4939 val_rmse_stderror: 1.784\n","New best_val_rmse: 0.4939\n","\n","32 steps took 40.4 seconds\n","Epoch: 1 batch_num: 164\n","train_rmse_target: 0.4666 train_rmse_stderror: 0.04219 train_kl_div: 0.3986\n","val_rmse_target: 0.5031 val_rmse_stderror: 1.803\n","Still best_val_rmse: 0.4939 (from epoch 1)\n","\n","64 steps took 80.9 seconds\n","Epoch: 2 batch_num: 40\n","train_rmse_target: 0.301 train_rmse_stderror: 0.02484 train_kl_div: 0.1934\n","val_rmse_target: 0.4994 val_rmse_stderror: 1.78\n","Still best_val_rmse: 0.4939 (from epoch 1)\n","\n","32 steps took 40.3 seconds\n","Epoch: 2 batch_num: 72\n","train_rmse_target: 0.3783 train_rmse_stderror: 0.03001 train_kl_div: 0.2713\n","val_rmse_target: 0.5017 val_rmse_stderror: 1.777\n","Still best_val_rmse: 0.4939 (from epoch 1)\n","\n","64 steps took 80.7 seconds\n","Epoch: 2 batch_num: 136\n","train_rmse_target: 0.2793 train_rmse_stderror: 0.01952 train_kl_div: 0.1679\n","val_rmse_target: 0.5493 val_rmse_stderror: 1.777\n","Still best_val_rmse: 0.4939 (from epoch 1)\n","\n","64 steps took 80.9 seconds\n","Epoch: 3 batch_num: 12\n","train_rmse_target: 0.1383 train_rmse_stderror: 0.03347 train_kl_div: 0.04498\n","val_rmse_target: 0.4826 val_rmse_stderror: 1.78\n","New best_val_rmse: 0.4826\n","\n","16 steps took 20.2 seconds\n","Epoch: 3 batch_num: 28\n","train_rmse_target: 0.1444 train_rmse_stderror: 0.02099 train_kl_div: 0.04457\n","val_rmse_target: 0.4853 val_rmse_stderror: 1.781\n","Still best_val_rmse: 0.4826 (from epoch 3)\n","\n","16 steps took 20.2 seconds\n","Epoch: 3 batch_num: 44\n","train_rmse_target: 0.1486 train_rmse_stderror: 0.02929 train_kl_div: 0.05165\n","val_rmse_target: 0.4943 val_rmse_stderror: 1.772\n","Still best_val_rmse: 0.4826 (from epoch 3)\n","\n","32 steps took 40.3 seconds\n","Epoch: 3 batch_num: 76\n","train_rmse_target: 0.2045 train_rmse_stderror: 0.01984 train_kl_div: 0.09099\n","val_rmse_target: 0.4925 val_rmse_stderror: 1.779\n","Still best_val_rmse: 0.4826 (from epoch 3)\n","\n","32 steps took 40.3 seconds\n","Epoch: 3 batch_num: 108\n","train_rmse_target: 0.2074 train_rmse_stderror: 0.03591 train_kl_div: 0.09826\n","val_rmse_target: 0.4972 val_rmse_stderror: 1.784\n","Still best_val_rmse: 0.4826 (from epoch 3)\n","\n","32 steps took 40.3 seconds\n","Epoch: 3 batch_num: 140\n","train_rmse_target: 0.1728 train_rmse_stderror: 0.02272 train_kl_div: 0.05863\n","val_rmse_target: 0.4962 val_rmse_stderror: 1.784\n","Still best_val_rmse: 0.4826 (from epoch 3)\n","\n","32 steps took 40.3 seconds\n","Epoch: 3 batch_num: 172\n","train_rmse_target: 0.1868 train_rmse_stderror: 0.03124 train_kl_div: 0.07023\n","val_rmse_target: 0.4926 val_rmse_stderror: 1.784\n","Still best_val_rmse: 0.4826 (from epoch 3)\n","\n","32 steps took 40.6 seconds\n","Epoch: 4 batch_num: 16\n","train_rmse_target: 0.107 train_rmse_stderror: 0.0205 train_kl_div: 0.02374\n","val_rmse_target: 0.4865 val_rmse_stderror: 1.78\n","Still best_val_rmse: 0.4826 (from epoch 3)\n","\n","16 steps took 20.1 seconds\n","Epoch: 4 batch_num: 32\n","train_rmse_target: 0.1857 train_rmse_stderror: 0.03067 train_kl_div: 0.07836\n","val_rmse_target: 0.4968 val_rmse_stderror: 1.779\n","Still best_val_rmse: 0.4826 (from epoch 3)\n","\n","32 steps took 40.3 seconds\n","Epoch: 4 batch_num: 64\n","train_rmse_target: 0.1344 train_rmse_stderror: 0.02527 train_kl_div: 0.04008\n","val_rmse_target: 0.4922 val_rmse_stderror: 1.777\n","Still best_val_rmse: 0.4826 (from epoch 3)\n","\n","32 steps took 40.3 seconds\n","Epoch: 4 batch_num: 96\n","train_rmse_target: 0.1382 train_rmse_stderror: 0.02276 train_kl_div: 0.04294\n","val_rmse_target: 0.489 val_rmse_stderror: 1.78\n","Still best_val_rmse: 0.4826 (from epoch 3)\n","\n","16 steps took 20.1 seconds\n","Epoch: 4 batch_num: 112\n","train_rmse_target: 0.2292 train_rmse_stderror: 0.03435 train_kl_div: 0.08992\n","val_rmse_target: 0.4949 val_rmse_stderror: 1.78\n","Still best_val_rmse: 0.4826 (from epoch 3)\n","\n","32 steps took 40.3 seconds\n","Epoch: 4 batch_num: 144\n","train_rmse_target: 0.2276 train_rmse_stderror: 0.02706 train_kl_div: 0.09776\n","val_rmse_target: 0.4943 val_rmse_stderror: 1.78\n","Still best_val_rmse: 0.4826 (from epoch 3)\n","\n","32 steps took 40.3 seconds\n","Epoch: 4 batch_num: 176\n","train_rmse_target: 0.1316 train_rmse_stderror: 0.02657 train_kl_div: 0.0396\n","val_rmse_target: 0.4943 val_rmse_stderror: 1.779\n","Still best_val_rmse: 0.4826 (from epoch 3)\n","\n","Performance estimates:\n","[0.4933007558258711, 0.48256763162233135]\n","Mean: 0.4879341937241012\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 3/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 81.7 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.9306 train_rmse_stderror: 0.04689 train_kl_div: 1.551\n","val_rmse_target: 0.6408 val_rmse_stderror: 1.107\n","New best_val_rmse: 0.6408\n","\n","64 steps took 80.7 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.5752 train_rmse_stderror: 0.04071 train_kl_div: 0.6889\n","val_rmse_target: 0.5507 val_rmse_stderror: 1.099\n","New best_val_rmse: 0.5507\n","\n","64 steps took 80.9 seconds\n","Epoch: 1 batch_num: 4\n","train_rmse_target: 0.4153 train_rmse_stderror: 0.03677 train_kl_div: 0.3655\n","val_rmse_target: 0.5462 val_rmse_stderror: 1.094\n","New best_val_rmse: 0.5462\n","\n","64 steps took 80.7 seconds\n","Epoch: 1 batch_num: 68\n","train_rmse_target: 0.513 train_rmse_stderror: 0.0406 train_kl_div: 0.4599\n","val_rmse_target: 0.5237 val_rmse_stderror: 1.097\n","New best_val_rmse: 0.5237\n","\n","64 steps took 80.8 seconds\n","Epoch: 1 batch_num: 132\n","train_rmse_target: 0.4018 train_rmse_stderror: 0.02576 train_kl_div: 0.369\n","val_rmse_target: 0.5508 val_rmse_stderror: 1.111\n","Still best_val_rmse: 0.5237 (from epoch 1)\n","\n","64 steps took 80.9 seconds\n","Epoch: 2 batch_num: 8\n","train_rmse_target: 0.3366 train_rmse_stderror: 0.0239 train_kl_div: 0.2341\n","val_rmse_target: 0.4895 val_rmse_stderror: 1.09\n","New best_val_rmse: 0.4895\n","\n","16 steps took 20.2 seconds\n","Epoch: 2 batch_num: 24\n","train_rmse_target: 0.154 train_rmse_stderror: 0.03176 train_kl_div: 0.05798\n","val_rmse_target: 0.497 val_rmse_stderror: 1.111\n","Still best_val_rmse: 0.4895 (from epoch 2)\n","\n","32 steps took 40.3 seconds\n","Epoch: 2 batch_num: 56\n","train_rmse_target: 0.4757 train_rmse_stderror: 0.03294 train_kl_div: 0.3965\n","val_rmse_target: 0.5115 val_rmse_stderror: 1.1\n","Still best_val_rmse: 0.4895 (from epoch 2)\n","\n","64 steps took 80.7 seconds\n","Epoch: 2 batch_num: 120\n","train_rmse_target: 0.3354 train_rmse_stderror: 0.03227 train_kl_div: 0.2214\n","val_rmse_target: 0.505 val_rmse_stderror: 1.11\n","Still best_val_rmse: 0.4895 (from epoch 2)\n","\n","64 steps took 80.6 seconds\n","Epoch: 2 batch_num: 184\n","train_rmse_target: 0.2628 train_rmse_stderror: 0.03037 train_kl_div: 0.1491\n","val_rmse_target: 0.5032 val_rmse_stderror: 1.1\n","Still best_val_rmse: 0.4895 (from epoch 2)\n","\n","64 steps took 80.9 seconds\n","Epoch: 3 batch_num: 60\n","train_rmse_target: 0.2315 train_rmse_stderror: 0.01855 train_kl_div: 0.1098\n","val_rmse_target: 0.4936 val_rmse_stderror: 1.101\n","Still best_val_rmse: 0.4895 (from epoch 2)\n","\n","32 steps took 40.3 seconds\n","Epoch: 3 batch_num: 92\n","train_rmse_target: 0.1361 train_rmse_stderror: 0.03142 train_kl_div: 0.04313\n","val_rmse_target: 0.4898 val_rmse_stderror: 1.106\n","Still best_val_rmse: 0.4895 (from epoch 2)\n","\n","16 steps took 20.2 seconds\n","Epoch: 3 batch_num: 108\n","train_rmse_target: 0.1797 train_rmse_stderror: 0.02056 train_kl_div: 0.06276\n","val_rmse_target: 0.4922 val_rmse_stderror: 1.108\n","Still best_val_rmse: 0.4895 (from epoch 2)\n","\n","32 steps took 40.3 seconds\n","Epoch: 3 batch_num: 140\n","train_rmse_target: 0.1691 train_rmse_stderror: 0.03453 train_kl_div: 0.05436\n","val_rmse_target: 0.513 val_rmse_stderror: 1.108\n","Still best_val_rmse: 0.4895 (from epoch 2)\n","\n","64 steps took 80.9 seconds\n","Epoch: 4 batch_num: 16\n","train_rmse_target: 0.1418 train_rmse_stderror: 0.02296 train_kl_div: 0.03973\n","val_rmse_target: 0.4918 val_rmse_stderror: 1.107\n","Still best_val_rmse: 0.4895 (from epoch 2)\n","\n","32 steps took 40.3 seconds\n","Epoch: 4 batch_num: 48\n","train_rmse_target: 0.09253 train_rmse_stderror: 0.0228 train_kl_div: 0.0213\n","val_rmse_target: 0.4969 val_rmse_stderror: 1.104\n","Still best_val_rmse: 0.4895 (from epoch 2)\n","\n","32 steps took 40.3 seconds\n","Epoch: 4 batch_num: 80\n","train_rmse_target: 0.2508 train_rmse_stderror: 0.01825 train_kl_div: 0.1109\n","val_rmse_target: 0.4923 val_rmse_stderror: 1.107\n","Still best_val_rmse: 0.4895 (from epoch 2)\n","\n","32 steps took 40.3 seconds\n","Epoch: 4 batch_num: 112\n","train_rmse_target: 0.1188 train_rmse_stderror: 0.03606 train_kl_div: 0.03204\n","val_rmse_target: 0.4965 val_rmse_stderror: 1.105\n","Still best_val_rmse: 0.4895 (from epoch 2)\n","\n","32 steps took 40.3 seconds\n","Epoch: 4 batch_num: 144\n","train_rmse_target: 0.1229 train_rmse_stderror: 0.02312 train_kl_div: 0.03431\n","val_rmse_target: 0.4948 val_rmse_stderror: 1.106\n","Still best_val_rmse: 0.4895 (from epoch 2)\n","\n","32 steps took 40.3 seconds\n","Epoch: 4 batch_num: 176\n","train_rmse_target: 0.165 train_rmse_stderror: 0.025 train_kl_div: 0.05162\n","val_rmse_target: 0.4945 val_rmse_stderror: 1.107\n","Still best_val_rmse: 0.4895 (from epoch 2)\n","\n","Performance estimates:\n","[0.4933007558258711, 0.48256763162233135, 0.48952966116944263]\n","Mean: 0.48846601620588165\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 4/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 81.6 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.6633 train_rmse_stderror: 0.03883 train_kl_div: 0.8143\n","val_rmse_target: 0.6654 val_rmse_stderror: 1.16\n","New best_val_rmse: 0.6654\n","\n","64 steps took 80.7 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.5588 train_rmse_stderror: 0.05491 train_kl_div: 0.5508\n","val_rmse_target: 0.5914 val_rmse_stderror: 1.153\n","New best_val_rmse: 0.5914\n","\n","64 steps took 81.0 seconds\n","Epoch: 1 batch_num: 4\n","train_rmse_target: 0.4847 train_rmse_stderror: 0.0165 train_kl_div: 0.5274\n","val_rmse_target: 0.6342 val_rmse_stderror: 1.157\n","Still best_val_rmse: 0.5914 (from epoch 0)\n","\n","64 steps took 80.7 seconds\n","Epoch: 1 batch_num: 68\n","train_rmse_target: 0.5705 train_rmse_stderror: 0.04205 train_kl_div: 0.7096\n","val_rmse_target: 0.5565 val_rmse_stderror: 1.177\n","New best_val_rmse: 0.5565\n","\n","64 steps took 80.7 seconds\n","Epoch: 1 batch_num: 132\n","train_rmse_target: 0.4735 train_rmse_stderror: 0.02973 train_kl_div: 0.4732\n","val_rmse_target: 0.6115 val_rmse_stderror: 1.162\n","Still best_val_rmse: 0.5565 (from epoch 1)\n","\n","64 steps took 80.9 seconds\n","Epoch: 2 batch_num: 8\n","train_rmse_target: 0.3542 train_rmse_stderror: 0.03701 train_kl_div: 0.2573\n","val_rmse_target: 0.5263 val_rmse_stderror: 1.166\n","New best_val_rmse: 0.5263\n","\n","64 steps took 80.7 seconds\n","Epoch: 2 batch_num: 72\n","train_rmse_target: 0.4375 train_rmse_stderror: 0.02792 train_kl_div: 0.3425\n","val_rmse_target: 0.5467 val_rmse_stderror: 1.153\n","Still best_val_rmse: 0.5263 (from epoch 2)\n","\n","64 steps took 80.7 seconds\n","Epoch: 2 batch_num: 136\n","train_rmse_target: 0.227 train_rmse_stderror: 0.02548 train_kl_div: 0.1172\n","val_rmse_target: 0.5274 val_rmse_stderror: 1.163\n","Still best_val_rmse: 0.5263 (from epoch 2)\n","\n","64 steps took 80.9 seconds\n","Epoch: 3 batch_num: 12\n","train_rmse_target: 0.222 train_rmse_stderror: 0.01832 train_kl_div: 0.1084\n","val_rmse_target: 0.5273 val_rmse_stderror: 1.161\n","Still best_val_rmse: 0.5263 (from epoch 2)\n","\n","64 steps took 80.7 seconds\n","Epoch: 3 batch_num: 76\n","train_rmse_target: 0.2323 train_rmse_stderror: 0.01899 train_kl_div: 0.105\n","val_rmse_target: 0.5164 val_rmse_stderror: 1.165\n","New best_val_rmse: 0.5164\n","\n","64 steps took 80.8 seconds\n","Epoch: 3 batch_num: 140\n","train_rmse_target: 0.1359 train_rmse_stderror: 0.02877 train_kl_div: 0.04404\n","val_rmse_target: 0.5153 val_rmse_stderror: 1.156\n","New best_val_rmse: 0.5153\n","\n","64 steps took 81.0 seconds\n","Epoch: 4 batch_num: 16\n","train_rmse_target: 0.1975 train_rmse_stderror: 0.02442 train_kl_div: 0.07651\n","val_rmse_target: 0.5225 val_rmse_stderror: 1.163\n","Still best_val_rmse: 0.5153 (from epoch 3)\n","\n","64 steps took 80.7 seconds\n","Epoch: 4 batch_num: 80\n","train_rmse_target: 0.2297 train_rmse_stderror: 0.02725 train_kl_div: 0.09431\n","val_rmse_target: 0.5149 val_rmse_stderror: 1.158\n","New best_val_rmse: 0.5149\n","\n","64 steps took 80.7 seconds\n","Epoch: 4 batch_num: 144\n","train_rmse_target: 0.1337 train_rmse_stderror: 0.03053 train_kl_div: 0.04243\n","val_rmse_target: 0.5166 val_rmse_stderror: 1.161\n","Still best_val_rmse: 0.5149 (from epoch 4)\n","\n","Performance estimates:\n","[0.4933007558258711, 0.48256763162233135, 0.48952966116944263, 0.514924976009845]\n","Mean: 0.4950807561568725\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 5/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 81.7 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.536 train_rmse_stderror: 0.09121 train_kl_div: 0.6513\n","val_rmse_target: 0.6559 val_rmse_stderror: 1.769\n","New best_val_rmse: 0.6559\n","\n","64 steps took 80.7 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.4073 train_rmse_stderror: 0.03846 train_kl_div: 0.3506\n","val_rmse_target: 0.5565 val_rmse_stderror: 1.787\n","New best_val_rmse: 0.5565\n","\n","64 steps took 80.9 seconds\n","Epoch: 1 batch_num: 4\n","train_rmse_target: 0.662 train_rmse_stderror: 0.04112 train_kl_div: 0.793\n","val_rmse_target: 0.5425 val_rmse_stderror: 1.769\n","New best_val_rmse: 0.5425\n","\n","64 steps took 80.7 seconds\n","Epoch: 1 batch_num: 68\n","train_rmse_target: 0.3718 train_rmse_stderror: 0.04517 train_kl_div: 0.2317\n","val_rmse_target: 0.503 val_rmse_stderror: 1.78\n","New best_val_rmse: 0.503\n","\n","64 steps took 80.7 seconds\n","Epoch: 1 batch_num: 132\n","train_rmse_target: 0.2831 train_rmse_stderror: 0.03958 train_kl_div: 0.1747\n","val_rmse_target: 0.5097 val_rmse_stderror: 1.77\n","Still best_val_rmse: 0.503 (from epoch 1)\n","\n","64 steps took 80.9 seconds\n","Epoch: 2 batch_num: 8\n","train_rmse_target: 0.327 train_rmse_stderror: 0.02609 train_kl_div: 0.2113\n","val_rmse_target: 0.5017 val_rmse_stderror: 1.774\n","New best_val_rmse: 0.5017\n","\n","64 steps took 80.7 seconds\n","Epoch: 2 batch_num: 72\n","train_rmse_target: 0.1896 train_rmse_stderror: 0.02912 train_kl_div: 0.08609\n","val_rmse_target: 0.493 val_rmse_stderror: 1.776\n","New best_val_rmse: 0.493\n","\n","32 steps took 40.3 seconds\n","Epoch: 2 batch_num: 104\n","train_rmse_target: 0.292 train_rmse_stderror: 0.04058 train_kl_div: 0.1739\n","val_rmse_target: 0.4949 val_rmse_stderror: 1.77\n","Still best_val_rmse: 0.493 (from epoch 2)\n","\n","32 steps took 40.3 seconds\n","Epoch: 2 batch_num: 136\n","train_rmse_target: 0.2176 train_rmse_stderror: 0.02534 train_kl_div: 0.1023\n","val_rmse_target: 0.5094 val_rmse_stderror: 1.775\n","Still best_val_rmse: 0.493 (from epoch 2)\n","\n","64 steps took 80.9 seconds\n","Epoch: 3 batch_num: 12\n","train_rmse_target: 0.1441 train_rmse_stderror: 0.0167 train_kl_div: 0.04568\n","val_rmse_target: 0.5056 val_rmse_stderror: 1.773\n","Still best_val_rmse: 0.493 (from epoch 2)\n","\n","64 steps took 80.7 seconds\n","Epoch: 3 batch_num: 76\n","train_rmse_target: 0.1819 train_rmse_stderror: 0.02641 train_kl_div: 0.06691\n","val_rmse_target: 0.4978 val_rmse_stderror: 1.774\n","Still best_val_rmse: 0.493 (from epoch 2)\n","\n","32 steps took 40.4 seconds\n","Epoch: 3 batch_num: 108\n","train_rmse_target: 0.1377 train_rmse_stderror: 0.01824 train_kl_div: 0.04517\n","val_rmse_target: 0.4953 val_rmse_stderror: 1.777\n","Still best_val_rmse: 0.493 (from epoch 2)\n","\n","32 steps took 40.3 seconds\n","Epoch: 3 batch_num: 140\n","train_rmse_target: 0.2324 train_rmse_stderror: 0.03238 train_kl_div: 0.1027\n","val_rmse_target: 0.5029 val_rmse_stderror: 1.768\n","Still best_val_rmse: 0.493 (from epoch 2)\n","\n","64 steps took 80.9 seconds\n","Epoch: 4 batch_num: 16\n","train_rmse_target: 0.1449 train_rmse_stderror: 0.03792 train_kl_div: 0.03671\n","val_rmse_target: 0.4985 val_rmse_stderror: 1.766\n","Still best_val_rmse: 0.493 (from epoch 2)\n","\n","32 steps took 40.3 seconds\n","Epoch: 4 batch_num: 48\n","train_rmse_target: 0.1275 train_rmse_stderror: 0.01675 train_kl_div: 0.03446\n","val_rmse_target: 0.497 val_rmse_stderror: 1.77\n","Still best_val_rmse: 0.493 (from epoch 2)\n","\n","32 steps took 40.3 seconds\n","Epoch: 4 batch_num: 80\n","train_rmse_target: 0.1382 train_rmse_stderror: 0.02365 train_kl_div: 0.04293\n","val_rmse_target: 0.4982 val_rmse_stderror: 1.772\n","Still best_val_rmse: 0.493 (from epoch 2)\n","\n","32 steps took 40.4 seconds\n","Epoch: 4 batch_num: 112\n","train_rmse_target: 0.112 train_rmse_stderror: 0.02523 train_kl_div: 0.02986\n","val_rmse_target: 0.4975 val_rmse_stderror: 1.773\n","Still best_val_rmse: 0.493 (from epoch 2)\n","\n","32 steps took 40.3 seconds\n","Epoch: 4 batch_num: 144\n","train_rmse_target: 0.1372 train_rmse_stderror: 0.02591 train_kl_div: 0.04525\n","val_rmse_target: 0.4985 val_rmse_stderror: 1.772\n","Still best_val_rmse: 0.493 (from epoch 2)\n","\n","32 steps took 40.3 seconds\n","Epoch: 4 batch_num: 176\n","train_rmse_target: 0.09233 train_rmse_stderror: 0.02456 train_kl_div: 0.02057\n","val_rmse_target: 0.498 val_rmse_stderror: 1.772\n","Still best_val_rmse: 0.493 (from epoch 2)\n","\n","Performance estimates:\n","[0.4933007558258711, 0.48256763162233135, 0.48952966116944263, 0.514924976009845, 0.4930456814505802]\n","Mean: 0.4946737412156141\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HgUJCFeLhLaP","executionInfo":{"status":"ok","timestamp":1626414647341,"user_tz":-540,"elapsed":24,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"efec5317-fda7-42b9-d296-5c19d5ada3c6"},"source":["import tracemalloc\n","\n","tracemalloc.start()\n","\n","# ... run your application ...\n","\n","snapshot = tracemalloc.take_snapshot()\n","top_stats = snapshot.statistics('lineno')\n","\n","print(\"[ Top 10 ]\")\n","for stat in top_stats[:10]:\n","    print(stat)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["[ Top 10 ]\n","/usr/lib/python3.7/codeop.py:141: size=189 B, count=2, average=94 B\n","/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2820: size=112 B, count=3, average=37 B\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"m4v-cGx-Mv7S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626414647342,"user_tz":-540,"elapsed":17,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"720d3c6d-62f7-4f6c-c6bb-d8b9b17662c1"},"source":["print(list_val_rmse)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["[0.4933007558258711, 0.48256763162233135, 0.48952966116944263, 0.514924976009845, 0.4930456814505802]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"q2CdCMuIKDMP","executionInfo":{"status":"ok","timestamp":1626414647342,"user_tz":-540,"elapsed":12,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#rep = MemReporter(model)\n","#rep.report()"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"eLl1yDOOKIe7","executionInfo":{"status":"ok","timestamp":1626414647342,"user_tz":-540,"elapsed":12,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#rep = MemReporter(model.roberta)\n","#rep.report()"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"7qkqnknA_m9D","executionInfo":{"status":"ok","timestamp":1626414647343,"user_tz":-540,"elapsed":12,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#gpuinfo()"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"PwrqSMdYA6Pu","executionInfo":{"status":"ok","timestamp":1626414647343,"user_tz":-540,"elapsed":12,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#del model\n","#del optimizer \n","#del train_loader\n","#del val_loader\n","#del scheduler \n","#del list_val_rmse\n","#del train_indices\n","#del val_indices\n","#del tokenizer\n","#torch.cuda.empty_cache()\n","#gpuinfo()"],"execution_count":30,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wXcHyUSJXecL"},"source":["# Inference"]},{"cell_type":"code","metadata":{"id":"YIV6UllSIGoa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626414760263,"user_tz":-540,"elapsed":112931,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"410d899d-184a-457d-cc2d-17c0b525f32c"},"source":["%cd\n","!mkdir .kaggle\n","!mkdir /content/model\n","!cp /content/drive/MyDrive/Colab_Files/kaggle-api/kaggle.json .kaggle/\n","\n","!cp -r /content/model_1.pth /content/model/model_1.pth\n","!cp -r /content/model_2.pth /content/model/model_2.pth\n","!cp -r /content/model_3.pth /content/model/model_3.pth\n","!cp -r /content/model_4.pth /content/model/model_4.pth\n","!cp -r /content/model_5.pth /content/model/model_5.pth"],"execution_count":31,"outputs":[{"output_type":"stream","text":["/root\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"14ddOZH4IMam","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626415202851,"user_tz":-540,"elapsed":442603,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"caa6c495-c62a-44ee-9334-ce68d35809cf"},"source":["\n","\n","def dataset_upload():\n","    import json\n","    from kaggle.api.kaggle_api_extended import KaggleApi\n","\n","    id = f'{USERID}/{EX_NO}'\n","\n","    dataset_metadata = {}\n","    dataset_metadata['id'] = id\n","    dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n","    dataset_metadata['title'] = f'{EX_NO}'\n","\n","    with open(UPLOAD_DIR / 'dataset-metadata.json', 'w') as f:\n","        json.dump(dataset_metadata, f, indent=4)\n","\n","    api = KaggleApi()\n","    api.authenticate()\n","\n","    # データセットがない場合\n","    if f'{USERID}/{EX_NO}' not in [str(d) for d in api.dataset_list(user=USERID, search=f'\"{EX_NO}\"')]:\n","        api.dataset_create_new(folder=UPLOAD_DIR,\n","                               convert_to_csv=False,\n","                               dir_mode='skip')\n","    # データセットがある場合\n","    else:\n","        api.dataset_create_version(folder=UPLOAD_DIR,\n","                                   version_notes='update',\n","                                   convert_to_csv=False,\n","                                   delete_old_versions=True,\n","                                   dir_mode='skip')\n","dataset_upload()\n","\n"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Starting upload for file model_3.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.32G/1.32G [01:42<00:00, 13.9MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_3.pth (1GB)\n","Starting upload for file model_1.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.32G/1.32G [01:25<00:00, 16.7MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_1.pth (1GB)\n","Starting upload for file model_5.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.32G/1.32G [01:18<00:00, 18.1MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_5.pth (1GB)\n","Starting upload for file model_2.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.32G/1.32G [01:22<00:00, 17.2MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_2.pth (1GB)\n","Starting upload for file model_4.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.32G/1.32G [01:29<00:00, 15.9MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_4.pth (1GB)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"huJwVMSAPuDO","executionInfo":{"status":"ok","timestamp":1626415202856,"user_tz":-540,"elapsed":27,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"0zzuBPobmLFu","executionInfo":{"status":"ok","timestamp":1626415202856,"user_tz":-540,"elapsed":24,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wpc8ro9hmNci","executionInfo":{"status":"ok","timestamp":1626415202857,"user_tz":-540,"elapsed":24,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"ceDI72NumT5-","executionInfo":{"status":"ok","timestamp":1626415202858,"user_tz":-540,"elapsed":24,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":32,"outputs":[]}]}