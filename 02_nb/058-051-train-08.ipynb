{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"058-051-train-08.ipynb","provenance":[{"file_id":"17BUK8yRF7SDX0khlOXoHcFRTEFffkvRb","timestamp":1627488927996},{"file_id":"1wNpTEKAuuKP7ivTcm1f9j0sdmYU1RyzA","timestamp":1627306793279},{"file_id":"1uE__yBR1oxeYaUIrUTMEOffmeyuJBRAU","timestamp":1627305921964},{"file_id":"1PbEPh6kL5p5cdH5HC8iHoMVCIzA0MqvB","timestamp":1627284576770},{"file_id":"1TlxQ4e-ZX1Zy51dKLuhNdrBWg1qhojqP","timestamp":1627273765934},{"file_id":"17a4F4aC9L0QBqU8BRTrdqPn0WwJ0b08b","timestamp":1626746992716},{"file_id":"1G_W9irFTrEmDeHR0S6_u0bjpk8nxipXW","timestamp":1626689695352},{"file_id":"1bhhkorT--y8XXaVLM8hibVgC-tLqZ16P","timestamp":1626358153868},{"file_id":"1WtT2hX6O9Qbt_hb9sF50nM2QmDXFi-XA","timestamp":1626338366006},{"file_id":"1k_p5wftcUeo711Xho1-T5an2Xkneau-J","timestamp":1626323813472},{"file_id":"1Vz2GB2BNTWuefEFkCSh3TBPEIel7KG1t","timestamp":1626317426487},{"file_id":"1djoMWojeaIPopG5tS1jNMohn8ineblRh","timestamp":1626306831897},{"file_id":"1-6tlDO8158Pi6TpptIF884oFaEiT4Uxb","timestamp":1626276420047},{"file_id":"1js8eA3mDNS8mwSpCiHuzPeARFlUPAVrg","timestamp":1626272452526},{"file_id":"1yhcPgulwJtjJKUK9IuRKmNMhJ-4YXGol","timestamp":1626267205517},{"file_id":"1mnnSv0Pofn1QxArywV81VYqnZPB8uUWN","timestamp":1626180468522},{"file_id":"1RRdjt_UAeHmr5QQBAMyC82Fq1s31OWdK","timestamp":1625833136005},{"file_id":"1JPgg44HFemzwk8VSCXih3PejL0idy-C4","timestamp":1625825483466},{"file_id":"1Ye6wqVX71xAAAhmjXkw9IpRvTqeUyJDA","timestamp":1625812137500}],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ucCbvGD1XvG7","executionInfo":{"status":"ok","timestamp":1627805572708,"user_tz":-540,"elapsed":529,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"a90b838c-a025-4697-b9cb-5a7d206ac445"},"source":["import sys\n","if 'google.colab' in sys.modules:  # colab特有の処理_2回目以降\n","  # Google Driveのマウント\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","\n","  # ライブラリのパス指定\n","  sys.path.append('/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules')\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FACwJ6icpxrR","executionInfo":{"status":"ok","timestamp":1627805577770,"user_tz":-540,"elapsed":4632,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# データセットをDriveから取得\n","!mkdir -p 'input'\n","!mkdir -p 'clrp-pre-trained'\n","\n","!cp -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/00_input/commonlitreadabilityprize/' '/content/input'\n","!cp -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/97_pre_trained/clrp_pretrained_manish_epoch5/pre-trained-roberta/clrp_roberta_large/' '/content/clrp-pre-trained'"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"RV9-VwbpZLZ9","executionInfo":{"status":"ok","timestamp":1627805577772,"user_tz":-540,"elapsed":30,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["from pathlib import Path\n","\n","# input\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    DATA_DIR = Path('../input/commonlitreadabilityprize/')\n","\n","elif 'google.colab' in sys.modules: # Colab環境\n","    DATA_DIR = Path('/content/input/commonlitreadabilityprize')\n","\n","else:\n","    DATA_DIR = Path('../00_input/commonlitreadabilityprize/')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"x5difyXe00UV","executionInfo":{"status":"ok","timestamp":1627805577773,"user_tz":-540,"elapsed":13,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["from pathlib import Path\n","\n","# tokenizer\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    TOKENIZER_DIR = '../input/roberta-transformers-pytorch/roberta-large'\n","elif 'google.colab' in sys.modules: # Colab環境\n","    TOKENIZER_DIR = '/content/clrp-pre-trained/clrp_roberta_large' # 仮で、毎回DLする想定のモデル名を指定。あとで変更予定。\n","else:\n","    TOKENIZER_DIR = 'roberta-large'"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"tKjsUxnOeDYl","executionInfo":{"status":"ok","timestamp":1627805577774,"user_tz":-540,"elapsed":13,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["from pathlib import Path\n","\n","# pre-trained model\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    PRE_TRAINED_MODEL_DIR = '../input/roberta-transformers-pytorch/roberta-large'\n","elif 'google.colab' in sys.modules: # Colab環境\n","    PRE_TRAINED_MODEL_DIR = '/content/clrp-pre-trained/clrp_roberta_large' # 仮で、毎回DLする想定のモデル名を指定。あとで変更予定。\n","else:\n","    PRE_TRAINED_MODEL_DIR = 'roberta-large'"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZLaT2V0ReoAZ","executionInfo":{"status":"ok","timestamp":1627814014043,"user_tz":-540,"elapsed":312,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["UPLOAD_DIR = Path('/content/model')\n","EX_NO = '058-051-train-08'  # 実験番号などを入れる、folderのpathにする\n","USERID = 'calpis10000'"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"id":"hOGjAb4pAJ0F","executionInfo":{"status":"ok","timestamp":1627805577775,"user_tz":-540,"elapsed":14,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["import subprocess\n","import shlex\n","\n","def gpuinfo():\n","    \"\"\"\n","    Returns size of total GPU RAM and used GPU RAM.\n","\n","    Parameters\n","    ----------\n","    None\n","\n","    Returns\n","    -------\n","    info : dict\n","        Total GPU RAM in integer for key 'total_MiB'.\n","        Used GPU RAM in integer for key 'used_MiB'.\n","    \"\"\"\n","\n","    command = 'nvidia-smi -q -d MEMORY | sed -n \"/FB Memory Usage/,/Free/p\" | sed -e \"1d\" -e \"4d\" -e \"s/ MiB//g\" | cut -d \":\" -f 2 | cut -c2-'\n","    commands = [shlex.split(part) for part in command.split(' | ')]\n","    for i, cmd in enumerate(commands):\n","        if i==0:\n","            res = subprocess.Popen(cmd, stdout=subprocess.PIPE)\n","        else:\n","            res = subprocess.Popen(cmd, stdin=res.stdout, stdout=subprocess.PIPE)\n","    total, used = map(int, res.communicate()[0].decode('utf-8').strip().split('\\n'))\n","    info = {'total_MiB':total, 'used_MiB':used}\n","    return info\n"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g3-6m5MKXecB"},"source":["# Overview\n","This nb is based on copy from https://www.kaggle.com/andretugan/lightweight-roberta-solution-in-pytorch .\n","\n","Acknowledgments(from base nb): \n","some ideas were taken from kernels by [Torch](https://www.kaggle.com/rhtsingh) and [Maunish](https://www.kaggle.com/maunish)."]},{"cell_type":"code","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-04T06:26:32.834365Z","iopub.execute_input":"2021-07-04T06:26:32.834903Z","iopub.status.idle":"2021-07-04T06:26:40.143740Z","shell.execute_reply.started":"2021-07-04T06:26:32.834785Z","shell.execute_reply":"2021-07-04T06:26:40.142864Z"},"trusted":true,"id":"HRsRZ06WXecD","executionInfo":{"status":"ok","timestamp":1627805581945,"user_tz":-540,"elapsed":4183,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["import os\n","import math\n","import random\n","import time\n","\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","\n","from transformers import AdamW # optimizer\n","from transformers import AutoTokenizer\n","from transformers import AutoModel\n","from transformers import AutoConfig\n","from transformers import get_cosine_schedule_with_warmup # scheduler\n","from pytorch_memlab import profile\n","import pytorch_memlab\n","from pytorch_memlab import MemReporter\n","\n","from sklearn.model_selection import KFold, StratifiedKFold\n","\n","import gc\n","gc.enable()"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.145217Z","iopub.execute_input":"2021-07-04T06:26:40.145539Z","iopub.status.idle":"2021-07-04T06:26:40.201326Z","shell.execute_reply.started":"2021-07-04T06:26:40.145504Z","shell.execute_reply":"2021-07-04T06:26:40.200136Z"},"trusted":true,"id":"omBfwshTXecE","executionInfo":{"status":"ok","timestamp":1627805581946,"user_tz":-540,"elapsed":15,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["NUM_FOLDS = 5 # K Fold\n","NUM_EPOCHS = 5 # Epochs\n","BATCH_SIZE = 12 # Batch Size\n","MAX_LEN = 248 # ベクトル長\n","EVAL_SCHEDULE = [(0.55, 64), (-1., 32)] # schedulerの何らかの設定？\n","ROBERTA_PATH = PRE_TRAINED_MODEL_DIR # roberta pre-trainedモデル(モデルとして指定)\n","TOKENIZER_PATH = TOKENIZER_DIR # roberta pre-trainedモデル(Tokenizerとして指定)\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\" # cudaがなければcpuを使えばいいじゃない"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.203398Z","iopub.execute_input":"2021-07-04T06:26:40.204055Z","iopub.status.idle":"2021-07-04T06:26:40.211572Z","shell.execute_reply.started":"2021-07-04T06:26:40.204015Z","shell.execute_reply":"2021-07-04T06:26:40.210762Z"},"trusted":true,"id":"4qcuXqwtXecF","executionInfo":{"status":"ok","timestamp":1627805581946,"user_tz":-540,"elapsed":14,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["def set_random_seed(random_seed):\n","    random.seed(random_seed)\n","    np.random.seed(random_seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(random_seed)\n","\n","    torch.manual_seed(random_seed)\n","    torch.cuda.manual_seed(random_seed)\n","    torch.cuda.manual_seed_all(random_seed)\n","\n","    torch.backends.cudnn.deterministic = True# cudnnによる最適化で結果が変わらないためのおまじない "],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.214188Z","iopub.execute_input":"2021-07-04T06:26:40.214809Z","iopub.status.idle":"2021-07-04T06:26:40.309744Z","shell.execute_reply.started":"2021-07-04T06:26:40.214769Z","shell.execute_reply":"2021-07-04T06:26:40.308926Z"},"trusted":true,"id":"70PyLsJTXecF","executionInfo":{"status":"ok","timestamp":1627805581947,"user_tz":-540,"elapsed":14,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# read train_df(kfold)\n","train_kf_df = pd.read_csv(DATA_DIR/\"train_kfold.csv\")"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.311021Z","iopub.execute_input":"2021-07-04T06:26:40.311347Z","iopub.status.idle":"2021-07-04T06:26:40.624393Z","shell.execute_reply.started":"2021-07-04T06:26:40.311314Z","shell.execute_reply":"2021-07-04T06:26:40.623347Z"},"trusted":true,"id":"xf0662k4XecF","executionInfo":{"status":"ok","timestamp":1627805581948,"user_tz":-540,"elapsed":15,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# tokenizerを指定\n","tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N6aaghNkXecG"},"source":["# Dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UU5uZKIcDjkV","executionInfo":{"status":"ok","timestamp":1627805582507,"user_tz":-540,"elapsed":574,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"89b034e6-3e33-48be-9f68-c1873f8cff86"},"source":["# 前処理用\n","import string\n","import re\n","# ローカルの場合、stopwordsをダウンロード\n","import nltk\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    pass\n","else:\n","    import nltk\n","    nltk.download('stopwords')\n","    nltk.download('averaged_perceptron_tagger')\n","    os.listdir(os.path.expanduser('~/nltk_data/corpora/stopwords/'))\n","\n","# テキスト前処理\n","# https://www.kaggle.com/alaasedeeq/commonlit-readability-eda\n","\n","#filtering the unwanted symbols, spaces, ....etc\n","to_replace_by_space = re.compile('[/(){}\\[\\]|@,;]')\n","punctuation = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n","bad_symbols = re.compile('[^0-9a-z #+_]')\n","stopwords = set(nltk.corpus.stopwords.words('english'))\n","\n","def text_prepare(text):\n","    '''\n","    text: a string\n","    returna modified version of the string\n","    '''\n","    text = text.lower() # lowercase text\n","    text = re.sub(punctuation, '',text)\n","    text = re.sub(to_replace_by_space, \" \", text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n","    text = re.sub(bad_symbols, \"\", text)         # delete symbols which are in BAD_SYMBOLS_RE from text\n","    text = \" \".join([word for word in text.split(\" \") if word not in stopwords]) # delete stopwords from text\n","    text = re.sub(' +', ' ', text)\n","    return text\n","\n","def text_normalization(s:pd.Series):\n","    x = s.apply(text_prepare)\n","    return x\n","\n","# Counterオブジェクトを取得\n","def get_counter(text:str):\n","    text_list = [wrd for wrd in text.split(\" \") if wrd not in ('', '\\n')]\n","    counter = collections.Counter(text_list)\n","    return counter\n"],"execution_count":13,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ze-E2aCfgsfj","executionInfo":{"status":"ok","timestamp":1627805582508,"user_tz":-540,"elapsed":23,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# ベースとなる継承元のクラス\n","class BaseBlock(object):\n","    def fit(self, input_df, y=None):\n","        return self.transform(input_df)\n","    def transform(self, input_df):\n","        raise NotImplementedError()\n","\n","import collections\n","\n","class TextDescriptionBlock(BaseBlock):\n","    \"\"\"テキストに関する統計量を返す block\"\"\"\n","    def __init__(self, column: str):\n","        \"\"\"\n","        args:\n","            column: str\n","                変換対象のカラム名\n","        \"\"\"\n","        self.column = column\n","        self.param_prefix = f'col={column}'\n","\n","    # 前処理\n","    def preprocess(self, input_df):\n","        x = text_normalization(input_df[self.column])\n","        return x\n","        \n","    def fit(self, input_df, y=None):\n","        return self.transform(input_df)\n","\n","    def transform(self, input_df):\n","        # 前処理\n","        self.text = self.preprocess(input_df)\n","        self.counters = self.text.map(get_counter)\n","\n","        # 変換処理\n","        _length = input_df[self.column].fillna('').map(lambda x: len(x) if x!='' else np.nan)\n","        _wrd_cnt = self.counters.map(lambda x: sum(x.values()))\n","        _wrd_nuniq = self.counters.map(lambda x: len(x))\n","        _wrd_mean = self.counters.map(lambda x: np.mean(list(x.values())))\n","        _wrd_max = self.counters.map(lambda x: np.max(list(x.values())))\n","        \n","        word_length = self.counters.map(lambda x: np.array([len(i) for i in x.keys()]))\n","        word_length_desc = word_length.map(lambda x: pd.Series(x.ravel()).describe())\n","        _word_length_desc_df = pd.DataFrame(word_length_desc.tolist()).iloc[:,1:]\n","        _word_length_desc_df = _word_length_desc_df.add_prefix('word_length_')\n","        \n","        out_df = pd.concat([_length, _wrd_cnt, _wrd_nuniq, _wrd_mean, _wrd_max], axis=1)\n","        out_df = out_df.reset_index().drop('index', axis='columns')\n","        out_df.columns = ['text_length', 'word_count', 'word_nunique', 'word_appearance_mean', 'word_appearance_max']\n","        out_df = pd.concat([out_df, _word_length_desc_df], axis=1).fillna(-1)\n","        return out_df.add_suffix(f'_{self.column}')"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"kyxEmzmUmK3m","executionInfo":{"status":"ok","timestamp":1627805582508,"user_tz":-540,"elapsed":22,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["desc_block = TextDescriptionBlock('excerpt')\n","desc_feats = desc_block.fit(train_kf_df.head(10))"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":379},"id":"CpqqxGGfqBho","executionInfo":{"status":"ok","timestamp":1627805582509,"user_tz":-540,"elapsed":23,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"d6883d0f-4b36-4947-a8a0-a1666bd1a78a"},"source":["desc_feats.head(30)"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_length_excerpt</th>\n","      <th>word_count_excerpt</th>\n","      <th>word_nunique_excerpt</th>\n","      <th>word_appearance_mean_excerpt</th>\n","      <th>word_appearance_max_excerpt</th>\n","      <th>word_length_mean_excerpt</th>\n","      <th>word_length_std_excerpt</th>\n","      <th>word_length_min_excerpt</th>\n","      <th>word_length_25%_excerpt</th>\n","      <th>word_length_50%_excerpt</th>\n","      <th>word_length_75%_excerpt</th>\n","      <th>word_length_max_excerpt</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1123</td>\n","      <td>104</td>\n","      <td>82</td>\n","      <td>1.268293</td>\n","      <td>4</td>\n","      <td>6.024390</td>\n","      <td>2.154385</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>6.0</td>\n","      <td>7.00</td>\n","      <td>12.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>868</td>\n","      <td>87</td>\n","      <td>76</td>\n","      <td>1.144737</td>\n","      <td>4</td>\n","      <td>5.907895</td>\n","      <td>2.406534</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>5.0</td>\n","      <td>7.00</td>\n","      <td>17.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>987</td>\n","      <td>83</td>\n","      <td>70</td>\n","      <td>1.185714</td>\n","      <td>3</td>\n","      <td>6.871429</td>\n","      <td>2.547641</td>\n","      <td>3.0</td>\n","      <td>5.0</td>\n","      <td>7.0</td>\n","      <td>8.75</td>\n","      <td>13.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>962</td>\n","      <td>82</td>\n","      <td>71</td>\n","      <td>1.154930</td>\n","      <td>4</td>\n","      <td>6.507042</td>\n","      <td>2.401626</td>\n","      <td>3.0</td>\n","      <td>5.0</td>\n","      <td>6.0</td>\n","      <td>8.00</td>\n","      <td>15.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>904</td>\n","      <td>87</td>\n","      <td>71</td>\n","      <td>1.225352</td>\n","      <td>6</td>\n","      <td>5.563380</td>\n","      <td>1.826256</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>5.0</td>\n","      <td>7.00</td>\n","      <td>11.0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>907</td>\n","      <td>87</td>\n","      <td>55</td>\n","      <td>1.581818</td>\n","      <td>8</td>\n","      <td>5.072727</td>\n","      <td>1.708958</td>\n","      <td>2.0</td>\n","      <td>4.0</td>\n","      <td>5.0</td>\n","      <td>6.00</td>\n","      <td>9.0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>734</td>\n","      <td>75</td>\n","      <td>63</td>\n","      <td>1.190476</td>\n","      <td>3</td>\n","      <td>5.301587</td>\n","      <td>1.783752</td>\n","      <td>2.0</td>\n","      <td>4.0</td>\n","      <td>5.0</td>\n","      <td>6.00</td>\n","      <td>11.0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>992</td>\n","      <td>83</td>\n","      <td>70</td>\n","      <td>1.185714</td>\n","      <td>3</td>\n","      <td>6.042857</td>\n","      <td>2.209569</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>6.0</td>\n","      <td>7.00</td>\n","      <td>13.0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>1046</td>\n","      <td>87</td>\n","      <td>80</td>\n","      <td>1.087500</td>\n","      <td>3</td>\n","      <td>6.612500</td>\n","      <td>2.399862</td>\n","      <td>3.0</td>\n","      <td>5.0</td>\n","      <td>6.0</td>\n","      <td>8.00</td>\n","      <td>14.0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>1033</td>\n","      <td>93</td>\n","      <td>84</td>\n","      <td>1.107143</td>\n","      <td>4</td>\n","      <td>5.928571</td>\n","      <td>2.166479</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>6.0</td>\n","      <td>7.00</td>\n","      <td>12.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   text_length_excerpt  ...  word_length_max_excerpt\n","0                 1123  ...                     12.0\n","1                  868  ...                     17.0\n","2                  987  ...                     13.0\n","3                  962  ...                     15.0\n","4                  904  ...                     11.0\n","5                  907  ...                      9.0\n","6                  734  ...                     11.0\n","7                  992  ...                     13.0\n","8                 1046  ...                     14.0\n","9                 1033  ...                     12.0\n","\n","[10 rows x 12 columns]"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3BtmbpIqm57Q","executionInfo":{"status":"ok","timestamp":1627805582512,"user_tz":-540,"elapsed":24,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"49bcf834-ccc1-4406-bda3-f58cf6dc8b1c"},"source":["desc_feats.values[1:10]"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 868.        ,   87.        ,   76.        ,    1.14473684,\n","           4.        ,    5.90789474,    2.4065335 ,    3.        ,\n","           4.        ,    5.        ,    7.        ,   17.        ],\n","       [ 987.        ,   83.        ,   70.        ,    1.18571429,\n","           3.        ,    6.87142857,    2.5476413 ,    3.        ,\n","           5.        ,    7.        ,    8.75      ,   13.        ],\n","       [ 962.        ,   82.        ,   71.        ,    1.15492958,\n","           4.        ,    6.50704225,    2.40162587,    3.        ,\n","           5.        ,    6.        ,    8.        ,   15.        ],\n","       [ 904.        ,   87.        ,   71.        ,    1.22535211,\n","           6.        ,    5.56338028,    1.82625608,    3.        ,\n","           4.        ,    5.        ,    7.        ,   11.        ],\n","       [ 907.        ,   87.        ,   55.        ,    1.58181818,\n","           8.        ,    5.07272727,    1.70895837,    2.        ,\n","           4.        ,    5.        ,    6.        ,    9.        ],\n","       [ 734.        ,   75.        ,   63.        ,    1.19047619,\n","           3.        ,    5.3015873 ,    1.78375212,    2.        ,\n","           4.        ,    5.        ,    6.        ,   11.        ],\n","       [ 992.        ,   83.        ,   70.        ,    1.18571429,\n","           3.        ,    6.04285714,    2.20956888,    3.        ,\n","           4.        ,    6.        ,    7.        ,   13.        ],\n","       [1046.        ,   87.        ,   80.        ,    1.0875    ,\n","           3.        ,    6.6125    ,    2.39986155,    3.        ,\n","           5.        ,    6.        ,    8.        ,   14.        ],\n","       [1033.        ,   93.        ,   84.        ,    1.10714286,\n","           4.        ,    5.92857143,    2.1664791 ,    3.        ,\n","           4.        ,    6.        ,    7.        ,   12.        ]])"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nDXvT9BbmWGa","executionInfo":{"status":"ok","timestamp":1627805582513,"user_tz":-540,"elapsed":19,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"53178d39-0177-4472-a3ed-9cf6230b158d"},"source":["desc_feats.isnull().sum()"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["text_length_excerpt             0\n","word_count_excerpt              0\n","word_nunique_excerpt            0\n","word_appearance_mean_excerpt    0\n","word_appearance_max_excerpt     0\n","word_length_mean_excerpt        0\n","word_length_std_excerpt         0\n","word_length_min_excerpt         0\n","word_length_25%_excerpt         0\n","word_length_50%_excerpt         0\n","word_length_75%_excerpt         0\n","word_length_max_excerpt         0\n","dtype: int64"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"iAse0IDWDjho","executionInfo":{"status":"ok","timestamp":1627805582513,"user_tz":-540,"elapsed":14,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# Dataset用のClass。\n","class LitDataset(Dataset):\n","    def __init__(self, df, inference_only=False):\n","        super().__init__()\n","\n","        self.df = df        \n","        self.inference_only = inference_only # Testデータ用フラグ\n","        self.text = df.excerpt.tolist() # 分析対象カラムをlistにする。(分かち書きではなく、Seriesをlistへ変換するような処理)\n","        #self.text = [text.replace(\"\\n\", \" \") for text in self.text] # 単語単位で分かち書きする場合\n","        #self.text_len = text_normalization(df.excerpt).map(lambda x: [0 if i >= len(x.split(' ')) else len(x.split(' ')[i]) for i in range(132)])\n","        desc_block = TextDescriptionBlock('excerpt')\n","        self.text_desc = desc_block.fit(self.df)\n","\n","        if not self.inference_only:\n","            self.target = torch.tensor(df.target.values, dtype=torch.float32) # trainのみ、targetをtensorに変換\n","            self.standard_error = torch.tensor(df.standard_error.values, dtype=torch.float32) \n","\n","        self.encoded = tokenizer.batch_encode_plus( # textをtokenize\n","            self.text,\n","            padding = 'max_length',            \n","            max_length = MAX_LEN,\n","            truncation = True, # 最大長を超える文字は切り捨て\n","            return_attention_mask=True\n","        )        \n"," \n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    \n","    def __getitem__(self, index): # 変換結果を返す\n","        input_ids = torch.tensor(self.encoded['input_ids'][index])\n","        attention_mask = torch.tensor(self.encoded['attention_mask'][index])\n","        #input_len = torch.tensor(self.text_len.iloc[index], dtype=torch.float32)\n","        input_desc = torch.tensor(self.text_desc.values[index], dtype=torch.float32)\n","\n","        if self.inference_only:\n","            return (input_ids, attention_mask, input_desc)            \n","        else:\n","            target = self.target[index]\n","            standard_error = self.standard_error[index]\n","            return (input_ids, attention_mask, input_desc, target, standard_error)"],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KKtdy32wXecG"},"source":["# Model\n","The model is inspired by the one from [Maunish](https://www.kaggle.com/maunish/clrp-roberta-svm)."]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.649629Z","iopub.execute_input":"2021-07-04T06:26:40.650066Z","iopub.status.idle":"2021-07-04T06:26:40.666374Z","shell.execute_reply.started":"2021-07-04T06:26:40.650002Z","shell.execute_reply":"2021-07-04T06:26:40.665211Z"},"trusted":true,"id":"BpkxjXEUXecH","executionInfo":{"status":"ok","timestamp":1627805582514,"user_tz":-540,"elapsed":15,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["class LitModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        config = AutoConfig.from_pretrained(ROBERTA_PATH) # pretrainedからconfigを読み込み\n","        config.update({\"output_hidden_states\":True, # config更新: embedding層を抽出\n","                       \"hidden_dropout_prob\": 0.0, # config更新: dropoutしない\n","                       \"layer_norm_eps\": 1e-7}) # config更新: layer normalizationのepsilon                      \n","        \n","        self.roberta = AutoModel.from_pretrained(ROBERTA_PATH, config=config)\n","            \n","        self.attention = nn.Sequential(# attentionレイヤー            \n","            nn.Linear(config.hidden_size, 512),      \n","            nn.Tanh(),                       \n","            nn.Linear(512, 1),\n","            nn.Softmax(dim=1)\n","        )\n","\n","        self.numeric_feats = nn.Sequential(\n","            nn.Linear(12, 12),\n","            nn.BatchNorm1d(12),\n","            nn.ReLU(),\n","            nn.Dropout(0.2)\n","        )\n","\n","        self.regressor = nn.Sequential( # target、stderror                  \n","            nn.Linear(config.hidden_size + 12, 2)                        \n","        )\n","\n","        #self.bin_class = nn.Sequential( # target_sign\n","        #    nn.Linear(config.hidden_size + 64, 1),\n","        #    nn.Dropout(p=0.2),\n","        #    nn.Sigmoid()                       \n","        #)\n","\n","\n","    def forward(self, input_ids, attention_mask, input_desc):\n","        roberta_output = self.roberta(input_ids=input_ids, # robertaに入力データを流し、出力としてrobertaモデル(layerの複合体)を得る\n","                                      attention_mask=attention_mask)     \n","        # attention_pooling\n","        last_hidden_state = roberta_output.hidden_states[-1] # robertaモデルの最後のlayerを得る\n","        weights = self.attention(last_hidden_state) # robertaの最後のlayerをattentionへ入力し、出力として重みを得る                \n","        context_vector = torch.sum(weights * last_hidden_state, dim=1) # 重み×最後の層を足し合わせて文書ベクトルとする。\n","        # word_length_conv1d\n","        #input_chnl = input_len.unsqueeze(1)\n","        #conv1_layers = self.conv1_layers(input_chnl)\n","        #conv1_layers_v = conv1_layers.view(conv1_layers.size(0),-1)\n","\n","        # numeric_feats\n","        numeric_feats = self.numeric_feats(input_desc)\n","\n","        # https://www.kaggle.com/rhtsingh/utilizing-transformer-representations-efficiently\n","        # last_hidden_state = roberta_output[0]\n","        # input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        # sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        # sum_mask = input_mask_expanded.sum(1)\n","        # sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        # mean_embeddings = sum_embeddings / sum_mask\n","        cat_layers = torch.cat([context_vector, numeric_feats], dim=1)\n","        return self.regressor(cat_layers)\n","        \n","        # Now we reduce the context vector to the prediction score.\n","        #return self.regressor(mean_embeddings) # 文書ベクトルを線形層に入力し、targetを出力する"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.672515Z","iopub.execute_input":"2021-07-04T06:26:40.672944Z","iopub.status.idle":"2021-07-04T06:26:40.684593Z","shell.execute_reply.started":"2021-07-04T06:26:40.672908Z","shell.execute_reply":"2021-07-04T06:26:40.683569Z"},"trusted":true,"id":"bB4jvQTxXecH","executionInfo":{"status":"ok","timestamp":1627805582514,"user_tz":-540,"elapsed":14,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["def eval_mse(model, data_loader):\n","    \"\"\"Evaluates the mean squared error of the |model| on |data_loader|\"\"\"\n","    model.eval() # evalモードを選択。Batch Normとかdropoutをしなくなる           \n","    mse_mean_sum = 0\n","    mse_std_sum = 0\n","\n","    with torch.no_grad(): # 勾配の計算をしない(予測のみ行う)\n","        for batch_num, (input_ids, attention_mask, input_feats, target, standard_error) in enumerate(data_loader): # data_loaderからinput, attentin_mask, targetをbatchごとに取り出す\n","            input_ids = input_ids.to(DEVICE)   \n","            attention_mask = attention_mask.to(DEVICE)  \n","            input_feats = input_feats.to(DEVICE) \n","            target = target.to(DEVICE)\n","            standard_error = standard_error.to(DEVICE)\n","            \n","            output = model(input_ids, attention_mask, input_feats) # 取得した値をモデルへ入力し、出力として予測値を得る。\n","\n","            mse_mean_sum += nn.MSELoss(reduction=\"sum\")(output[:,0].flatten(), target).item() # 誤差の合計を得る(Batchごとに計算した誤差を足し上げる)\n","            mse_std_sum += nn.MSELoss(reduction=\"sum\")(output[:,1].flatten(), standard_error).item() # 誤差の合計を得る(Batchごとに計算した誤差を足し上げる)\n","\n","\n","    del input_ids\n","    del attention_mask\n","\n","    mse_mean_result = mse_mean_sum / len(data_loader.dataset)\n","    mse_std_result = mse_std_sum / len(data_loader.dataset)\n","\n","    return mse_mean_result, mse_std_result"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.690155Z","iopub.execute_input":"2021-07-04T06:26:40.692530Z","iopub.status.idle":"2021-07-04T06:26:40.703425Z","shell.execute_reply.started":"2021-07-04T06:26:40.692488Z","shell.execute_reply":"2021-07-04T06:26:40.702366Z"},"trusted":true,"id":"47bDno_LXecI","executionInfo":{"status":"ok","timestamp":1627805582515,"user_tz":-540,"elapsed":15,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 推論結果を返す\n","def predict(model, data_loader):\n","    \"\"\"Returns an np.array with predictions of the |model| on |data_loader|\"\"\"\n","    model.eval() # evalモード(dropout, batch_normしない)\n","\n","    result = np.zeros(len(data_loader.dataset)) # 結果をdataset長のzero配列として用意\n","    index = 0\n","    \n","    with torch.no_grad(): # 勾配の計算をしないblock(inputすると、現状の重みによる推論結果を返す)\n","        for batch_num, (input_ids, attention_mask, input_feats) in enumerate(data_loader): # data_loaderからbatchごとにinputを得る\n","            input_ids = input_ids.to(DEVICE)\n","            attention_mask = attention_mask.to(DEVICE)\n","            input_feats = input_feats.to(DEVICE)\n","                        \n","            output = model(input_ids, attention_mask, input_feats) # modelにinputを入力し、予測結果を得る。\n","            output_target = output[:,0]\n","\n","            result[index : index + output_target.shape[0]] = output_target.flatten().to(\"cpu\") # result[index ~ predの長さ]へ、予測結果を格納\n","            index += output_target.shape[0] # indexを更新\n","\n","    return result # 全batchで推論が終わったら、結果を返す"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.708605Z","iopub.execute_input":"2021-07-04T06:26:40.709024Z","iopub.status.idle":"2021-07-04T06:26:40.730675Z","shell.execute_reply.started":"2021-07-04T06:26:40.708983Z","shell.execute_reply":"2021-07-04T06:26:40.729705Z"},"trusted":true,"id":"oInneuAmXecI","executionInfo":{"status":"ok","timestamp":1627805583101,"user_tz":-540,"elapsed":600,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 学習\n","def train(model, # モデル\n","          model_path, # モデルのアウトプット先\n","          train_loader, # train-setのdata_loader\n","          val_loader, # valid-setのdata_loader\n","          optimizer, # optimizer\n","          scheduler=None, # scheduler, デフォルトはNone\n","          num_epochs=NUM_EPOCHS # epoch数、notebook冒頭で指定した値\n","         ):    \n","    \n","    best_val_rmse = None\n","    best_val_sign_bce = None\n","    best_epoch = 0\n","    step = 0\n","    last_eval_step = 0\n","    eval_period = EVAL_SCHEDULE[0][1] # eval期間(って何？) 冒頭で決めたEVAL_SCHEDULEの最初のtupleの[1]を取得\n","\n","    start = time.time() # 時間計測用\n","\n","    for epoch in range(num_epochs): # 指定したEpoch数だけ繰り返し\n","        val_rmse = None         \n","\n","        for batch_num, (input_ids, attention_mask, input_feats, target, standard_error) in enumerate(train_loader): # train_loaderからinput, targetを取得\n","            input_ids = input_ids.to(DEVICE) # inputをDEVICEへ突っ込む\n","            attention_mask = attention_mask.to(DEVICE)   \n","            input_feats = input_feats.to(DEVICE)\n","            target = target.to(DEVICE)\n","            standard_error = standard_error.to(DEVICE)\n","\n","            optimizer.zero_grad() # 勾配を初期化            \n","            model.train() # 学習モード開始\n","\n","            # https://www.kaggle.com/c/commonlitreadabilityprize/discussion/239421\n","            output = model(input_ids, attention_mask, input_feats) # input,attention_maskを入力し、予測結果を得る\n","            p = torch.distributions.Normal(output[:,0], torch.sqrt(output[:,1]**2))\n","            q = torch.distributions.Normal(target, standard_error)\n","            kl_vector = torch.distributions.kl_divergence(p, q)\n","\n","            loss = kl_vector.mean()\n","\n","            loss.backward() \n","            optimizer.step() # 重みを更新する\n","\n","            if scheduler:\n","                scheduler.step() # schedulerが与えられた場合は、schedulerの学習率更新\n","            \n","            if step >= last_eval_step + eval_period: # batchを回すごとにstepを増やしていって、「前回evalしたstep + eval_period(16)」を超えたら実行。\n","                print(gpuinfo())\n","                # Evaluate the model on val_loader.\n","                elapsed_seconds = time.time() - start # 経過時間\n","                num_steps = step - last_eval_step # 経過ステップ数\n","                print(f\"\\n{num_steps} steps took {elapsed_seconds:0.3} seconds\")\n","                last_eval_step = step # 前回stepの更新\n","                \n","                # valid-setによるrmse計算\n","                train_kldiv = loss\n","                \n","                val_mse_mean, val_mse_std = eval_mse(model, val_loader)\n","                val_rmse_mean = math.sqrt(val_mse_mean)                            \n","                val_rmse_std = math.sqrt(val_mse_std)                            \n","\n","                print(f\"Epoch: {epoch} batch_num: {batch_num}\")\n","                print(f\"train_kldiv: {train_kldiv:0.4}\"\n","                      )\n","                print(f\"val_rmse_mean: {val_rmse_mean:0.4}\",\n","                      f\"val_rmse_std: {val_rmse_std:0.4}\"\n","                      )\n","\n","                for rmse, period in EVAL_SCHEDULE: # eval_periodをvalid-rmseで切り替える処理\n","                    if val_rmse_mean >= rmse: # valid rmseをEVAL_SCHEDULEと比較し、0項 > valid rmseとなるまで回す : EVAL_SCHEDULE = [(0.50, 16), (0.49, 8), (0.48, 4), (0.47, 2), (-1., 1)]\n","                        eval_period = period # eval_periodを更新\n","                        break                               \n","\n","                if not best_val_rmse or val_rmse_mean < best_val_rmse: # 初回(best_val_rmse==None), またはbest_val_rmseを更新したらモデルを保存する\n","                    best_val_rmse = val_rmse_mean\n","                    best_epoch = epoch\n","                    torch.save(model.state_dict(), model_path) # 最高の自分を保存\n","                    print(f\"New best_val_rmse: {best_val_rmse:0.4}\")\n","                else:       \n","                    print(f\"Still best_val_rmse: {best_val_rmse:0.4}\", # 更新されない場合は、元のスコアを表示\n","                          f\"(from epoch {best_epoch})\")      \n","\n","                start = time.time()\n","            \n","            # batchごとにメモリ解放\n","            del input_ids\n","            del attention_mask\n","            torch.cuda.empty_cache()                                            \n","            step += 1\n","    \n","    return best_val_rmse"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.735798Z","iopub.execute_input":"2021-07-04T06:26:40.738398Z","iopub.status.idle":"2021-07-04T06:26:40.750876Z","shell.execute_reply.started":"2021-07-04T06:26:40.738356Z","shell.execute_reply":"2021-07-04T06:26:40.749635Z"},"trusted":true,"id":"rMY0fjXwXecJ","executionInfo":{"status":"ok","timestamp":1627805583102,"user_tz":-540,"elapsed":7,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# optimizerの作成\n","def create_optimizer(model):\n","    parameters = []\n","\n","    named_parameters = list(model.named_parameters()) # モデルパラメータの取得\n","    roberta_parameters = list(model.roberta.named_parameters())[:-2] # パラメータをroberta用、attention用、regressor用に格納。(直接引っ張ってくる形式に変更)\n","\n","    attention_parameters = list(model.attention.named_parameters())\n","    attention_group = [{'params': params, 'lr': 2e-5} for (name, params) in attention_parameters] # attention用パラメータをリストとして取得\n","    parameters += attention_group\n","\n","    regressor_parameters = list(model.regressor.named_parameters())\n","    regressor_group = [{'params': params, 'lr': 2e-5} for (name, params) in regressor_parameters] # reg用パラメータをリストとして取得\n","    parameters += regressor_group\n","\n","    numeric_feats_parameters = list(model.numeric_feats.named_parameters())\n","    numeric_feats_group = [{'params': params, 'lr': 2e-5} for (name, params) in numeric_feats_parameters] # reg用パラメータをリストとして取得\n","    parameters += numeric_feats_group\n","\n","    for layer_num, (name, params) in enumerate(roberta_parameters): # レイヤーごとにname, paramsを取得していろんな処理\n","        weight_decay = 0.0 if \"bias\" in name else 0.01\n","\n","        lr = 8e-6\n","\n","        if layer_num >= 69:        \n","            lr = 2e-5\n","\n","        if layer_num >= 133:\n","            lr = 4e-5\n","\n","        parameters.append({\"params\": params,\n","                           \"weight_decay\": weight_decay,\n","                           \"lr\": lr})\n","\n","    return AdamW(parameters) # 最終的に、AdamWにパラメータを入力する。\n"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"4PLKHwvKtNBn","executionInfo":{"status":"ok","timestamp":1627805583103,"user_tz":-540,"elapsed":7,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["def train_and_save_model(train_indices, val_indices, model_path):\n","    train_dataset = LitDataset(train_kf_df.loc[train_indices]) # train, validのDataset\n","    val_dataset = LitDataset(train_kf_df.loc[val_indices])\n","        \n","    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n","                              drop_last=True, shuffle=True, num_workers=2) # train, validのDataLoader\n","    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n","                            drop_last=False, shuffle=False, num_workers=2)    \n","\n","    model = LitModel().to(DEVICE) # modelをDEVICEへぶち込む\n","    optimizer = create_optimizer(model) # optimizerをモデルから作成\n","    scheduler = get_cosine_schedule_with_warmup( # schedulerを作成\n","        optimizer,\n","        num_training_steps=NUM_EPOCHS * len(train_loader),\n","        num_warmup_steps=50)    \n","    rmse = train(model, model_path, train_loader, val_loader, optimizer, scheduler=scheduler)\n","\n","    del train_dataset\n","    del val_dataset\n","    del train_loader\n","    del val_loader\n","    del model\n","    del optimizer\n","    del scheduler\n","    gc.collect() \n","    torch.cuda.empty_cache()\n","    return rmse"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.755813Z","iopub.execute_input":"2021-07-04T06:26:40.758373Z","iopub.status.idle":"2021-07-04T06:27:12.493221Z","shell.execute_reply.started":"2021-07-04T06:26:40.758265Z","shell.execute_reply":"2021-07-04T06:27:12.490139Z"},"trusted":true,"id":"k2LGJD3XXecK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627813899416,"user_tz":-540,"elapsed":8316319,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"5d47a4db-7e0a-4521-ea5c-2c2a4badd178"},"source":["# 実行処理。 KFold & 学習\n","SEED = 1000\n","list_val_rmse = []\n","\n","for fold in sorted(train_kf_df['kfold'].unique()):\n","    print(f\"\\nFold {fold + 1}/{NUM_FOLDS}\")\n","    print(gpuinfo())\n","    model_path = f\"model_{fold + 1}.pth\" # model_fold数_.pth\n","    set_random_seed(SEED + fold) # SEEDはfold別に変わるようにする\n","\n","    train_indices = (train_kf_df['kfold'] != fold)\n","    val_indices = (train_kf_df['kfold'] == fold)\n","    list_val_rmse.append(train_and_save_model(train_indices, val_indices, model_path))\n","    print(\"\\nPerformance estimates:\")\n","    print(list_val_rmse)\n","    print(\"Mean:\", np.array(list_val_rmse).mean())\n","    print(gpuinfo())"],"execution_count":26,"outputs":[{"output_type":"stream","text":["\n","Fold 1/5\n","{'total_MiB': 16280, 'used_MiB': 2}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","64 steps took 82.9 seconds\n","Epoch: 0 batch_num: 64\n","train_kldiv: 0.3856\n","val_rmse_mean: 0.6357 val_rmse_std: 0.9843\n","New best_val_rmse: 0.6357\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","64 steps took 82.0 seconds\n","Epoch: 0 batch_num: 128\n","train_kldiv: 0.1546\n","val_rmse_mean: 0.5712 val_rmse_std: 1.016\n","New best_val_rmse: 0.5712\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","64 steps took 82.2 seconds\n","Epoch: 1 batch_num: 4\n","train_kldiv: 0.6451\n","val_rmse_mean: 0.5777 val_rmse_std: 0.9943\n","Still best_val_rmse: 0.5712 (from epoch 0)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","64 steps took 82.0 seconds\n","Epoch: 1 batch_num: 68\n","train_kldiv: 0.1712\n","val_rmse_mean: 0.5456 val_rmse_std: 0.9614\n","New best_val_rmse: 0.5456\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.3 seconds\n","Epoch: 1 batch_num: 100\n","train_kldiv: 0.2379\n","val_rmse_mean: 0.5085 val_rmse_std: 1.01\n","New best_val_rmse: 0.5085\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.3 seconds\n","Epoch: 1 batch_num: 132\n","train_kldiv: 0.6476\n","val_rmse_mean: 0.5406 val_rmse_std: 1.004\n","Still best_val_rmse: 0.5085 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.3 seconds\n","Epoch: 1 batch_num: 164\n","train_kldiv: 0.4408\n","val_rmse_mean: 0.5495 val_rmse_std: 0.989\n","Still best_val_rmse: 0.5085 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.5 seconds\n","Epoch: 2 batch_num: 8\n","train_kldiv: 0.2951\n","val_rmse_mean: 0.5235 val_rmse_std: 0.9593\n","Still best_val_rmse: 0.5085 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.3 seconds\n","Epoch: 2 batch_num: 40\n","train_kldiv: 0.09801\n","val_rmse_mean: 0.5003 val_rmse_std: 0.9834\n","New best_val_rmse: 0.5003\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.3 seconds\n","Epoch: 2 batch_num: 72\n","train_kldiv: 0.09521\n","val_rmse_mean: 0.5284 val_rmse_std: 1.006\n","Still best_val_rmse: 0.5003 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.3 seconds\n","Epoch: 2 batch_num: 104\n","train_kldiv: 0.2556\n","val_rmse_mean: 0.5015 val_rmse_std: 0.9685\n","Still best_val_rmse: 0.5003 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.3 seconds\n","Epoch: 2 batch_num: 136\n","train_kldiv: 0.1833\n","val_rmse_mean: 0.5252 val_rmse_std: 1.02\n","Still best_val_rmse: 0.5003 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.4 seconds\n","Epoch: 2 batch_num: 168\n","train_kldiv: 0.1108\n","val_rmse_mean: 0.5017 val_rmse_std: 0.9946\n","Still best_val_rmse: 0.5003 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.5 seconds\n","Epoch: 3 batch_num: 12\n","train_kldiv: 0.04745\n","val_rmse_mean: 0.4944 val_rmse_std: 0.9891\n","New best_val_rmse: 0.4944\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.3 seconds\n","Epoch: 3 batch_num: 44\n","train_kldiv: 0.09949\n","val_rmse_mean: 0.4983 val_rmse_std: 0.9743\n","Still best_val_rmse: 0.4944 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.3 seconds\n","Epoch: 3 batch_num: 76\n","train_kldiv: 0.062\n","val_rmse_mean: 0.5112 val_rmse_std: 0.9837\n","Still best_val_rmse: 0.4944 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.3 seconds\n","Epoch: 3 batch_num: 108\n","train_kldiv: 0.06865\n","val_rmse_mean: 0.5001 val_rmse_std: 0.973\n","Still best_val_rmse: 0.4944 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.3 seconds\n","Epoch: 3 batch_num: 140\n","train_kldiv: 0.07467\n","val_rmse_mean: 0.4933 val_rmse_std: 0.9888\n","New best_val_rmse: 0.4933\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.3 seconds\n","Epoch: 3 batch_num: 172\n","train_kldiv: 0.03821\n","val_rmse_mean: 0.4943 val_rmse_std: 0.9779\n","Still best_val_rmse: 0.4933 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.6 seconds\n","Epoch: 4 batch_num: 16\n","train_kldiv: 0.041\n","val_rmse_mean: 0.4946 val_rmse_std: 0.9729\n","Still best_val_rmse: 0.4933 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.4 seconds\n","Epoch: 4 batch_num: 48\n","train_kldiv: 0.03506\n","val_rmse_mean: 0.4922 val_rmse_std: 0.9887\n","New best_val_rmse: 0.4922\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.4 seconds\n","Epoch: 4 batch_num: 80\n","train_kldiv: 0.06183\n","val_rmse_mean: 0.4924 val_rmse_std: 0.9723\n","Still best_val_rmse: 0.4922 (from epoch 4)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.3 seconds\n","Epoch: 4 batch_num: 112\n","train_kldiv: 0.01803\n","val_rmse_mean: 0.4933 val_rmse_std: 0.9791\n","Still best_val_rmse: 0.4922 (from epoch 4)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.4 seconds\n","Epoch: 4 batch_num: 144\n","train_kldiv: 0.02766\n","val_rmse_mean: 0.4934 val_rmse_std: 0.9775\n","Still best_val_rmse: 0.4922 (from epoch 4)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.3 seconds\n","Epoch: 4 batch_num: 176\n","train_kldiv: 0.05654\n","val_rmse_mean: 0.4936 val_rmse_std: 0.9812\n","Still best_val_rmse: 0.4922 (from epoch 4)\n","\n","Performance estimates:\n","[0.49222245576405277]\n","Mean: 0.49222245576405277\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 2/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","64 steps took 83.2 seconds\n","Epoch: 0 batch_num: 64\n","train_kldiv: 0.8067\n","val_rmse_mean: 0.5994 val_rmse_std: 0.05465\n","New best_val_rmse: 0.5994\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","64 steps took 82.2 seconds\n","Epoch: 0 batch_num: 128\n","train_kldiv: 0.5915\n","val_rmse_mean: 0.5194 val_rmse_std: 0.03916\n","New best_val_rmse: 0.5194\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.3 seconds\n","Epoch: 0 batch_num: 160\n","train_kldiv: 0.7344\n","val_rmse_mean: 0.5729 val_rmse_std: 0.03954\n","Still best_val_rmse: 0.5194 (from epoch 0)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","64 steps took 82.4 seconds\n","Epoch: 1 batch_num: 36\n","train_kldiv: 0.07553\n","val_rmse_mean: 0.5273 val_rmse_std: 0.03786\n","Still best_val_rmse: 0.5194 (from epoch 0)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.3 seconds\n","Epoch: 1 batch_num: 68\n","train_kldiv: 0.3651\n","val_rmse_mean: 0.4926 val_rmse_std: 0.04146\n","New best_val_rmse: 0.4926\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.4 seconds\n","Epoch: 1 batch_num: 100\n","train_kldiv: 0.09374\n","val_rmse_mean: 0.4771 val_rmse_std: 0.03671\n","New best_val_rmse: 0.4771\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.3 seconds\n","Epoch: 1 batch_num: 132\n","train_kldiv: 0.1285\n","val_rmse_mean: 0.4933 val_rmse_std: 0.04458\n","Still best_val_rmse: 0.4771 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.2 seconds\n","Epoch: 1 batch_num: 164\n","train_kldiv: 0.3253\n","val_rmse_mean: 0.4785 val_rmse_std: 0.04074\n","Still best_val_rmse: 0.4771 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.4 seconds\n","Epoch: 2 batch_num: 8\n","train_kldiv: 0.1171\n","val_rmse_mean: 0.5173 val_rmse_std: 0.037\n","Still best_val_rmse: 0.4771 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.3 seconds\n","Epoch: 2 batch_num: 40\n","train_kldiv: 0.06167\n","val_rmse_mean: 0.4864 val_rmse_std: 0.03586\n","Still best_val_rmse: 0.4771 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.3 seconds\n","Epoch: 2 batch_num: 72\n","train_kldiv: 0.09131\n","val_rmse_mean: 0.471 val_rmse_std: 0.03927\n","New best_val_rmse: 0.471\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.3 seconds\n","Epoch: 2 batch_num: 104\n","train_kldiv: 0.1062\n","val_rmse_mean: 0.4781 val_rmse_std: 0.0351\n","Still best_val_rmse: 0.471 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.2 seconds\n","Epoch: 2 batch_num: 136\n","train_kldiv: 0.1214\n","val_rmse_mean: 0.5068 val_rmse_std: 0.03763\n","Still best_val_rmse: 0.471 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.2 seconds\n","Epoch: 2 batch_num: 168\n","train_kldiv: 0.06042\n","val_rmse_mean: 0.4671 val_rmse_std: 0.03617\n","New best_val_rmse: 0.4671\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.5 seconds\n","Epoch: 3 batch_num: 12\n","train_kldiv: 0.11\n","val_rmse_mean: 0.468 val_rmse_std: 0.03586\n","Still best_val_rmse: 0.4671 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.2 seconds\n","Epoch: 3 batch_num: 44\n","train_kldiv: 0.03031\n","val_rmse_mean: 0.4628 val_rmse_std: 0.03532\n","New best_val_rmse: 0.4628\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.3 seconds\n","Epoch: 3 batch_num: 76\n","train_kldiv: 0.03861\n","val_rmse_mean: 0.4698 val_rmse_std: 0.03467\n","Still best_val_rmse: 0.4628 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.2 seconds\n","Epoch: 3 batch_num: 108\n","train_kldiv: 0.04657\n","val_rmse_mean: 0.4603 val_rmse_std: 0.03432\n","New best_val_rmse: 0.4603\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.3 seconds\n","Epoch: 3 batch_num: 140\n","train_kldiv: 0.03408\n","val_rmse_mean: 0.4646 val_rmse_std: 0.03429\n","Still best_val_rmse: 0.4603 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.3 seconds\n","Epoch: 3 batch_num: 172\n","train_kldiv: 0.01452\n","val_rmse_mean: 0.4644 val_rmse_std: 0.03445\n","Still best_val_rmse: 0.4603 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.4 seconds\n","Epoch: 4 batch_num: 16\n","train_kldiv: 0.01552\n","val_rmse_mean: 0.4635 val_rmse_std: 0.0348\n","Still best_val_rmse: 0.4603 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.3 seconds\n","Epoch: 4 batch_num: 48\n","train_kldiv: 0.02959\n","val_rmse_mean: 0.461 val_rmse_std: 0.03528\n","Still best_val_rmse: 0.4603 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.2 seconds\n","Epoch: 4 batch_num: 80\n","train_kldiv: 0.01474\n","val_rmse_mean: 0.4634 val_rmse_std: 0.03433\n","Still best_val_rmse: 0.4603 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.3 seconds\n","Epoch: 4 batch_num: 112\n","train_kldiv: 0.01805\n","val_rmse_mean: 0.4621 val_rmse_std: 0.03446\n","Still best_val_rmse: 0.4603 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.2 seconds\n","Epoch: 4 batch_num: 144\n","train_kldiv: 0.02535\n","val_rmse_mean: 0.4623 val_rmse_std: 0.03437\n","Still best_val_rmse: 0.4603 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.3 seconds\n","Epoch: 4 batch_num: 176\n","train_kldiv: 0.01719\n","val_rmse_mean: 0.4622 val_rmse_std: 0.03435\n","Still best_val_rmse: 0.4603 (from epoch 3)\n","\n","Performance estimates:\n","[0.49222245576405277, 0.4603411269615789]\n","Mean: 0.47628179136281584\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 3/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","64 steps took 83.2 seconds\n","Epoch: 0 batch_num: 64\n","train_kldiv: 0.6979\n","val_rmse_mean: 0.6 val_rmse_std: 0.06103\n","New best_val_rmse: 0.6\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","64 steps took 82.2 seconds\n","Epoch: 0 batch_num: 128\n","train_kldiv: 0.4156\n","val_rmse_mean: 0.596 val_rmse_std: 0.04486\n","New best_val_rmse: 0.596\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","64 steps took 82.5 seconds\n","Epoch: 1 batch_num: 4\n","train_kldiv: 0.4541\n","val_rmse_mean: 0.5427 val_rmse_std: 0.04138\n","New best_val_rmse: 0.5427\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.5 seconds\n","Epoch: 1 batch_num: 36\n","train_kldiv: 0.6101\n","val_rmse_mean: 0.5448 val_rmse_std: 0.0393\n","Still best_val_rmse: 0.5427 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.4 seconds\n","Epoch: 1 batch_num: 68\n","train_kldiv: 0.48\n","val_rmse_mean: 0.5105 val_rmse_std: 0.04024\n","New best_val_rmse: 0.5105\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.5 seconds\n","Epoch: 1 batch_num: 100\n","train_kldiv: 0.1291\n","val_rmse_mean: 0.5039 val_rmse_std: 0.04277\n","New best_val_rmse: 0.5039\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.5 seconds\n","Epoch: 1 batch_num: 132\n","train_kldiv: 0.4401\n","val_rmse_mean: 0.5006 val_rmse_std: 0.03924\n","New best_val_rmse: 0.5006\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.5 seconds\n","Epoch: 1 batch_num: 164\n","train_kldiv: 0.4787\n","val_rmse_mean: 0.5125 val_rmse_std: 0.04299\n","Still best_val_rmse: 0.5006 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.7 seconds\n","Epoch: 2 batch_num: 8\n","train_kldiv: 0.1521\n","val_rmse_mean: 0.4907 val_rmse_std: 0.04084\n","New best_val_rmse: 0.4907\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.5 seconds\n","Epoch: 2 batch_num: 40\n","train_kldiv: 0.1083\n","val_rmse_mean: 0.484 val_rmse_std: 0.03987\n","New best_val_rmse: 0.484\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.4 seconds\n","Epoch: 2 batch_num: 72\n","train_kldiv: 0.05728\n","val_rmse_mean: 0.489 val_rmse_std: 0.04084\n","Still best_val_rmse: 0.484 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.4 seconds\n","Epoch: 2 batch_num: 104\n","train_kldiv: 0.2576\n","val_rmse_mean: 0.4838 val_rmse_std: 0.03956\n","New best_val_rmse: 0.4838\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.4 seconds\n","Epoch: 2 batch_num: 136\n","train_kldiv: 0.06748\n","val_rmse_mean: 0.494 val_rmse_std: 0.03894\n","Still best_val_rmse: 0.4838 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.4 seconds\n","Epoch: 2 batch_num: 168\n","train_kldiv: 0.2212\n","val_rmse_mean: 0.5093 val_rmse_std: 0.04408\n","Still best_val_rmse: 0.4838 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.6 seconds\n","Epoch: 3 batch_num: 12\n","train_kldiv: 0.03868\n","val_rmse_mean: 0.478 val_rmse_std: 0.04633\n","New best_val_rmse: 0.478\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.4 seconds\n","Epoch: 3 batch_num: 44\n","train_kldiv: 0.04625\n","val_rmse_mean: 0.4858 val_rmse_std: 0.04395\n","Still best_val_rmse: 0.478 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.4 seconds\n","Epoch: 3 batch_num: 76\n","train_kldiv: 0.05345\n","val_rmse_mean: 0.4858 val_rmse_std: 0.0407\n","Still best_val_rmse: 0.478 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.4 seconds\n","Epoch: 3 batch_num: 108\n","train_kldiv: 0.07578\n","val_rmse_mean: 0.4827 val_rmse_std: 0.03882\n","Still best_val_rmse: 0.478 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.3 seconds\n","Epoch: 3 batch_num: 140\n","train_kldiv: 0.05917\n","val_rmse_mean: 0.4822 val_rmse_std: 0.03812\n","Still best_val_rmse: 0.478 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.3 seconds\n","Epoch: 3 batch_num: 172\n","train_kldiv: 0.04085\n","val_rmse_mean: 0.4811 val_rmse_std: 0.03881\n","Still best_val_rmse: 0.478 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.6 seconds\n","Epoch: 4 batch_num: 16\n","train_kldiv: 0.03574\n","val_rmse_mean: 0.4792 val_rmse_std: 0.03814\n","Still best_val_rmse: 0.478 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.3 seconds\n","Epoch: 4 batch_num: 48\n","train_kldiv: 0.01224\n","val_rmse_mean: 0.4772 val_rmse_std: 0.03851\n","New best_val_rmse: 0.4772\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.4 seconds\n","Epoch: 4 batch_num: 80\n","train_kldiv: 0.02647\n","val_rmse_mean: 0.4781 val_rmse_std: 0.03791\n","Still best_val_rmse: 0.4772 (from epoch 4)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.3 seconds\n","Epoch: 4 batch_num: 112\n","train_kldiv: 0.03165\n","val_rmse_mean: 0.4802 val_rmse_std: 0.03867\n","Still best_val_rmse: 0.4772 (from epoch 4)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.3 seconds\n","Epoch: 4 batch_num: 144\n","train_kldiv: 0.01532\n","val_rmse_mean: 0.4804 val_rmse_std: 0.03843\n","Still best_val_rmse: 0.4772 (from epoch 4)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.3 seconds\n","Epoch: 4 batch_num: 176\n","train_kldiv: 0.01666\n","val_rmse_mean: 0.4799 val_rmse_std: 0.03829\n","Still best_val_rmse: 0.4772 (from epoch 4)\n","\n","Performance estimates:\n","[0.49222245576405277, 0.4603411269615789, 0.47719261912022]\n","Mean: 0.47658540061528387\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 4/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","64 steps took 83.4 seconds\n","Epoch: 0 batch_num: 64\n","train_kldiv: 0.9179\n","val_rmse_mean: 0.7407 val_rmse_std: 0.9931\n","New best_val_rmse: 0.7407\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","64 steps took 82.3 seconds\n","Epoch: 0 batch_num: 128\n","train_kldiv: 0.4925\n","val_rmse_mean: 0.609 val_rmse_std: 0.9816\n","New best_val_rmse: 0.609\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","64 steps took 82.6 seconds\n","Epoch: 1 batch_num: 4\n","train_kldiv: 0.3618\n","val_rmse_mean: 0.6682 val_rmse_std: 0.9831\n","Still best_val_rmse: 0.609 (from epoch 0)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","64 steps took 82.3 seconds\n","Epoch: 1 batch_num: 68\n","train_kldiv: 0.2277\n","val_rmse_mean: 0.5403 val_rmse_std: 0.9804\n","New best_val_rmse: 0.5403\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.5 seconds\n","Epoch: 1 batch_num: 100\n","train_kldiv: 0.2599\n","val_rmse_mean: 0.5158 val_rmse_std: 0.9616\n","New best_val_rmse: 0.5158\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.5 seconds\n","Epoch: 1 batch_num: 132\n","train_kldiv: 0.3638\n","val_rmse_mean: 0.5476 val_rmse_std: 0.975\n","Still best_val_rmse: 0.5158 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.5 seconds\n","Epoch: 1 batch_num: 164\n","train_kldiv: 0.317\n","val_rmse_mean: 0.4918 val_rmse_std: 0.99\n","New best_val_rmse: 0.4918\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.8 seconds\n","Epoch: 2 batch_num: 8\n","train_kldiv: 0.1536\n","val_rmse_mean: 0.5047 val_rmse_std: 0.9737\n","Still best_val_rmse: 0.4918 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.5 seconds\n","Epoch: 2 batch_num: 40\n","train_kldiv: 0.1243\n","val_rmse_mean: 0.4712 val_rmse_std: 0.9921\n","New best_val_rmse: 0.4712\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.5 seconds\n","Epoch: 2 batch_num: 72\n","train_kldiv: 0.08207\n","val_rmse_mean: 0.4745 val_rmse_std: 0.9803\n","Still best_val_rmse: 0.4712 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.4 seconds\n","Epoch: 2 batch_num: 104\n","train_kldiv: 0.146\n","val_rmse_mean: 0.4693 val_rmse_std: 0.9992\n","New best_val_rmse: 0.4693\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.4 seconds\n","Epoch: 2 batch_num: 136\n","train_kldiv: 0.1111\n","val_rmse_mean: 0.492 val_rmse_std: 0.9884\n","Still best_val_rmse: 0.4693 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.4 seconds\n","Epoch: 2 batch_num: 168\n","train_kldiv: 0.1423\n","val_rmse_mean: 0.4789 val_rmse_std: 0.9853\n","Still best_val_rmse: 0.4693 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.6 seconds\n","Epoch: 3 batch_num: 12\n","train_kldiv: 0.0797\n","val_rmse_mean: 0.4722 val_rmse_std: 0.9749\n","Still best_val_rmse: 0.4693 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.4 seconds\n","Epoch: 3 batch_num: 44\n","train_kldiv: 0.04027\n","val_rmse_mean: 0.4709 val_rmse_std: 0.9831\n","Still best_val_rmse: 0.4693 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.4 seconds\n","Epoch: 3 batch_num: 76\n","train_kldiv: 0.03364\n","val_rmse_mean: 0.4744 val_rmse_std: 0.9812\n","Still best_val_rmse: 0.4693 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.4 seconds\n","Epoch: 3 batch_num: 108\n","train_kldiv: 0.02969\n","val_rmse_mean: 0.4701 val_rmse_std: 0.9861\n","Still best_val_rmse: 0.4693 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.4 seconds\n","Epoch: 3 batch_num: 140\n","train_kldiv: 0.04933\n","val_rmse_mean: 0.4776 val_rmse_std: 0.9836\n","Still best_val_rmse: 0.4693 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.4 seconds\n","Epoch: 3 batch_num: 172\n","train_kldiv: 0.03674\n","val_rmse_mean: 0.47 val_rmse_std: 0.9697\n","Still best_val_rmse: 0.4693 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.6 seconds\n","Epoch: 4 batch_num: 16\n","train_kldiv: 0.01335\n","val_rmse_mean: 0.4723 val_rmse_std: 0.9746\n","Still best_val_rmse: 0.4693 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.4 seconds\n","Epoch: 4 batch_num: 48\n","train_kldiv: 0.01529\n","val_rmse_mean: 0.4713 val_rmse_std: 0.9788\n","Still best_val_rmse: 0.4693 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.4 seconds\n","Epoch: 4 batch_num: 80\n","train_kldiv: 0.02551\n","val_rmse_mean: 0.4741 val_rmse_std: 0.9843\n","Still best_val_rmse: 0.4693 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.4 seconds\n","Epoch: 4 batch_num: 112\n","train_kldiv: 0.02918\n","val_rmse_mean: 0.4728 val_rmse_std: 0.9821\n","Still best_val_rmse: 0.4693 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.4 seconds\n","Epoch: 4 batch_num: 144\n","train_kldiv: 0.01283\n","val_rmse_mean: 0.4725 val_rmse_std: 0.9828\n","Still best_val_rmse: 0.4693 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.5 seconds\n","Epoch: 4 batch_num: 176\n","train_kldiv: 0.0319\n","val_rmse_mean: 0.4727 val_rmse_std: 0.982\n","Still best_val_rmse: 0.4693 (from epoch 2)\n","\n","Performance estimates:\n","[0.49222245576405277, 0.4603411269615789, 0.47719261912022, 0.4692679840967917]\n","Mean: 0.47475604648566083\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 5/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","64 steps took 83.4 seconds\n","Epoch: 0 batch_num: 64\n","train_kldiv: 2.005\n","val_rmse_mean: 0.6244 val_rmse_std: 0.08491\n","New best_val_rmse: 0.6244\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","64 steps took 82.3 seconds\n","Epoch: 0 batch_num: 128\n","train_kldiv: 0.3984\n","val_rmse_mean: 0.5325 val_rmse_std: 0.06956\n","New best_val_rmse: 0.5325\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.4 seconds\n","Epoch: 0 batch_num: 160\n","train_kldiv: 0.7912\n","val_rmse_mean: 0.5687 val_rmse_std: 0.04807\n","Still best_val_rmse: 0.5325 (from epoch 0)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","64 steps took 82.5 seconds\n","Epoch: 1 batch_num: 36\n","train_kldiv: 0.7264\n","val_rmse_mean: 0.5319 val_rmse_std: 0.05193\n","New best_val_rmse: 0.5319\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.4 seconds\n","Epoch: 1 batch_num: 68\n","train_kldiv: 0.505\n","val_rmse_mean: 0.496 val_rmse_std: 0.04254\n","New best_val_rmse: 0.496\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.4 seconds\n","Epoch: 1 batch_num: 100\n","train_kldiv: 0.3789\n","val_rmse_mean: 0.5537 val_rmse_std: 0.04477\n","Still best_val_rmse: 0.496 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","64 steps took 82.3 seconds\n","Epoch: 1 batch_num: 164\n","train_kldiv: 0.7471\n","val_rmse_mean: 0.518 val_rmse_std: 0.04118\n","Still best_val_rmse: 0.496 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.7 seconds\n","Epoch: 2 batch_num: 8\n","train_kldiv: 0.2511\n","val_rmse_mean: 0.4889 val_rmse_std: 0.04137\n","New best_val_rmse: 0.4889\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.5 seconds\n","Epoch: 2 batch_num: 40\n","train_kldiv: 0.1256\n","val_rmse_mean: 0.4902 val_rmse_std: 0.04055\n","Still best_val_rmse: 0.4889 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.4 seconds\n","Epoch: 2 batch_num: 72\n","train_kldiv: 0.1441\n","val_rmse_mean: 0.4859 val_rmse_std: 0.03873\n","New best_val_rmse: 0.4859\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.4 seconds\n","Epoch: 2 batch_num: 104\n","train_kldiv: 0.1644\n","val_rmse_mean: 0.4902 val_rmse_std: 0.04141\n","Still best_val_rmse: 0.4859 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.4 seconds\n","Epoch: 2 batch_num: 136\n","train_kldiv: 0.1503\n","val_rmse_mean: 0.4869 val_rmse_std: 0.04172\n","Still best_val_rmse: 0.4859 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.4 seconds\n","Epoch: 2 batch_num: 168\n","train_kldiv: 0.1368\n","val_rmse_mean: 0.5033 val_rmse_std: 0.04057\n","Still best_val_rmse: 0.4859 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.6 seconds\n","Epoch: 3 batch_num: 12\n","train_kldiv: 0.07001\n","val_rmse_mean: 0.477 val_rmse_std: 0.03967\n","New best_val_rmse: 0.477\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.5 seconds\n","Epoch: 3 batch_num: 44\n","train_kldiv: 0.07014\n","val_rmse_mean: 0.479 val_rmse_std: 0.04187\n","Still best_val_rmse: 0.477 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.4 seconds\n","Epoch: 3 batch_num: 76\n","train_kldiv: 0.07979\n","val_rmse_mean: 0.4776 val_rmse_std: 0.0396\n","Still best_val_rmse: 0.477 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.4 seconds\n","Epoch: 3 batch_num: 108\n","train_kldiv: 0.04869\n","val_rmse_mean: 0.4785 val_rmse_std: 0.04107\n","Still best_val_rmse: 0.477 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.4 seconds\n","Epoch: 3 batch_num: 140\n","train_kldiv: 0.04485\n","val_rmse_mean: 0.4823 val_rmse_std: 0.03969\n","Still best_val_rmse: 0.477 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.4 seconds\n","Epoch: 3 batch_num: 172\n","train_kldiv: 0.08229\n","val_rmse_mean: 0.4704 val_rmse_std: 0.0394\n","New best_val_rmse: 0.4704\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.6 seconds\n","Epoch: 4 batch_num: 16\n","train_kldiv: 0.02362\n","val_rmse_mean: 0.4768 val_rmse_std: 0.03895\n","Still best_val_rmse: 0.4704 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.4 seconds\n","Epoch: 4 batch_num: 48\n","train_kldiv: 0.03119\n","val_rmse_mean: 0.4741 val_rmse_std: 0.0414\n","Still best_val_rmse: 0.4704 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.4 seconds\n","Epoch: 4 batch_num: 80\n","train_kldiv: 0.07141\n","val_rmse_mean: 0.4748 val_rmse_std: 0.03871\n","Still best_val_rmse: 0.4704 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.4 seconds\n","Epoch: 4 batch_num: 112\n","train_kldiv: 0.02138\n","val_rmse_mean: 0.4753 val_rmse_std: 0.03906\n","Still best_val_rmse: 0.4704 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.4 seconds\n","Epoch: 4 batch_num: 144\n","train_kldiv: 0.02171\n","val_rmse_mean: 0.476 val_rmse_std: 0.03847\n","Still best_val_rmse: 0.4704 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15093}\n","\n","32 steps took 41.4 seconds\n","Epoch: 4 batch_num: 176\n","train_kldiv: 0.02512\n","val_rmse_mean: 0.4767 val_rmse_std: 0.03895\n","Still best_val_rmse: 0.4704 (from epoch 3)\n","\n","Performance estimates:\n","[0.49222245576405277, 0.4603411269615789, 0.47719261912022, 0.4692679840967917, 0.4704381102938533]\n","Mean: 0.47389245924729934\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"YSFnleU5vZS8","executionInfo":{"status":"ok","timestamp":1627813899418,"user_tz":-540,"elapsed":41,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"8a6140e3-9526-47fb-c809-be2d7bd11229"},"source":["\"\"\"desc_block = TextDescriptionBlock('excerpt')\n","desc_feats = desc_block.fit(train_kf_df.loc[train_indices])\n","desc_block_src = TextDescriptionBlock('excerpt')\n","desc_feats_src = desc_block_src.fit(train_kf_df.head(10))\"\"\""],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"desc_block = TextDescriptionBlock('excerpt')\\ndesc_feats = desc_block.fit(train_kf_df.loc[train_indices])\\ndesc_block_src = TextDescriptionBlock('excerpt')\\ndesc_feats_src = desc_block_src.fit(train_kf_df.head(10))\""]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":69},"id":"D0biwiMjq5KP","executionInfo":{"status":"ok","timestamp":1627813899418,"user_tz":-540,"elapsed":36,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"1486591b-651a-4b8e-97b1-f47ac5b16984"},"source":["\"\"\"train_dataset = LitDataset(train_kf_df.loc[train_indices]) # train, validのDataset\n","val_dataset = LitDataset(train_kf_df.loc[val_indices])\n","    \n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n","                          drop_last=True, shuffle=True, num_workers=2) # train, validのDataLoader\n","val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n","                        drop_last=False, shuffle=False, num_workers=2)    \n","\"\"\""],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'train_dataset = LitDataset(train_kf_df.loc[train_indices]) # train, validのDataset\\nval_dataset = LitDataset(train_kf_df.loc[val_indices])\\n    \\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\\n                          drop_last=True, shuffle=True, num_workers=2) # train, validのDataLoader\\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\\n                        drop_last=False, shuffle=False, num_workers=2)    \\n'"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"m4v-cGx-Mv7S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627813899419,"user_tz":-540,"elapsed":34,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"16ff805b-bc40-4826-91b0-c856ae23fdc8"},"source":["print(list_val_rmse)"],"execution_count":29,"outputs":[{"output_type":"stream","text":["[0.49222245576405277, 0.4603411269615789, 0.47719261912022, 0.4692679840967917, 0.4704381102938533]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XU4gRXHCBEpC","executionInfo":{"status":"ok","timestamp":1627813899420,"user_tz":-540,"elapsed":27,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"iAb99KSKBEmd","executionInfo":{"status":"ok","timestamp":1627813899420,"user_tz":-540,"elapsed":27,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"jH0aFzWxBEkG","executionInfo":{"status":"ok","timestamp":1627813899421,"user_tz":-540,"elapsed":27,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"q2CdCMuIKDMP","executionInfo":{"status":"ok","timestamp":1627813899421,"user_tz":-540,"elapsed":26,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#rep = MemReporter(model)\n","#rep.report()"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"eLl1yDOOKIe7","executionInfo":{"status":"ok","timestamp":1627813899422,"user_tz":-540,"elapsed":27,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#rep = MemReporter(model.roberta)\n","#rep.report()"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"7qkqnknA_m9D","executionInfo":{"status":"ok","timestamp":1627813899422,"user_tz":-540,"elapsed":26,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#gpuinfo()"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"PwrqSMdYA6Pu","executionInfo":{"status":"ok","timestamp":1627813899423,"user_tz":-540,"elapsed":27,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#del model\n","#del optimizer \n","#del train_loader\n","#del val_loader\n","#del scheduler \n","#del list_val_rmse\n","#del train_indices\n","#del val_indices\n","#del tokenizer\n","#torch.cuda.empty_cache()\n","#gpuinfo()"],"execution_count":33,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wXcHyUSJXecL"},"source":["# upload models"]},{"cell_type":"code","metadata":{"id":"YIV6UllSIGoa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627814137540,"user_tz":-540,"elapsed":110386,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"08999cbe-e348-4143-cd37-aad0d829b5ee"},"source":["%cd\n","!mkdir .kaggle\n","!mkdir /content/model\n","!cp /content/drive/MyDrive/Colab_Files/kaggle-api/kaggle.json .kaggle/\n","\n","!cp -r /content/model_1.pth /content/model/model_1.pth\n","!cp -r /content/model_2.pth /content/model/model_2.pth\n","!cp -r /content/model_3.pth /content/model/model_3.pth\n","!cp -r /content/model_4.pth /content/model/model_4.pth\n","!cp -r /content/model_5.pth /content/model/model_5.pth"],"execution_count":37,"outputs":[{"output_type":"stream","text":["/root\n","mkdir: cannot create directory ‘.kaggle’: File exists\n","mkdir: cannot create directory ‘/content/model’: File exists\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"14ddOZH4IMam","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627814392922,"user_tz":-540,"elapsed":254005,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"8126e6f2-37eb-4de6-e710-957e14d4f94b"},"source":["def dataset_upload():\n","    import json\n","    from kaggle.api.kaggle_api_extended import KaggleApi\n","\n","    id = f'{USERID}/{EX_NO}'\n","    print(id)\n","\n","    dataset_metadata = {}\n","    dataset_metadata['id'] = id\n","    dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n","    dataset_metadata['title'] = f'{EX_NO}'\n","\n","    with open(UPLOAD_DIR / 'dataset-metadata.json', 'w') as f:\n","        json.dump(dataset_metadata, f, indent=4)\n","\n","    api = KaggleApi()\n","    api.authenticate()\n","\n","    # データセットがない場合\n","    if f'{USERID}/{EX_NO}' not in [str(d) for d in api.dataset_list(user=USERID, search=f'\"{EX_NO}\"')]:\n","        api.dataset_create_new(folder=UPLOAD_DIR,\n","                               convert_to_csv=False,\n","                               dir_mode='skip')\n","    # データセットがある場合\n","    else:\n","        api.dataset_create_version(folder=UPLOAD_DIR,\n","                                   version_notes='update',\n","                                   convert_to_csv=False,\n","                                   delete_old_versions=True,\n","                                   dir_mode='skip')\n","dataset_upload()\n","\n"],"execution_count":38,"outputs":[{"output_type":"stream","text":["calpis10000/058-051-train-08\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0.00/1.33G [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Starting upload for file model_4.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [00:48<00:00, 29.3MB/s]\n","  0%|          | 0.00/1.33G [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_4.pth (1GB)\n","Starting upload for file model_1.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [00:51<00:00, 27.6MB/s]\n","  0%|          | 0.00/1.33G [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_1.pth (1GB)\n","Starting upload for file model_5.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [00:49<00:00, 28.5MB/s]\n","  0%|          | 0.00/1.33G [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_5.pth (1GB)\n","Starting upload for file model_3.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [00:50<00:00, 28.4MB/s]\n","  0%|          | 0.00/1.33G [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_3.pth (1GB)\n","Starting upload for file model_2.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [00:49<00:00, 28.6MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_2.pth (1GB)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"huJwVMSAPuDO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627814593130,"user_tz":-540,"elapsed":175120,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"629b6f2d-9a5a-4009-b343-3d71f97171a8"},"source":["# validation再実行_予測結果取得\n","all_predictions = np.zeros(len(train_kf_df)) # 推論結果について、「fold　× 推論df」のzero行列で枠を作る\n","\n","for fold_ in sorted(train_kf_df['kfold'].unique()):\n","    model_path = UPLOAD_DIR/f\"model_{fold_ + 1}.pth\" # 対応するモデルを読む\n","    print(f\"\\nUsing {model_path}\")\n","\n","    val_idx = train_kf_df['kfold'] == fold_\n","    val_df = train_kf_df[val_idx]\n","    val_dataset = LitDataset(val_df, inference_only=True) # TestのDataset(何で、もう一回作るのだろう？)\n","    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n","                          drop_last=False, shuffle=False, num_workers=2) # TestのDataLoader\n","\n","    model = LitModel()\n","    model.load_state_dict(torch.load(model_path))    # 対応するモデルから、重みを読み込む\n","    model.to(DEVICE) # モデルをDEVICEへぶち込む\n","\n","    all_predictions[val_idx] = predict(model, val_loader) # 推論結果行列の対象列に、推論結果を入力(以後、繰り返し)\n","\n","    del model\n","    gc.collect()\n"],"execution_count":40,"outputs":[{"output_type":"stream","text":["\n","Using /content/model/model_1.pth\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Using /content/model/model_2.pth\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Using /content/model/model_3.pth\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Using /content/model/model_4.pth\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Using /content/model/model_5.pth\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"0zzuBPobmLFu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627814672683,"user_tz":-540,"elapsed":294,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"1d62d8e4-b3ee-45cc-9ac1-013d4d852ec1"},"source":["from sklearn.metrics import mean_squared_error\n","import math\n","np.sqrt(mean_squared_error(train_kf_df.target.values, all_predictions))"],"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.4740143473754611"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"code","metadata":{"id":"Wpc8ro9hmNci","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627818107100,"user_tz":-540,"elapsed":386,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"87ff32e1-abd8-4137-afea-824ee49ae96b"},"source":["train_kf_df['pred'] = all_predictions\n","fold = 1\n","tg_true = train_kf_df[train_kf_df['kfold']==fold]['target'].values\n","tg_pred = train_kf_df[train_kf_df['kfold']==fold]['pred'].values\n","np.sqrt(mean_squared_error(tg_true, tg_pred))"],"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.4603411280282739"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"code","metadata":{"id":"ceDI72NumT5-","colab":{"base_uri":"https://localhost:8080/","height":296},"executionInfo":{"status":"ok","timestamp":1627814678159,"user_tz":-540,"elapsed":703,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"0b2ca1f3-4326-4827-85e6-f138bf86d05f"},"source":["train_kf_df['pred'] = all_predictions\n","train_kf_df['diff_sq'] = (train_kf_df['target'] - train_kf_df['pred'])**2\n","train_kf_df.plot(kind='scatter', x='target', y='diff_sq')"],"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7fb31e61dd50>"]},"metadata":{"tags":[]},"execution_count":43},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"PvRi_JQgwcKI","colab":{"base_uri":"https://localhost:8080/","height":841},"executionInfo":{"status":"ok","timestamp":1627814684713,"user_tz":-540,"elapsed":556,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"7335a7e5-9704-4f14-911f-6a113b2d6818"},"source":["# 二乗誤差が2.0を超える列\n","thr_ = 2.0 \n","train_kf_df[train_kf_df['diff_sq'] > thr_]"],"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>url_legal</th>\n","      <th>license</th>\n","      <th>excerpt</th>\n","      <th>target</th>\n","      <th>standard_error</th>\n","      <th>kfold</th>\n","      <th>bins_tg</th>\n","      <th>bins_std</th>\n","      <th>bins</th>\n","      <th>pred</th>\n","      <th>diff_sq</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>141</th>\n","      <td>bcd734621</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Midas was enjoying himself in his treasure-roo...</td>\n","      <td>0.943021</td>\n","      <td>0.537713</td>\n","      <td>0</td>\n","      <td>10</td>\n","      <td>5</td>\n","      <td>105</td>\n","      <td>-0.856971</td>\n","      <td>3.239972</td>\n","    </tr>\n","    <tr>\n","      <th>304</th>\n","      <td>f04e03fd8</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Jupiter, two hours high, was the herald of the...</td>\n","      <td>-3.229761</td>\n","      <td>0.551435</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>-1.775514</td>\n","      <td>2.114837</td>\n","    </tr>\n","    <tr>\n","      <th>741</th>\n","      <td>24e00a515</td>\n","      <td>https://simple.wikipedia.org/wiki/Inkpad</td>\n","      <td>CC BY-SA 3.0 and GFDL</td>\n","      <td>An inkpad is a small box which contains a pad ...</td>\n","      <td>0.627619</td>\n","      <td>0.520607</td>\n","      <td>3</td>\n","      <td>9</td>\n","      <td>5</td>\n","      <td>95</td>\n","      <td>-0.804203</td>\n","      <td>2.050115</td>\n","    </tr>\n","    <tr>\n","      <th>990</th>\n","      <td>afeb324bd</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>On the morning of the 20th of March, a long se...</td>\n","      <td>0.401053</td>\n","      <td>0.481889</td>\n","      <td>0</td>\n","      <td>9</td>\n","      <td>2</td>\n","      <td>92</td>\n","      <td>-1.423263</td>\n","      <td>3.328128</td>\n","    </tr>\n","    <tr>\n","      <th>1152</th>\n","      <td>03b761fd9</td>\n","      <td>https://simple.wikipedia.org/wiki/Larva</td>\n","      <td>CC BY-SA 3.0 and GFDL</td>\n","      <td>Probably the most widely accepted theory expla...</td>\n","      <td>-2.778515</td>\n","      <td>0.533111</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>15</td>\n","      <td>-1.218542</td>\n","      <td>2.433515</td>\n","    </tr>\n","    <tr>\n","      <th>1412</th>\n","      <td>8f35441e3</td>\n","      <td>https://www.africanstorybook.org/#</td>\n","      <td>CC BY 4.0</td>\n","      <td>Every day, Emeka's father took him to school i...</td>\n","      <td>1.583847</td>\n","      <td>0.624776</td>\n","      <td>1</td>\n","      <td>11</td>\n","      <td>10</td>\n","      <td>1110</td>\n","      <td>0.166397</td>\n","      <td>2.009165</td>\n","    </tr>\n","    <tr>\n","      <th>1944</th>\n","      <td>04ade0eb2</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>While I was hailing the brig, I spied a tract ...</td>\n","      <td>-3.315282</td>\n","      <td>0.544735</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>-1.543612</td>\n","      <td>3.138814</td>\n","    </tr>\n","    <tr>\n","      <th>2124</th>\n","      <td>76f92b721</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>The biggest desert in the world is in Africa, ...</td>\n","      <td>1.103341</td>\n","      <td>0.553751</td>\n","      <td>2</td>\n","      <td>10</td>\n","      <td>6</td>\n","      <td>106</td>\n","      <td>-0.431072</td>\n","      <td>2.354423</td>\n","    </tr>\n","    <tr>\n","      <th>2277</th>\n","      <td>7c732b8bb</td>\n","      <td>https://en.wikipedia.org/wiki/Environmental_sc...</td>\n","      <td>CC BY-SA 3.0</td>\n","      <td>Environmental science is an interdisciplinary ...</td>\n","      <td>-3.137143</td>\n","      <td>0.555843</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>16</td>\n","      <td>-1.633236</td>\n","      <td>2.261736</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             id  ...   diff_sq\n","141   bcd734621  ...  3.239972\n","304   f04e03fd8  ...  2.114837\n","741   24e00a515  ...  2.050115\n","990   afeb324bd  ...  3.328128\n","1152  03b761fd9  ...  2.433515\n","1412  8f35441e3  ...  2.009165\n","1944  04ade0eb2  ...  3.138814\n","2124  76f92b721  ...  2.354423\n","2277  7c732b8bb  ...  2.261736\n","\n","[9 rows x 12 columns]"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cL4lTGKjSAA5","executionInfo":{"status":"ok","timestamp":1627814687733,"user_tz":-540,"elapsed":349,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"292f6954-5bda-46f3-bce6-96722a83879a"},"source":["# 二乗誤差が2.0を超える文章\n","thr_ = 2.0 \n","tmp_df = train_kf_df[train_kf_df['diff_sq'] > thr_].copy()\n","for i in tmp_df.index:\n","  print(tmp_df.loc[i].target)\n","  #print(tmp_df.loc[i].standard_error)\n","  print(tmp_df.loc[i].pred)\n","  print(tmp_df.loc[i].excerpt)\n","  print('--------------------------')"],"execution_count":45,"outputs":[{"output_type":"stream","text":["0.943020903\n","-0.8569714426994324\n","Midas was enjoying himself in his treasure-room, one day, as usual, when he perceived a shadow fall over the heaps of gold; and, looking suddenly up, what should he behold but the figure of a stranger, standing in the bright and narrow sunbeam! It was a young man, with a cheerful and ruddy face. Whether it was that the imagination of King Midas threw a yellow tinge over everything, or whatever the cause might be, he could not help fancying that the smile with which the stranger regarded him had a kind of golden radiance in it. Certainly, although his figure intercepted the sunshine, there was now a brighter gleam upon all the piled-up treasures than before. Even the remotest corners had their share of it, and were lighted up, when the stranger smiled, as with tips of flame and sparkles of fire.\n","--------------------------\n","-3.229761439\n","-1.7755135297775269\n","Jupiter, two hours high, was the herald of the day; the Pleiades, just above the horizon, shed their sweet influence in the east; Lyra sparkled near the zenith; Andromeda veiled her newly discovered glories from the naked eye in the south; the steady Pointers, far beneath the pole, looked meekly up from the depths of the north to their sovereign.\n","Such was the glorious spectacle as I entered the train. As we proceeded, the timid approach of twilight became more perceptible; the intense blue of the sky began to soften; the smaller stars, like little children, went first to rest; the sister-beams of the Pleiades soon melted together; but the bright constellations of the west and north remained unchanged. Steadily the wondrous transfiguration went on. Hands of angels, hidden from mortal eyes, shifted the scenery of the heavens; the glories of night dissolved into the glories of the dawn.\n","--------------------------\n","0.627618676\n","-0.804203450679779\n","An inkpad is a small box which contains a pad of cloth or other material. It is impregnated with ink (the pad is inky). A marker is pressed onto the pad, then onto paper. Any raised marks on the pad leave an impression in ink on the paper.\n","Ink pads are used with rubber stamps. On the stamp is the symbol of an organization, for example. After a form has been passed by an official, it is stamped to show it is authentic. Another variation is a date stamp, placed on all letters which arrive in the building. Another version is a stamp with a facsimile (copy) of an official's signature. Using this, staff can send out letters when the official is not present. Rubber stamps and ink pads have been used for at least a hundred years by civil servants and businesses. They are still in use in many countries but are gradually being replaced with other systems.\n","--------------------------\n","0.401052549\n","-1.4232631921768188\n","On the morning of the 20th of March, a long series of earthquakes spread alarm throughout all the cities and numerous villages that are scattered over the sides of Mt. Etna. The shocks followed each other at intervals of a few minutes; dull subterranean rumblings were heard; and a catastrophe was seen to be impending. Toward evening the ground cracked at the lower part of the south side of the mountain, at the limit of the cultivated zone, and at four kilometers to the north of the village of Nicolosi. There formed on the earth a large number of very wide fissures, through which escaped great volumes of steam and gases which enveloped the mountain in a thick haze; and toward night, a very bright red light, which, seen from Catania, seemed to come out in great waves from the foot of the mountain, announced the coming of the lava.\n","--------------------------\n","-2.778515087\n","-1.218542218208313\n","Probably the most widely accepted theory explaining the evolution of larval stages is the need for dispersal. Sessile organisms such as barnacles and tunicates, and sea-floor groups like mussels and crabs, need some way to move their young into new territory, since they cannot move long distances as adults. Many species have relatively long pelagic larval stages (how long a larva is in the water column). During this time, larvae feed and grow, and many species move through several stages of development. For example, most barnacles molt through six nauplius larva stages before molting to a cipris, when they look to settle. The larvae eat different food from the adults, and disperse.\n","The other consideration is the small size of the eggs. If animals lay many small eggs (and most do), then the young stages cannot live the life the adults lead. They must live a separate life until they have the size and capability to live as an adult. This is what the larvae do.\n","--------------------------\n","1.583846826\n","0.1663965880870819\n","Every day, Emeka's father took him to school in his car. He also brought Emeka home after school. One afternoon on their way home, Emeka's father stopped to buy something at a big shop. From the car, Emeka looked across the road and saw an old man. He was carrying a big load on his head. He was tired and walked slowly. Emeka kept looking at him. The old man sat under the shade of a tree on the walkway and opened his bag. He had two flat plastic water bottles, which he was making into shoes. Emeka thought about that old man for a long time. He felt sad. When he got home, he could not eat. He thought about what he could do. He got up and took some money from his money bag. He called Chita and jumped on his bicycle. Emeka rode to the shop where his father had shopped. The boy ran into the shop and came out with a bag. He went to where the old man was resting against a tree. Emeka called out, \"Good afternoon, sir.\" The man answered, \"Peace to you, my child.\"\n","--------------------------\n","-3.31528229\n","-1.5436124801635742\n","While I was hailing the brig, I spied a tract of water lying between us, where no great waves came, but which yet boiled white all over and bristled in the moon with rings and bubbles. Sometimes the whole tract swung to one side, like the tail of a live serpent; sometimes, for a glimpse, it would all disappear and then boil up again. What it was I had no guess, which for the time increased my fear of it; but I now know it must have been the roost or tide-race, which had carried me away so fast and tumbled me about so cruelly, and at last, as if tired of that play, had flung out me and the spare yard upon its landward margin.\n","I now lay quite becalmed, and began to feel that a man can die of cold as well as of drowning. The shores of Earraid were close in; I could see in the moonlight the dots of heather and the sparkling of the mica in the rocks.\n","--------------------------\n","1.103341259\n","-0.43107175827026367\n","The biggest desert in the world is in Africa, and is called the Sahara. It is almost as large as the Atlantic Ocean, but instead of water it is all sands and rocks. Like the ocean, it is visited with storms; dreadful gales, when the wind scoops up thousands of tons of sand and drives them forward, burying and crushing all they meet. And it has islands, too—small green patches, where springs bubble through the ground, and ferns and acacias and palm-trees grow. When a traveler sees one of these fertile spots afar off, he feels as a tempest-tossed sailor does at sight of land. It is delightful to quit the hot, baking sun, sit in shadow under the trees, and rest the eyes, long wearied with dazzling sands, on the sweet green and the clear spring. Oases, these islands are called. Long distances divide them. It is often a race for life to get across from one to the other.\n","--------------------------\n","-3.1371432610000003\n","-1.6332364082336426\n","Environmental science is an interdisciplinary academic field that integrates physical, biological and information sciences (including ecology, biology, physics, chemistry, zoology, mineralogy, oceanology, limnology, soil science, geology, atmospheric science, and geodesy) to the study of the environment, and the solution of environmental problems. Environmental science emerged from the fields of natural history and medicine during the Enlightenment. Today it provides an integrated, quantitative, and interdisciplinary approach to the study of environmental systems.\n","Related areas of study include environmental studies and environmental engineering. Environmental studies incorporate more of the social sciences for understanding human relationships, perceptions and policies towards the environment. Environmental engineering focuses on design and technology for improving environmental quality in every aspect. Environmental scientists work on subjects like the understanding of earth processes, evaluating alternative energy systems, pollution control and mitigation, natural resource management, and the effects of global climate change. Environmental issues almost always include an interaction of physical, chemical, and biological processes.\n","--------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"d89ElwoOUPDx"},"source":[""],"execution_count":null,"outputs":[]}]}