{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"044-train-03.ipynb","provenance":[{"file_id":"1bhhkorT--y8XXaVLM8hibVgC-tLqZ16P","timestamp":1626358153868},{"file_id":"1WtT2hX6O9Qbt_hb9sF50nM2QmDXFi-XA","timestamp":1626338366006},{"file_id":"1k_p5wftcUeo711Xho1-T5an2Xkneau-J","timestamp":1626323813472},{"file_id":"1Vz2GB2BNTWuefEFkCSh3TBPEIel7KG1t","timestamp":1626317426487},{"file_id":"1djoMWojeaIPopG5tS1jNMohn8ineblRh","timestamp":1626306831897},{"file_id":"1-6tlDO8158Pi6TpptIF884oFaEiT4Uxb","timestamp":1626276420047},{"file_id":"1js8eA3mDNS8mwSpCiHuzPeARFlUPAVrg","timestamp":1626272452526},{"file_id":"1yhcPgulwJtjJKUK9IuRKmNMhJ-4YXGol","timestamp":1626267205517},{"file_id":"1mnnSv0Pofn1QxArywV81VYqnZPB8uUWN","timestamp":1626180468522},{"file_id":"1RRdjt_UAeHmr5QQBAMyC82Fq1s31OWdK","timestamp":1625833136005},{"file_id":"1JPgg44HFemzwk8VSCXih3PejL0idy-C4","timestamp":1625825483466},{"file_id":"1Ye6wqVX71xAAAhmjXkw9IpRvTqeUyJDA","timestamp":1625812137500}],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":86},"id":"Z6yRwt-PXtbP","executionInfo":{"status":"ok","timestamp":1626450617718,"user_tz":-540,"elapsed":371,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"0a0fcf5f-9c7f-4c4c-da81-1010876a082f"},"source":["\"\"\"\n","if 'google.colab' in sys.modules:  # colab環境特有の処理_初回のみ\n","  # Google Driveのマウント\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","\n","  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules' \\\n","   -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/requirements.txt' \\\n","   --ignore-installed\n","\n","  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules' \\\n","   transformers -U\n","  !pip install gensim==4.0.1 --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\n","  !pip install pytorch_memlab --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\n","\"\"\""],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\nif 'google.colab' in sys.modules:  # colab環境特有の処理_初回のみ\\n  # Google Driveのマウント\\n  from google.colab import drive\\n  drive.mount('/content/drive')\\n\\n  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'    -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/requirements.txt'    --ignore-installed\\n\\n  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'    transformers -U\\n  !pip install gensim==4.0.1 --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\\n  !pip install pytorch_memlab --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\\n\""]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ucCbvGD1XvG7","executionInfo":{"status":"ok","timestamp":1626450618340,"user_tz":-540,"elapsed":361,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"fe9c488a-241f-4a68-8510-7e2287928238"},"source":["import sys\n","if 'google.colab' in sys.modules:  # colab特有の処理_2回目以降\n","  # Google Driveのマウント\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","\n","  # データセットをDriveから取得\n","  !mkdir -p 'input'\n","  !cp -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/00_input' '/content/input'\n","\n","  # ライブラリのパス指定\n","  sys.path.append('/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules')\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RV9-VwbpZLZ9","executionInfo":{"status":"ok","timestamp":1626450618563,"user_tz":-540,"elapsed":226,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["from pathlib import Path\n","\n","# input\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    DATA_DIR = Path('../input/commonlitreadabilityprize/')\n","\n","elif 'google.colab' in sys.modules: # Colab環境\n","    !mkdir 'input' -p\n","    !cp '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/00_input/commonlitreadabilityprize/' './input' -r\n","    DATA_DIR = Path('/content/input/commonlitreadabilityprize')\n","\n","else:\n","    DATA_DIR = Path('../00_input/commonlitreadabilityprize/')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"8tMampUSaDo5","executionInfo":{"status":"ok","timestamp":1626450618564,"user_tz":-540,"elapsed":6,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["from pathlib import Path\n","\n","# pre-trained model\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    PRE_TRAINED_MODEL_DIR = '../input/roberta-transformers-pytorch/roberta-large'\n","elif 'google.colab' in sys.modules: # Colab環境\n","    PRE_TRAINED_MODEL_DIR = 'roberta-large' # 仮で、毎回DLする想定のモデル名を指定。あとで変更予定。\n","else:\n","    PRE_TRAINED_MODEL_DIR = 'roberta-large'"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"tKjsUxnOeDYl","executionInfo":{"status":"ok","timestamp":1626450618564,"user_tz":-540,"elapsed":6,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["from pathlib import Path\n","\n","# pre-trained model\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    PRE_TRAINED_MODEL_DIR = '../input/roberta-transformers-pytorch/roberta-large'\n","elif 'google.colab' in sys.modules: # Colab環境\n","    PRE_TRAINED_MODEL_DIR = 'roberta-large' # 仮で、毎回DLする想定のモデル名を指定。あとで変更予定。\n","else:\n","    PRE_TRAINED_MODEL_DIR = 'roberta-large'"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZLaT2V0ReoAZ","executionInfo":{"status":"ok","timestamp":1626450618565,"user_tz":-540,"elapsed":5,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["UPLOAD_DIR = Path('/content/model')\n","EX_NO = '044-train-03'  # 実験番号などを入れる、folderのpathにする\n","USERID = 'calpis10000'"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"hOGjAb4pAJ0F","executionInfo":{"status":"ok","timestamp":1626450618565,"user_tz":-540,"elapsed":5,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["import subprocess\n","import shlex\n","\n","def gpuinfo():\n","    \"\"\"\n","    Returns size of total GPU RAM and used GPU RAM.\n","\n","    Parameters\n","    ----------\n","    None\n","\n","    Returns\n","    -------\n","    info : dict\n","        Total GPU RAM in integer for key 'total_MiB'.\n","        Used GPU RAM in integer for key 'used_MiB'.\n","    \"\"\"\n","\n","    command = 'nvidia-smi -q -d MEMORY | sed -n \"/FB Memory Usage/,/Free/p\" | sed -e \"1d\" -e \"4d\" -e \"s/ MiB//g\" | cut -d \":\" -f 2 | cut -c2-'\n","    commands = [shlex.split(part) for part in command.split(' | ')]\n","    for i, cmd in enumerate(commands):\n","        if i==0:\n","            res = subprocess.Popen(cmd, stdout=subprocess.PIPE)\n","        else:\n","            res = subprocess.Popen(cmd, stdin=res.stdout, stdout=subprocess.PIPE)\n","    total, used = map(int, res.communicate()[0].decode('utf-8').strip().split('\\n'))\n","    info = {'total_MiB':total, 'used_MiB':used}\n","    return info\n"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g3-6m5MKXecB"},"source":["# Overview\n","This nb is based on copy from https://www.kaggle.com/andretugan/lightweight-roberta-solution-in-pytorch .\n","\n","Acknowledgments(from base nb): \n","some ideas were taken from kernels by [Torch](https://www.kaggle.com/rhtsingh) and [Maunish](https://www.kaggle.com/maunish)."]},{"cell_type":"code","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-04T06:26:32.834365Z","iopub.execute_input":"2021-07-04T06:26:32.834903Z","iopub.status.idle":"2021-07-04T06:26:40.143740Z","shell.execute_reply.started":"2021-07-04T06:26:32.834785Z","shell.execute_reply":"2021-07-04T06:26:40.142864Z"},"trusted":true,"id":"HRsRZ06WXecD","executionInfo":{"status":"ok","timestamp":1626450622307,"user_tz":-540,"elapsed":3746,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["import os\n","import math\n","import random\n","import time\n","\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","\n","from transformers import AdamW # optimizer\n","from transformers import AutoTokenizer\n","from transformers import AutoModel\n","from transformers import AutoConfig\n","from transformers import get_cosine_schedule_with_warmup # scheduler\n","from pytorch_memlab import profile\n","import pytorch_memlab\n","from pytorch_memlab import MemReporter\n","\n","from sklearn.model_selection import KFold, StratifiedKFold\n","\n","import gc\n","gc.enable()"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.145217Z","iopub.execute_input":"2021-07-04T06:26:40.145539Z","iopub.status.idle":"2021-07-04T06:26:40.201326Z","shell.execute_reply.started":"2021-07-04T06:26:40.145504Z","shell.execute_reply":"2021-07-04T06:26:40.200136Z"},"trusted":true,"id":"omBfwshTXecE","executionInfo":{"status":"ok","timestamp":1626450622313,"user_tz":-540,"elapsed":14,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["NUM_FOLDS = 5 # K Fold\n","NUM_EPOCHS = 5 # Epochs\n","BATCH_SIZE = 12 # Batch Size\n","MAX_LEN = 248 # ベクトル長\n","EVAL_SCHEDULE = [(0.55, 64), (0.50, 32), (0.49, 16), (0.48, 8), (0.47, 4), (0.46, 2), (-1., 1)] # schedulerの何らかの設定？\n","ROBERTA_PATH = PRE_TRAINED_MODEL_DIR # roberta pre-trainedモデル(モデルとして指定)\n","TOKENIZER_PATH = PRE_TRAINED_MODEL_DIR # roberta pre-trainedモデル(Tokenizerとして指定)\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\" # cudaがなければcpuを使えばいいじゃない"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.203398Z","iopub.execute_input":"2021-07-04T06:26:40.204055Z","iopub.status.idle":"2021-07-04T06:26:40.211572Z","shell.execute_reply.started":"2021-07-04T06:26:40.204015Z","shell.execute_reply":"2021-07-04T06:26:40.210762Z"},"trusted":true,"id":"4qcuXqwtXecF","executionInfo":{"status":"ok","timestamp":1626450622314,"user_tz":-540,"elapsed":13,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["def set_random_seed(random_seed):\n","    random.seed(random_seed)\n","    np.random.seed(random_seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(random_seed)\n","\n","    torch.manual_seed(random_seed)\n","    torch.cuda.manual_seed(random_seed)\n","    torch.cuda.manual_seed_all(random_seed)\n","\n","    torch.backends.cudnn.deterministic = True# cudnnによる最適化で結果が変わらないためのおまじない "],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.214188Z","iopub.execute_input":"2021-07-04T06:26:40.214809Z","iopub.status.idle":"2021-07-04T06:26:40.309744Z","shell.execute_reply.started":"2021-07-04T06:26:40.214769Z","shell.execute_reply":"2021-07-04T06:26:40.308926Z"},"trusted":true,"id":"70PyLsJTXecF","executionInfo":{"status":"ok","timestamp":1626450622314,"user_tz":-540,"elapsed":12,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# train, testを読む\n","train_df = pd.read_csv(DATA_DIR/\"train.csv\")\n","\n","# Remove incomplete entries if any.\n","train_df.drop(train_df[(train_df.target == 0) & (train_df.standard_error == 0)].index,\n","              inplace=True)\n","train_df.reset_index(drop=True, inplace=True)\n","\n","test_df = pd.read_csv(DATA_DIR/\"test.csv\")\n","submission_df = pd.read_csv(DATA_DIR/\"sample_submission.csv\")"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"9ZYOB59L8qtA","executionInfo":{"status":"ok","timestamp":1626450622315,"user_tz":-540,"elapsed":12,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"8484a464-f898-485d-f85c-19fa025f46f4"},"source":["train_df.head()\n"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>url_legal</th>\n","      <th>license</th>\n","      <th>excerpt</th>\n","      <th>target</th>\n","      <th>standard_error</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>c12129c31</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>When the young people returned to the ballroom...</td>\n","      <td>-0.340259</td>\n","      <td>0.464009</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>85aa80a4c</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>All through dinner time, Mrs. Fayre was somewh...</td>\n","      <td>-0.315372</td>\n","      <td>0.480805</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>b69ac6792</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>As Roger had predicted, the snow departed as q...</td>\n","      <td>-0.580118</td>\n","      <td>0.476676</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>dd1000b26</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>And outside before the palace a great garden w...</td>\n","      <td>-1.054013</td>\n","      <td>0.450007</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>37c1b32fb</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Once upon a time there were Three Bears who li...</td>\n","      <td>0.247197</td>\n","      <td>0.510845</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          id url_legal  ...    target standard_error\n","0  c12129c31       NaN  ... -0.340259       0.464009\n","1  85aa80a4c       NaN  ... -0.315372       0.480805\n","2  b69ac6792       NaN  ... -0.580118       0.476676\n","3  dd1000b26       NaN  ... -1.054013       0.450007\n","4  37c1b32fb       NaN  ...  0.247197       0.510845\n","\n","[5 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.311021Z","iopub.execute_input":"2021-07-04T06:26:40.311347Z","iopub.status.idle":"2021-07-04T06:26:40.624393Z","shell.execute_reply.started":"2021-07-04T06:26:40.311314Z","shell.execute_reply":"2021-07-04T06:26:40.623347Z"},"trusted":true,"id":"xf0662k4XecF","executionInfo":{"status":"ok","timestamp":1626450624581,"user_tz":-540,"elapsed":2276,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# tokenizerを指定\n","tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N6aaghNkXecG"},"source":["# Dataset"]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.628883Z","iopub.execute_input":"2021-07-04T06:26:40.629347Z","iopub.status.idle":"2021-07-04T06:26:40.644338Z","shell.execute_reply.started":"2021-07-04T06:26:40.629309Z","shell.execute_reply":"2021-07-04T06:26:40.643336Z"},"trusted":true,"id":"zkopT0U1XecG","executionInfo":{"status":"ok","timestamp":1626450624584,"user_tz":-540,"elapsed":10,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# Dataset用のClass。おそらく、trainとtestでインスタンスを生成し、DataFrameと同じように扱えるような思想。\n","class LitDataset(Dataset):\n","    def __init__(self, df, inference_only=False):\n","        super().__init__()\n","\n","        self.df = df        \n","        self.inference_only = inference_only # Testデータ用フラグ\n","        self.text = df.excerpt.tolist() # 分析対象カラムをlistにする。(分かち書きではなく、Seriesをlistへ変換するような処理)\n","        #self.text = [text.replace(\"\\n\", \" \") for text in self.text] # 単語単位で分かち書きする場合\n","        \n","        if not self.inference_only:\n","            self.target = torch.tensor(df.target.values, dtype=torch.float32) # trainのみ、targetをtensorに変換\n","            self.standard_error = torch.tensor(df.standard_error.values, dtype=torch.float32) \n","\n","        self.encoded = tokenizer.batch_encode_plus( # textをtokenize\n","            self.text,\n","            padding = 'max_length',            \n","            max_length = MAX_LEN,\n","            truncation = True, # 最大長を超える文字は切り捨て\n","            return_attention_mask=True\n","        )        \n"," \n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    \n","    def __getitem__(self, index): # 変換結果を返す\n","        input_ids = torch.tensor(self.encoded['input_ids'][index])\n","        attention_mask = torch.tensor(self.encoded['attention_mask'][index])\n","        \n","        if self.inference_only:\n","            return (input_ids, attention_mask)            \n","        else:\n","            target = self.target[index]\n","            standard_error = self.standard_error[index]\n","            return (input_ids, attention_mask, target, standard_error)"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KKtdy32wXecG"},"source":["# Model\n","The model is inspired by the one from [Maunish](https://www.kaggle.com/maunish/clrp-roberta-svm)."]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.649629Z","iopub.execute_input":"2021-07-04T06:26:40.650066Z","iopub.status.idle":"2021-07-04T06:26:40.666374Z","shell.execute_reply.started":"2021-07-04T06:26:40.650002Z","shell.execute_reply":"2021-07-04T06:26:40.665211Z"},"trusted":true,"id":"BpkxjXEUXecH","executionInfo":{"status":"ok","timestamp":1626450624585,"user_tz":-540,"elapsed":9,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["class LitModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        config = AutoConfig.from_pretrained(ROBERTA_PATH) # pretrainedからconfigを読み込み\n","        config.update({\"output_hidden_states\":True, # config更新: embedding層を抽出\n","                       \"hidden_dropout_prob\": 0.0, # config更新: dropoutしない\n","                       \"layer_norm_eps\": 1e-7}) # config更新: layer normalizationのepsilon                      \n","        \n","        self.roberta = AutoModel.from_pretrained(ROBERTA_PATH, config=config) # cpuで処理する\n","            \n","        self.attention = nn.Sequential(# attentionレイヤー            \n","            nn.Linear(config.hidden_size, 512),      \n","            nn.Tanh(),                       \n","            nn.Linear(512, 1),\n","            nn.Softmax(dim=1)\n","        )\n","\n","        self.regressor = nn.Sequential( # 出力レイヤー                    \n","            nn.Linear(config.hidden_size*2, 2)                        \n","        )\n","\n","    def forward(self, input_ids, attention_mask):\n","        roberta_output = self.roberta(input_ids=input_ids, # robertaに入力データを流し、出力としてrobertaモデル(layerの複合体)を得る\n","                                      attention_mask=attention_mask)     \n","\n","        last_hidden_state_att = roberta_output.hidden_states[-1] # robertaモデルの最後のlayerを得る\n","        weights = self.attention(last_hidden_state_att) # robertaの最後のlayerをattentionへ入力し、出力として重みを得る                \n","        context_vector = torch.sum(weights * last_hidden_state_att, dim=1) # 重み×最後の層を足し合わせて文書ベクトルとする。\n","        \n","\n","        # https://www.kaggle.com/rhtsingh/utilizing-transformer-representations-efficiently\n","        last_hidden_state_mn = roberta_output[0]\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state_mn.size()).float()\n","        sum_embeddings = torch.sum(last_hidden_state_mn * input_mask_expanded, 1)\n","        sum_mask = input_mask_expanded.sum(1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        mean_embeddings = sum_embeddings / sum_mask\n","        \n","        cat_embeddings = torch.cat([context_vector, mean_embeddings], dim=1)\n","        # Now we reduce the context vector to the prediction score.\n","        return self.regressor(cat_embeddings)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.672515Z","iopub.execute_input":"2021-07-04T06:26:40.672944Z","iopub.status.idle":"2021-07-04T06:26:40.684593Z","shell.execute_reply.started":"2021-07-04T06:26:40.672908Z","shell.execute_reply":"2021-07-04T06:26:40.683569Z"},"trusted":true,"id":"bB4jvQTxXecH","executionInfo":{"status":"ok","timestamp":1626450624585,"user_tz":-540,"elapsed":8,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 評価指標(MSE)の計算。最終的に、ルートしてRMSEにすると思われる。\n","def eval_mse(model, data_loader):\n","    \"\"\"Evaluates the mean squared error of the |model| on |data_loader|\"\"\"\n","    model.eval() # evalモードを選択。Batch Normとかdropoutをしなくなる           \n","    mse_mean_sum = 0\n","    mse_std_sum = 0\n","\n","    with torch.no_grad(): # 勾配の計算をしないBlock\n","        for batch_num, (input_ids, attention_mask, target, standard_error) in enumerate(data_loader): # data_loaderからinput, attentin_mask, targetをbatchごとに取り出す\n","            input_ids = input_ids.to(DEVICE)   \n","            attention_mask = attention_mask.to(DEVICE)   \n","            target = target.to(DEVICE)      \n","            standard_error = standard_error.to(DEVICE) \n","            \n","            output = model(input_ids, attention_mask) # 取得した値をモデルへ入力し、出力として予測値を得る。\n","\n","            mse_mean_sum += nn.MSELoss(reduction=\"sum\")(output[:,0].flatten(), target).item() # 誤差の合計を得る(Batchごとに計算した誤差を足し上げる)\n","            mse_std_sum += nn.MSELoss(reduction=\"sum\")(output[:,1].flatten(), target).item() # 誤差の合計を得る(Batchごとに計算した誤差を足し上げる)\n","\n","    del input_ids\n","    del attention_mask\n","    del target\n","\n","    mse_mean_result = mse_mean_sum / len(data_loader.dataset)\n","    mse_std_result = mse_std_sum / len(data_loader.dataset)\n","  \n","    return mse_mean_result, mse_std_result # 誤差の合計をdataset長で除し、mseを取得＆返す"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.690155Z","iopub.execute_input":"2021-07-04T06:26:40.692530Z","iopub.status.idle":"2021-07-04T06:26:40.703425Z","shell.execute_reply.started":"2021-07-04T06:26:40.692488Z","shell.execute_reply":"2021-07-04T06:26:40.702366Z"},"trusted":true,"id":"47bDno_LXecI","executionInfo":{"status":"ok","timestamp":1626450624586,"user_tz":-540,"elapsed":8,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 推論結果を返す\n","def predict(model, data_loader):\n","    \"\"\"Returns an np.array with predictions of the |model| on |data_loader|\"\"\"\n","    model.eval() # evalモード(dropout, batch_normしない)\n","\n","    result = np.zeros(len(data_loader.dataset)) # 結果をdataset長のzero配列として用意\n","    index = 0\n","    \n","    with torch.no_grad(): # 勾配の計算をしないblock(inputすると、現状の重みによる推論結果を返す)\n","        for batch_num, (input_ids, attention_mask) in enumerate(data_loader): # data_loaderからbatchごとにinputを得る\n","            input_ids = input_ids.to(DEVICE)\n","            attention_mask = attention_mask.to(DEVICE)\n","                        \n","            output = model(input_ids, attention_mask) # modelにinputを入力し、予測結果を得る。\n","\n","            result[index : index + output[:,0].shape[0]] = output[:,0].flatten().to(\"cpu\") # result[index ~ predの長さ]へ、予測結果を格納\n","            index += pred.shape[0] # indexを更新\n","\n","    return result # 全batchで推論が終わったら、結果を返す"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.708605Z","iopub.execute_input":"2021-07-04T06:26:40.709024Z","iopub.status.idle":"2021-07-04T06:26:40.730675Z","shell.execute_reply.started":"2021-07-04T06:26:40.708983Z","shell.execute_reply":"2021-07-04T06:26:40.729705Z"},"trusted":true,"id":"oInneuAmXecI","executionInfo":{"status":"ok","timestamp":1626450624586,"user_tz":-540,"elapsed":7,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 学習\n","def train(model, # モデル\n","          model_path, # モデルのアウトプット先\n","          train_loader, # train-setのdata_loader\n","          val_loader, # valid-setのdata_loader\n","          optimizer, # optimizer\n","          scheduler=None, # scheduler, デフォルトはNone\n","          num_epochs=NUM_EPOCHS # epoch数、notebook冒頭で指定した値\n","         ):    \n","    \n","    best_val_rmse = None\n","    best_epoch = 0\n","    step = 0\n","    last_eval_step = 0\n","    eval_period = EVAL_SCHEDULE[0][1] # eval期間(って何？) 冒頭で決めたEVAL_SCHEDULEの最初のtupleの[1]を取得\n","\n","    start = time.time() # 時間計測用\n","\n","    for epoch in range(num_epochs): # 指定したEpoch数だけ繰り返し\n","        val_rmse = None         \n","\n","        for batch_num, (input_ids, attention_mask, target, standard_error) in enumerate(train_loader): # train_loaderからinput, targetを取得\n","            input_ids = input_ids.to(DEVICE) # inputをDEVICEへ突っ込む\n","            attention_mask = attention_mask.to(DEVICE)       \n","            target = target.to(DEVICE)\n","            standard_error = standard_error.to(DEVICE)  \n","\n","            optimizer.zero_grad() # 勾配を初期化            \n","            model.train() # 学習モード開始\n","\n","            # https://www.kaggle.com/c/commonlitreadabilityprize/discussion/239421\n","            output = model(input_ids, attention_mask) # input,attention_maskを入力し、予測結果を得る\n","            p = torch.distributions.Normal(output[:,0], torch.sqrt(output[:,1]**2))\n","            q = torch.distributions.Normal(target, standard_error)\n","            kl_vector = torch.distributions.kl_divergence(p, q)\n","            loss = kl_vector.mean()\n","\n","            loss.backward() # 誤差逆伝播法により勾配を得る\n","            optimizer.step() # 重みを更新する\n","\n","            if scheduler:\n","                scheduler.step() # schedulerが与えられた場合は、schedulerの学習率更新\n","            \n","            if step >= last_eval_step + eval_period: # batchを回すごとにstepを増やしていって、「前回evalしたstep + eval_period(16)」を超えたら実行。\n","                # Evaluate the model on val_loader.\n","                elapsed_seconds = time.time() - start # 経過時間\n","                num_steps = step - last_eval_step # 経過ステップ数\n","                print(f\"\\n{num_steps} steps took {elapsed_seconds:0.3} seconds\")\n","                last_eval_step = step # 前回stepの更新\n","                \n","                # valid-setによるrmse計算\n","                train_mean_mse = nn.MSELoss(reduction=\"mean\")(output[:,0].flatten(), target) \n","                train_std_mse = nn.MSELoss(reduction=\"mean\")(torch.sqrt(output[:,1]**2).flatten(), standard_error) \n","\n","                train_mean_rmse = math.sqrt(train_mean_mse)\n","                train_std_rmse = math.sqrt(train_std_mse)\n","\n","                val_mean_mse, val_std_mse = eval_mse(model, val_loader)\n","                val_mean_rmse = math.sqrt(val_mean_mse)                            \n","                val_std_rmse = math.sqrt(val_std_mse)                            \n","\n","                print(f\"Epoch: {epoch} batch_num: {batch_num}\")\n","                print(f\"train_rmse_target: {train_mean_rmse:0.4}\",\n","                      f\"train_rmse_stderror: {train_std_rmse:0.4}\",\n","                      f\"train_kl_div: {loss:0.4}\",\n","                      )\n","                print(f\"val_rmse_target: {val_mean_rmse:0.4}\",\n","                      f\"val_rmse_stderror: {val_std_rmse:0.4}\"\n","                      )\n","\n","                for rmse, period in EVAL_SCHEDULE: # eval_periodをvalid-rmseで切り替える処理\n","                    if val_mean_rmse >= rmse: # valid rmseをEVAL_SCHEDULEと比較し、0項 > valid rmseとなるまで回す : EVAL_SCHEDULE = [(0.50, 16), (0.49, 8), (0.48, 4), (0.47, 2), (-1., 1)]\n","                        eval_period = period # eval_periodを更新\n","                        break                               \n","\n","                if not best_val_rmse or val_mean_rmse < best_val_rmse: # 初回(best_val_rmse==None), またはbest_val_rmseを更新したらモデルを保存する\n","                    best_val_rmse = val_mean_rmse\n","                    best_epoch = epoch\n","                    torch.save(model.state_dict(), model_path) # 最高の自分を保存\n","                    print(f\"New best_val_rmse: {best_val_rmse:0.4}\")\n","                else:       \n","                    print(f\"Still best_val_rmse: {best_val_rmse:0.4}\", # 更新されない場合は、元のスコアを表示\n","                          f\"(from epoch {best_epoch})\")      \n","                                                  \n","                start = time.time()\n","            \n","            # batchごとにメモリ解放\n","            del input_ids\n","            del attention_mask\n","            del target\n","            torch.cuda.empty_cache()                                            \n","            step += 1\n","    \n","    return best_val_rmse"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.735798Z","iopub.execute_input":"2021-07-04T06:26:40.738398Z","iopub.status.idle":"2021-07-04T06:26:40.750876Z","shell.execute_reply.started":"2021-07-04T06:26:40.738356Z","shell.execute_reply":"2021-07-04T06:26:40.749635Z"},"trusted":true,"id":"rMY0fjXwXecJ","executionInfo":{"status":"ok","timestamp":1626450624970,"user_tz":-540,"elapsed":16,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# optimizerの作成\n","def create_optimizer(model):\n","    named_parameters = list(model.named_parameters()) # モデルパラメータの取得\n","    \n","    roberta_parameters = list(model.roberta.named_parameters())[:-2] # パラメータをroberta用、attention用、regressor用に格納。(直接引っ張ってくる形式に変更)\n","    attention_parameters = list(model.attention.named_parameters())\n","    regressor_parameters = list(model.regressor.named_parameters())\n","        \n","    attention_group = [params for (name, params) in attention_parameters] # attention用パラメータをリストとして取得\n","    regressor_group = [params for (name, params) in regressor_parameters] # reg用パラメータをリストとして取得\n","\n","    parameters = []\n","    parameters.append({\"params\": attention_group}) # パラメータをリストに辞書として格納していく\n","    parameters.append({\"params\": regressor_group})\n","\n","    for layer_num, (name, params) in enumerate(roberta_parameters): # レイヤーごとにname, paramsを取得していろんな処理\n","        weight_decay = 0.0 if \"bias\" in name else 0.01\n","\n","        lr = 2e-6\n","\n","        if layer_num >= 69:        \n","            lr = 5e-6\n","\n","        if layer_num >= 133:\n","            lr = 1e-5\n","\n","        parameters.append({\"params\": params,\n","                           \"weight_decay\": weight_decay,\n","                           \"lr\": lr})\n","\n","    return AdamW(parameters) # 最終的に、AdamWにパラメータを入力する。\n"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"EbaJojz0Zjif","executionInfo":{"status":"ok","timestamp":1626450624971,"user_tz":-540,"elapsed":16,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# https://www.kaggle.com/abhishek/step-1-create-folds\n","def create_folds(data, num_splits, SEED, return_df=False):\n","    # we create a new column called kfold and fill it with -1\n","    data[\"kfold\"] = -1\n","    \n","    # the next step is to randomize the rows of the data\n","    data = data.sample(frac=1).reset_index(drop=True)\n","\n","    # calculate number of bins by Sturge's rule\n","    # I take the floor of the value, you can also\n","    # just round it\n","    num_bins = int(np.floor(1 + np.log2(len(data))))\n","    \n","    # bin targets\n","    data.loc[:, \"bins_tg\"] = pd.cut(\n","        data[\"target\"], bins=num_bins, labels=False\n","    ).map(lambda x: str(x))\n","\n","    # bin standard_error\n","    data.loc[:, \"bins_std\"] = pd.cut(\n","        data[\"standard_error\"], bins=num_bins, labels=False\n","    )\n","\n","    # bins\n","    data.loc[:, \"bins\"] = data['bins_tg'].map(lambda x: str(x)) + data['bins_std'].map(lambda x: str(x))\n","\n","    # initiate the kfold class from model_selection module\n","    kf = StratifiedKFold(n_splits=5, random_state=SEED, shuffle=True)\n","\n","    # note that, instead of targets, we use bins!\n","    if return_df:\n","      for f, (t_, v_) in enumerate(kf.split(X=data, y=data.bins.values)):\n","        data.loc[v_, 'kfold'] = f\n","      return data\n","    else:\n","      return kf.split(X=data, y=data.bins.values)"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"id":"vAmhaYaylMk5","executionInfo":{"status":"ok","timestamp":1626450624972,"user_tz":-540,"elapsed":16,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"b95b747f-a8e8-4601-d140-52317ef0316e"},"source":["# 検証用\n","SEED = 1000\n","st_kfold_bins_df = create_folds(train_df, num_splits=5, SEED=SEED, return_df=True)\n","st_kfold_bins_df['bins_tg'] = st_kfold_bins_df['bins_tg'].map(lambda x: float(x))\n","st_kfold_bins_df['bins_std'] = st_kfold_bins_df['bins_std'].map(lambda x: float(x))\n","st_kfold_bins_df.groupby('kfold').agg({'bins_tg': ['min', 'max', 'mean'],\n","                                    'bins_std': ['min', 'max', 'mean']})"],"execution_count":21,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  % (min_groups, self.n_splits)), UserWarning)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","\n","    .dataframe thead tr:last-of-type th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th></th>\n","      <th colspan=\"3\" halign=\"left\">bins_tg</th>\n","      <th colspan=\"3\" halign=\"left\">bins_std</th>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <th>min</th>\n","      <th>max</th>\n","      <th>mean</th>\n","      <th>min</th>\n","      <th>max</th>\n","      <th>mean</th>\n","    </tr>\n","    <tr>\n","      <th>kfold</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>5.571429</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>2.922399</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>5.513228</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>2.945326</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>5.530864</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>2.924162</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>5.553004</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>2.908127</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>5.581272</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>2.945230</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      bins_tg                 bins_std                \n","          min   max      mean      min   max      mean\n","kfold                                                 \n","0         0.0  11.0  5.571429      0.0  11.0  2.922399\n","1         0.0  11.0  5.513228      0.0  11.0  2.945326\n","2         0.0  11.0  5.530864      0.0  11.0  2.924162\n","3         0.0  11.0  5.553004      0.0  11.0  2.908127\n","4         0.0  11.0  5.581272      0.0  11.0  2.945230"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"TyjgRCu3mmqG","executionInfo":{"status":"ok","timestamp":1626450624972,"user_tz":-540,"elapsed":12,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"4PLKHwvKtNBn","executionInfo":{"status":"ok","timestamp":1626450624973,"user_tz":-540,"elapsed":13,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["def train_and_save_model(train_indices, val_indices, model_path):\n","    train_dataset = LitDataset(train_df.loc[train_indices]) # train, validのDataset\n","    val_dataset = LitDataset(train_df.loc[val_indices])\n","        \n","    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n","                              drop_last=True, shuffle=True, num_workers=2) # train, validのDataLoader\n","    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n","                            drop_last=False, shuffle=False, num_workers=2)    \n","\n","    model = LitModel().to(DEVICE) # modelをDEVICEへぶち込む\n","    optimizer = create_optimizer(model) # optimizerをモデルから作成\n","    scheduler = get_cosine_schedule_with_warmup( # schedulerを作成\n","        optimizer,\n","        num_training_steps=NUM_EPOCHS * len(train_loader),\n","        num_warmup_steps=50)    \n","    rmse = train(model, model_path, train_loader, val_loader, optimizer, scheduler=scheduler)\n","\n","    del train_dataset\n","    del val_dataset\n","    del train_loader\n","    del val_loader\n","    del model\n","    del optimizer\n","    del scheduler\n","    gc.collect() \n","    torch.cuda.empty_cache()\n","    return rmse"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.755813Z","iopub.execute_input":"2021-07-04T06:26:40.758373Z","iopub.status.idle":"2021-07-04T06:27:12.493221Z","shell.execute_reply.started":"2021-07-04T06:26:40.758265Z","shell.execute_reply":"2021-07-04T06:27:12.490139Z"},"trusted":true,"id":"k2LGJD3XXecK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626459065835,"user_tz":-540,"elapsed":8440874,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"6eb52b52-40aa-4044-f702-03e359094a9c"},"source":["# 実行処理。 KFold & 学習\n","SEED = 1000\n","list_val_rmse = []\n","\n","#kfold = KFold(n_splits=NUM_FOLDS, random_state=SEED, shuffle=True)\n","kfold = create_folds(train_df, 5, SEED=SEED, return_df=False) # binsで切る場合\n","\n","for fold, (train_indices, val_indices) in enumerate(kfold):    \n","    print(f\"\\nFold {fold + 1}/{NUM_FOLDS}\")\n","    print(gpuinfo())\n","    model_path = f\"model_{fold + 1}.pth\" # model_fold数_.pth\n","    set_random_seed(SEED + fold) # SEEDはfold別に変わるようにする\n","    list_val_rmse.append(train_and_save_model(train_indices, val_indices, model_path))\n","\n","    print(\"\\nPerformance estimates:\")\n","    print(list_val_rmse)\n","    print(\"Mean:\", np.array(list_val_rmse).mean())\n","    print(gpuinfo())"],"execution_count":23,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  % (min_groups, self.n_splits)), UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Fold 1/5\n","{'total_MiB': 16280, 'used_MiB': 2}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 82.4 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.9772 train_rmse_stderror: 0.05355 train_kl_div: 1.761\n","val_rmse_target: 0.6973 val_rmse_stderror: 1.828\n","New best_val_rmse: 0.6973\n","\n","64 steps took 81.5 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.4982 train_rmse_stderror: 0.07043 train_kl_div: 0.4513\n","val_rmse_target: 0.556 val_rmse_stderror: 1.848\n","New best_val_rmse: 0.556\n","\n","64 steps took 81.7 seconds\n","Epoch: 1 batch_num: 4\n","train_rmse_target: 0.4931 train_rmse_stderror: 0.06331 train_kl_div: 0.5463\n","val_rmse_target: 0.5893 val_rmse_stderror: 1.818\n","Still best_val_rmse: 0.556 (from epoch 0)\n","\n","64 steps took 81.5 seconds\n","Epoch: 1 batch_num: 68\n","train_rmse_target: 0.5255 train_rmse_stderror: 0.03515 train_kl_div: 0.5301\n","val_rmse_target: 0.5171 val_rmse_stderror: 1.817\n","New best_val_rmse: 0.5171\n","\n","32 steps took 40.8 seconds\n","Epoch: 1 batch_num: 100\n","train_rmse_target: 0.3301 train_rmse_stderror: 0.02399 train_kl_div: 0.2392\n","val_rmse_target: 0.5231 val_rmse_stderror: 1.833\n","Still best_val_rmse: 0.5171 (from epoch 1)\n","\n","32 steps took 40.7 seconds\n","Epoch: 1 batch_num: 132\n","train_rmse_target: 0.6374 train_rmse_stderror: 0.05591 train_kl_div: 0.8106\n","val_rmse_target: 0.5089 val_rmse_stderror: 1.799\n","New best_val_rmse: 0.5089\n","\n","32 steps took 40.8 seconds\n","Epoch: 1 batch_num: 164\n","train_rmse_target: 0.3427 train_rmse_stderror: 0.02488 train_kl_div: 0.2232\n","val_rmse_target: 0.5396 val_rmse_stderror: 1.818\n","Still best_val_rmse: 0.5089 (from epoch 1)\n","\n","32 steps took 41.0 seconds\n","Epoch: 2 batch_num: 8\n","train_rmse_target: 0.4468 train_rmse_stderror: 0.04161 train_kl_div: 0.4271\n","val_rmse_target: 0.5101 val_rmse_stderror: 1.824\n","Still best_val_rmse: 0.5089 (from epoch 1)\n","\n","32 steps took 40.8 seconds\n","Epoch: 2 batch_num: 40\n","train_rmse_target: 0.2833 train_rmse_stderror: 0.05048 train_kl_div: 0.1924\n","val_rmse_target: 0.5079 val_rmse_stderror: 1.839\n","New best_val_rmse: 0.5079\n","\n","32 steps took 40.8 seconds\n","Epoch: 2 batch_num: 72\n","train_rmse_target: 0.2694 train_rmse_stderror: 0.04467 train_kl_div: 0.152\n","val_rmse_target: 0.4845 val_rmse_stderror: 1.84\n","New best_val_rmse: 0.4845\n","\n","8 steps took 10.2 seconds\n","Epoch: 2 batch_num: 80\n","train_rmse_target: 0.3311 train_rmse_stderror: 0.02202 train_kl_div: 0.2343\n","val_rmse_target: 0.5572 val_rmse_stderror: 1.822\n","Still best_val_rmse: 0.4845 (from epoch 2)\n","\n","64 steps took 81.6 seconds\n","Epoch: 2 batch_num: 144\n","train_rmse_target: 0.4509 train_rmse_stderror: 0.02666 train_kl_div: 0.4028\n","val_rmse_target: 0.5109 val_rmse_stderror: 1.829\n","Still best_val_rmse: 0.4845 (from epoch 2)\n","\n","32 steps took 40.7 seconds\n","Epoch: 2 batch_num: 176\n","train_rmse_target: 0.4161 train_rmse_stderror: 0.03633 train_kl_div: 0.3649\n","val_rmse_target: 0.4985 val_rmse_stderror: 1.817\n","Still best_val_rmse: 0.4845 (from epoch 2)\n","\n","16 steps took 20.6 seconds\n","Epoch: 3 batch_num: 4\n","train_rmse_target: 0.3401 train_rmse_stderror: 0.04014 train_kl_div: 0.2195\n","val_rmse_target: 0.5069 val_rmse_stderror: 1.818\n","Still best_val_rmse: 0.4845 (from epoch 2)\n","\n","32 steps took 40.8 seconds\n","Epoch: 3 batch_num: 36\n","train_rmse_target: 0.2044 train_rmse_stderror: 0.03139 train_kl_div: 0.09503\n","val_rmse_target: 0.5179 val_rmse_stderror: 1.822\n","Still best_val_rmse: 0.4845 (from epoch 2)\n","\n","32 steps took 40.8 seconds\n","Epoch: 3 batch_num: 68\n","train_rmse_target: 0.2415 train_rmse_stderror: 0.02921 train_kl_div: 0.1192\n","val_rmse_target: 0.5152 val_rmse_stderror: 1.83\n","Still best_val_rmse: 0.4845 (from epoch 2)\n","\n","32 steps took 40.8 seconds\n","Epoch: 3 batch_num: 100\n","train_rmse_target: 0.2981 train_rmse_stderror: 0.03278 train_kl_div: 0.1813\n","val_rmse_target: 0.5336 val_rmse_stderror: 1.822\n","Still best_val_rmse: 0.4845 (from epoch 2)\n","\n","32 steps took 40.7 seconds\n","Epoch: 3 batch_num: 132\n","train_rmse_target: 0.199 train_rmse_stderror: 0.02808 train_kl_div: 0.08946\n","val_rmse_target: 0.5017 val_rmse_stderror: 1.821\n","Still best_val_rmse: 0.4845 (from epoch 2)\n","\n","32 steps took 40.7 seconds\n","Epoch: 3 batch_num: 164\n","train_rmse_target: 0.2968 train_rmse_stderror: 0.02716 train_kl_div: 0.1801\n","val_rmse_target: 0.5028 val_rmse_stderror: 1.831\n","Still best_val_rmse: 0.4845 (from epoch 2)\n","\n","32 steps took 40.9 seconds\n","Epoch: 4 batch_num: 8\n","train_rmse_target: 0.2008 train_rmse_stderror: 0.02754 train_kl_div: 0.08613\n","val_rmse_target: 0.5094 val_rmse_stderror: 1.829\n","Still best_val_rmse: 0.4845 (from epoch 2)\n","\n","32 steps took 40.8 seconds\n","Epoch: 4 batch_num: 40\n","train_rmse_target: 0.2101 train_rmse_stderror: 0.03026 train_kl_div: 0.08973\n","val_rmse_target: 0.5001 val_rmse_stderror: 1.828\n","Still best_val_rmse: 0.4845 (from epoch 2)\n","\n","32 steps took 40.7 seconds\n","Epoch: 4 batch_num: 72\n","train_rmse_target: 0.1585 train_rmse_stderror: 0.0275 train_kl_div: 0.05858\n","val_rmse_target: 0.5133 val_rmse_stderror: 1.822\n","Still best_val_rmse: 0.4845 (from epoch 2)\n","\n","32 steps took 40.7 seconds\n","Epoch: 4 batch_num: 104\n","train_rmse_target: 0.1898 train_rmse_stderror: 0.02583 train_kl_div: 0.07753\n","val_rmse_target: 0.5048 val_rmse_stderror: 1.822\n","Still best_val_rmse: 0.4845 (from epoch 2)\n","\n","32 steps took 40.7 seconds\n","Epoch: 4 batch_num: 136\n","train_rmse_target: 0.2333 train_rmse_stderror: 0.03769 train_kl_div: 0.08937\n","val_rmse_target: 0.5061 val_rmse_stderror: 1.824\n","Still best_val_rmse: 0.4845 (from epoch 2)\n","\n","32 steps took 40.7 seconds\n","Epoch: 4 batch_num: 168\n","train_rmse_target: 0.1492 train_rmse_stderror: 0.0461 train_kl_div: 0.05472\n","val_rmse_target: 0.5094 val_rmse_stderror: 1.824\n","Still best_val_rmse: 0.4845 (from epoch 2)\n","\n","Performance estimates:\n","[0.48451842935149647]\n","Mean: 0.48451842935149647\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 2/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 82.4 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 1.152 train_rmse_stderror: 0.0608 train_kl_div: 2.633\n","val_rmse_target: 0.6638 val_rmse_stderror: 1.715\n","New best_val_rmse: 0.6638\n","\n","64 steps took 81.5 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.8122 train_rmse_stderror: 0.05047 train_kl_div: 1.532\n","val_rmse_target: 0.7648 val_rmse_stderror: 1.741\n","Still best_val_rmse: 0.6638 (from epoch 0)\n","\n","64 steps took 81.7 seconds\n","Epoch: 1 batch_num: 4\n","train_rmse_target: 0.5198 train_rmse_stderror: 0.02571 train_kl_div: 0.5745\n","val_rmse_target: 0.5722 val_rmse_stderror: 1.748\n","New best_val_rmse: 0.5722\n","\n","64 steps took 81.5 seconds\n","Epoch: 1 batch_num: 68\n","train_rmse_target: 0.4619 train_rmse_stderror: 0.0318 train_kl_div: 0.4516\n","val_rmse_target: 0.5565 val_rmse_stderror: 1.751\n","New best_val_rmse: 0.5565\n","\n","64 steps took 81.5 seconds\n","Epoch: 1 batch_num: 132\n","train_rmse_target: 0.4226 train_rmse_stderror: 0.04101 train_kl_div: 0.3343\n","val_rmse_target: 0.5436 val_rmse_stderror: 1.738\n","New best_val_rmse: 0.5436\n","\n","32 steps took 40.7 seconds\n","Epoch: 1 batch_num: 164\n","train_rmse_target: 0.3825 train_rmse_stderror: 0.03063 train_kl_div: 0.3034\n","val_rmse_target: 0.5155 val_rmse_stderror: 1.738\n","New best_val_rmse: 0.5155\n","\n","32 steps took 41.0 seconds\n","Epoch: 2 batch_num: 8\n","train_rmse_target: 0.2322 train_rmse_stderror: 0.03089 train_kl_div: 0.1158\n","val_rmse_target: 0.503 val_rmse_stderror: 1.74\n","New best_val_rmse: 0.503\n","\n","32 steps took 40.8 seconds\n","Epoch: 2 batch_num: 40\n","train_rmse_target: 0.3859 train_rmse_stderror: 0.03958 train_kl_div: 0.2793\n","val_rmse_target: 0.4853 val_rmse_stderror: 1.739\n","New best_val_rmse: 0.4853\n","\n","8 steps took 10.2 seconds\n","Epoch: 2 batch_num: 48\n","train_rmse_target: 0.4271 train_rmse_stderror: 0.03217 train_kl_div: 0.3845\n","val_rmse_target: 0.4924 val_rmse_stderror: 1.744\n","Still best_val_rmse: 0.4853 (from epoch 2)\n","\n","16 steps took 20.4 seconds\n","Epoch: 2 batch_num: 64\n","train_rmse_target: 0.3431 train_rmse_stderror: 0.03902 train_kl_div: 0.2223\n","val_rmse_target: 0.4953 val_rmse_stderror: 1.756\n","Still best_val_rmse: 0.4853 (from epoch 2)\n","\n","16 steps took 20.4 seconds\n","Epoch: 2 batch_num: 80\n","train_rmse_target: 0.2303 train_rmse_stderror: 0.04701 train_kl_div: 0.1138\n","val_rmse_target: 0.4955 val_rmse_stderror: 1.726\n","Still best_val_rmse: 0.4853 (from epoch 2)\n","\n","16 steps took 20.4 seconds\n","Epoch: 2 batch_num: 96\n","train_rmse_target: 0.3506 train_rmse_stderror: 0.03229 train_kl_div: 0.2271\n","val_rmse_target: 0.5104 val_rmse_stderror: 1.734\n","Still best_val_rmse: 0.4853 (from epoch 2)\n","\n","32 steps took 40.7 seconds\n","Epoch: 2 batch_num: 128\n","train_rmse_target: 0.3029 train_rmse_stderror: 0.032 train_kl_div: 0.1817\n","val_rmse_target: 0.4997 val_rmse_stderror: 1.745\n","Still best_val_rmse: 0.4853 (from epoch 2)\n","\n","16 steps took 20.4 seconds\n","Epoch: 2 batch_num: 144\n","train_rmse_target: 0.2151 train_rmse_stderror: 0.03688 train_kl_div: 0.09772\n","val_rmse_target: 0.4931 val_rmse_stderror: 1.743\n","Still best_val_rmse: 0.4853 (from epoch 2)\n","\n","16 steps took 20.3 seconds\n","Epoch: 2 batch_num: 160\n","train_rmse_target: 0.1977 train_rmse_stderror: 0.04692 train_kl_div: 0.07938\n","val_rmse_target: 0.5009 val_rmse_stderror: 1.75\n","Still best_val_rmse: 0.4853 (from epoch 2)\n","\n","32 steps took 40.9 seconds\n","Epoch: 3 batch_num: 4\n","train_rmse_target: 0.2286 train_rmse_stderror: 0.04204 train_kl_div: 0.08831\n","val_rmse_target: 0.5039 val_rmse_stderror: 1.739\n","Still best_val_rmse: 0.4853 (from epoch 2)\n","\n","32 steps took 40.8 seconds\n","Epoch: 3 batch_num: 36\n","train_rmse_target: 0.2267 train_rmse_stderror: 0.03449 train_kl_div: 0.1076\n","val_rmse_target: 0.5197 val_rmse_stderror: 1.738\n","Still best_val_rmse: 0.4853 (from epoch 2)\n","\n","32 steps took 40.7 seconds\n","Epoch: 3 batch_num: 68\n","train_rmse_target: 0.1833 train_rmse_stderror: 0.03377 train_kl_div: 0.07376\n","val_rmse_target: 0.4978 val_rmse_stderror: 1.745\n","Still best_val_rmse: 0.4853 (from epoch 2)\n","\n","16 steps took 20.4 seconds\n","Epoch: 3 batch_num: 84\n","train_rmse_target: 0.147 train_rmse_stderror: 0.03593 train_kl_div: 0.04895\n","val_rmse_target: 0.4958 val_rmse_stderror: 1.734\n","Still best_val_rmse: 0.4853 (from epoch 2)\n","\n","16 steps took 20.4 seconds\n","Epoch: 3 batch_num: 100\n","train_rmse_target: 0.2593 train_rmse_stderror: 0.02842 train_kl_div: 0.1486\n","val_rmse_target: 0.4964 val_rmse_stderror: 1.73\n","Still best_val_rmse: 0.4853 (from epoch 2)\n","\n","16 steps took 20.4 seconds\n","Epoch: 3 batch_num: 116\n","train_rmse_target: 0.1257 train_rmse_stderror: 0.02846 train_kl_div: 0.03603\n","val_rmse_target: 0.5005 val_rmse_stderror: 1.735\n","Still best_val_rmse: 0.4853 (from epoch 2)\n","\n","32 steps took 40.7 seconds\n","Epoch: 3 batch_num: 148\n","train_rmse_target: 0.1708 train_rmse_stderror: 0.02219 train_kl_div: 0.05741\n","val_rmse_target: 0.4931 val_rmse_stderror: 1.745\n","Still best_val_rmse: 0.4853 (from epoch 2)\n","\n","16 steps took 20.4 seconds\n","Epoch: 3 batch_num: 164\n","train_rmse_target: 0.2685 train_rmse_stderror: 0.03058 train_kl_div: 0.1673\n","val_rmse_target: 0.495 val_rmse_stderror: 1.737\n","Still best_val_rmse: 0.4853 (from epoch 2)\n","\n","16 steps took 20.4 seconds\n","Epoch: 3 batch_num: 180\n","train_rmse_target: 0.2054 train_rmse_stderror: 0.03838 train_kl_div: 0.08039\n","val_rmse_target: 0.4985 val_rmse_stderror: 1.738\n","Still best_val_rmse: 0.4853 (from epoch 2)\n","\n","16 steps took 20.6 seconds\n","Epoch: 4 batch_num: 8\n","train_rmse_target: 0.1303 train_rmse_stderror: 0.01979 train_kl_div: 0.03947\n","val_rmse_target: 0.4957 val_rmse_stderror: 1.742\n","Still best_val_rmse: 0.4853 (from epoch 2)\n","\n","16 steps took 20.4 seconds\n","Epoch: 4 batch_num: 24\n","train_rmse_target: 0.1069 train_rmse_stderror: 0.02767 train_kl_div: 0.02832\n","val_rmse_target: 0.4951 val_rmse_stderror: 1.736\n","Still best_val_rmse: 0.4853 (from epoch 2)\n","\n","16 steps took 20.4 seconds\n","Epoch: 4 batch_num: 40\n","train_rmse_target: 0.1612 train_rmse_stderror: 0.03048 train_kl_div: 0.0564\n","val_rmse_target: 0.4956 val_rmse_stderror: 1.737\n","Still best_val_rmse: 0.4853 (from epoch 2)\n","\n","16 steps took 20.4 seconds\n","Epoch: 4 batch_num: 56\n","train_rmse_target: 0.1627 train_rmse_stderror: 0.02595 train_kl_div: 0.05961\n","val_rmse_target: 0.4965 val_rmse_stderror: 1.742\n","Still best_val_rmse: 0.4853 (from epoch 2)\n","\n","16 steps took 20.4 seconds\n","Epoch: 4 batch_num: 72\n","train_rmse_target: 0.1458 train_rmse_stderror: 0.02779 train_kl_div: 0.04449\n","val_rmse_target: 0.4956 val_rmse_stderror: 1.741\n","Still best_val_rmse: 0.4853 (from epoch 2)\n","\n","16 steps took 20.4 seconds\n","Epoch: 4 batch_num: 88\n","train_rmse_target: 0.1951 train_rmse_stderror: 0.0399 train_kl_div: 0.07897\n","val_rmse_target: 0.4962 val_rmse_stderror: 1.737\n","Still best_val_rmse: 0.4853 (from epoch 2)\n","\n","16 steps took 20.4 seconds\n","Epoch: 4 batch_num: 104\n","train_rmse_target: 0.1153 train_rmse_stderror: 0.02254 train_kl_div: 0.02942\n","val_rmse_target: 0.4963 val_rmse_stderror: 1.742\n","Still best_val_rmse: 0.4853 (from epoch 2)\n","\n","16 steps took 20.4 seconds\n","Epoch: 4 batch_num: 120\n","train_rmse_target: 0.1678 train_rmse_stderror: 0.02663 train_kl_div: 0.06802\n","val_rmse_target: 0.4987 val_rmse_stderror: 1.741\n","Still best_val_rmse: 0.4853 (from epoch 2)\n","\n","16 steps took 20.4 seconds\n","Epoch: 4 batch_num: 136\n","train_rmse_target: 0.1837 train_rmse_stderror: 0.0256 train_kl_div: 0.05713\n","val_rmse_target: 0.499 val_rmse_stderror: 1.739\n","Still best_val_rmse: 0.4853 (from epoch 2)\n","\n","16 steps took 20.4 seconds\n","Epoch: 4 batch_num: 152\n","train_rmse_target: 0.2915 train_rmse_stderror: 0.03882 train_kl_div: 0.1603\n","val_rmse_target: 0.4975 val_rmse_stderror: 1.74\n","Still best_val_rmse: 0.4853 (from epoch 2)\n","\n","16 steps took 20.4 seconds\n","Epoch: 4 batch_num: 168\n","train_rmse_target: 0.1632 train_rmse_stderror: 0.02231 train_kl_div: 0.0569\n","val_rmse_target: 0.4974 val_rmse_stderror: 1.74\n","Still best_val_rmse: 0.4853 (from epoch 2)\n","\n","16 steps took 20.4 seconds\n","Epoch: 4 batch_num: 184\n","train_rmse_target: 0.1645 train_rmse_stderror: 0.02981 train_kl_div: 0.05956\n","val_rmse_target: 0.4975 val_rmse_stderror: 1.74\n","Still best_val_rmse: 0.4853 (from epoch 2)\n","\n","Performance estimates:\n","[0.48451842935149647, 0.4853203145995822]\n","Mean: 0.48491937197553936\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 3/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 82.5 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.7106 train_rmse_stderror: 0.05834 train_kl_div: 1.038\n","val_rmse_target: 0.6869 val_rmse_stderror: 1.121\n","New best_val_rmse: 0.6869\n","\n","64 steps took 81.5 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.7973 train_rmse_stderror: 0.05858 train_kl_div: 1.113\n","val_rmse_target: 0.6305 val_rmse_stderror: 1.122\n","New best_val_rmse: 0.6305\n","\n","64 steps took 81.7 seconds\n","Epoch: 1 batch_num: 4\n","train_rmse_target: 0.2868 train_rmse_stderror: 0.0267 train_kl_div: 0.1839\n","val_rmse_target: 0.512 val_rmse_stderror: 1.13\n","New best_val_rmse: 0.512\n","\n","32 steps took 40.8 seconds\n","Epoch: 1 batch_num: 36\n","train_rmse_target: 0.2914 train_rmse_stderror: 0.04691 train_kl_div: 0.1869\n","val_rmse_target: 0.5182 val_rmse_stderror: 1.127\n","Still best_val_rmse: 0.512 (from epoch 1)\n","\n","32 steps took 40.8 seconds\n","Epoch: 1 batch_num: 68\n","train_rmse_target: 0.5408 train_rmse_stderror: 0.05978 train_kl_div: 0.4773\n","val_rmse_target: 0.5057 val_rmse_stderror: 1.119\n","New best_val_rmse: 0.5057\n","\n","32 steps took 40.9 seconds\n","Epoch: 1 batch_num: 100\n","train_rmse_target: 0.4072 train_rmse_stderror: 0.0351 train_kl_div: 0.3386\n","val_rmse_target: 0.5907 val_rmse_stderror: 1.135\n","Still best_val_rmse: 0.5057 (from epoch 1)\n","\n","64 steps took 81.6 seconds\n","Epoch: 1 batch_num: 164\n","train_rmse_target: 0.4066 train_rmse_stderror: 0.02589 train_kl_div: 0.3392\n","val_rmse_target: 0.4999 val_rmse_stderror: 1.122\n","New best_val_rmse: 0.4999\n","\n","16 steps took 20.4 seconds\n","Epoch: 1 batch_num: 180\n","train_rmse_target: 0.4031 train_rmse_stderror: 0.02496 train_kl_div: 0.3512\n","val_rmse_target: 0.4987 val_rmse_stderror: 1.11\n","New best_val_rmse: 0.4987\n","\n","16 steps took 20.6 seconds\n","Epoch: 2 batch_num: 8\n","train_rmse_target: 0.2475 train_rmse_stderror: 0.03279 train_kl_div: 0.1172\n","val_rmse_target: 0.5013 val_rmse_stderror: 1.12\n","Still best_val_rmse: 0.4987 (from epoch 1)\n","\n","32 steps took 40.8 seconds\n","Epoch: 2 batch_num: 40\n","train_rmse_target: 0.2037 train_rmse_stderror: 0.02635 train_kl_div: 0.09238\n","val_rmse_target: 0.4928 val_rmse_stderror: 1.123\n","New best_val_rmse: 0.4928\n","\n","16 steps took 20.4 seconds\n","Epoch: 2 batch_num: 56\n","train_rmse_target: 0.3313 train_rmse_stderror: 0.03811 train_kl_div: 0.2252\n","val_rmse_target: 0.5108 val_rmse_stderror: 1.125\n","Still best_val_rmse: 0.4928 (from epoch 2)\n","\n","32 steps took 40.8 seconds\n","Epoch: 2 batch_num: 88\n","train_rmse_target: 0.399 train_rmse_stderror: 0.0355 train_kl_div: 0.2915\n","val_rmse_target: 0.5093 val_rmse_stderror: 1.121\n","Still best_val_rmse: 0.4928 (from epoch 2)\n","\n","32 steps took 40.8 seconds\n","Epoch: 2 batch_num: 120\n","train_rmse_target: 0.2443 train_rmse_stderror: 0.05098 train_kl_div: 0.1287\n","val_rmse_target: 0.5086 val_rmse_stderror: 1.118\n","Still best_val_rmse: 0.4928 (from epoch 2)\n","\n","32 steps took 40.8 seconds\n","Epoch: 2 batch_num: 152\n","train_rmse_target: 0.3071 train_rmse_stderror: 0.03366 train_kl_div: 0.1794\n","val_rmse_target: 0.4931 val_rmse_stderror: 1.117\n","Still best_val_rmse: 0.4928 (from epoch 2)\n","\n","16 steps took 20.4 seconds\n","Epoch: 2 batch_num: 168\n","train_rmse_target: 0.3559 train_rmse_stderror: 0.04327 train_kl_div: 0.2347\n","val_rmse_target: 0.4968 val_rmse_stderror: 1.126\n","Still best_val_rmse: 0.4928 (from epoch 2)\n","\n","16 steps took 20.4 seconds\n","Epoch: 2 batch_num: 184\n","train_rmse_target: 0.4235 train_rmse_stderror: 0.04029 train_kl_div: 0.3838\n","val_rmse_target: 0.4919 val_rmse_stderror: 1.123\n","New best_val_rmse: 0.4919\n","\n","16 steps took 20.6 seconds\n","Epoch: 3 batch_num: 12\n","train_rmse_target: 0.1361 train_rmse_stderror: 0.02079 train_kl_div: 0.04004\n","val_rmse_target: 0.4962 val_rmse_stderror: 1.129\n","Still best_val_rmse: 0.4919 (from epoch 2)\n","\n","16 steps took 20.4 seconds\n","Epoch: 3 batch_num: 28\n","train_rmse_target: 0.1257 train_rmse_stderror: 0.0159 train_kl_div: 0.0319\n","val_rmse_target: 0.494 val_rmse_stderror: 1.126\n","Still best_val_rmse: 0.4919 (from epoch 2)\n","\n","16 steps took 20.4 seconds\n","Epoch: 3 batch_num: 44\n","train_rmse_target: 0.2869 train_rmse_stderror: 0.03407 train_kl_div: 0.1411\n","val_rmse_target: 0.4999 val_rmse_stderror: 1.128\n","Still best_val_rmse: 0.4919 (from epoch 2)\n","\n","16 steps took 20.4 seconds\n","Epoch: 3 batch_num: 60\n","train_rmse_target: 0.13 train_rmse_stderror: 0.03611 train_kl_div: 0.03972\n","val_rmse_target: 0.4924 val_rmse_stderror: 1.132\n","Still best_val_rmse: 0.4919 (from epoch 2)\n","\n","16 steps took 20.4 seconds\n","Epoch: 3 batch_num: 76\n","train_rmse_target: 0.1691 train_rmse_stderror: 0.02151 train_kl_div: 0.05571\n","val_rmse_target: 0.4947 val_rmse_stderror: 1.124\n","Still best_val_rmse: 0.4919 (from epoch 2)\n","\n","16 steps took 20.4 seconds\n","Epoch: 3 batch_num: 92\n","train_rmse_target: 0.2221 train_rmse_stderror: 0.02756 train_kl_div: 0.1001\n","val_rmse_target: 0.4934 val_rmse_stderror: 1.123\n","Still best_val_rmse: 0.4919 (from epoch 2)\n","\n","16 steps took 20.4 seconds\n","Epoch: 3 batch_num: 108\n","train_rmse_target: 0.1471 train_rmse_stderror: 0.01853 train_kl_div: 0.0476\n","val_rmse_target: 0.4927 val_rmse_stderror: 1.123\n","Still best_val_rmse: 0.4919 (from epoch 2)\n","\n","16 steps took 20.4 seconds\n","Epoch: 3 batch_num: 124\n","train_rmse_target: 0.1583 train_rmse_stderror: 0.03488 train_kl_div: 0.05708\n","val_rmse_target: 0.4951 val_rmse_stderror: 1.123\n","Still best_val_rmse: 0.4919 (from epoch 2)\n","\n","16 steps took 20.4 seconds\n","Epoch: 3 batch_num: 140\n","train_rmse_target: 0.1684 train_rmse_stderror: 0.03738 train_kl_div: 0.0655\n","val_rmse_target: 0.4964 val_rmse_stderror: 1.126\n","Still best_val_rmse: 0.4919 (from epoch 2)\n","\n","16 steps took 20.4 seconds\n","Epoch: 3 batch_num: 156\n","train_rmse_target: 0.1466 train_rmse_stderror: 0.03637 train_kl_div: 0.04678\n","val_rmse_target: 0.4975 val_rmse_stderror: 1.131\n","Still best_val_rmse: 0.4919 (from epoch 2)\n","\n","16 steps took 20.4 seconds\n","Epoch: 3 batch_num: 172\n","train_rmse_target: 0.2438 train_rmse_stderror: 0.01725 train_kl_div: 0.1145\n","val_rmse_target: 0.5005 val_rmse_stderror: 1.121\n","Still best_val_rmse: 0.4919 (from epoch 2)\n","\n","32 steps took 40.9 seconds\n","Epoch: 4 batch_num: 16\n","train_rmse_target: 0.1413 train_rmse_stderror: 0.01649 train_kl_div: 0.04061\n","val_rmse_target: 0.4969 val_rmse_stderror: 1.124\n","Still best_val_rmse: 0.4919 (from epoch 2)\n","\n","16 steps took 20.4 seconds\n","Epoch: 4 batch_num: 32\n","train_rmse_target: 0.3532 train_rmse_stderror: 0.03021 train_kl_div: 0.229\n","val_rmse_target: 0.4949 val_rmse_stderror: 1.128\n","Still best_val_rmse: 0.4919 (from epoch 2)\n","\n","16 steps took 20.4 seconds\n","Epoch: 4 batch_num: 48\n","train_rmse_target: 0.1104 train_rmse_stderror: 0.02655 train_kl_div: 0.03019\n","val_rmse_target: 0.4957 val_rmse_stderror: 1.125\n","Still best_val_rmse: 0.4919 (from epoch 2)\n","\n","16 steps took 20.4 seconds\n","Epoch: 4 batch_num: 64\n","train_rmse_target: 0.09607 train_rmse_stderror: 0.03304 train_kl_div: 0.0247\n","val_rmse_target: 0.4952 val_rmse_stderror: 1.122\n","Still best_val_rmse: 0.4919 (from epoch 2)\n","\n","16 steps took 20.4 seconds\n","Epoch: 4 batch_num: 80\n","train_rmse_target: 0.08479 train_rmse_stderror: 0.02504 train_kl_div: 0.0167\n","val_rmse_target: 0.494 val_rmse_stderror: 1.121\n","Still best_val_rmse: 0.4919 (from epoch 2)\n","\n","16 steps took 20.4 seconds\n","Epoch: 4 batch_num: 96\n","train_rmse_target: 0.1413 train_rmse_stderror: 0.02456 train_kl_div: 0.04027\n","val_rmse_target: 0.4939 val_rmse_stderror: 1.123\n","Still best_val_rmse: 0.4919 (from epoch 2)\n","\n","16 steps took 20.4 seconds\n","Epoch: 4 batch_num: 112\n","train_rmse_target: 0.158 train_rmse_stderror: 0.01113 train_kl_div: 0.05489\n","val_rmse_target: 0.4943 val_rmse_stderror: 1.125\n","Still best_val_rmse: 0.4919 (from epoch 2)\n","\n","16 steps took 20.4 seconds\n","Epoch: 4 batch_num: 128\n","train_rmse_target: 0.1697 train_rmse_stderror: 0.02906 train_kl_div: 0.06784\n","val_rmse_target: 0.4939 val_rmse_stderror: 1.124\n","Still best_val_rmse: 0.4919 (from epoch 2)\n","\n","16 steps took 20.4 seconds\n","Epoch: 4 batch_num: 144\n","train_rmse_target: 0.1172 train_rmse_stderror: 0.01384 train_kl_div: 0.02765\n","val_rmse_target: 0.4939 val_rmse_stderror: 1.124\n","Still best_val_rmse: 0.4919 (from epoch 2)\n","\n","16 steps took 20.4 seconds\n","Epoch: 4 batch_num: 160\n","train_rmse_target: 0.09606 train_rmse_stderror: 0.02383 train_kl_div: 0.02144\n","val_rmse_target: 0.4938 val_rmse_stderror: 1.123\n","Still best_val_rmse: 0.4919 (from epoch 2)\n","\n","16 steps took 20.4 seconds\n","Epoch: 4 batch_num: 176\n","train_rmse_target: 0.1104 train_rmse_stderror: 0.01751 train_kl_div: 0.02765\n","val_rmse_target: 0.4938 val_rmse_stderror: 1.123\n","Still best_val_rmse: 0.4919 (from epoch 2)\n","\n","Performance estimates:\n","[0.48451842935149647, 0.4853203145995822, 0.49193428980069187]\n","Mean: 0.4872576779172569\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 4/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 82.6 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.8167 train_rmse_stderror: 0.05873 train_kl_div: 1.269\n","val_rmse_target: 0.7443 val_rmse_stderror: 1.116\n","New best_val_rmse: 0.7443\n","\n","64 steps took 81.6 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.5253 train_rmse_stderror: 0.0423 train_kl_div: 0.5661\n","val_rmse_target: 0.6034 val_rmse_stderror: 1.142\n","New best_val_rmse: 0.6034\n","\n","64 steps took 81.9 seconds\n","Epoch: 1 batch_num: 4\n","train_rmse_target: 0.3801 train_rmse_stderror: 0.03587 train_kl_div: 0.3151\n","val_rmse_target: 0.5872 val_rmse_stderror: 1.131\n","New best_val_rmse: 0.5872\n","\n","64 steps took 81.7 seconds\n","Epoch: 1 batch_num: 68\n","train_rmse_target: 0.3369 train_rmse_stderror: 0.04988 train_kl_div: 0.2094\n","val_rmse_target: 0.5312 val_rmse_stderror: 1.105\n","New best_val_rmse: 0.5312\n","\n","32 steps took 40.9 seconds\n","Epoch: 1 batch_num: 100\n","train_rmse_target: 0.5828 train_rmse_stderror: 0.03739 train_kl_div: 0.6775\n","val_rmse_target: 0.5837 val_rmse_stderror: 1.135\n","Still best_val_rmse: 0.5312 (from epoch 1)\n","\n","64 steps took 81.6 seconds\n","Epoch: 1 batch_num: 164\n","train_rmse_target: 0.3113 train_rmse_stderror: 0.04694 train_kl_div: 0.2324\n","val_rmse_target: 0.5235 val_rmse_stderror: 1.14\n","New best_val_rmse: 0.5235\n","\n","32 steps took 41.0 seconds\n","Epoch: 2 batch_num: 8\n","train_rmse_target: 0.344 train_rmse_stderror: 0.01659 train_kl_div: 0.256\n","val_rmse_target: 0.5297 val_rmse_stderror: 1.125\n","Still best_val_rmse: 0.5235 (from epoch 1)\n","\n","32 steps took 40.8 seconds\n","Epoch: 2 batch_num: 40\n","train_rmse_target: 0.2725 train_rmse_stderror: 0.03593 train_kl_div: 0.1815\n","val_rmse_target: 0.527 val_rmse_stderror: 1.135\n","Still best_val_rmse: 0.5235 (from epoch 1)\n","\n","32 steps took 40.8 seconds\n","Epoch: 2 batch_num: 72\n","train_rmse_target: 0.2763 train_rmse_stderror: 0.03396 train_kl_div: 0.1688\n","val_rmse_target: 0.5174 val_rmse_stderror: 1.134\n","New best_val_rmse: 0.5174\n","\n","32 steps took 40.8 seconds\n","Epoch: 2 batch_num: 104\n","train_rmse_target: 0.2038 train_rmse_stderror: 0.03093 train_kl_div: 0.09494\n","val_rmse_target: 0.5151 val_rmse_stderror: 1.133\n","New best_val_rmse: 0.5151\n","\n","32 steps took 40.8 seconds\n","Epoch: 2 batch_num: 136\n","train_rmse_target: 0.2719 train_rmse_stderror: 0.034 train_kl_div: 0.1592\n","val_rmse_target: 0.5365 val_rmse_stderror: 1.127\n","Still best_val_rmse: 0.5151 (from epoch 2)\n","\n","32 steps took 40.8 seconds\n","Epoch: 2 batch_num: 168\n","train_rmse_target: 0.4335 train_rmse_stderror: 0.03994 train_kl_div: 0.3465\n","val_rmse_target: 0.5468 val_rmse_stderror: 1.134\n","Still best_val_rmse: 0.5151 (from epoch 2)\n","\n","32 steps took 41.0 seconds\n","Epoch: 3 batch_num: 12\n","train_rmse_target: 0.2191 train_rmse_stderror: 0.0214 train_kl_div: 0.0992\n","val_rmse_target: 0.5186 val_rmse_stderror: 1.137\n","Still best_val_rmse: 0.5151 (from epoch 2)\n","\n","32 steps took 40.8 seconds\n","Epoch: 3 batch_num: 44\n","train_rmse_target: 0.1854 train_rmse_stderror: 0.02371 train_kl_div: 0.07084\n","val_rmse_target: 0.5149 val_rmse_stderror: 1.126\n","New best_val_rmse: 0.5149\n","\n","32 steps took 40.8 seconds\n","Epoch: 3 batch_num: 76\n","train_rmse_target: 0.1167 train_rmse_stderror: 0.02685 train_kl_div: 0.03107\n","val_rmse_target: 0.5253 val_rmse_stderror: 1.133\n","Still best_val_rmse: 0.5149 (from epoch 3)\n","\n","32 steps took 40.8 seconds\n","Epoch: 3 batch_num: 108\n","train_rmse_target: 0.2043 train_rmse_stderror: 0.03584 train_kl_div: 0.07164\n","val_rmse_target: 0.5104 val_rmse_stderror: 1.132\n","New best_val_rmse: 0.5104\n","\n","32 steps took 40.8 seconds\n","Epoch: 3 batch_num: 140\n","train_rmse_target: 0.2808 train_rmse_stderror: 0.03159 train_kl_div: 0.1568\n","val_rmse_target: 0.51 val_rmse_stderror: 1.128\n","New best_val_rmse: 0.51\n","\n","32 steps took 40.8 seconds\n","Epoch: 3 batch_num: 172\n","train_rmse_target: 0.2002 train_rmse_stderror: 0.03084 train_kl_div: 0.08792\n","val_rmse_target: 0.5144 val_rmse_stderror: 1.131\n","Still best_val_rmse: 0.51 (from epoch 3)\n","\n","32 steps took 41.0 seconds\n","Epoch: 4 batch_num: 16\n","train_rmse_target: 0.115 train_rmse_stderror: 0.02415 train_kl_div: 0.03254\n","val_rmse_target: 0.5267 val_rmse_stderror: 1.137\n","Still best_val_rmse: 0.51 (from epoch 3)\n","\n","32 steps took 40.8 seconds\n","Epoch: 4 batch_num: 48\n","train_rmse_target: 0.1985 train_rmse_stderror: 0.02621 train_kl_div: 0.08343\n","val_rmse_target: 0.5139 val_rmse_stderror: 1.13\n","Still best_val_rmse: 0.51 (from epoch 3)\n","\n","32 steps took 40.8 seconds\n","Epoch: 4 batch_num: 80\n","train_rmse_target: 0.1603 train_rmse_stderror: 0.02083 train_kl_div: 0.05522\n","val_rmse_target: 0.5105 val_rmse_stderror: 1.132\n","Still best_val_rmse: 0.51 (from epoch 3)\n","\n","32 steps took 40.8 seconds\n","Epoch: 4 batch_num: 112\n","train_rmse_target: 0.1689 train_rmse_stderror: 0.04041 train_kl_div: 0.05394\n","val_rmse_target: 0.5148 val_rmse_stderror: 1.133\n","Still best_val_rmse: 0.51 (from epoch 3)\n","\n","32 steps took 40.8 seconds\n","Epoch: 4 batch_num: 144\n","train_rmse_target: 0.2074 train_rmse_stderror: 0.02464 train_kl_div: 0.08472\n","val_rmse_target: 0.5126 val_rmse_stderror: 1.132\n","Still best_val_rmse: 0.51 (from epoch 3)\n","\n","32 steps took 40.8 seconds\n","Epoch: 4 batch_num: 176\n","train_rmse_target: 0.1354 train_rmse_stderror: 0.02418 train_kl_div: 0.0414\n","val_rmse_target: 0.5134 val_rmse_stderror: 1.132\n","Still best_val_rmse: 0.51 (from epoch 3)\n","\n","Performance estimates:\n","[0.48451842935149647, 0.4853203145995822, 0.49193428980069187, 0.5099960541157885]\n","Mean: 0.4929422719668898\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 5/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 82.5 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.706 train_rmse_stderror: 0.08057 train_kl_div: 1.115\n","val_rmse_target: 0.8453 val_rmse_stderror: 1.773\n","New best_val_rmse: 0.8453\n","\n","64 steps took 81.6 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.3683 train_rmse_stderror: 0.0407 train_kl_div: 0.2846\n","val_rmse_target: 0.6397 val_rmse_stderror: 1.801\n","New best_val_rmse: 0.6397\n","\n","64 steps took 81.8 seconds\n","Epoch: 1 batch_num: 4\n","train_rmse_target: 0.2576 train_rmse_stderror: 0.03273 train_kl_div: 0.1456\n","val_rmse_target: 0.5892 val_rmse_stderror: 1.811\n","New best_val_rmse: 0.5892\n","\n","64 steps took 81.6 seconds\n","Epoch: 1 batch_num: 68\n","train_rmse_target: 0.6092 train_rmse_stderror: 0.07057 train_kl_div: 0.5739\n","val_rmse_target: 0.5378 val_rmse_stderror: 1.807\n","New best_val_rmse: 0.5378\n","\n","32 steps took 40.8 seconds\n","Epoch: 1 batch_num: 100\n","train_rmse_target: 0.5092 train_rmse_stderror: 0.0308 train_kl_div: 0.5105\n","val_rmse_target: 0.6022 val_rmse_stderror: 1.799\n","Still best_val_rmse: 0.5378 (from epoch 1)\n","\n","64 steps took 81.6 seconds\n","Epoch: 1 batch_num: 164\n","train_rmse_target: 0.3769 train_rmse_stderror: 0.03363 train_kl_div: 0.3029\n","val_rmse_target: 0.5712 val_rmse_stderror: 1.799\n","Still best_val_rmse: 0.5378 (from epoch 1)\n","\n","64 steps took 81.8 seconds\n","Epoch: 2 batch_num: 40\n","train_rmse_target: 0.2637 train_rmse_stderror: 0.02917 train_kl_div: 0.1635\n","val_rmse_target: 0.5393 val_rmse_stderror: 1.803\n","Still best_val_rmse: 0.5378 (from epoch 1)\n","\n","32 steps took 40.8 seconds\n","Epoch: 2 batch_num: 72\n","train_rmse_target: 0.3696 train_rmse_stderror: 0.03075 train_kl_div: 0.2864\n","val_rmse_target: 0.5163 val_rmse_stderror: 1.808\n","New best_val_rmse: 0.5163\n","\n","32 steps took 40.8 seconds\n","Epoch: 2 batch_num: 104\n","train_rmse_target: 0.5366 train_rmse_stderror: 0.04672 train_kl_div: 0.5023\n","val_rmse_target: 0.5309 val_rmse_stderror: 1.817\n","Still best_val_rmse: 0.5163 (from epoch 2)\n","\n","32 steps took 40.8 seconds\n","Epoch: 2 batch_num: 136\n","train_rmse_target: 0.3575 train_rmse_stderror: 0.03703 train_kl_div: 0.252\n","val_rmse_target: 0.5281 val_rmse_stderror: 1.805\n","Still best_val_rmse: 0.5163 (from epoch 2)\n","\n","32 steps took 40.8 seconds\n","Epoch: 2 batch_num: 168\n","train_rmse_target: 0.2937 train_rmse_stderror: 0.03851 train_kl_div: 0.1871\n","val_rmse_target: 0.5385 val_rmse_stderror: 1.803\n","Still best_val_rmse: 0.5163 (from epoch 2)\n","\n","32 steps took 41.0 seconds\n","Epoch: 3 batch_num: 12\n","train_rmse_target: 0.2769 train_rmse_stderror: 0.03035 train_kl_div: 0.1673\n","val_rmse_target: 0.5358 val_rmse_stderror: 1.802\n","Still best_val_rmse: 0.5163 (from epoch 2)\n","\n","32 steps took 40.8 seconds\n","Epoch: 3 batch_num: 44\n","train_rmse_target: 0.15 train_rmse_stderror: 0.03906 train_kl_div: 0.047\n","val_rmse_target: 0.5088 val_rmse_stderror: 1.81\n","New best_val_rmse: 0.5088\n","\n","32 steps took 40.8 seconds\n","Epoch: 3 batch_num: 76\n","train_rmse_target: 0.3767 train_rmse_stderror: 0.02937 train_kl_div: 0.2548\n","val_rmse_target: 0.5094 val_rmse_stderror: 1.809\n","Still best_val_rmse: 0.5088 (from epoch 3)\n","\n","32 steps took 40.8 seconds\n","Epoch: 3 batch_num: 108\n","train_rmse_target: 0.2506 train_rmse_stderror: 0.03942 train_kl_div: 0.1245\n","val_rmse_target: 0.5105 val_rmse_stderror: 1.804\n","Still best_val_rmse: 0.5088 (from epoch 3)\n","\n","32 steps took 40.8 seconds\n","Epoch: 3 batch_num: 140\n","train_rmse_target: 0.2508 train_rmse_stderror: 0.01856 train_kl_div: 0.1217\n","val_rmse_target: 0.5122 val_rmse_stderror: 1.805\n","Still best_val_rmse: 0.5088 (from epoch 3)\n","\n","32 steps took 40.8 seconds\n","Epoch: 3 batch_num: 172\n","train_rmse_target: 0.1543 train_rmse_stderror: 0.0273 train_kl_div: 0.05298\n","val_rmse_target: 0.512 val_rmse_stderror: 1.808\n","Still best_val_rmse: 0.5088 (from epoch 3)\n","\n","32 steps took 41.0 seconds\n","Epoch: 4 batch_num: 16\n","train_rmse_target: 0.1928 train_rmse_stderror: 0.02057 train_kl_div: 0.08209\n","val_rmse_target: 0.5138 val_rmse_stderror: 1.803\n","Still best_val_rmse: 0.5088 (from epoch 3)\n","\n","32 steps took 40.8 seconds\n","Epoch: 4 batch_num: 48\n","train_rmse_target: 0.2917 train_rmse_stderror: 0.03068 train_kl_div: 0.1774\n","val_rmse_target: 0.5139 val_rmse_stderror: 1.812\n","Still best_val_rmse: 0.5088 (from epoch 3)\n","\n","32 steps took 40.8 seconds\n","Epoch: 4 batch_num: 80\n","train_rmse_target: 0.2015 train_rmse_stderror: 0.02163 train_kl_div: 0.08189\n","val_rmse_target: 0.5109 val_rmse_stderror: 1.806\n","Still best_val_rmse: 0.5088 (from epoch 3)\n","\n","32 steps took 40.8 seconds\n","Epoch: 4 batch_num: 112\n","train_rmse_target: 0.116 train_rmse_stderror: 0.02653 train_kl_div: 0.03264\n","val_rmse_target: 0.5136 val_rmse_stderror: 1.808\n","Still best_val_rmse: 0.5088 (from epoch 3)\n","\n","32 steps took 40.8 seconds\n","Epoch: 4 batch_num: 144\n","train_rmse_target: 0.2047 train_rmse_stderror: 0.03194 train_kl_div: 0.08181\n","val_rmse_target: 0.5143 val_rmse_stderror: 1.807\n","Still best_val_rmse: 0.5088 (from epoch 3)\n","\n","32 steps took 40.8 seconds\n","Epoch: 4 batch_num: 176\n","train_rmse_target: 0.191 train_rmse_stderror: 0.02442 train_kl_div: 0.08107\n","val_rmse_target: 0.5136 val_rmse_stderror: 1.807\n","Still best_val_rmse: 0.5088 (from epoch 3)\n","\n","Performance estimates:\n","[0.48451842935149647, 0.4853203145995822, 0.49193428980069187, 0.5099960541157885, 0.5088251873500622]\n","Mean: 0.4961188550435242\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HgUJCFeLhLaP","executionInfo":{"status":"ok","timestamp":1626459065837,"user_tz":-540,"elapsed":43,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"524af707-6df9-4995-db7a-8914695b9acd"},"source":["import tracemalloc\n","\n","tracemalloc.start()\n","\n","# ... run your application ...\n","\n","snapshot = tracemalloc.take_snapshot()\n","top_stats = snapshot.statistics('lineno')\n","\n","print(\"[ Top 10 ]\")\n","for stat in top_stats[:10]:\n","    print(stat)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["[ Top 10 ]\n","/usr/lib/python3.7/codeop.py:141: size=189 B, count=2, average=94 B\n","/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2820: size=112 B, count=3, average=37 B\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"m4v-cGx-Mv7S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626459065838,"user_tz":-540,"elapsed":35,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"2b55a5c2-8453-4ea0-80c5-16b15b81927b"},"source":["print(list_val_rmse)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["[0.48451842935149647, 0.4853203145995822, 0.49193428980069187, 0.5099960541157885, 0.5088251873500622]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"q2CdCMuIKDMP","executionInfo":{"status":"ok","timestamp":1626459065839,"user_tz":-540,"elapsed":28,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#rep = MemReporter(model)\n","#rep.report()"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"eLl1yDOOKIe7","executionInfo":{"status":"ok","timestamp":1626459065839,"user_tz":-540,"elapsed":27,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#rep = MemReporter(model.roberta)\n","#rep.report()"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"7qkqnknA_m9D","executionInfo":{"status":"ok","timestamp":1626459065840,"user_tz":-540,"elapsed":27,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#gpuinfo()"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"PwrqSMdYA6Pu","executionInfo":{"status":"ok","timestamp":1626459065840,"user_tz":-540,"elapsed":27,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#del model\n","#del optimizer \n","#del train_loader\n","#del val_loader\n","#del scheduler \n","#del list_val_rmse\n","#del train_indices\n","#del val_indices\n","#del tokenizer\n","#torch.cuda.empty_cache()\n","#gpuinfo()"],"execution_count":29,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wXcHyUSJXecL"},"source":["# Inference"]},{"cell_type":"code","metadata":{"id":"YIV6UllSIGoa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626459179235,"user_tz":-540,"elapsed":113421,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"ef06bf51-7b74-4f57-c8f4-f8cec29973dc"},"source":["%cd\n","!mkdir .kaggle\n","!mkdir /content/model\n","!cp /content/drive/MyDrive/Colab_Files/kaggle-api/kaggle.json .kaggle/\n","\n","!cp -r /content/model_1.pth /content/model/model_1.pth\n","!cp -r /content/model_2.pth /content/model/model_2.pth\n","!cp -r /content/model_3.pth /content/model/model_3.pth\n","!cp -r /content/model_4.pth /content/model/model_4.pth\n","!cp -r /content/model_5.pth /content/model/model_5.pth"],"execution_count":30,"outputs":[{"output_type":"stream","text":["/root\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"14ddOZH4IMam","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626459331828,"user_tz":-540,"elapsed":152606,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"7f7845cd-90f4-41d9-d849-d5f17d8e7b28"},"source":["\n","\n","def dataset_upload():\n","    import json\n","    from kaggle.api.kaggle_api_extended import KaggleApi\n","\n","    id = f'{USERID}/{EX_NO}'\n","\n","    dataset_metadata = {}\n","    dataset_metadata['id'] = id\n","    dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n","    dataset_metadata['title'] = f'{EX_NO}'\n","\n","    with open(UPLOAD_DIR / 'dataset-metadata.json', 'w') as f:\n","        json.dump(dataset_metadata, f, indent=4)\n","\n","    api = KaggleApi()\n","    api.authenticate()\n","\n","    # データセットがない場合\n","    if f'{USERID}/{EX_NO}' not in [str(d) for d in api.dataset_list(user=USERID, search=f'\"{EX_NO}\"')]:\n","        api.dataset_create_new(folder=UPLOAD_DIR,\n","                               convert_to_csv=False,\n","                               dir_mode='skip')\n","    # データセットがある場合\n","    else:\n","        api.dataset_create_version(folder=UPLOAD_DIR,\n","                                   version_notes='update',\n","                                   convert_to_csv=False,\n","                                   delete_old_versions=True,\n","                                   dir_mode='skip')\n","dataset_upload()\n","\n"],"execution_count":31,"outputs":[{"output_type":"stream","text":["\r  0%|          | 0.00/1.33G [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Starting upload for file model_3.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [00:25<00:00, 56.5MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_3.pth (1GB)\n","Starting upload for file model_1.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [00:34<00:00, 40.8MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_1.pth (1GB)\n","Starting upload for file model_5.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [00:32<00:00, 44.3MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_5.pth (1GB)\n","Starting upload for file model_2.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [00:27<00:00, 50.9MB/s]\n","  0%|          | 0.00/1.33G [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_2.pth (1GB)\n","Starting upload for file model_4.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [00:26<00:00, 52.8MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_4.pth (1GB)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"huJwVMSAPuDO","executionInfo":{"status":"ok","timestamp":1626459331831,"user_tz":-540,"elapsed":11,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"0zzuBPobmLFu","executionInfo":{"status":"ok","timestamp":1626459331831,"user_tz":-540,"elapsed":9,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wpc8ro9hmNci","executionInfo":{"status":"ok","timestamp":1626459331832,"user_tz":-540,"elapsed":9,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"ceDI72NumT5-","executionInfo":{"status":"ok","timestamp":1626459331832,"user_tz":-540,"elapsed":9,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":31,"outputs":[]}]}