{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"046-train-01.ipynb","provenance":[{"file_id":"1bhhkorT--y8XXaVLM8hibVgC-tLqZ16P","timestamp":1626358153868},{"file_id":"1WtT2hX6O9Qbt_hb9sF50nM2QmDXFi-XA","timestamp":1626338366006},{"file_id":"1k_p5wftcUeo711Xho1-T5an2Xkneau-J","timestamp":1626323813472},{"file_id":"1Vz2GB2BNTWuefEFkCSh3TBPEIel7KG1t","timestamp":1626317426487},{"file_id":"1djoMWojeaIPopG5tS1jNMohn8ineblRh","timestamp":1626306831897},{"file_id":"1-6tlDO8158Pi6TpptIF884oFaEiT4Uxb","timestamp":1626276420047},{"file_id":"1js8eA3mDNS8mwSpCiHuzPeARFlUPAVrg","timestamp":1626272452526},{"file_id":"1yhcPgulwJtjJKUK9IuRKmNMhJ-4YXGol","timestamp":1626267205517},{"file_id":"1mnnSv0Pofn1QxArywV81VYqnZPB8uUWN","timestamp":1626180468522},{"file_id":"1RRdjt_UAeHmr5QQBAMyC82Fq1s31OWdK","timestamp":1625833136005},{"file_id":"1JPgg44HFemzwk8VSCXih3PejL0idy-C4","timestamp":1625825483466},{"file_id":"1Ye6wqVX71xAAAhmjXkw9IpRvTqeUyJDA","timestamp":1625812137500}],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"362f68b336e747b48e583b6b00ca3e47":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_fed46087e93a4b5d86042207ed092645","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_01321f8df04942fba9b011e77d67659d","IPY_MODEL_2d38c1dc74b94980a83a42e81efe42f7"]}},"fed46087e93a4b5d86042207ed092645":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"01321f8df04942fba9b011e77d67659d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_db3ba3bed82c4976bbef784281ebdb05","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":482,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":482,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a2d087c5c45b47baa5aed45b3d9eea52"}},"2d38c1dc74b94980a83a42e81efe42f7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_999c7b0f60de4e90b490100ac9d002a6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 482/482 [00:00&lt;00:00, 760B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4d9d6d200a2445a491f708dd73060e1c"}},"db3ba3bed82c4976bbef784281ebdb05":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a2d087c5c45b47baa5aed45b3d9eea52":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"999c7b0f60de4e90b490100ac9d002a6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4d9d6d200a2445a491f708dd73060e1c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0d3577dce90e4527b607b4217b8e0ff9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b5f5b9df3237448c8cb1bc29fe93f9b8","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4fab78a060a245e0a0d055ef0457e64c","IPY_MODEL_99991d1239f343e68af3c5a494316774"]}},"b5f5b9df3237448c8cb1bc29fe93f9b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4fab78a060a245e0a0d055ef0457e64c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e3ff7195c8bd4c2f8a63880a8996d96a","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":898823,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":898823,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ae55f816225a4d6489f546296820ac4d"}},"99991d1239f343e68af3c5a494316774":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_72a9147d58c64aeb80b9ab2827aa7620","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 899k/899k [00:39&lt;00:00, 22.8kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0cb1c36625ed4bf99cffbf13bd8b2208"}},"e3ff7195c8bd4c2f8a63880a8996d96a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ae55f816225a4d6489f546296820ac4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"72a9147d58c64aeb80b9ab2827aa7620":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0cb1c36625ed4bf99cffbf13bd8b2208":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"20a1c0fb2a2a4854a8d6c119d366187d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b6850d44d6a84d34b892b3dd9eac98e4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b76293a3badb4ff38c912cb76415e7a9","IPY_MODEL_5fca1d72ca7b4a23a3b49c5633f868d5"]}},"b6850d44d6a84d34b892b3dd9eac98e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b76293a3badb4ff38c912cb76415e7a9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_69dbd5c0a63348c19f53cf8f14f99ad6","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":456318,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":456318,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9a8e814374624bcabe80578b8150758e"}},"5fca1d72ca7b4a23a3b49c5633f868d5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_26b3a39c8138480cb91c13423e57f5ae","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 456k/456k [00:01&lt;00:00, 328kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cf7ebbf80753458ca068cf99911fdd9d"}},"69dbd5c0a63348c19f53cf8f14f99ad6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9a8e814374624bcabe80578b8150758e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"26b3a39c8138480cb91c13423e57f5ae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"cf7ebbf80753458ca068cf99911fdd9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7698c8581cba49b39db1d1d7ae22bbfd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a41b10d7478046e38ed5a049a6532e01","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_92d92198d5384d9797c7e468e0ed44b4","IPY_MODEL_80cd0ebcf9cc4a3e96524e52ab9697fb"]}},"a41b10d7478046e38ed5a049a6532e01":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"92d92198d5384d9797c7e468e0ed44b4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_da69f78ed61a4f3eb5ff190a8693fed1","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1355863,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1355863,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b8b71675368d4f689f622daf82f4bd82"}},"80cd0ebcf9cc4a3e96524e52ab9697fb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bef6e35f19054784a895d657871c3f7e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.36M/1.36M [00:37&lt;00:00, 36.2kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_079c57aaebca4f95a8f455d32a194c12"}},"da69f78ed61a4f3eb5ff190a8693fed1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b8b71675368d4f689f622daf82f4bd82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bef6e35f19054784a895d657871c3f7e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"079c57aaebca4f95a8f455d32a194c12":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":103},"id":"Z6yRwt-PXtbP","executionInfo":{"status":"ok","timestamp":1626689442576,"user_tz":-540,"elapsed":11,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"d514cf9f-4118-4d29-fbfd-6f81797da30e"},"source":["\"\"\"\n","if 'google.colab' in sys.modules:  # colab環境特有の処理_初回のみ\n","  # Google Driveのマウント\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","\n","  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules' \\\n","   -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/requirements.txt' \\\n","   --ignore-installed\n","\n","  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules' \\\n","   transformers -U\n","  !pip install gensim==4.0.1 --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\n","  !pip install pytorch_memlab --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\n","\"\"\""],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\nif 'google.colab' in sys.modules:  # colab環境特有の処理_初回のみ\\n  # Google Driveのマウント\\n  from google.colab import drive\\n  drive.mount('/content/drive')\\n\\n  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'    -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/requirements.txt'    --ignore-installed\\n\\n  !pip install --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'    transformers -U\\n  !pip install gensim==4.0.1 --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\\n  !pip install pytorch_memlab --target '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules'\\n\""]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ucCbvGD1XvG7","executionInfo":{"status":"ok","timestamp":1626689644892,"user_tz":-540,"elapsed":5703,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"d18647ce-1274-4e9b-be9e-dc652068b57d"},"source":["import sys\n","if 'google.colab' in sys.modules:  # colab特有の処理_2回目以降\n","  # Google Driveのマウント\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","\n","  # データセットをDriveから取得\n","  !mkdir -p 'input'\n","  !cp -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/00_input/commonlitreadabilityprize/' '/content/input'\n","  !cp -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/97_pre_trained/clrp_pretrained_03' '/content/clrp-roberta-large'\n","  # ライブラリのパス指定\n","  sys.path.append('/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules')\n"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RV9-VwbpZLZ9","executionInfo":{"status":"ok","timestamp":1626665297434,"user_tz":-540,"elapsed":216,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["from pathlib import Path\n","\n","# input\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    DATA_DIR = Path('../input/commonlitreadabilityprize/')\n","\n","elif 'google.colab' in sys.modules: # Colab環境\n","    DATA_DIR = Path('/content/input/commonlitreadabilityprize')\n","\n","else:\n","    DATA_DIR = Path('../00_input/commonlitreadabilityprize/')"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"x5difyXe00UV","executionInfo":{"status":"ok","timestamp":1626665628950,"user_tz":-540,"elapsed":234,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["from pathlib import Path\n","\n","# tokenizer\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    TOKENIZER_DIR = '../input/roberta-transformers-pytorch/roberta-large'\n","elif 'google.colab' in sys.modules: # Colab環境\n","    TOKENIZER_DIR = 'roberta-large' # 仮で、毎回DLする想定のモデル名を指定。あとで変更予定。\n","else:\n","    TOKENIZER_DIR = 'roberta-large'"],"execution_count":39,"outputs":[]},{"cell_type":"code","metadata":{"id":"tKjsUxnOeDYl","executionInfo":{"status":"ok","timestamp":1626665631055,"user_tz":-540,"elapsed":252,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["from pathlib import Path\n","\n","# pre-trained model\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    PRE_TRAINED_MODEL_DIR = '../input/roberta-transformers-pytorch/roberta-large'\n","elif 'google.colab' in sys.modules: # Colab環境\n","    PRE_TRAINED_MODEL_DIR = '/content/clrp-roberta-large' # 仮で、毎回DLする想定のモデル名を指定。あとで変更予定。\n","else:\n","    PRE_TRAINED_MODEL_DIR = 'roberta-large'"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZLaT2V0ReoAZ","executionInfo":{"status":"ok","timestamp":1626665633288,"user_tz":-540,"elapsed":241,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["UPLOAD_DIR = Path('/content/model')\n","EX_NO = '046-train-01'  # 実験番号などを入れる、folderのpathにする\n","USERID = 'calpis10000'"],"execution_count":41,"outputs":[]},{"cell_type":"code","metadata":{"id":"hOGjAb4pAJ0F","executionInfo":{"status":"ok","timestamp":1626665633681,"user_tz":-540,"elapsed":3,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["import subprocess\n","import shlex\n","\n","def gpuinfo():\n","    \"\"\"\n","    Returns size of total GPU RAM and used GPU RAM.\n","\n","    Parameters\n","    ----------\n","    None\n","\n","    Returns\n","    -------\n","    info : dict\n","        Total GPU RAM in integer for key 'total_MiB'.\n","        Used GPU RAM in integer for key 'used_MiB'.\n","    \"\"\"\n","\n","    command = 'nvidia-smi -q -d MEMORY | sed -n \"/FB Memory Usage/,/Free/p\" | sed -e \"1d\" -e \"4d\" -e \"s/ MiB//g\" | cut -d \":\" -f 2 | cut -c2-'\n","    commands = [shlex.split(part) for part in command.split(' | ')]\n","    for i, cmd in enumerate(commands):\n","        if i==0:\n","            res = subprocess.Popen(cmd, stdout=subprocess.PIPE)\n","        else:\n","            res = subprocess.Popen(cmd, stdin=res.stdout, stdout=subprocess.PIPE)\n","    total, used = map(int, res.communicate()[0].decode('utf-8').strip().split('\\n'))\n","    info = {'total_MiB':total, 'used_MiB':used}\n","    return info\n"],"execution_count":42,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g3-6m5MKXecB"},"source":["# Overview\n","This nb is based on copy from https://www.kaggle.com/andretugan/lightweight-roberta-solution-in-pytorch .\n","\n","Acknowledgments(from base nb): \n","some ideas were taken from kernels by [Torch](https://www.kaggle.com/rhtsingh) and [Maunish](https://www.kaggle.com/maunish)."]},{"cell_type":"code","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-04T06:26:32.834365Z","iopub.execute_input":"2021-07-04T06:26:32.834903Z","iopub.status.idle":"2021-07-04T06:26:40.143740Z","shell.execute_reply.started":"2021-07-04T06:26:32.834785Z","shell.execute_reply":"2021-07-04T06:26:40.142864Z"},"trusted":true,"id":"HRsRZ06WXecD","executionInfo":{"status":"ok","timestamp":1626665636149,"user_tz":-540,"elapsed":3,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["import os\n","import math\n","import random\n","import time\n","\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","\n","from transformers import AdamW # optimizer\n","from transformers import AutoTokenizer\n","from transformers import AutoModel\n","from transformers import AutoConfig\n","from transformers import get_cosine_schedule_with_warmup # scheduler\n","from pytorch_memlab import profile\n","import pytorch_memlab\n","from pytorch_memlab import MemReporter\n","\n","from sklearn.model_selection import KFold, StratifiedKFold\n","\n","import gc\n","gc.enable()"],"execution_count":43,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.145217Z","iopub.execute_input":"2021-07-04T06:26:40.145539Z","iopub.status.idle":"2021-07-04T06:26:40.201326Z","shell.execute_reply.started":"2021-07-04T06:26:40.145504Z","shell.execute_reply":"2021-07-04T06:26:40.200136Z"},"trusted":true,"id":"omBfwshTXecE","executionInfo":{"status":"ok","timestamp":1626665641700,"user_tz":-540,"elapsed":235,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["NUM_FOLDS = 5 # K Fold\n","NUM_EPOCHS = 5 # Epochs\n","BATCH_SIZE = 12 # Batch Size\n","MAX_LEN = 248 # ベクトル長\n","EVAL_SCHEDULE = [(0.55, 64), (0.50, 32), (0.49, 16), (0.48, 8), (0.47, 4), (0.46, 2), (-1., 1)] # schedulerの何らかの設定？\n","ROBERTA_PATH = PRE_TRAINED_MODEL_DIR # roberta pre-trainedモデル(モデルとして指定)\n","TOKENIZER_PATH = TOKENIZER_DIR # roberta pre-trainedモデル(Tokenizerとして指定)\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\" # cudaがなければcpuを使えばいいじゃない"],"execution_count":44,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.203398Z","iopub.execute_input":"2021-07-04T06:26:40.204055Z","iopub.status.idle":"2021-07-04T06:26:40.211572Z","shell.execute_reply.started":"2021-07-04T06:26:40.204015Z","shell.execute_reply":"2021-07-04T06:26:40.210762Z"},"trusted":true,"id":"4qcuXqwtXecF","executionInfo":{"status":"ok","timestamp":1626665642749,"user_tz":-540,"elapsed":2,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["def set_random_seed(random_seed):\n","    random.seed(random_seed)\n","    np.random.seed(random_seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(random_seed)\n","\n","    torch.manual_seed(random_seed)\n","    torch.cuda.manual_seed(random_seed)\n","    torch.cuda.manual_seed_all(random_seed)\n","\n","    torch.backends.cudnn.deterministic = True# cudnnによる最適化で結果が変わらないためのおまじない "],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.214188Z","iopub.execute_input":"2021-07-04T06:26:40.214809Z","iopub.status.idle":"2021-07-04T06:26:40.309744Z","shell.execute_reply.started":"2021-07-04T06:26:40.214769Z","shell.execute_reply":"2021-07-04T06:26:40.308926Z"},"trusted":true,"id":"70PyLsJTXecF","executionInfo":{"status":"ok","timestamp":1626665643718,"user_tz":-540,"elapsed":3,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# train, testを読む\n","train_df = pd.read_csv(DATA_DIR/\"train.csv\")\n","\n","# Remove incomplete entries if any.\n","train_df.drop(train_df[(train_df.target == 0) & (train_df.standard_error == 0)].index,\n","              inplace=True)\n","train_df.reset_index(drop=True, inplace=True)\n","\n","test_df = pd.read_csv(DATA_DIR/\"test.csv\")\n","submission_df = pd.read_csv(DATA_DIR/\"sample_submission.csv\")"],"execution_count":46,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"9ZYOB59L8qtA","executionInfo":{"status":"ok","timestamp":1626665644493,"user_tz":-540,"elapsed":10,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"9d2bca18-e0cc-4130-ae2a-d6d57531248c"},"source":["train_df.head()\n"],"execution_count":47,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>url_legal</th>\n","      <th>license</th>\n","      <th>excerpt</th>\n","      <th>target</th>\n","      <th>standard_error</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>c12129c31</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>When the young people returned to the ballroom...</td>\n","      <td>-0.340259</td>\n","      <td>0.464009</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>85aa80a4c</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>All through dinner time, Mrs. Fayre was somewh...</td>\n","      <td>-0.315372</td>\n","      <td>0.480805</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>b69ac6792</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>As Roger had predicted, the snow departed as q...</td>\n","      <td>-0.580118</td>\n","      <td>0.476676</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>dd1000b26</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>And outside before the palace a great garden w...</td>\n","      <td>-1.054013</td>\n","      <td>0.450007</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>37c1b32fb</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Once upon a time there were Three Bears who li...</td>\n","      <td>0.247197</td>\n","      <td>0.510845</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          id url_legal  ...    target standard_error\n","0  c12129c31       NaN  ... -0.340259       0.464009\n","1  85aa80a4c       NaN  ... -0.315372       0.480805\n","2  b69ac6792       NaN  ... -0.580118       0.476676\n","3  dd1000b26       NaN  ... -1.054013       0.450007\n","4  37c1b32fb       NaN  ...  0.247197       0.510845\n","\n","[5 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":47}]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.311021Z","iopub.execute_input":"2021-07-04T06:26:40.311347Z","iopub.status.idle":"2021-07-04T06:26:40.624393Z","shell.execute_reply.started":"2021-07-04T06:26:40.311314Z","shell.execute_reply":"2021-07-04T06:26:40.623347Z"},"trusted":true,"id":"xf0662k4XecF","colab":{"base_uri":"https://localhost:8080/","height":213,"referenced_widgets":["362f68b336e747b48e583b6b00ca3e47","fed46087e93a4b5d86042207ed092645","01321f8df04942fba9b011e77d67659d","2d38c1dc74b94980a83a42e81efe42f7","db3ba3bed82c4976bbef784281ebdb05","a2d087c5c45b47baa5aed45b3d9eea52","999c7b0f60de4e90b490100ac9d002a6","4d9d6d200a2445a491f708dd73060e1c","0d3577dce90e4527b607b4217b8e0ff9","b5f5b9df3237448c8cb1bc29fe93f9b8","4fab78a060a245e0a0d055ef0457e64c","99991d1239f343e68af3c5a494316774","e3ff7195c8bd4c2f8a63880a8996d96a","ae55f816225a4d6489f546296820ac4d","72a9147d58c64aeb80b9ab2827aa7620","0cb1c36625ed4bf99cffbf13bd8b2208","20a1c0fb2a2a4854a8d6c119d366187d","b6850d44d6a84d34b892b3dd9eac98e4","b76293a3badb4ff38c912cb76415e7a9","5fca1d72ca7b4a23a3b49c5633f868d5","69dbd5c0a63348c19f53cf8f14f99ad6","9a8e814374624bcabe80578b8150758e","26b3a39c8138480cb91c13423e57f5ae","cf7ebbf80753458ca068cf99911fdd9d","7698c8581cba49b39db1d1d7ae22bbfd","a41b10d7478046e38ed5a049a6532e01","92d92198d5384d9797c7e468e0ed44b4","80cd0ebcf9cc4a3e96524e52ab9697fb","da69f78ed61a4f3eb5ff190a8693fed1","b8b71675368d4f689f622daf82f4bd82","bef6e35f19054784a895d657871c3f7e","079c57aaebca4f95a8f455d32a194c12"]},"executionInfo":{"status":"ok","timestamp":1626665650836,"user_tz":-540,"elapsed":5309,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"a8504a22-ac6f-4380-af43-9a8c4ac4f0cc"},"source":["# tokenizerを指定\n","tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)"],"execution_count":48,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"362f68b336e747b48e583b6b00ca3e47","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=482.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0d3577dce90e4527b607b4217b8e0ff9","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"20a1c0fb2a2a4854a8d6c119d366187d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7698c8581cba49b39db1d1d7ae22bbfd","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355863.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"N6aaghNkXecG"},"source":["# Dataset"]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.628883Z","iopub.execute_input":"2021-07-04T06:26:40.629347Z","iopub.status.idle":"2021-07-04T06:26:40.644338Z","shell.execute_reply.started":"2021-07-04T06:26:40.629309Z","shell.execute_reply":"2021-07-04T06:26:40.643336Z"},"trusted":true,"id":"zkopT0U1XecG","executionInfo":{"status":"ok","timestamp":1626665654005,"user_tz":-540,"elapsed":225,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# Dataset用のClass。おそらく、trainとtestでインスタンスを生成し、DataFrameと同じように扱えるような思想。\n","class LitDataset(Dataset):\n","    def __init__(self, df, inference_only=False):\n","        super().__init__()\n","\n","        self.df = df        \n","        self.inference_only = inference_only # Testデータ用フラグ\n","        self.text = df.excerpt.tolist() # 分析対象カラムをlistにする。(分かち書きではなく、Seriesをlistへ変換するような処理)\n","        #self.text = [text.replace(\"\\n\", \" \") for text in self.text] # 単語単位で分かち書きする場合\n","        \n","        if not self.inference_only:\n","            self.target = torch.tensor(df.target.values, dtype=torch.float32) # trainのみ、targetをtensorに変換\n","            self.standard_error = torch.tensor(df.standard_error.values, dtype=torch.float32) \n","\n","        self.encoded = tokenizer.batch_encode_plus( # textをtokenize\n","            self.text,\n","            padding = 'max_length',            \n","            max_length = MAX_LEN,\n","            truncation = True, # 最大長を超える文字は切り捨て\n","            return_attention_mask=True\n","        )        \n"," \n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    \n","    def __getitem__(self, index): # 変換結果を返す\n","        input_ids = torch.tensor(self.encoded['input_ids'][index])\n","        attention_mask = torch.tensor(self.encoded['attention_mask'][index])\n","        \n","        if self.inference_only:\n","            return (input_ids, attention_mask)            \n","        else:\n","            target = self.target[index]\n","            standard_error = self.standard_error[index]\n","            return (input_ids, attention_mask, target, standard_error)"],"execution_count":49,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KKtdy32wXecG"},"source":["# Model\n","The model is inspired by the one from [Maunish](https://www.kaggle.com/maunish/clrp-roberta-svm)."]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.649629Z","iopub.execute_input":"2021-07-04T06:26:40.650066Z","iopub.status.idle":"2021-07-04T06:26:40.666374Z","shell.execute_reply.started":"2021-07-04T06:26:40.650002Z","shell.execute_reply":"2021-07-04T06:26:40.665211Z"},"trusted":true,"id":"BpkxjXEUXecH","executionInfo":{"status":"ok","timestamp":1626665655630,"user_tz":-540,"elapsed":221,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["class LitModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        config = AutoConfig.from_pretrained(ROBERTA_PATH) # pretrainedからconfigを読み込み\n","        config.update({\"output_hidden_states\":True, # config更新: embedding層を抽出\n","                       \"hidden_dropout_prob\": 0.0, # config更新: dropoutしない\n","                       \"layer_norm_eps\": 1e-7}) # config更新: layer normalizationのepsilon                      \n","        \n","        self.roberta = AutoModel.from_pretrained(ROBERTA_PATH, config=config) # cpuで処理する\n","            \n","        self.attention = nn.Sequential(# attentionレイヤー            \n","            nn.Linear(config.hidden_size, 512),      \n","            nn.Tanh(),                       \n","            nn.Linear(512, 1),\n","            nn.Softmax(dim=1)\n","        )\n","\n","        self.regressor = nn.Sequential( # 出力レイヤー                    \n","            nn.Linear(config.hidden_size, 2)                        \n","        )\n","\n","    def forward(self, input_ids, attention_mask):\n","        roberta_output = self.roberta(input_ids=input_ids, # robertaに入力データを流し、出力としてrobertaモデル(layerの複合体)を得る\n","                                      attention_mask=attention_mask)     \n","\n","        last_hidden_state = roberta_output.hidden_states[-1] # robertaモデルの最後のlayerを得る\n","        weights = self.attention(last_hidden_state) # robertaの最後のlayerをattentionへ入力し、出力として重みを得る                \n","        context_vector = torch.sum(weights * last_hidden_state, dim=1) # 重み×最後の層を足し合わせて文書ベクトルとする。\n","        return self.regressor(context_vector) # 文書ベクトルを線形層に入力し、targetを出力する\n","\n","        # https://www.kaggle.com/rhtsingh/utilizing-transformer-representations-efficiently\n","        #last_hidden_state = roberta_output[0]\n","        #input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        #sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        #sum_mask = input_mask_expanded.sum(1)\n","        #sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        #mean_embeddings = sum_embeddings / sum_mask\n","\n","        \n","        # Now we reduce the context vector to the prediction score.\n","        #return self.regressor(mean_embeddings) # 文書ベクトルを線形層に入力し、targetを出力する"],"execution_count":50,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.672515Z","iopub.execute_input":"2021-07-04T06:26:40.672944Z","iopub.status.idle":"2021-07-04T06:26:40.684593Z","shell.execute_reply.started":"2021-07-04T06:26:40.672908Z","shell.execute_reply":"2021-07-04T06:26:40.683569Z"},"trusted":true,"id":"bB4jvQTxXecH","executionInfo":{"status":"ok","timestamp":1626665671206,"user_tz":-540,"elapsed":214,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 評価指標(MSE)の計算。最終的に、ルートしてRMSEにすると思われる。\n","def eval_mse(model, data_loader):\n","    \"\"\"Evaluates the mean squared error of the |model| on |data_loader|\"\"\"\n","    model.eval() # evalモードを選択。Batch Normとかdropoutをしなくなる           \n","    mse_mean_sum = 0\n","    mse_std_sum = 0\n","\n","    with torch.no_grad(): # 勾配の計算をしないBlock\n","        for batch_num, (input_ids, attention_mask, target, standard_error) in enumerate(data_loader): # data_loaderからinput, attentin_mask, targetをbatchごとに取り出す\n","            input_ids = input_ids.to(DEVICE)   \n","            attention_mask = attention_mask.to(DEVICE)   \n","            target = target.to(DEVICE)      \n","            standard_error = standard_error.to(DEVICE) \n","            \n","            output = model(input_ids, attention_mask) # 取得した値をモデルへ入力し、出力として予測値を得る。\n","\n","            mse_mean_sum += nn.MSELoss(reduction=\"sum\")(output[:,0].flatten(), target).item() # 誤差の合計を得る(Batchごとに計算した誤差を足し上げる)\n","            mse_std_sum += nn.MSELoss(reduction=\"sum\")(output[:,1].flatten(), target).item() # 誤差の合計を得る(Batchごとに計算した誤差を足し上げる)\n","\n","    del input_ids\n","    del attention_mask\n","    del target\n","\n","    mse_mean_result = mse_mean_sum / len(data_loader.dataset)\n","    mse_std_result = mse_std_sum / len(data_loader.dataset)\n","  \n","    return mse_mean_result, mse_std_result # 誤差の合計をdataset長で除し、mseを取得＆返す"],"execution_count":51,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.690155Z","iopub.execute_input":"2021-07-04T06:26:40.692530Z","iopub.status.idle":"2021-07-04T06:26:40.703425Z","shell.execute_reply.started":"2021-07-04T06:26:40.692488Z","shell.execute_reply":"2021-07-04T06:26:40.702366Z"},"trusted":true,"id":"47bDno_LXecI","executionInfo":{"status":"ok","timestamp":1626665673631,"user_tz":-540,"elapsed":225,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 推論結果を返す\n","def predict(model, data_loader):\n","    \"\"\"Returns an np.array with predictions of the |model| on |data_loader|\"\"\"\n","    model.eval() # evalモード(dropout, batch_normしない)\n","\n","    result = np.zeros(len(data_loader.dataset)) # 結果をdataset長のzero配列として用意\n","    index = 0\n","    \n","    with torch.no_grad(): # 勾配の計算をしないblock(inputすると、現状の重みによる推論結果を返す)\n","        for batch_num, (input_ids, attention_mask) in enumerate(data_loader): # data_loaderからbatchごとにinputを得る\n","            input_ids = input_ids.to(DEVICE)\n","            attention_mask = attention_mask.to(DEVICE)\n","                        \n","            output = model(input_ids, attention_mask) # modelにinputを入力し、予測結果を得る。\n","\n","            result[index : index + output[:,0].shape[0]] = output[:,0].flatten().to(\"cpu\") # result[index ~ predの長さ]へ、予測結果を格納\n","            index += pred.shape[0] # indexを更新\n","\n","    return result # 全batchで推論が終わったら、結果を返す"],"execution_count":52,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.708605Z","iopub.execute_input":"2021-07-04T06:26:40.709024Z","iopub.status.idle":"2021-07-04T06:26:40.730675Z","shell.execute_reply.started":"2021-07-04T06:26:40.708983Z","shell.execute_reply":"2021-07-04T06:26:40.729705Z"},"trusted":true,"id":"oInneuAmXecI","executionInfo":{"status":"ok","timestamp":1626665675539,"user_tz":-540,"elapsed":215,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 学習\n","def train(model, # モデル\n","          model_path, # モデルのアウトプット先\n","          train_loader, # train-setのdata_loader\n","          val_loader, # valid-setのdata_loader\n","          optimizer, # optimizer\n","          scheduler=None, # scheduler, デフォルトはNone\n","          num_epochs=NUM_EPOCHS # epoch数、notebook冒頭で指定した値\n","         ):    \n","    \n","    best_val_rmse = None\n","    best_epoch = 0\n","    step = 0\n","    last_eval_step = 0\n","    eval_period = EVAL_SCHEDULE[0][1] # eval期間(って何？) 冒頭で決めたEVAL_SCHEDULEの最初のtupleの[1]を取得\n","\n","    start = time.time() # 時間計測用\n","\n","    for epoch in range(num_epochs): # 指定したEpoch数だけ繰り返し\n","        val_rmse = None         \n","\n","        for batch_num, (input_ids, attention_mask, target, standard_error) in enumerate(train_loader): # train_loaderからinput, targetを取得\n","            input_ids = input_ids.to(DEVICE) # inputをDEVICEへ突っ込む\n","            attention_mask = attention_mask.to(DEVICE)       \n","            target = target.to(DEVICE)\n","            standard_error = standard_error.to(DEVICE)  \n","\n","            optimizer.zero_grad() # 勾配を初期化            \n","            model.train() # 学習モード開始\n","\n","            # https://www.kaggle.com/c/commonlitreadabilityprize/discussion/239421\n","            output = model(input_ids, attention_mask) # input,attention_maskを入力し、予測結果を得る\n","            p = torch.distributions.Normal(output[:,0], torch.sqrt(output[:,1]**2))\n","            q = torch.distributions.Normal(target, standard_error)\n","            kl_vector = torch.distributions.kl_divergence(p, q)\n","            loss = kl_vector.mean()\n","\n","            loss.backward() # 誤差逆伝播法により勾配を得る\n","            optimizer.step() # 重みを更新する\n","\n","            if scheduler:\n","                scheduler.step() # schedulerが与えられた場合は、schedulerの学習率更新\n","            \n","            if step >= last_eval_step + eval_period: # batchを回すごとにstepを増やしていって、「前回evalしたstep + eval_period(16)」を超えたら実行。\n","                # Evaluate the model on val_loader.\n","                elapsed_seconds = time.time() - start # 経過時間\n","                num_steps = step - last_eval_step # 経過ステップ数\n","                print(f\"\\n{num_steps} steps took {elapsed_seconds:0.3} seconds\")\n","                last_eval_step = step # 前回stepの更新\n","                \n","                # valid-setによるrmse計算\n","                train_mean_mse = nn.MSELoss(reduction=\"mean\")(output[:,0].flatten(), target) \n","                train_std_mse = nn.MSELoss(reduction=\"mean\")(torch.sqrt(output[:,1]**2).flatten(), standard_error) \n","\n","                train_mean_rmse = math.sqrt(train_mean_mse)\n","                train_std_rmse = math.sqrt(train_std_mse)\n","\n","                val_mean_mse, val_std_mse = eval_mse(model, val_loader)\n","                val_mean_rmse = math.sqrt(val_mean_mse)                            \n","                val_std_rmse = math.sqrt(val_std_mse)                            \n","\n","                print(f\"Epoch: {epoch} batch_num: {batch_num}\")\n","                print(f\"train_rmse_target: {train_mean_rmse:0.4}\",\n","                      f\"train_rmse_stderror: {train_std_rmse:0.4}\",\n","                      f\"train_kl_div: {loss:0.4}\",\n","                      )\n","                print(f\"val_rmse_target: {val_mean_rmse:0.4}\",\n","                      f\"val_rmse_stderror: {val_std_rmse:0.4}\"\n","                      )\n","\n","                for rmse, period in EVAL_SCHEDULE: # eval_periodをvalid-rmseで切り替える処理\n","                    if val_mean_rmse >= rmse: # valid rmseをEVAL_SCHEDULEと比較し、0項 > valid rmseとなるまで回す : EVAL_SCHEDULE = [(0.50, 16), (0.49, 8), (0.48, 4), (0.47, 2), (-1., 1)]\n","                        eval_period = period # eval_periodを更新\n","                        break                               \n","\n","                if not best_val_rmse or val_mean_rmse < best_val_rmse: # 初回(best_val_rmse==None), またはbest_val_rmseを更新したらモデルを保存する\n","                    best_val_rmse = val_mean_rmse\n","                    best_epoch = epoch\n","                    torch.save(model.state_dict(), model_path) # 最高の自分を保存\n","                    print(f\"New best_val_rmse: {best_val_rmse:0.4}\")\n","                else:       \n","                    print(f\"Still best_val_rmse: {best_val_rmse:0.4}\", # 更新されない場合は、元のスコアを表示\n","                          f\"(from epoch {best_epoch})\")      \n","                                                  \n","                start = time.time()\n","            \n","            # batchごとにメモリ解放\n","            del input_ids\n","            del attention_mask\n","            del target\n","            torch.cuda.empty_cache()                                            \n","            step += 1\n","    \n","    return best_val_rmse"],"execution_count":53,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.735798Z","iopub.execute_input":"2021-07-04T06:26:40.738398Z","iopub.status.idle":"2021-07-04T06:26:40.750876Z","shell.execute_reply.started":"2021-07-04T06:26:40.738356Z","shell.execute_reply":"2021-07-04T06:26:40.749635Z"},"trusted":true,"id":"rMY0fjXwXecJ","executionInfo":{"status":"ok","timestamp":1626665677473,"user_tz":-540,"elapsed":227,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# optimizerの作成\n","def create_optimizer(model):\n","    named_parameters = list(model.named_parameters()) # モデルパラメータの取得\n","    \n","    roberta_parameters = list(model.roberta.named_parameters())[:-2] # パラメータをroberta用、attention用、regressor用に格納。(直接引っ張ってくる形式に変更)\n","    attention_parameters = list(model.attention.named_parameters())\n","    regressor_parameters = list(model.regressor.named_parameters())\n","        \n","    attention_group = [params for (name, params) in attention_parameters] # attention用パラメータをリストとして取得\n","    regressor_group = [params for (name, params) in regressor_parameters] # reg用パラメータをリストとして取得\n","\n","    parameters = []\n","    parameters.append({\"params\": attention_group}) # パラメータをリストに辞書として格納していく\n","    parameters.append({\"params\": regressor_group})\n","\n","    for layer_num, (name, params) in enumerate(roberta_parameters): # レイヤーごとにname, paramsを取得していろんな処理\n","        weight_decay = 0.0 if \"bias\" in name else 0.01\n","\n","        lr = 2e-6\n","\n","        if layer_num >= 69:        \n","            lr = 5e-6\n","\n","        if layer_num >= 133:\n","            lr = 1e-5\n","\n","        parameters.append({\"params\": params,\n","                           \"weight_decay\": weight_decay,\n","                           \"lr\": lr})\n","\n","    return AdamW(parameters) # 最終的に、AdamWにパラメータを入力する。\n"],"execution_count":54,"outputs":[]},{"cell_type":"code","metadata":{"id":"EbaJojz0Zjif","executionInfo":{"status":"ok","timestamp":1626665679489,"user_tz":-540,"elapsed":327,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# https://www.kaggle.com/abhishek/step-1-create-folds\n","def create_folds(data, num_splits, SEED, return_df=False):\n","    # we create a new column called kfold and fill it with -1\n","    data[\"kfold\"] = -1\n","    \n","    # the next step is to randomize the rows of the data\n","    data = data.sample(frac=1).reset_index(drop=True)\n","\n","    # calculate number of bins by Sturge's rule\n","    # I take the floor of the value, you can also\n","    # just round it\n","    num_bins = int(np.floor(1 + np.log2(len(data))))\n","    \n","    # bin targets\n","    data.loc[:, \"bins_tg\"] = pd.cut(\n","        data[\"target\"], bins=num_bins, labels=False\n","    ).map(lambda x: str(x))\n","\n","    # bin standard_error\n","    data.loc[:, \"bins_std\"] = pd.cut(\n","        data[\"standard_error\"], bins=num_bins, labels=False\n","    )\n","\n","    # bins\n","    data.loc[:, \"bins\"] = data['bins_tg'].map(lambda x: str(x)) + data['bins_std'].map(lambda x: str(x))\n","\n","    # initiate the kfold class from model_selection module\n","    kf = StratifiedKFold(n_splits=5, random_state=SEED, shuffle=True)\n","\n","    # note that, instead of targets, we use bins!\n","    if return_df:\n","      for f, (t_, v_) in enumerate(kf.split(X=data, y=data.bins.values)):\n","        data.loc[v_, 'kfold'] = f\n","      return data\n","    else:\n","      return kf.split(X=data, y=data.bins.values)"],"execution_count":55,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":320},"id":"vAmhaYaylMk5","executionInfo":{"status":"ok","timestamp":1626676233077,"user_tz":-540,"elapsed":289,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"6ed65d35-d7e3-420e-b824-bacf271bd84e"},"source":["# 検証用\n","SEED = 1000\n","st_kfold_bins_df = create_folds(train_df, num_splits=5, SEED=SEED, return_df=True)\n","st_kfold_bins_df['bins_tg'] = st_kfold_bins_df['bins_tg'].map(lambda x: float(x))\n","st_kfold_bins_df['bins_std'] = st_kfold_bins_df['bins_std'].map(lambda x: float(x))\n","st_kfold_bins_df.groupby('kfold').agg({'bins_tg': ['min', 'max', 'mean'],\n","                                    'bins_std': ['min', 'max', 'mean']})"],"execution_count":65,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  % (min_groups, self.n_splits)), UserWarning)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","\n","    .dataframe thead tr:last-of-type th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th></th>\n","      <th colspan=\"3\" halign=\"left\">bins_tg</th>\n","      <th colspan=\"3\" halign=\"left\">bins_std</th>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <th>min</th>\n","      <th>max</th>\n","      <th>mean</th>\n","      <th>min</th>\n","      <th>max</th>\n","      <th>mean</th>\n","    </tr>\n","    <tr>\n","      <th>kfold</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>5.553792</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>2.932981</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>5.532628</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>2.950617</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>5.537919</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>2.924162</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>5.560071</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>2.932862</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>5.565371</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>2.904594</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      bins_tg                 bins_std                \n","          min   max      mean      min   max      mean\n","kfold                                                 \n","0         0.0  11.0  5.553792      0.0  11.0  2.932981\n","1         0.0  11.0  5.532628      0.0  11.0  2.950617\n","2         0.0  11.0  5.537919      0.0  11.0  2.924162\n","3         0.0  11.0  5.560071      0.0  11.0  2.932862\n","4         0.0  11.0  5.565371      0.0  11.0  2.904594"]},"metadata":{"tags":[]},"execution_count":65}]},{"cell_type":"code","metadata":{"id":"TyjgRCu3mmqG","executionInfo":{"status":"ok","timestamp":1626665683401,"user_tz":-540,"elapsed":218,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":56,"outputs":[]},{"cell_type":"code","metadata":{"id":"4PLKHwvKtNBn","executionInfo":{"status":"ok","timestamp":1626665683632,"user_tz":-540,"elapsed":2,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["def train_and_save_model(train_indices, val_indices, model_path):\n","    train_dataset = LitDataset(train_df.loc[train_indices]) # train, validのDataset\n","    val_dataset = LitDataset(train_df.loc[val_indices])\n","        \n","    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n","                              drop_last=True, shuffle=True, num_workers=2) # train, validのDataLoader\n","    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n","                            drop_last=False, shuffle=False, num_workers=2)    \n","\n","    model = LitModel().to(DEVICE) # modelをDEVICEへぶち込む\n","    optimizer = create_optimizer(model) # optimizerをモデルから作成\n","    scheduler = get_cosine_schedule_with_warmup( # schedulerを作成\n","        optimizer,\n","        num_training_steps=NUM_EPOCHS * len(train_loader),\n","        num_warmup_steps=50)    \n","    rmse = train(model, model_path, train_loader, val_loader, optimizer, scheduler=scheduler)\n","\n","    del train_dataset\n","    del val_dataset\n","    del train_loader\n","    del val_loader\n","    del model\n","    del optimizer\n","    del scheduler\n","    gc.collect() \n","    torch.cuda.empty_cache()\n","    return rmse"],"execution_count":57,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.755813Z","iopub.execute_input":"2021-07-04T06:26:40.758373Z","iopub.status.idle":"2021-07-04T06:27:12.493221Z","shell.execute_reply.started":"2021-07-04T06:26:40.758265Z","shell.execute_reply":"2021-07-04T06:27:12.490139Z"},"trusted":true,"id":"k2LGJD3XXecK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626674243176,"user_tz":-540,"elapsed":8557728,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"63127ba5-2a84-4463-ed50-dddca0c81d77"},"source":["# 実行処理。 KFold & 学習\n","SEED = 1000\n","list_val_rmse = []\n","\n","#kfold = KFold(n_splits=NUM_FOLDS, random_state=SEED, shuffle=True)\n","kfold = create_folds(train_df, 5, SEED=SEED, return_df=False) # binsで切る場合\n","\n","for fold, (train_indices, val_indices) in enumerate(kfold):    \n","    print(f\"\\nFold {fold + 1}/{NUM_FOLDS}\")\n","    print(gpuinfo())\n","    model_path = f\"model_{fold + 1}.pth\" # model_fold数_.pth\n","    set_random_seed(SEED + fold) # SEEDはfold別に変わるようにする\n","    list_val_rmse.append(train_and_save_model(train_indices, val_indices, model_path))\n","\n","    print(\"\\nPerformance estimates:\")\n","    print(list_val_rmse)\n","    print(\"Mean:\", np.array(list_val_rmse).mean())\n","    print(gpuinfo())"],"execution_count":58,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  % (min_groups, self.n_splits)), UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Fold 1/5\n","{'total_MiB': 16280, 'used_MiB': 2}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 82.6 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.6282 train_rmse_stderror: 0.07424 train_kl_div: 0.8315\n","val_rmse_target: 0.6764 val_rmse_stderror: 1.77\n","New best_val_rmse: 0.6764\n","\n","64 steps took 81.1 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.5041 train_rmse_stderror: 0.0533 train_kl_div: 0.5427\n","val_rmse_target: 0.6269 val_rmse_stderror: 1.793\n","New best_val_rmse: 0.6269\n","\n","64 steps took 81.3 seconds\n","Epoch: 1 batch_num: 4\n","train_rmse_target: 0.5143 train_rmse_stderror: 0.04201 train_kl_div: 0.5566\n","val_rmse_target: 0.5618 val_rmse_stderror: 1.765\n","New best_val_rmse: 0.5618\n","\n","64 steps took 81.1 seconds\n","Epoch: 1 batch_num: 68\n","train_rmse_target: 0.5395 train_rmse_stderror: 0.04733 train_kl_div: 0.5378\n","val_rmse_target: 0.5745 val_rmse_stderror: 1.765\n","Still best_val_rmse: 0.5618 (from epoch 1)\n","\n","64 steps took 81.1 seconds\n","Epoch: 1 batch_num: 132\n","train_rmse_target: 0.3457 train_rmse_stderror: 0.03379 train_kl_div: 0.2665\n","val_rmse_target: 0.5305 val_rmse_stderror: 1.774\n","New best_val_rmse: 0.5305\n","\n","32 steps took 40.6 seconds\n","Epoch: 1 batch_num: 164\n","train_rmse_target: 0.3732 train_rmse_stderror: 0.0407 train_kl_div: 0.2919\n","val_rmse_target: 0.5364 val_rmse_stderror: 1.756\n","Still best_val_rmse: 0.5305 (from epoch 1)\n","\n","32 steps took 40.7 seconds\n","Epoch: 2 batch_num: 8\n","train_rmse_target: 0.2673 train_rmse_stderror: 0.04016 train_kl_div: 0.1437\n","val_rmse_target: 0.5119 val_rmse_stderror: 1.768\n","New best_val_rmse: 0.5119\n","\n","32 steps took 40.6 seconds\n","Epoch: 2 batch_num: 40\n","train_rmse_target: 0.302 train_rmse_stderror: 0.03242 train_kl_div: 0.1844\n","val_rmse_target: 0.5122 val_rmse_stderror: 1.766\n","Still best_val_rmse: 0.5119 (from epoch 2)\n","\n","32 steps took 40.6 seconds\n","Epoch: 2 batch_num: 72\n","train_rmse_target: 0.3076 train_rmse_stderror: 0.03761 train_kl_div: 0.1909\n","val_rmse_target: 0.5148 val_rmse_stderror: 1.768\n","Still best_val_rmse: 0.5119 (from epoch 2)\n","\n","32 steps took 40.6 seconds\n","Epoch: 2 batch_num: 104\n","train_rmse_target: 0.3281 train_rmse_stderror: 0.04192 train_kl_div: 0.2243\n","val_rmse_target: 0.5642 val_rmse_stderror: 1.778\n","Still best_val_rmse: 0.5119 (from epoch 2)\n","\n","64 steps took 81.1 seconds\n","Epoch: 2 batch_num: 168\n","train_rmse_target: 0.2346 train_rmse_stderror: 0.02386 train_kl_div: 0.1223\n","val_rmse_target: 0.5183 val_rmse_stderror: 1.765\n","Still best_val_rmse: 0.5119 (from epoch 2)\n","\n","32 steps took 40.7 seconds\n","Epoch: 3 batch_num: 12\n","train_rmse_target: 0.1232 train_rmse_stderror: 0.04318 train_kl_div: 0.03823\n","val_rmse_target: 0.5185 val_rmse_stderror: 1.765\n","Still best_val_rmse: 0.5119 (from epoch 2)\n","\n","32 steps took 40.5 seconds\n","Epoch: 3 batch_num: 44\n","train_rmse_target: 0.1268 train_rmse_stderror: 0.03584 train_kl_div: 0.04008\n","val_rmse_target: 0.5211 val_rmse_stderror: 1.784\n","Still best_val_rmse: 0.5119 (from epoch 2)\n","\n","32 steps took 40.5 seconds\n","Epoch: 3 batch_num: 76\n","train_rmse_target: 0.1837 train_rmse_stderror: 0.02719 train_kl_div: 0.06551\n","val_rmse_target: 0.527 val_rmse_stderror: 1.767\n","Still best_val_rmse: 0.5119 (from epoch 2)\n","\n","32 steps took 40.5 seconds\n","Epoch: 3 batch_num: 108\n","train_rmse_target: 0.1724 train_rmse_stderror: 0.03095 train_kl_div: 0.06564\n","val_rmse_target: 0.5133 val_rmse_stderror: 1.78\n","Still best_val_rmse: 0.5119 (from epoch 2)\n","\n","32 steps took 40.5 seconds\n","Epoch: 3 batch_num: 140\n","train_rmse_target: 0.138 train_rmse_stderror: 0.03623 train_kl_div: 0.03874\n","val_rmse_target: 0.5151 val_rmse_stderror: 1.778\n","Still best_val_rmse: 0.5119 (from epoch 2)\n","\n","32 steps took 40.5 seconds\n","Epoch: 3 batch_num: 172\n","train_rmse_target: 0.1111 train_rmse_stderror: 0.01827 train_kl_div: 0.02697\n","val_rmse_target: 0.5122 val_rmse_stderror: 1.77\n","Still best_val_rmse: 0.5119 (from epoch 2)\n","\n","32 steps took 40.7 seconds\n","Epoch: 4 batch_num: 16\n","train_rmse_target: 0.215 train_rmse_stderror: 0.05005 train_kl_div: 0.07803\n","val_rmse_target: 0.5171 val_rmse_stderror: 1.77\n","Still best_val_rmse: 0.5119 (from epoch 2)\n","\n","32 steps took 40.6 seconds\n","Epoch: 4 batch_num: 48\n","train_rmse_target: 0.1561 train_rmse_stderror: 0.02496 train_kl_div: 0.05439\n","val_rmse_target: 0.5152 val_rmse_stderror: 1.771\n","Still best_val_rmse: 0.5119 (from epoch 2)\n","\n","32 steps took 40.6 seconds\n","Epoch: 4 batch_num: 80\n","train_rmse_target: 0.1692 train_rmse_stderror: 0.03643 train_kl_div: 0.06651\n","val_rmse_target: 0.5166 val_rmse_stderror: 1.773\n","Still best_val_rmse: 0.5119 (from epoch 2)\n","\n","32 steps took 40.6 seconds\n","Epoch: 4 batch_num: 112\n","train_rmse_target: 0.09066 train_rmse_stderror: 0.01735 train_kl_div: 0.01905\n","val_rmse_target: 0.5186 val_rmse_stderror: 1.775\n","Still best_val_rmse: 0.5119 (from epoch 2)\n","\n","32 steps took 40.6 seconds\n","Epoch: 4 batch_num: 144\n","train_rmse_target: 0.09969 train_rmse_stderror: 0.03732 train_kl_div: 0.02642\n","val_rmse_target: 0.5183 val_rmse_stderror: 1.772\n","Still best_val_rmse: 0.5119 (from epoch 2)\n","\n","32 steps took 40.6 seconds\n","Epoch: 4 batch_num: 176\n","train_rmse_target: 0.1297 train_rmse_stderror: 0.02144 train_kl_div: 0.03653\n","val_rmse_target: 0.5184 val_rmse_stderror: 1.773\n","Still best_val_rmse: 0.5119 (from epoch 2)\n","\n","Performance estimates:\n","[0.5119349079125822]\n","Mean: 0.5119349079125822\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 2/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 82.2 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.7371 train_rmse_stderror: 0.05451 train_kl_div: 1.188\n","val_rmse_target: 0.71 val_rmse_stderror: 1.176\n","New best_val_rmse: 0.71\n","\n","64 steps took 81.2 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.566 train_rmse_stderror: 0.05597 train_kl_div: 0.6961\n","val_rmse_target: 0.5898 val_rmse_stderror: 1.125\n","New best_val_rmse: 0.5898\n","\n","64 steps took 81.4 seconds\n","Epoch: 1 batch_num: 4\n","train_rmse_target: 0.428 train_rmse_stderror: 0.05726 train_kl_div: 0.3916\n","val_rmse_target: 0.6007 val_rmse_stderror: 1.149\n","Still best_val_rmse: 0.5898 (from epoch 0)\n","\n","64 steps took 81.2 seconds\n","Epoch: 1 batch_num: 68\n","train_rmse_target: 0.5028 train_rmse_stderror: 0.03782 train_kl_div: 0.4648\n","val_rmse_target: 0.5758 val_rmse_stderror: 1.144\n","New best_val_rmse: 0.5758\n","\n","64 steps took 81.2 seconds\n","Epoch: 1 batch_num: 132\n","train_rmse_target: 0.6232 train_rmse_stderror: 0.05196 train_kl_div: 0.8073\n","val_rmse_target: 0.6402 val_rmse_stderror: 1.126\n","Still best_val_rmse: 0.5758 (from epoch 1)\n","\n","64 steps took 81.4 seconds\n","Epoch: 2 batch_num: 8\n","train_rmse_target: 0.3844 train_rmse_stderror: 0.03498 train_kl_div: 0.3221\n","val_rmse_target: 0.5148 val_rmse_stderror: 1.162\n","New best_val_rmse: 0.5148\n","\n","32 steps took 40.6 seconds\n","Epoch: 2 batch_num: 40\n","train_rmse_target: 0.3221 train_rmse_stderror: 0.04194 train_kl_div: 0.226\n","val_rmse_target: 0.5091 val_rmse_stderror: 1.153\n","New best_val_rmse: 0.5091\n","\n","32 steps took 40.6 seconds\n","Epoch: 2 batch_num: 72\n","train_rmse_target: 0.3004 train_rmse_stderror: 0.03193 train_kl_div: 0.1851\n","val_rmse_target: 0.5184 val_rmse_stderror: 1.163\n","Still best_val_rmse: 0.5091 (from epoch 2)\n","\n","32 steps took 40.6 seconds\n","Epoch: 2 batch_num: 104\n","train_rmse_target: 0.2924 train_rmse_stderror: 0.04534 train_kl_div: 0.1956\n","val_rmse_target: 0.5027 val_rmse_stderror: 1.136\n","New best_val_rmse: 0.5027\n","\n","32 steps took 40.6 seconds\n","Epoch: 2 batch_num: 136\n","train_rmse_target: 0.3095 train_rmse_stderror: 0.02715 train_kl_div: 0.2073\n","val_rmse_target: 0.5298 val_rmse_stderror: 1.14\n","Still best_val_rmse: 0.5027 (from epoch 2)\n","\n","32 steps took 40.6 seconds\n","Epoch: 2 batch_num: 168\n","train_rmse_target: 0.2835 train_rmse_stderror: 0.02949 train_kl_div: 0.1699\n","val_rmse_target: 0.5457 val_rmse_stderror: 1.141\n","Still best_val_rmse: 0.5027 (from epoch 2)\n","\n","32 steps took 40.8 seconds\n","Epoch: 3 batch_num: 12\n","train_rmse_target: 0.3237 train_rmse_stderror: 0.04438 train_kl_div: 0.2072\n","val_rmse_target: 0.5416 val_rmse_stderror: 1.137\n","Still best_val_rmse: 0.5027 (from epoch 2)\n","\n","32 steps took 40.6 seconds\n","Epoch: 3 batch_num: 44\n","train_rmse_target: 0.3156 train_rmse_stderror: 0.0354 train_kl_div: 0.1984\n","val_rmse_target: 0.5037 val_rmse_stderror: 1.146\n","Still best_val_rmse: 0.5027 (from epoch 2)\n","\n","32 steps took 40.6 seconds\n","Epoch: 3 batch_num: 76\n","train_rmse_target: 0.181 train_rmse_stderror: 0.04209 train_kl_div: 0.08051\n","val_rmse_target: 0.5341 val_rmse_stderror: 1.147\n","Still best_val_rmse: 0.5027 (from epoch 2)\n","\n","32 steps took 40.6 seconds\n","Epoch: 3 batch_num: 108\n","train_rmse_target: 0.1985 train_rmse_stderror: 0.03732 train_kl_div: 0.08669\n","val_rmse_target: 0.5061 val_rmse_stderror: 1.137\n","Still best_val_rmse: 0.5027 (from epoch 2)\n","\n","32 steps took 40.6 seconds\n","Epoch: 3 batch_num: 140\n","train_rmse_target: 0.2943 train_rmse_stderror: 0.04047 train_kl_div: 0.1785\n","val_rmse_target: 0.5243 val_rmse_stderror: 1.15\n","Still best_val_rmse: 0.5027 (from epoch 2)\n","\n","32 steps took 40.6 seconds\n","Epoch: 3 batch_num: 172\n","train_rmse_target: 0.3645 train_rmse_stderror: 0.02593 train_kl_div: 0.252\n","val_rmse_target: 0.5113 val_rmse_stderror: 1.152\n","Still best_val_rmse: 0.5027 (from epoch 2)\n","\n","32 steps took 40.8 seconds\n","Epoch: 4 batch_num: 16\n","train_rmse_target: 0.2127 train_rmse_stderror: 0.02651 train_kl_div: 0.09543\n","val_rmse_target: 0.515 val_rmse_stderror: 1.15\n","Still best_val_rmse: 0.5027 (from epoch 2)\n","\n","32 steps took 40.6 seconds\n","Epoch: 4 batch_num: 48\n","train_rmse_target: 0.2308 train_rmse_stderror: 0.04256 train_kl_div: 0.1169\n","val_rmse_target: 0.5198 val_rmse_stderror: 1.145\n","Still best_val_rmse: 0.5027 (from epoch 2)\n","\n","32 steps took 40.6 seconds\n","Epoch: 4 batch_num: 80\n","train_rmse_target: 0.2269 train_rmse_stderror: 0.03348 train_kl_div: 0.1137\n","val_rmse_target: 0.5265 val_rmse_stderror: 1.149\n","Still best_val_rmse: 0.5027 (from epoch 2)\n","\n","32 steps took 40.6 seconds\n","Epoch: 4 batch_num: 112\n","train_rmse_target: 0.34 train_rmse_stderror: 0.04443 train_kl_div: 0.1788\n","val_rmse_target: 0.5206 val_rmse_stderror: 1.15\n","Still best_val_rmse: 0.5027 (from epoch 2)\n","\n","32 steps took 40.6 seconds\n","Epoch: 4 batch_num: 144\n","train_rmse_target: 0.1787 train_rmse_stderror: 0.02822 train_kl_div: 0.06626\n","val_rmse_target: 0.5199 val_rmse_stderror: 1.15\n","Still best_val_rmse: 0.5027 (from epoch 2)\n","\n","32 steps took 40.6 seconds\n","Epoch: 4 batch_num: 176\n","train_rmse_target: 0.154 train_rmse_stderror: 0.02053 train_kl_div: 0.05491\n","val_rmse_target: 0.5198 val_rmse_stderror: 1.15\n","Still best_val_rmse: 0.5027 (from epoch 2)\n","\n","Performance estimates:\n","[0.5119349079125822, 0.502654862343284]\n","Mean: 0.5072948851279331\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 3/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 82.1 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.6538 train_rmse_stderror: 0.07434 train_kl_div: 0.9115\n","val_rmse_target: 0.6568 val_rmse_stderror: 1.724\n","New best_val_rmse: 0.6568\n","\n","64 steps took 81.2 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.6457 train_rmse_stderror: 0.04957 train_kl_div: 0.9134\n","val_rmse_target: 0.5525 val_rmse_stderror: 1.768\n","New best_val_rmse: 0.5525\n","\n","64 steps took 81.4 seconds\n","Epoch: 1 batch_num: 4\n","train_rmse_target: 0.392 train_rmse_stderror: 0.0554 train_kl_div: 0.3101\n","val_rmse_target: 0.5407 val_rmse_stderror: 1.762\n","New best_val_rmse: 0.5407\n","\n","32 steps took 40.6 seconds\n","Epoch: 1 batch_num: 36\n","train_rmse_target: 0.3632 train_rmse_stderror: 0.03256 train_kl_div: 0.2899\n","val_rmse_target: 0.5124 val_rmse_stderror: 1.742\n","New best_val_rmse: 0.5124\n","\n","32 steps took 40.6 seconds\n","Epoch: 1 batch_num: 68\n","train_rmse_target: 0.3577 train_rmse_stderror: 0.05136 train_kl_div: 0.2784\n","val_rmse_target: 0.5298 val_rmse_stderror: 1.766\n","Still best_val_rmse: 0.5124 (from epoch 1)\n","\n","32 steps took 40.6 seconds\n","Epoch: 1 batch_num: 100\n","train_rmse_target: 0.5588 train_rmse_stderror: 0.03792 train_kl_div: 0.6334\n","val_rmse_target: 0.5839 val_rmse_stderror: 1.77\n","Still best_val_rmse: 0.5124 (from epoch 1)\n","\n","64 steps took 81.2 seconds\n","Epoch: 1 batch_num: 164\n","train_rmse_target: 0.2942 train_rmse_stderror: 0.06436 train_kl_div: 0.2239\n","val_rmse_target: 0.5458 val_rmse_stderror: 1.753\n","Still best_val_rmse: 0.5124 (from epoch 1)\n","\n","32 steps took 40.7 seconds\n","Epoch: 2 batch_num: 8\n","train_rmse_target: 0.3319 train_rmse_stderror: 0.03981 train_kl_div: 0.2299\n","val_rmse_target: 0.5201 val_rmse_stderror: 1.792\n","Still best_val_rmse: 0.5124 (from epoch 1)\n","\n","32 steps took 40.6 seconds\n","Epoch: 2 batch_num: 40\n","train_rmse_target: 0.2617 train_rmse_stderror: 0.04411 train_kl_div: 0.1473\n","val_rmse_target: 0.5213 val_rmse_stderror: 1.781\n","Still best_val_rmse: 0.5124 (from epoch 1)\n","\n","32 steps took 40.6 seconds\n","Epoch: 2 batch_num: 72\n","train_rmse_target: 0.3917 train_rmse_stderror: 0.03451 train_kl_div: 0.2994\n","val_rmse_target: 0.5195 val_rmse_stderror: 1.77\n","Still best_val_rmse: 0.5124 (from epoch 1)\n","\n","32 steps took 40.6 seconds\n","Epoch: 2 batch_num: 104\n","train_rmse_target: 0.3145 train_rmse_stderror: 0.03576 train_kl_div: 0.2128\n","val_rmse_target: 0.5156 val_rmse_stderror: 1.766\n","Still best_val_rmse: 0.5124 (from epoch 1)\n","\n","32 steps took 40.6 seconds\n","Epoch: 2 batch_num: 136\n","train_rmse_target: 0.4218 train_rmse_stderror: 0.04208 train_kl_div: 0.3871\n","val_rmse_target: 0.5369 val_rmse_stderror: 1.772\n","Still best_val_rmse: 0.5124 (from epoch 1)\n","\n","32 steps took 40.6 seconds\n","Epoch: 2 batch_num: 168\n","train_rmse_target: 0.3207 train_rmse_stderror: 0.03915 train_kl_div: 0.2049\n","val_rmse_target: 0.5085 val_rmse_stderror: 1.785\n","New best_val_rmse: 0.5085\n","\n","32 steps took 40.7 seconds\n","Epoch: 3 batch_num: 12\n","train_rmse_target: 0.2107 train_rmse_stderror: 0.03586 train_kl_div: 0.0918\n","val_rmse_target: 0.5138 val_rmse_stderror: 1.772\n","Still best_val_rmse: 0.5085 (from epoch 2)\n","\n","32 steps took 40.6 seconds\n","Epoch: 3 batch_num: 44\n","train_rmse_target: 0.1959 train_rmse_stderror: 0.03962 train_kl_div: 0.08831\n","val_rmse_target: 0.5372 val_rmse_stderror: 1.764\n","Still best_val_rmse: 0.5085 (from epoch 2)\n","\n","32 steps took 40.6 seconds\n","Epoch: 3 batch_num: 76\n","train_rmse_target: 0.2513 train_rmse_stderror: 0.03501 train_kl_div: 0.1356\n","val_rmse_target: 0.5073 val_rmse_stderror: 1.773\n","New best_val_rmse: 0.5073\n","\n","32 steps took 40.6 seconds\n","Epoch: 3 batch_num: 108\n","train_rmse_target: 0.2852 train_rmse_stderror: 0.0366 train_kl_div: 0.1847\n","val_rmse_target: 0.5062 val_rmse_stderror: 1.763\n","New best_val_rmse: 0.5062\n","\n","32 steps took 40.6 seconds\n","Epoch: 3 batch_num: 140\n","train_rmse_target: 0.1586 train_rmse_stderror: 0.03861 train_kl_div: 0.05869\n","val_rmse_target: 0.5104 val_rmse_stderror: 1.761\n","Still best_val_rmse: 0.5062 (from epoch 3)\n","\n","32 steps took 40.6 seconds\n","Epoch: 3 batch_num: 172\n","train_rmse_target: 0.3074 train_rmse_stderror: 0.03224 train_kl_div: 0.2056\n","val_rmse_target: 0.5137 val_rmse_stderror: 1.766\n","Still best_val_rmse: 0.5062 (from epoch 3)\n","\n","32 steps took 40.7 seconds\n","Epoch: 4 batch_num: 16\n","train_rmse_target: 0.1699 train_rmse_stderror: 0.03966 train_kl_div: 0.07164\n","val_rmse_target: 0.5117 val_rmse_stderror: 1.768\n","Still best_val_rmse: 0.5062 (from epoch 3)\n","\n","32 steps took 40.6 seconds\n","Epoch: 4 batch_num: 48\n","train_rmse_target: 0.2488 train_rmse_stderror: 0.035 train_kl_div: 0.1081\n","val_rmse_target: 0.5111 val_rmse_stderror: 1.764\n","Still best_val_rmse: 0.5062 (from epoch 3)\n","\n","32 steps took 40.6 seconds\n","Epoch: 4 batch_num: 80\n","train_rmse_target: 0.1753 train_rmse_stderror: 0.01853 train_kl_div: 0.06984\n","val_rmse_target: 0.5067 val_rmse_stderror: 1.766\n","Still best_val_rmse: 0.5062 (from epoch 3)\n","\n","32 steps took 40.6 seconds\n","Epoch: 4 batch_num: 112\n","train_rmse_target: 0.1834 train_rmse_stderror: 0.03827 train_kl_div: 0.07762\n","val_rmse_target: 0.5112 val_rmse_stderror: 1.77\n","Still best_val_rmse: 0.5062 (from epoch 3)\n","\n","32 steps took 40.6 seconds\n","Epoch: 4 batch_num: 144\n","train_rmse_target: 0.1723 train_rmse_stderror: 0.04487 train_kl_div: 0.06871\n","val_rmse_target: 0.5113 val_rmse_stderror: 1.768\n","Still best_val_rmse: 0.5062 (from epoch 3)\n","\n","32 steps took 40.6 seconds\n","Epoch: 4 batch_num: 176\n","train_rmse_target: 0.2204 train_rmse_stderror: 0.0367 train_kl_div: 0.1103\n","val_rmse_target: 0.5111 val_rmse_stderror: 1.766\n","Still best_val_rmse: 0.5062 (from epoch 3)\n","\n","Performance estimates:\n","[0.5119349079125822, 0.502654862343284, 0.5061779405356829]\n","Mean: 0.5069225702638497\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 4/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 82.1 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.7175 train_rmse_stderror: 0.06823 train_kl_div: 1.124\n","val_rmse_target: 0.6841 val_rmse_stderror: 1.86\n","New best_val_rmse: 0.6841\n","\n","64 steps took 81.6 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.5255 train_rmse_stderror: 0.03246 train_kl_div: 0.5534\n","val_rmse_target: 0.6866 val_rmse_stderror: 1.823\n","Still best_val_rmse: 0.6841 (from epoch 0)\n","\n","64 steps took 81.4 seconds\n","Epoch: 1 batch_num: 4\n","train_rmse_target: 0.6297 train_rmse_stderror: 0.04869 train_kl_div: 0.7308\n","val_rmse_target: 0.5546 val_rmse_stderror: 1.813\n","New best_val_rmse: 0.5546\n","\n","64 steps took 81.2 seconds\n","Epoch: 1 batch_num: 68\n","train_rmse_target: 0.7537 train_rmse_stderror: 0.051 train_kl_div: 1.271\n","val_rmse_target: 0.6232 val_rmse_stderror: 1.804\n","Still best_val_rmse: 0.5546 (from epoch 1)\n","\n","64 steps took 81.2 seconds\n","Epoch: 1 batch_num: 132\n","train_rmse_target: 0.4222 train_rmse_stderror: 0.03905 train_kl_div: 0.3913\n","val_rmse_target: 0.5322 val_rmse_stderror: 1.801\n","New best_val_rmse: 0.5322\n","\n","32 steps took 40.6 seconds\n","Epoch: 1 batch_num: 164\n","train_rmse_target: 0.509 train_rmse_stderror: 0.04635 train_kl_div: 0.5374\n","val_rmse_target: 0.5643 val_rmse_stderror: 1.821\n","Still best_val_rmse: 0.5322 (from epoch 1)\n","\n","64 steps took 81.4 seconds\n","Epoch: 2 batch_num: 40\n","train_rmse_target: 0.5162 train_rmse_stderror: 0.03184 train_kl_div: 0.4696\n","val_rmse_target: 0.5416 val_rmse_stderror: 1.799\n","Still best_val_rmse: 0.5322 (from epoch 1)\n","\n","32 steps took 40.6 seconds\n","Epoch: 2 batch_num: 72\n","train_rmse_target: 0.2946 train_rmse_stderror: 0.04069 train_kl_div: 0.1508\n","val_rmse_target: 0.523 val_rmse_stderror: 1.805\n","New best_val_rmse: 0.523\n","\n","32 steps took 40.6 seconds\n","Epoch: 2 batch_num: 104\n","train_rmse_target: 0.3011 train_rmse_stderror: 0.03728 train_kl_div: 0.1863\n","val_rmse_target: 0.5352 val_rmse_stderror: 1.809\n","Still best_val_rmse: 0.523 (from epoch 2)\n","\n","32 steps took 40.6 seconds\n","Epoch: 2 batch_num: 136\n","train_rmse_target: 0.27 train_rmse_stderror: 0.03146 train_kl_div: 0.1595\n","val_rmse_target: 0.5238 val_rmse_stderror: 1.805\n","Still best_val_rmse: 0.523 (from epoch 2)\n","\n","32 steps took 40.6 seconds\n","Epoch: 2 batch_num: 168\n","train_rmse_target: 0.3379 train_rmse_stderror: 0.03628 train_kl_div: 0.2558\n","val_rmse_target: 0.5217 val_rmse_stderror: 1.813\n","New best_val_rmse: 0.5217\n","\n","32 steps took 40.8 seconds\n","Epoch: 3 batch_num: 12\n","train_rmse_target: 0.3597 train_rmse_stderror: 0.02283 train_kl_div: 0.2389\n","val_rmse_target: 0.5255 val_rmse_stderror: 1.811\n","Still best_val_rmse: 0.5217 (from epoch 2)\n","\n","32 steps took 40.6 seconds\n","Epoch: 3 batch_num: 44\n","train_rmse_target: 0.2377 train_rmse_stderror: 0.0309 train_kl_div: 0.1214\n","val_rmse_target: 0.5252 val_rmse_stderror: 1.816\n","Still best_val_rmse: 0.5217 (from epoch 2)\n","\n","32 steps took 40.6 seconds\n","Epoch: 3 batch_num: 76\n","train_rmse_target: 0.3361 train_rmse_stderror: 0.04359 train_kl_div: 0.2055\n","val_rmse_target: 0.521 val_rmse_stderror: 1.819\n","New best_val_rmse: 0.521\n","\n","32 steps took 40.6 seconds\n","Epoch: 3 batch_num: 108\n","train_rmse_target: 0.2438 train_rmse_stderror: 0.02492 train_kl_div: 0.1406\n","val_rmse_target: 0.5253 val_rmse_stderror: 1.799\n","Still best_val_rmse: 0.521 (from epoch 3)\n","\n","32 steps took 40.6 seconds\n","Epoch: 3 batch_num: 140\n","train_rmse_target: 0.2268 train_rmse_stderror: 0.03164 train_kl_div: 0.1147\n","val_rmse_target: 0.5162 val_rmse_stderror: 1.813\n","New best_val_rmse: 0.5162\n","\n","32 steps took 40.6 seconds\n","Epoch: 3 batch_num: 172\n","train_rmse_target: 0.2914 train_rmse_stderror: 0.04727 train_kl_div: 0.1607\n","val_rmse_target: 0.5216 val_rmse_stderror: 1.807\n","Still best_val_rmse: 0.5162 (from epoch 3)\n","\n","32 steps took 40.8 seconds\n","Epoch: 4 batch_num: 16\n","train_rmse_target: 0.2357 train_rmse_stderror: 0.02546 train_kl_div: 0.1151\n","val_rmse_target: 0.5242 val_rmse_stderror: 1.807\n","Still best_val_rmse: 0.5162 (from epoch 3)\n","\n","32 steps took 40.5 seconds\n","Epoch: 4 batch_num: 48\n","train_rmse_target: 0.2555 train_rmse_stderror: 0.04211 train_kl_div: 0.1277\n","val_rmse_target: 0.5254 val_rmse_stderror: 1.81\n","Still best_val_rmse: 0.5162 (from epoch 3)\n","\n","32 steps took 40.6 seconds\n","Epoch: 4 batch_num: 80\n","train_rmse_target: 0.2237 train_rmse_stderror: 0.03897 train_kl_div: 0.1024\n","val_rmse_target: 0.5257 val_rmse_stderror: 1.802\n","Still best_val_rmse: 0.5162 (from epoch 3)\n","\n","32 steps took 40.6 seconds\n","Epoch: 4 batch_num: 112\n","train_rmse_target: 0.2467 train_rmse_stderror: 0.03871 train_kl_div: 0.105\n","val_rmse_target: 0.524 val_rmse_stderror: 1.807\n","Still best_val_rmse: 0.5162 (from epoch 3)\n","\n","32 steps took 40.6 seconds\n","Epoch: 4 batch_num: 144\n","train_rmse_target: 0.2338 train_rmse_stderror: 0.02965 train_kl_div: 0.09768\n","val_rmse_target: 0.5265 val_rmse_stderror: 1.808\n","Still best_val_rmse: 0.5162 (from epoch 3)\n","\n","32 steps took 40.6 seconds\n","Epoch: 4 batch_num: 176\n","train_rmse_target: 0.1861 train_rmse_stderror: 0.03648 train_kl_div: 0.08157\n","val_rmse_target: 0.5258 val_rmse_stderror: 1.808\n","Still best_val_rmse: 0.5162 (from epoch 3)\n","\n","Performance estimates:\n","[0.5119349079125822, 0.502654862343284, 0.5061779405356829, 0.5162196715823569]\n","Mean: 0.5092468455934764\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 5/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","64 steps took 82.1 seconds\n","Epoch: 0 batch_num: 64\n","train_rmse_target: 0.9253 train_rmse_stderror: 0.05597 train_kl_div: 1.426\n","val_rmse_target: 0.7016 val_rmse_stderror: 1.773\n","New best_val_rmse: 0.7016\n","\n","64 steps took 81.2 seconds\n","Epoch: 0 batch_num: 128\n","train_rmse_target: 0.5595 train_rmse_stderror: 0.06641 train_kl_div: 0.5926\n","val_rmse_target: 0.6008 val_rmse_stderror: 1.753\n","New best_val_rmse: 0.6008\n","\n","64 steps took 81.3 seconds\n","Epoch: 1 batch_num: 4\n","train_rmse_target: 0.5027 train_rmse_stderror: 0.05374 train_kl_div: 0.5385\n","val_rmse_target: 0.5658 val_rmse_stderror: 1.733\n","New best_val_rmse: 0.5658\n","\n","64 steps took 81.1 seconds\n","Epoch: 1 batch_num: 68\n","train_rmse_target: 0.4494 train_rmse_stderror: 0.04041 train_kl_div: 0.4038\n","val_rmse_target: 0.4984 val_rmse_stderror: 1.758\n","New best_val_rmse: 0.4984\n","\n","16 steps took 20.3 seconds\n","Epoch: 1 batch_num: 84\n","train_rmse_target: 0.5022 train_rmse_stderror: 0.04064 train_kl_div: 0.4726\n","val_rmse_target: 0.4991 val_rmse_stderror: 1.752\n","Still best_val_rmse: 0.4984 (from epoch 1)\n","\n","16 steps took 20.3 seconds\n","Epoch: 1 batch_num: 100\n","train_rmse_target: 0.4622 train_rmse_stderror: 0.04539 train_kl_div: 0.4164\n","val_rmse_target: 0.4922 val_rmse_stderror: 1.784\n","New best_val_rmse: 0.4922\n","\n","16 steps took 20.3 seconds\n","Epoch: 1 batch_num: 116\n","train_rmse_target: 0.4669 train_rmse_stderror: 0.03321 train_kl_div: 0.4337\n","val_rmse_target: 0.5165 val_rmse_stderror: 1.75\n","Still best_val_rmse: 0.4922 (from epoch 1)\n","\n","32 steps took 40.5 seconds\n","Epoch: 1 batch_num: 148\n","train_rmse_target: 0.5476 train_rmse_stderror: 0.04491 train_kl_div: 0.594\n","val_rmse_target: 0.5063 val_rmse_stderror: 1.762\n","Still best_val_rmse: 0.4922 (from epoch 1)\n","\n","32 steps took 40.6 seconds\n","Epoch: 1 batch_num: 180\n","train_rmse_target: 0.3822 train_rmse_stderror: 0.04276 train_kl_div: 0.3023\n","val_rmse_target: 0.491 val_rmse_stderror: 1.756\n","New best_val_rmse: 0.491\n","\n","16 steps took 20.5 seconds\n","Epoch: 2 batch_num: 8\n","train_rmse_target: 0.3021 train_rmse_stderror: 0.04553 train_kl_div: 0.1986\n","val_rmse_target: 0.4898 val_rmse_stderror: 1.747\n","New best_val_rmse: 0.4898\n","\n","8 steps took 10.1 seconds\n","Epoch: 2 batch_num: 16\n","train_rmse_target: 0.3899 train_rmse_stderror: 0.03712 train_kl_div: 0.2557\n","val_rmse_target: 0.494 val_rmse_stderror: 1.769\n","Still best_val_rmse: 0.4898 (from epoch 2)\n","\n","16 steps took 20.3 seconds\n","Epoch: 2 batch_num: 32\n","train_rmse_target: 0.3328 train_rmse_stderror: 0.03887 train_kl_div: 0.2168\n","val_rmse_target: 0.4865 val_rmse_stderror: 1.768\n","New best_val_rmse: 0.4865\n","\n","8 steps took 10.2 seconds\n","Epoch: 2 batch_num: 40\n","train_rmse_target: 0.2534 train_rmse_stderror: 0.05675 train_kl_div: 0.1315\n","val_rmse_target: 0.4999 val_rmse_stderror: 1.741\n","Still best_val_rmse: 0.4865 (from epoch 2)\n","\n","16 steps took 20.3 seconds\n","Epoch: 2 batch_num: 56\n","train_rmse_target: 0.3119 train_rmse_stderror: 0.02739 train_kl_div: 0.1872\n","val_rmse_target: 0.503 val_rmse_stderror: 1.764\n","Still best_val_rmse: 0.4865 (from epoch 2)\n","\n","32 steps took 40.6 seconds\n","Epoch: 2 batch_num: 88\n","train_rmse_target: 0.3974 train_rmse_stderror: 0.04307 train_kl_div: 0.2859\n","val_rmse_target: 0.4878 val_rmse_stderror: 1.761\n","Still best_val_rmse: 0.4865 (from epoch 2)\n","\n","8 steps took 10.1 seconds\n","Epoch: 2 batch_num: 96\n","train_rmse_target: 0.2924 train_rmse_stderror: 0.03031 train_kl_div: 0.18\n","val_rmse_target: 0.492 val_rmse_stderror: 1.755\n","Still best_val_rmse: 0.4865 (from epoch 2)\n","\n","16 steps took 20.3 seconds\n","Epoch: 2 batch_num: 112\n","train_rmse_target: 0.2955 train_rmse_stderror: 0.03341 train_kl_div: 0.1748\n","val_rmse_target: 0.4831 val_rmse_stderror: 1.769\n","New best_val_rmse: 0.4831\n","\n","8 steps took 10.1 seconds\n","Epoch: 2 batch_num: 120\n","train_rmse_target: 0.3165 train_rmse_stderror: 0.04792 train_kl_div: 0.1985\n","val_rmse_target: 0.4972 val_rmse_stderror: 1.75\n","Still best_val_rmse: 0.4831 (from epoch 2)\n","\n","16 steps took 20.3 seconds\n","Epoch: 2 batch_num: 136\n","train_rmse_target: 0.3689 train_rmse_stderror: 0.02755 train_kl_div: 0.2693\n","val_rmse_target: 0.4949 val_rmse_stderror: 1.767\n","Still best_val_rmse: 0.4831 (from epoch 2)\n","\n","16 steps took 20.3 seconds\n","Epoch: 2 batch_num: 152\n","train_rmse_target: 0.3147 train_rmse_stderror: 0.04547 train_kl_div: 0.2059\n","val_rmse_target: 0.4829 val_rmse_stderror: 1.759\n","New best_val_rmse: 0.4829\n","\n","8 steps took 10.2 seconds\n","Epoch: 2 batch_num: 160\n","train_rmse_target: 0.2964 train_rmse_stderror: 0.02335 train_kl_div: 0.1692\n","val_rmse_target: 0.4921 val_rmse_stderror: 1.757\n","Still best_val_rmse: 0.4829 (from epoch 2)\n","\n","16 steps took 20.3 seconds\n","Epoch: 2 batch_num: 176\n","train_rmse_target: 0.2452 train_rmse_stderror: 0.03162 train_kl_div: 0.1301\n","val_rmse_target: 0.4901 val_rmse_stderror: 1.753\n","Still best_val_rmse: 0.4829 (from epoch 2)\n","\n","16 steps took 20.4 seconds\n","Epoch: 3 batch_num: 4\n","train_rmse_target: 0.1743 train_rmse_stderror: 0.02804 train_kl_div: 0.0548\n","val_rmse_target: 0.4809 val_rmse_stderror: 1.758\n","New best_val_rmse: 0.4809\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 12\n","train_rmse_target: 0.1807 train_rmse_stderror: 0.03052 train_kl_div: 0.06846\n","val_rmse_target: 0.4784 val_rmse_stderror: 1.757\n","New best_val_rmse: 0.4784\n","\n","4 steps took 5.06 seconds\n","Epoch: 3 batch_num: 16\n","train_rmse_target: 0.2894 train_rmse_stderror: 0.03635 train_kl_div: 0.1466\n","val_rmse_target: 0.4837 val_rmse_stderror: 1.757\n","Still best_val_rmse: 0.4784 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 24\n","train_rmse_target: 0.2179 train_rmse_stderror: 0.02202 train_kl_div: 0.1014\n","val_rmse_target: 0.4828 val_rmse_stderror: 1.768\n","Still best_val_rmse: 0.4784 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 32\n","train_rmse_target: 0.1455 train_rmse_stderror: 0.02284 train_kl_div: 0.04873\n","val_rmse_target: 0.5032 val_rmse_stderror: 1.744\n","Still best_val_rmse: 0.4784 (from epoch 3)\n","\n","32 steps took 40.6 seconds\n","Epoch: 3 batch_num: 64\n","train_rmse_target: 0.2029 train_rmse_stderror: 0.02945 train_kl_div: 0.08269\n","val_rmse_target: 0.4824 val_rmse_stderror: 1.759\n","Still best_val_rmse: 0.4784 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 72\n","train_rmse_target: 0.1826 train_rmse_stderror: 0.02204 train_kl_div: 0.07436\n","val_rmse_target: 0.4893 val_rmse_stderror: 1.758\n","Still best_val_rmse: 0.4784 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 80\n","train_rmse_target: 0.1325 train_rmse_stderror: 0.02342 train_kl_div: 0.04061\n","val_rmse_target: 0.4816 val_rmse_stderror: 1.757\n","Still best_val_rmse: 0.4784 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 88\n","train_rmse_target: 0.1805 train_rmse_stderror: 0.02771 train_kl_div: 0.07402\n","val_rmse_target: 0.4806 val_rmse_stderror: 1.762\n","Still best_val_rmse: 0.4784 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 96\n","train_rmse_target: 0.1842 train_rmse_stderror: 0.03749 train_kl_div: 0.07513\n","val_rmse_target: 0.4927 val_rmse_stderror: 1.756\n","Still best_val_rmse: 0.4784 (from epoch 3)\n","\n","16 steps took 20.3 seconds\n","Epoch: 3 batch_num: 112\n","train_rmse_target: 0.1637 train_rmse_stderror: 0.0295 train_kl_div: 0.06324\n","val_rmse_target: 0.4822 val_rmse_stderror: 1.754\n","Still best_val_rmse: 0.4784 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 120\n","train_rmse_target: 0.2577 train_rmse_stderror: 0.03232 train_kl_div: 0.1462\n","val_rmse_target: 0.4865 val_rmse_stderror: 1.767\n","Still best_val_rmse: 0.4784 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 128\n","train_rmse_target: 0.2342 train_rmse_stderror: 0.03008 train_kl_div: 0.1058\n","val_rmse_target: 0.4842 val_rmse_stderror: 1.755\n","Still best_val_rmse: 0.4784 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 136\n","train_rmse_target: 0.2314 train_rmse_stderror: 0.02782 train_kl_div: 0.1115\n","val_rmse_target: 0.4856 val_rmse_stderror: 1.762\n","Still best_val_rmse: 0.4784 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 144\n","train_rmse_target: 0.2074 train_rmse_stderror: 0.01927 train_kl_div: 0.09059\n","val_rmse_target: 0.4884 val_rmse_stderror: 1.755\n","Still best_val_rmse: 0.4784 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 152\n","train_rmse_target: 0.2635 train_rmse_stderror: 0.03252 train_kl_div: 0.1236\n","val_rmse_target: 0.4865 val_rmse_stderror: 1.759\n","Still best_val_rmse: 0.4784 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 3 batch_num: 160\n","train_rmse_target: 0.1801 train_rmse_stderror: 0.02465 train_kl_div: 0.06754\n","val_rmse_target: 0.4927 val_rmse_stderror: 1.753\n","Still best_val_rmse: 0.4784 (from epoch 3)\n","\n","16 steps took 20.3 seconds\n","Epoch: 3 batch_num: 176\n","train_rmse_target: 0.1249 train_rmse_stderror: 0.0292 train_kl_div: 0.03542\n","val_rmse_target: 0.4902 val_rmse_stderror: 1.754\n","Still best_val_rmse: 0.4784 (from epoch 3)\n","\n","16 steps took 20.5 seconds\n","Epoch: 4 batch_num: 4\n","train_rmse_target: 0.2532 train_rmse_stderror: 0.02722 train_kl_div: 0.1204\n","val_rmse_target: 0.4859 val_rmse_stderror: 1.758\n","Still best_val_rmse: 0.4784 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 12\n","train_rmse_target: 0.1641 train_rmse_stderror: 0.02587 train_kl_div: 0.05333\n","val_rmse_target: 0.485 val_rmse_stderror: 1.76\n","Still best_val_rmse: 0.4784 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 20\n","train_rmse_target: 0.1331 train_rmse_stderror: 0.03132 train_kl_div: 0.04068\n","val_rmse_target: 0.4876 val_rmse_stderror: 1.756\n","Still best_val_rmse: 0.4784 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 28\n","train_rmse_target: 0.2161 train_rmse_stderror: 0.02505 train_kl_div: 0.09509\n","val_rmse_target: 0.4887 val_rmse_stderror: 1.758\n","Still best_val_rmse: 0.4784 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 36\n","train_rmse_target: 0.2195 train_rmse_stderror: 0.02576 train_kl_div: 0.08804\n","val_rmse_target: 0.488 val_rmse_stderror: 1.759\n","Still best_val_rmse: 0.4784 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 44\n","train_rmse_target: 0.1924 train_rmse_stderror: 0.02689 train_kl_div: 0.06506\n","val_rmse_target: 0.4895 val_rmse_stderror: 1.76\n","Still best_val_rmse: 0.4784 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 52\n","train_rmse_target: 0.1135 train_rmse_stderror: 0.02973 train_kl_div: 0.03248\n","val_rmse_target: 0.4915 val_rmse_stderror: 1.758\n","Still best_val_rmse: 0.4784 (from epoch 3)\n","\n","16 steps took 20.3 seconds\n","Epoch: 4 batch_num: 68\n","train_rmse_target: 0.2068 train_rmse_stderror: 0.02443 train_kl_div: 0.08612\n","val_rmse_target: 0.4875 val_rmse_stderror: 1.761\n","Still best_val_rmse: 0.4784 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 76\n","train_rmse_target: 0.1012 train_rmse_stderror: 0.02334 train_kl_div: 0.02308\n","val_rmse_target: 0.4865 val_rmse_stderror: 1.76\n","Still best_val_rmse: 0.4784 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 84\n","train_rmse_target: 0.1497 train_rmse_stderror: 0.03336 train_kl_div: 0.04874\n","val_rmse_target: 0.4868 val_rmse_stderror: 1.76\n","Still best_val_rmse: 0.4784 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 92\n","train_rmse_target: 0.1592 train_rmse_stderror: 0.02986 train_kl_div: 0.04205\n","val_rmse_target: 0.4885 val_rmse_stderror: 1.757\n","Still best_val_rmse: 0.4784 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 100\n","train_rmse_target: 0.1852 train_rmse_stderror: 0.01805 train_kl_div: 0.07308\n","val_rmse_target: 0.4897 val_rmse_stderror: 1.755\n","Still best_val_rmse: 0.4784 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 108\n","train_rmse_target: 0.2462 train_rmse_stderror: 0.03234 train_kl_div: 0.1141\n","val_rmse_target: 0.4893 val_rmse_stderror: 1.756\n","Still best_val_rmse: 0.4784 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 116\n","train_rmse_target: 0.1983 train_rmse_stderror: 0.01763 train_kl_div: 0.06832\n","val_rmse_target: 0.4885 val_rmse_stderror: 1.756\n","Still best_val_rmse: 0.4784 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 124\n","train_rmse_target: 0.1505 train_rmse_stderror: 0.02021 train_kl_div: 0.04982\n","val_rmse_target: 0.4882 val_rmse_stderror: 1.757\n","Still best_val_rmse: 0.4784 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 132\n","train_rmse_target: 0.1457 train_rmse_stderror: 0.02238 train_kl_div: 0.04287\n","val_rmse_target: 0.4874 val_rmse_stderror: 1.758\n","Still best_val_rmse: 0.4784 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 140\n","train_rmse_target: 0.1507 train_rmse_stderror: 0.02319 train_kl_div: 0.04715\n","val_rmse_target: 0.4877 val_rmse_stderror: 1.758\n","Still best_val_rmse: 0.4784 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 148\n","train_rmse_target: 0.189 train_rmse_stderror: 0.02379 train_kl_div: 0.06219\n","val_rmse_target: 0.4883 val_rmse_stderror: 1.758\n","Still best_val_rmse: 0.4784 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 156\n","train_rmse_target: 0.09384 train_rmse_stderror: 0.02097 train_kl_div: 0.02046\n","val_rmse_target: 0.4885 val_rmse_stderror: 1.758\n","Still best_val_rmse: 0.4784 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 164\n","train_rmse_target: 0.161 train_rmse_stderror: 0.02609 train_kl_div: 0.05558\n","val_rmse_target: 0.4883 val_rmse_stderror: 1.757\n","Still best_val_rmse: 0.4784 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 172\n","train_rmse_target: 0.1547 train_rmse_stderror: 0.04093 train_kl_div: 0.05423\n","val_rmse_target: 0.4883 val_rmse_stderror: 1.757\n","Still best_val_rmse: 0.4784 (from epoch 3)\n","\n","8 steps took 10.1 seconds\n","Epoch: 4 batch_num: 180\n","train_rmse_target: 0.1028 train_rmse_stderror: 0.02521 train_kl_div: 0.02587\n","val_rmse_target: 0.4882 val_rmse_stderror: 1.757\n","Still best_val_rmse: 0.4784 (from epoch 3)\n","\n","Performance estimates:\n","[0.5119349079125822, 0.502654862343284, 0.5061779405356829, 0.5162196715823569, 0.4784329881161345]\n","Mean: 0.503084074098008\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"m4v-cGx-Mv7S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626676193180,"user_tz":-540,"elapsed":233,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"6703d123-ea01-42fa-8d39-917b939d5277"},"source":["print(list_val_rmse)"],"execution_count":59,"outputs":[{"output_type":"stream","text":["[0.5119349079125822, 0.502654862343284, 0.5061779405356829, 0.5162196715823569, 0.4784329881161345]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"q2CdCMuIKDMP","executionInfo":{"status":"ok","timestamp":1626676195167,"user_tz":-540,"elapsed":361,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#rep = MemReporter(model)\n","#rep.report()"],"execution_count":60,"outputs":[]},{"cell_type":"code","metadata":{"id":"eLl1yDOOKIe7","executionInfo":{"status":"ok","timestamp":1626676195794,"user_tz":-540,"elapsed":4,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#rep = MemReporter(model.roberta)\n","#rep.report()"],"execution_count":61,"outputs":[]},{"cell_type":"code","metadata":{"id":"7qkqnknA_m9D","executionInfo":{"status":"ok","timestamp":1626676196571,"user_tz":-540,"elapsed":2,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#gpuinfo()"],"execution_count":62,"outputs":[]},{"cell_type":"code","metadata":{"id":"PwrqSMdYA6Pu","executionInfo":{"status":"ok","timestamp":1626676197387,"user_tz":-540,"elapsed":4,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#del model\n","#del optimizer \n","#del train_loader\n","#del val_loader\n","#del scheduler \n","#del list_val_rmse\n","#del train_indices\n","#del val_indices\n","#del tokenizer\n","#torch.cuda.empty_cache()\n","#gpuinfo()"],"execution_count":63,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wXcHyUSJXecL"},"source":["# Inference"]},{"cell_type":"code","metadata":{"id":"YIV6UllSIGoa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626676199679,"user_tz":-540,"elapsed":1002,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"c1477c20-36e1-4238-e996-de0763450912"},"source":["!cp -r /content/model_1.pth /content/model/model_1.pth\n","!cp -r /content/model_2.pth /content/model/model_2.pth\n","!cp -r /content/model_3.pth /content/model/model_3.pth\n","!cp -r /content/model_4.pth /content/model/model_4.pth\n","!cp -r /content/model_5.pth /content/model/model_5.pth"],"execution_count":64,"outputs":[{"output_type":"stream","text":["cp: cannot stat '/content/model_1.pth': No such file or directory\n","cp: cannot stat '/content/model_2.pth': No such file or directory\n","cp: cannot stat '/content/model_3.pth': No such file or directory\n","cp: cannot stat '/content/model_4.pth': No such file or directory\n","cp: cannot stat '/content/model_5.pth': No such file or directory\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"14ddOZH4IMam","executionInfo":{"status":"aborted","timestamp":1626664980608,"user_tz":-540,"elapsed":20,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["def dataset_upload():\n","    import json\n","    from kaggle.api.kaggle_api_extended import KaggleApi\n","\n","    id = f'{USERID}/{EX_NO}'\n","\n","    dataset_metadata = {}\n","    dataset_metadata['id'] = id\n","    dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n","    dataset_metadata['title'] = f'{EX_NO}'\n","\n","    with open(UPLOAD_DIR / 'dataset-metadata.json', 'w') as f:\n","        json.dump(dataset_metadata, f, indent=4)\n","\n","    api = KaggleApi()\n","    api.authenticate()\n","\n","    # データセットがない場合\n","    if f'{USERID}/{EX_NO}' not in [str(d) for d in api.dataset_list(user=USERID, search=f'\"{EX_NO}\"')]:\n","        api.dataset_create_new(folder=UPLOAD_DIR,\n","                               convert_to_csv=False,\n","                               dir_mode='skip')\n","    # データセットがある場合\n","    else:\n","        api.dataset_create_version(folder=UPLOAD_DIR,\n","                                   version_notes='update',\n","                                   convert_to_csv=False,\n","                                   delete_old_versions=True,\n","                                   dir_mode='skip')\n","dataset_upload()\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"huJwVMSAPuDO","executionInfo":{"status":"aborted","timestamp":1626664980609,"user_tz":-540,"elapsed":21,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0zzuBPobmLFu","executionInfo":{"status":"aborted","timestamp":1626664980609,"user_tz":-540,"elapsed":21,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wpc8ro9hmNci"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ceDI72NumT5-"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PvRi_JQgwcKI"},"source":[""],"execution_count":null,"outputs":[]}]}