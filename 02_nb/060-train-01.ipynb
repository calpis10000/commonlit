{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"060-train-01.ipynb","provenance":[{"file_id":"1CEQK5FqKSwMO6MjCXmCCM9_BGeLzsJbO","timestamp":1627819646939},{"file_id":"17BUK8yRF7SDX0khlOXoHcFRTEFffkvRb","timestamp":1627488927996},{"file_id":"1wNpTEKAuuKP7ivTcm1f9j0sdmYU1RyzA","timestamp":1627306793279},{"file_id":"1uE__yBR1oxeYaUIrUTMEOffmeyuJBRAU","timestamp":1627305921964},{"file_id":"1PbEPh6kL5p5cdH5HC8iHoMVCIzA0MqvB","timestamp":1627284576770},{"file_id":"1TlxQ4e-ZX1Zy51dKLuhNdrBWg1qhojqP","timestamp":1627273765934},{"file_id":"17a4F4aC9L0QBqU8BRTrdqPn0WwJ0b08b","timestamp":1626746992716},{"file_id":"1G_W9irFTrEmDeHR0S6_u0bjpk8nxipXW","timestamp":1626689695352},{"file_id":"1bhhkorT--y8XXaVLM8hibVgC-tLqZ16P","timestamp":1626358153868},{"file_id":"1WtT2hX6O9Qbt_hb9sF50nM2QmDXFi-XA","timestamp":1626338366006},{"file_id":"1k_p5wftcUeo711Xho1-T5an2Xkneau-J","timestamp":1626323813472},{"file_id":"1Vz2GB2BNTWuefEFkCSh3TBPEIel7KG1t","timestamp":1626317426487},{"file_id":"1djoMWojeaIPopG5tS1jNMohn8ineblRh","timestamp":1626306831897},{"file_id":"1-6tlDO8158Pi6TpptIF884oFaEiT4Uxb","timestamp":1626276420047},{"file_id":"1js8eA3mDNS8mwSpCiHuzPeARFlUPAVrg","timestamp":1626272452526},{"file_id":"1yhcPgulwJtjJKUK9IuRKmNMhJ-4YXGol","timestamp":1626267205517},{"file_id":"1mnnSv0Pofn1QxArywV81VYqnZPB8uUWN","timestamp":1626180468522},{"file_id":"1RRdjt_UAeHmr5QQBAMyC82Fq1s31OWdK","timestamp":1625833136005},{"file_id":"1JPgg44HFemzwk8VSCXih3PejL0idy-C4","timestamp":1625825483466},{"file_id":"1Ye6wqVX71xAAAhmjXkw9IpRvTqeUyJDA","timestamp":1625812137500}],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ucCbvGD1XvG7","executionInfo":{"status":"ok","timestamp":1627870963705,"user_tz":-540,"elapsed":392,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"0f62cd4f-d67c-410c-945d-dac96f9669a3"},"source":["import sys\n","if 'google.colab' in sys.modules:  # colab特有の処理_2回目以降\n","  # Google Driveのマウント\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","\n","  # ライブラリのパス指定\n","  sys.path.append('/content/drive/MyDrive/Colab_Files/kaggle/commonlit/XX_modules')\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FACwJ6icpxrR","executionInfo":{"status":"ok","timestamp":1627870969289,"user_tz":-540,"elapsed":5287,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# データセットをDriveから取得\n","!mkdir -p 'input'\n","!mkdir -p 'clrp-pre-trained'\n","\n","!cp -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/00_input/commonlitreadabilityprize/' '/content/input'\n","!cp -r '/content/drive/MyDrive/Colab_Files/kaggle/commonlit/97_pre_trained/clrp_pretrained_manish_epoch5/pre-trained-roberta/clrp_roberta_large/' '/content/clrp-pre-trained'"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"RV9-VwbpZLZ9","executionInfo":{"status":"ok","timestamp":1627870969290,"user_tz":-540,"elapsed":10,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["from pathlib import Path\n","\n","# input\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    DATA_DIR = Path('../input/commonlitreadabilityprize/')\n","\n","elif 'google.colab' in sys.modules: # Colab環境\n","    DATA_DIR = Path('/content/input/commonlitreadabilityprize')\n","\n","else:\n","    DATA_DIR = Path('../00_input/commonlitreadabilityprize/')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"x5difyXe00UV","executionInfo":{"status":"ok","timestamp":1627870969291,"user_tz":-540,"elapsed":10,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["from pathlib import Path\n","\n","# tokenizer\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    TOKENIZER_DIR = '../input/roberta-transformers-pytorch/roberta-large'\n","elif 'google.colab' in sys.modules: # Colab環境\n","    TOKENIZER_DIR = '/content/clrp-pre-trained/clrp_roberta_large' # 仮で、毎回DLする想定のモデル名を指定。あとで変更予定。\n","else:\n","    TOKENIZER_DIR = 'roberta-large'"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"tKjsUxnOeDYl","executionInfo":{"status":"ok","timestamp":1627870969292,"user_tz":-540,"elapsed":10,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["from pathlib import Path\n","\n","# pre-trained model\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    PRE_TRAINED_MODEL_DIR = '../input/roberta-transformers-pytorch/roberta-large'\n","elif 'google.colab' in sys.modules: # Colab環境\n","    PRE_TRAINED_MODEL_DIR = '/content/clrp-pre-trained/clrp_roberta_large' # 仮で、毎回DLする想定のモデル名を指定。あとで変更予定。\n","else:\n","    PRE_TRAINED_MODEL_DIR = 'roberta-large'"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZLaT2V0ReoAZ","executionInfo":{"status":"ok","timestamp":1627870969293,"user_tz":-540,"elapsed":10,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["UPLOAD_DIR = Path('/content/model')\n","EX_NO = '060-train-01'  # 実験番号などを入れる、folderのpathにする\n","USERID = 'calpis10000'"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"hOGjAb4pAJ0F","executionInfo":{"status":"ok","timestamp":1627870969293,"user_tz":-540,"elapsed":10,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["import subprocess\n","import shlex\n","\n","def gpuinfo():\n","    \"\"\"\n","    Returns size of total GPU RAM and used GPU RAM.\n","\n","    Parameters\n","    ----------\n","    None\n","\n","    Returns\n","    -------\n","    info : dict\n","        Total GPU RAM in integer for key 'total_MiB'.\n","        Used GPU RAM in integer for key 'used_MiB'.\n","    \"\"\"\n","\n","    command = 'nvidia-smi -q -d MEMORY | sed -n \"/FB Memory Usage/,/Free/p\" | sed -e \"1d\" -e \"4d\" -e \"s/ MiB//g\" | cut -d \":\" -f 2 | cut -c2-'\n","    commands = [shlex.split(part) for part in command.split(' | ')]\n","    for i, cmd in enumerate(commands):\n","        if i==0:\n","            res = subprocess.Popen(cmd, stdout=subprocess.PIPE)\n","        else:\n","            res = subprocess.Popen(cmd, stdin=res.stdout, stdout=subprocess.PIPE)\n","    total, used = map(int, res.communicate()[0].decode('utf-8').strip().split('\\n'))\n","    info = {'total_MiB':total, 'used_MiB':used}\n","    return info\n"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g3-6m5MKXecB"},"source":["# Overview\n","This nb is based on copy from https://www.kaggle.com/andretugan/lightweight-roberta-solution-in-pytorch .\n","\n","Acknowledgments(from base nb): \n","some ideas were taken from kernels by [Torch](https://www.kaggle.com/rhtsingh) and [Maunish](https://www.kaggle.com/maunish)."]},{"cell_type":"code","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-04T06:26:32.834365Z","iopub.execute_input":"2021-07-04T06:26:32.834903Z","iopub.status.idle":"2021-07-04T06:26:40.143740Z","shell.execute_reply.started":"2021-07-04T06:26:32.834785Z","shell.execute_reply":"2021-07-04T06:26:40.142864Z"},"trusted":true,"id":"HRsRZ06WXecD","executionInfo":{"status":"ok","timestamp":1627870973660,"user_tz":-540,"elapsed":4376,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["import os\n","import math\n","import random\n","import time\n","\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","\n","from transformers import AdamW # optimizer\n","from transformers import AutoTokenizer\n","from transformers import AutoModel\n","from transformers import AutoConfig\n","from transformers import get_cosine_schedule_with_warmup # scheduler\n","from pytorch_memlab import profile\n","import pytorch_memlab\n","from pytorch_memlab import MemReporter\n","\n","from sklearn.model_selection import KFold, StratifiedKFold\n","\n","import pickle\n","import gc\n","gc.enable()"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.145217Z","iopub.execute_input":"2021-07-04T06:26:40.145539Z","iopub.status.idle":"2021-07-04T06:26:40.201326Z","shell.execute_reply.started":"2021-07-04T06:26:40.145504Z","shell.execute_reply":"2021-07-04T06:26:40.200136Z"},"trusted":true,"id":"omBfwshTXecE","executionInfo":{"status":"ok","timestamp":1627870973664,"user_tz":-540,"elapsed":9,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["NUM_FOLDS = 5 # K Fold\n","NUM_EPOCHS = 5 # Epochs\n","BATCH_SIZE = 12 # Batch Size\n","MAX_LEN = 248 # ベクトル長\n","TFIDF_MAX_FEAT = 1024\n","\n","EVAL_SCHEDULE = [(0.55, 64), (-1., 32)] # schedulerの何らかの設定？\n","ROBERTA_PATH = PRE_TRAINED_MODEL_DIR # roberta pre-trainedモデル(モデルとして指定)\n","TOKENIZER_PATH = TOKENIZER_DIR # roberta pre-trainedモデル(Tokenizerとして指定)\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\" # cudaがなければcpuを使えばいいじゃない"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.203398Z","iopub.execute_input":"2021-07-04T06:26:40.204055Z","iopub.status.idle":"2021-07-04T06:26:40.211572Z","shell.execute_reply.started":"2021-07-04T06:26:40.204015Z","shell.execute_reply":"2021-07-04T06:26:40.210762Z"},"trusted":true,"id":"4qcuXqwtXecF","executionInfo":{"status":"ok","timestamp":1627870973664,"user_tz":-540,"elapsed":8,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["def set_random_seed(random_seed):\n","    random.seed(random_seed)\n","    np.random.seed(random_seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(random_seed)\n","\n","    torch.manual_seed(random_seed)\n","    torch.cuda.manual_seed(random_seed)\n","    torch.cuda.manual_seed_all(random_seed)\n","\n","    torch.backends.cudnn.deterministic = True# cudnnによる最適化で結果が変わらないためのおまじない "],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.214188Z","iopub.execute_input":"2021-07-04T06:26:40.214809Z","iopub.status.idle":"2021-07-04T06:26:40.309744Z","shell.execute_reply.started":"2021-07-04T06:26:40.214769Z","shell.execute_reply":"2021-07-04T06:26:40.308926Z"},"trusted":true,"id":"70PyLsJTXecF","executionInfo":{"status":"ok","timestamp":1627870973665,"user_tz":-540,"elapsed":8,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# read train_df(kfold)\n","train_kf_df = pd.read_csv(DATA_DIR/\"train_kfold.csv\")"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.311021Z","iopub.execute_input":"2021-07-04T06:26:40.311347Z","iopub.status.idle":"2021-07-04T06:26:40.624393Z","shell.execute_reply.started":"2021-07-04T06:26:40.311314Z","shell.execute_reply":"2021-07-04T06:26:40.623347Z"},"trusted":true,"id":"xf0662k4XecF","executionInfo":{"status":"ok","timestamp":1627870973665,"user_tz":-540,"elapsed":7,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# tokenizerを指定\n","tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N6aaghNkXecG"},"source":["# Dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UU5uZKIcDjkV","executionInfo":{"status":"ok","timestamp":1627870974112,"user_tz":-540,"elapsed":454,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"8580bc23-7eda-4ebd-8c16-602c2b27b414"},"source":["# 前処理用\n","import string\n","import re\n","import collections\n","\n","# ローカルの場合、stopwordsをダウンロード\n","import nltk\n","if 'kaggle_web_client' in sys.modules:  # kaggle環境\n","    pass\n","else:\n","    import nltk\n","    nltk.download('stopwords')\n","    nltk.download('averaged_perceptron_tagger')\n","    os.listdir(os.path.expanduser('~/nltk_data/corpora/stopwords/'))\n","\n","# テキスト前処理\n","# https://www.kaggle.com/alaasedeeq/commonlit-readability-eda\n","\n","#filtering the unwanted symbols, spaces, ....etc\n","to_replace_by_space = re.compile('[/(){}\\[\\]|@,;]')\n","punctuation = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n","bad_symbols = re.compile('[^0-9a-z #+_]')\n","stopwords = set(nltk.corpus.stopwords.words('english'))\n","\n","def text_prepare(text):\n","    '''\n","    text: a string\n","    returna modified version of the string\n","    '''\n","    text = text.lower() # lowercase text\n","    text = re.sub(punctuation, '',text)\n","    text = re.sub(to_replace_by_space, \" \", text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n","    text = re.sub(bad_symbols, \"\", text)         # delete symbols which are in BAD_SYMBOLS_RE from text\n","    text = \" \".join([word for word in text.split(\" \") if word not in stopwords]) # delete stopwords from text\n","    text = re.sub(' +', ' ', text)\n","    return text\n","\n","def text_normalization(s:pd.Series):\n","    x = s.apply(text_prepare)\n","    return x\n","\n","# Counterオブジェクトを取得\n","def get_counter(text:str):\n","    text_list = [wrd for wrd in text.split(\" \") if wrd not in ('', '\\n')]\n","    counter = collections.Counter(text_list)\n","    return counter\n","\n","# ベースとなる継承元のクラス\n","class BaseBlock(object):\n","    def fit(self, input_df, y=None):\n","        return self.transform(input_df)\n","    def transform(self, input_df):\n","        raise NotImplementedError()"],"execution_count":13,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ze-E2aCfgsfj","executionInfo":{"status":"ok","timestamp":1627870974113,"user_tz":-540,"elapsed":10,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["class TextDescriptionBlock(BaseBlock):\n","    \"\"\"テキストに関する統計量を返す block\"\"\"\n","    def __init__(self, column: str):\n","        \"\"\"\n","        args:\n","            column: str\n","                変換対象のカラム名\n","        \"\"\"\n","        self.column = column\n","        self.param_prefix = f'col={column}'\n","\n","    # 前処理\n","    def preprocess(self, input_df):\n","        x = text_normalization(input_df[self.column])\n","        return x\n","        \n","    def fit(self, input_df, y=None):\n","        return self.transform(input_df)\n","\n","    def transform(self, input_df):\n","        # 前処理\n","        self.text = self.preprocess(input_df)\n","        self.counters = self.text.map(get_counter)\n","\n","        # 変換処理\n","        _length = input_df[self.column].fillna('').map(lambda x: len(x) if x!='' else np.nan)\n","        _wrd_cnt = self.counters.map(lambda x: sum(x.values()))\n","        _wrd_nuniq = self.counters.map(lambda x: len(x))\n","        _wrd_mean = self.counters.map(lambda x: np.mean(list(x.values())))\n","        _wrd_max = self.counters.map(lambda x: np.max(list(x.values())))\n","        \n","        word_length = self.counters.map(lambda x: np.array([len(i) for i in x.keys()]))\n","        word_length_desc = word_length.map(lambda x: pd.Series(x.ravel()).describe())\n","        _word_length_desc_df = pd.DataFrame(word_length_desc.tolist()).iloc[:,1:]\n","        _word_length_desc_df = _word_length_desc_df.add_prefix('word_length_')\n","        \n","        out_df = pd.concat([_length, _wrd_cnt, _wrd_nuniq, _wrd_mean, _wrd_max], axis=1)\n","        out_df = out_df.reset_index().drop('index', axis='columns')\n","        out_df.columns = ['text_length', 'word_count', 'word_nunique', 'word_appearance_mean', 'word_appearance_max']\n","        out_df = pd.concat([out_df, _word_length_desc_df], axis=1).fillna(-1)\n","        return out_df.add_suffix(f'_{self.column}')"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z6lObnzFnYyK","executionInfo":{"status":"ok","timestamp":1627870974113,"user_tz":-540,"elapsed":9,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["class SentenceDescriptionBlock(BaseBlock):\n","    \"\"\"テキスト(センテンス)に関する統計量を返す block\"\"\"\n","    def __init__(self, column: str):\n","        \"\"\"\n","        args:\n","            column: str\n","                変換対象のカラム名\n","        \"\"\"\n","        self.column = column\n","        self.param_prefix = f'col={column}'\n","\n","    # 前処理\n","    def get_delimiter_feats(self, sentences: list):\n","      deli_df = pd.DataFrame([{'comma': i.count(','),\n","                                'colon': i.count(':'),\n","                                'semi-colon': i.count(';'),\n","                                'dash': i.count('—'),\n","                                'total': i.count(',') + i.count(':') + i.count(';') + i.count('—')\n","                                } for i in sentences])\n","      deli_disc = deli_df.describe().drop('count', axis='index')\n","      deli_disc.loc['sum', :] = deli_df.sum()\n","      deli_values = deli_disc.T.values.reshape(-1)\n","      col_list = []\n","      for col_ in deli_disc.columns:\n","        for idx_ in deli_disc.index:\n","          col_list.append(f'sentences_delim_{col_}_{idx_}')\n","      return pd.Series(data=deli_values, index=col_list)\n","\n","    def transform(self, input_df):\n","        self.text = input_df.reset_index().drop('index', axis='columns')[self.column]\n","        self.sentences = self.text.map(lambda x: [i for i in x.split('.') if len(i) > 0])\n","        out_df = pd.DataFrame()\n","\n","        # センテンス数\n","        out_df['sentences_cnt'] = self.sentences.map(lambda x: len(x)) \n","\n","        # センテンス長 × 各種統計量\n","        sentences_len = self.sentences.map(lambda x: [len(i) for i in x])\n","        sentences_len_df = pd.DataFrame(\n","                                        sentences_len.map(\n","                                            lambda x: pd.Series(x).describe().drop('count')\n","                                            ).tolist()\n","                                        ).add_prefix('sentence_length_')\n","\n","        # センテンスの単語数(クリーニング)\n","        sentences_clean = self.sentences.map(lambda x: [text_prepare(i) for i in x])\n","        sentences_wrd_counter = sentences_clean.map(lambda x: [get_counter(i) for i in x])\n","\n","        sentences_wrd_cnt_df = pd.DataFrame( # 単語数\n","                                        sentences_wrd_counter.map(\n","                                            lambda x: pd.Series([sum(i.values()) for i in x]).describe().drop('count')\n","                                            ).tolist()\n","                                        ).add_prefix('sentence_word_cnt_') \n","\n","        sentences_wrd_uniq_df = pd.DataFrame( # 単語のユニーク数\n","                                        sentences_wrd_counter.map(\n","                                            lambda x: pd.Series([len(i) for i in x]).describe().drop('count')\n","                                            ).tolist()\n","                                        ).add_prefix('sentence_word_uniq_')\n","\n","        # 区切り文字の数を取得\n","        sentences_deli_df = self.sentences.apply(self.get_delimiter_feats)       \n","        \n","        out_df = pd.concat([out_df, \n","                            sentences_len_df, \n","                            sentences_wrd_cnt_df, \n","                            sentences_wrd_uniq_df, \n","                            sentences_deli_df], axis=1)\n","        \n","        out_df = out_df.reset_index().drop('index', axis='columns')\n","        return out_df.add_suffix(f'_{self.column}')"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ca_p2ldNhU5X","executionInfo":{"status":"ok","timestamp":1627870974113,"user_tz":-540,"elapsed":9,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 参考: https://www.guruguru.science/competitions/16/discussions/556029f7-484d-40d4-ad6a-9d86337487e2/\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","# ベースとなる継承元のクラス\n","class BaseBlock(object):\n","    def fit(self, input_df, y=None):\n","        return self.transform(input_df)\n","    def transform(self, input_df):\n","        raise NotImplementedError()\n","\n","\n","class TfidfSimpleBlock(BaseBlock):\n","    \"\"\"シンプルなTF-IDF特徴を作成する block\"\"\"\n","    def __init__(self, column: str, max_features=50, ngram_range=(1,1), use_idf=True):\n","        \"\"\"\n","        args:\n","            column: str\n","                変換対象のカラム名\n","        \"\"\"\n","        self.column = column\n","        self.max_features=max_features\n","        self.ngram_range=ngram_range\n","        self.use_idf=use_idf\n","        self.param_prefix=f\"col={column}_max_features={max_features}_\\\n","                              ngram={ngram_range[0]}_{ngram_range[1]}_use_idf={use_idf}\"\n","\n","    def preprocess(self, input_df):\n","        x = text_normalization(input_df[self.column])\n","        return x\n","\n","    def get_master(self, _master_df):\n","        \"\"\"tdidfを計算するための全体集合を返す.\"\"\"\n","        return _master_df\n","    def fit(self, \n","            input_df, \n","            _master_df=None, \n","            y=None\n","           ):\n","        master_df = input_df if _master_df is None else self.get_master(_master_df)\n","        text = self.preprocess(master_df)\n","        self.vectorizer_ = TfidfVectorizer(max_features=self.max_features\n","                                      ,ngram_range=self.ngram_range\n","                                      ,use_idf=self.use_idf)\n","\n","        self.vectorizer_.fit(text)\n","        self.prefix = 'tfidf' if self.use_idf == True else 'tf'\n","        return self.transform(input_df)\n","\n","    def transform(self, input_df):\n","        text = self.preprocess(input_df)\n","        z = self.vectorizer_.transform(text)\n","\n","        out_df = pd.DataFrame(z.toarray())\n","        out_df.columns = self.vectorizer_.get_feature_names()\n","        return out_df.add_prefix(f'{self.prefix}_')"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"iAse0IDWDjho","executionInfo":{"status":"ok","timestamp":1627870974114,"user_tz":-540,"elapsed":9,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# Dataset用のClass。\n","class LitDataset(Dataset):\n","    def __init__(self, df, tfidf, inference_only=False):\n","        super().__init__()\n","\n","        self.df = df        \n","        self.inference_only = inference_only # Testデータ用フラグ\n","        self.text = df.excerpt.tolist() # 分析対象カラムをlistにする。(分かち書きではなく、Seriesをlistへ変換するような処理)\n","        #self.text = [text.replace(\"\\n\", \" \") for text in self.text] # 単語単位で分かち書きする場合\n","        #self.text_len = text_normalization(df.excerpt).map(lambda x: [0 if i >= len(x.split(' ')) else len(x.split(' ')[i]) for i in range(132)])\n","\n","        # FEAT_TEXT DESC\n","        desc_block = TextDescriptionBlock('excerpt')\n","        sent_block = SentenceDescriptionBlock('excerpt')\n","        text_desc = desc_block.fit(self.df)\n","        text_sent = sent_block.fit(self.df)\n","        self.text_feats = pd.concat([text_desc, text_sent], axis='columns')\n","        # FEAT_TFIDF\n","        self.tfidf = tfidf # fit済みのものを入力する。（クラス内ではtransformのみ行う）\n","        self.tfidf_vector = tfidf.transform(df).values\n","\n","        if not self.inference_only:\n","            self.target = torch.tensor(df.target.values, dtype=torch.float32) # trainのみ、targetをtensorに変換\n","            self.standard_error = torch.tensor(df.standard_error.values, dtype=torch.float32) \n","\n","        self.encoded = tokenizer.batch_encode_plus( # textをtokenize\n","            self.text,\n","            padding = 'max_length',            \n","            max_length = MAX_LEN,\n","            truncation = True, # 最大長を超える文字は切り捨て\n","            return_attention_mask=True\n","        )        \n"," \n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    \n","    def __getitem__(self, index): # 変換結果を返す\n","        input_ids = torch.tensor(self.encoded['input_ids'][index])\n","        attention_mask = torch.tensor(self.encoded['attention_mask'][index])\n","        #input_len = torch.tensor(self.text_len.iloc[index], dtype=torch.float32)\n","        input_desc = torch.tensor(self.text_feats.values[index], dtype=torch.float32)\n","        input_tfidf = torch.tensor(self.tfidf_vector[index, :], dtype=torch.float32)\n","\n","        if self.inference_only:\n","            return (input_ids, attention_mask, input_desc, input_tfidf)            \n","        else:\n","            target = self.target[index]\n","            standard_error = self.standard_error[index]\n","            return (input_ids, attention_mask, input_desc, input_tfidf, target, standard_error)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"PmEiwD6Dqk4Q","executionInfo":{"status":"ok","timestamp":1627870974114,"user_tz":-540,"elapsed":8,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 検証\n","#litds = LitDataset(train_kf_df.loc[train_indices])\n","#litds[0][2].shape"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"vhjZwnZNoU1i","executionInfo":{"status":"ok","timestamp":1627870974115,"user_tz":-540,"elapsed":8,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 検証\n","#litds = LitDataset(train_kf_df)\n","#litds[0][2].shape"],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KKtdy32wXecG"},"source":["# Model\n","The model is inspired by the one from [Maunish](https://www.kaggle.com/maunish/clrp-roberta-svm)."]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.649629Z","iopub.execute_input":"2021-07-04T06:26:40.650066Z","iopub.status.idle":"2021-07-04T06:26:40.666374Z","shell.execute_reply.started":"2021-07-04T06:26:40.650002Z","shell.execute_reply":"2021-07-04T06:26:40.665211Z"},"trusted":true,"id":"BpkxjXEUXecH","executionInfo":{"status":"ok","timestamp":1627870974115,"user_tz":-540,"elapsed":8,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["class LitModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        config = AutoConfig.from_pretrained(ROBERTA_PATH) # pretrainedからconfigを読み込み\n","        config.update({\"output_hidden_states\":True, # config更新: embedding層を抽出\n","                       \"hidden_dropout_prob\": 0.0, # config更新: dropoutしない\n","                       \"layer_norm_eps\": 1e-7}) # config更新: layer normalizationのepsilon                      \n","        \n","        self.roberta = AutoModel.from_pretrained(ROBERTA_PATH, config=config)\n","            \n","        self.attention = nn.Sequential(# attentionレイヤー            \n","            nn.Linear(config.hidden_size, 512),      \n","            nn.Tanh(),                       \n","            nn.Linear(512, 1),\n","            nn.Softmax(dim=1)\n","        )\n","\n","        self.numeric_feats = nn.Sequential(\n","            nn.Linear(74, 74),\n","            nn.BatchNorm1d(74),\n","            nn.ReLU(),\n","            nn.Dropout(0.2),\n","            nn.Linear(74, 74),\n","            nn.BatchNorm1d(74),\n","            nn.ReLU(),\n","            nn.Dropout(0.2)\n","        )\n","\n","        self.tfidf_feats = nn.Sequential(\n","            nn.Linear(TFIDF_MAX_FEAT, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 64),\n","            nn.ReLU(),\n","            nn.Linear(64, 64)\n","        )\n","\n","        self.regressor = nn.Sequential( # target、stderror                  \n","            nn.Linear(config.hidden_size + 74 + 64, 2),\n","        )\n","\n","        #self.bin_class = nn.Sequential( # target_sign\n","        #    nn.Linear(config.hidden_size + 64, 1),\n","        #    nn.Dropout(p=0.2),\n","        #    nn.Sigmoid()                       \n","        #)\n","\n","\n","    def forward(self, input_ids, attention_mask, input_desc, input_tfidf):\n","        roberta_output = self.roberta(input_ids=input_ids, # robertaに入力データを流し、出力としてrobertaモデル(layerの複合体)を得る\n","                                      attention_mask=attention_mask)     \n","        # attention_pooling\n","        last_hidden_state = roberta_output.hidden_states[-1] # robertaモデルの最後のlayerを得る\n","        weights = self.attention(last_hidden_state) # robertaの最後のlayerをattentionへ入力し、出力として重みを得る                \n","        context_vector = torch.sum(weights * last_hidden_state, dim=1) # 重み×最後の層を足し合わせて文書ベクトルとする。\n","        # word_length_conv1d\n","        #input_chnl = input_len.unsqueeze(1)\n","        #conv1_layers = self.conv1_layers(input_chnl)\n","        #conv1_layers_v = conv1_layers.view(conv1_layers.size(0),-1)\n","\n","        # numeric_feats\n","        numeric_feats = self.numeric_feats(input_desc)\n","        tfidf_feats = self.tfidf_feats(input_tfidf)\n","\n","        # https://www.kaggle.com/rhtsingh/utilizing-transformer-representations-efficiently\n","        # last_hidden_state = roberta_output[0]\n","        # input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        # sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        # sum_mask = input_mask_expanded.sum(1)\n","        # sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        # mean_embeddings = sum_embeddings / sum_mask\n","        cat_layers = torch.cat([context_vector, numeric_feats, tfidf_feats], dim=1)\n","        return self.regressor(cat_layers)\n","        \n","        # Now we reduce the context vector to the prediction score.\n","        #return self.regressor(mean_embeddings) # 文書ベクトルを線形層に入力し、targetを出力する"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.672515Z","iopub.execute_input":"2021-07-04T06:26:40.672944Z","iopub.status.idle":"2021-07-04T06:26:40.684593Z","shell.execute_reply.started":"2021-07-04T06:26:40.672908Z","shell.execute_reply":"2021-07-04T06:26:40.683569Z"},"trusted":true,"id":"bB4jvQTxXecH","executionInfo":{"status":"ok","timestamp":1627870974115,"user_tz":-540,"elapsed":7,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["def eval_mse(model, data_loader):\n","    \"\"\"Evaluates the mean squared error of the |model| on |data_loader|\"\"\"\n","    model.eval() # evalモードを選択。Batch Normとかdropoutをしなくなる           \n","    mse_mean_sum = 0\n","    mse_std_sum = 0\n","\n","    with torch.no_grad(): # 勾配の計算をしない(予測のみ行う)\n","        for batch_num, (input_ids, attention_mask, input_feats, input_tfidf, target, standard_error) in enumerate(data_loader): # data_loaderからinput, attentin_mask, targetをbatchごとに取り出す\n","            input_ids = input_ids.to(DEVICE)   \n","            attention_mask = attention_mask.to(DEVICE)  \n","            input_feats = input_feats.to(DEVICE) \n","            input_tfidf = input_tfidf.to(DEVICE)\n","            target = target.to(DEVICE)\n","            standard_error = standard_error.to(DEVICE)\n","            \n","            output = model(input_ids, attention_mask, input_feats, input_tfidf) # 取得した値をモデルへ入力し、出力として予測値を得る。\n","\n","            mse_mean_sum += nn.MSELoss(reduction=\"sum\")(output[:,0].flatten(), target).item() # 誤差の合計を得る(Batchごとに計算した誤差を足し上げる)\n","            mse_std_sum += nn.MSELoss(reduction=\"sum\")(output[:,1].flatten(), standard_error).item() # 誤差の合計を得る(Batchごとに計算した誤差を足し上げる)\n","\n","\n","    del input_ids\n","    del attention_mask\n","\n","    mse_mean_result = mse_mean_sum / len(data_loader.dataset)\n","    mse_std_result = mse_std_sum / len(data_loader.dataset)\n","\n","    return mse_mean_result, mse_std_result"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.690155Z","iopub.execute_input":"2021-07-04T06:26:40.692530Z","iopub.status.idle":"2021-07-04T06:26:40.703425Z","shell.execute_reply.started":"2021-07-04T06:26:40.692488Z","shell.execute_reply":"2021-07-04T06:26:40.702366Z"},"trusted":true,"id":"47bDno_LXecI","executionInfo":{"status":"ok","timestamp":1627870974469,"user_tz":-540,"elapsed":9,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 推論結果を返す\n","def predict(model, data_loader):\n","    \"\"\"Returns an np.array with predictions of the |model| on |data_loader|\"\"\"\n","    model.eval() # evalモード(dropout, batch_normしない)\n","\n","    result = np.zeros(len(data_loader.dataset)) # 結果をdataset長のzero配列として用意\n","    index = 0\n","    \n","    with torch.no_grad(): # 勾配の計算をしないblock(inputすると、現状の重みによる推論結果を返す)\n","        for batch_num, (input_ids, attention_mask, input_feats, input_tfidf) in enumerate(data_loader): # data_loaderからbatchごとにinputを得る\n","            input_ids = input_ids.to(DEVICE)\n","            attention_mask = attention_mask.to(DEVICE)\n","            input_feats = input_feats.to(DEVICE)\n","            input_tfidf = input_tfidf.to(DEVICE)\n","                        \n","            output = model(input_ids, attention_mask, input_feats, input_tfidf) # modelにinputを入力し、予測結果を得る。\n","            output_target = output[:,0]\n","\n","            result[index : index + output_target.shape[0]] = output_target.flatten().to(\"cpu\") # result[index ~ predの長さ]へ、予測結果を格納\n","            index += output_target.shape[0] # indexを更新\n","\n","    return result # 全batchで推論が終わったら、結果を返す"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.708605Z","iopub.execute_input":"2021-07-04T06:26:40.709024Z","iopub.status.idle":"2021-07-04T06:26:40.730675Z","shell.execute_reply.started":"2021-07-04T06:26:40.708983Z","shell.execute_reply":"2021-07-04T06:26:40.729705Z"},"trusted":true,"id":"oInneuAmXecI","executionInfo":{"status":"ok","timestamp":1627870974469,"user_tz":-540,"elapsed":7,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# 学習\n","def train(model, # モデル\n","          model_path, # モデルのアウトプット先\n","          train_loader, # train-setのdata_loader\n","          val_loader, # valid-setのdata_loader\n","          optimizer, # optimizer\n","          scheduler=None, # scheduler, デフォルトはNone\n","          num_epochs=NUM_EPOCHS # epoch数、notebook冒頭で指定した値\n","         ):    \n","    \n","    best_val_rmse = None\n","    best_val_sign_bce = None\n","    best_epoch = 0\n","    step = 0\n","    last_eval_step = 0\n","    eval_period = EVAL_SCHEDULE[0][1] # eval期間(って何？) 冒頭で決めたEVAL_SCHEDULEの最初のtupleの[1]を取得\n","\n","    start = time.time() # 時間計測用\n","\n","    for epoch in range(num_epochs): # 指定したEpoch数だけ繰り返し\n","        val_rmse = None         \n","\n","        for batch_num, (input_ids, attention_mask, input_feats, input_tfidf, target, standard_error) in enumerate(train_loader): # train_loaderからinput, targetを取得\n","            input_ids = input_ids.to(DEVICE) # inputをDEVICEへ突っ込む\n","            attention_mask = attention_mask.to(DEVICE)   \n","            input_feats = input_feats.to(DEVICE)\n","            input_tfidf = input_tfidf.to(DEVICE)\n","            target = target.to(DEVICE)\n","            standard_error = standard_error.to(DEVICE)\n","\n","            optimizer.zero_grad() # 勾配を初期化            \n","            model.train() # 学習モード開始\n","\n","            # https://www.kaggle.com/c/commonlitreadabilityprize/discussion/239421\n","            output = model(input_ids, attention_mask, input_feats, input_tfidf) # input,attention_maskを入力し、予測結果を得る\n","            p = torch.distributions.Normal(output[:,0], torch.sqrt(output[:,1]**2))\n","            q = torch.distributions.Normal(target, standard_error)\n","            kl_vector = torch.distributions.kl_divergence(p, q)\n","\n","            loss = kl_vector.mean()\n","\n","            loss.backward() \n","            optimizer.step() # 重みを更新する\n","\n","            if scheduler:\n","                scheduler.step() # schedulerが与えられた場合は、schedulerの学習率更新\n","            \n","            if step >= last_eval_step + eval_period: # batchを回すごとにstepを増やしていって、「前回evalしたstep + eval_period(16)」を超えたら実行。\n","                print(gpuinfo())\n","                # Evaluate the model on val_loader.\n","                elapsed_seconds = time.time() - start # 経過時間\n","                num_steps = step - last_eval_step # 経過ステップ数\n","                print(f\"\\n{num_steps} steps took {elapsed_seconds:0.3} seconds\")\n","                last_eval_step = step # 前回stepの更新\n","                \n","                # valid-setによるrmse計算\n","                train_kldiv = loss\n","                \n","                val_mse_mean, val_mse_std = eval_mse(model, val_loader)\n","                val_rmse_mean = math.sqrt(val_mse_mean)                            \n","                val_rmse_std = math.sqrt(val_mse_std)                            \n","\n","                print(f\"Epoch: {epoch} batch_num: {batch_num}\")\n","                print(f\"train_kldiv: {train_kldiv:0.4}\"\n","                      )\n","                print(f\"val_rmse_mean: {val_rmse_mean:0.4}\",\n","                      f\"val_rmse_std: {val_rmse_std:0.4}\"\n","                      )\n","\n","                for rmse, period in EVAL_SCHEDULE: # eval_periodをvalid-rmseで切り替える処理\n","                    if val_rmse_mean >= rmse: # valid rmseをEVAL_SCHEDULEと比較し、0項 > valid rmseとなるまで回す : EVAL_SCHEDULE = [(0.50, 16), (0.49, 8), (0.48, 4), (0.47, 2), (-1., 1)]\n","                        eval_period = period # eval_periodを更新\n","                        break                               \n","\n","                if not best_val_rmse or val_rmse_mean < best_val_rmse: # 初回(best_val_rmse==None), またはbest_val_rmseを更新したらモデルを保存する\n","                    best_val_rmse = val_rmse_mean\n","                    best_epoch = epoch\n","                    torch.save(model.state_dict(), model_path) # 最高の自分を保存\n","                    print(f\"New best_val_rmse: {best_val_rmse:0.4}\")\n","                else:       \n","                    print(f\"Still best_val_rmse: {best_val_rmse:0.4}\", # 更新されない場合は、元のスコアを表示\n","                          f\"(from epoch {best_epoch})\")      \n","\n","                start = time.time()\n","            \n","            # batchごとにメモリ解放\n","            del input_ids\n","            del attention_mask\n","            torch.cuda.empty_cache()                                            \n","            step += 1\n","    \n","    return best_val_rmse"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.735798Z","iopub.execute_input":"2021-07-04T06:26:40.738398Z","iopub.status.idle":"2021-07-04T06:26:40.750876Z","shell.execute_reply.started":"2021-07-04T06:26:40.738356Z","shell.execute_reply":"2021-07-04T06:26:40.749635Z"},"trusted":true,"id":"rMY0fjXwXecJ","executionInfo":{"status":"ok","timestamp":1627870974470,"user_tz":-540,"elapsed":7,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["# optimizerの作成\n","def create_optimizer(model):\n","    parameters = []\n","\n","    named_parameters = list(model.named_parameters()) # モデルパラメータの取得\n","    roberta_parameters = list(model.roberta.named_parameters())[:-2] # パラメータをroberta用、attention用、regressor用に格納。(直接引っ張ってくる形式に変更)\n","\n","    attention_parameters = list(model.attention.named_parameters())\n","    attention_group = [{'params': params, 'lr': 2e-5} for (name, params) in attention_parameters] # attention用パラメータをリストとして取得\n","    parameters += attention_group\n","\n","    regressor_parameters = list(model.regressor.named_parameters())\n","    regressor_group = [{'params': params, 'lr': 2e-5} for (name, params) in regressor_parameters] # reg用パラメータをリストとして取得\n","    parameters += regressor_group\n","\n","    numeric_feats_parameters = list(model.numeric_feats.named_parameters())\n","    numeric_feats_group = [{'params': params, 'lr': 2e-5} for (name, params) in numeric_feats_parameters] # reg用パラメータをリストとして取得\n","    parameters += numeric_feats_group\n","\n","    tfidf_feats_parameters = list(model.tfidf_feats.named_parameters())\n","    tfidf_feats_group = [{'params': params, 'lr': 2e-5} for (name, params) in tfidf_feats_parameters] # reg用パラメータをリストとして取得\n","    parameters += tfidf_feats_group\n","\n","    for layer_num, (name, params) in enumerate(roberta_parameters): # レイヤーごとにname, paramsを取得していろんな処理\n","        weight_decay = 0.0 if \"bias\" in name else 0.01\n","\n","        lr = 8e-6\n","\n","        if layer_num >= 69:        \n","            lr = 2e-5\n","\n","        if layer_num >= 133:\n","            lr = 4e-5\n","\n","        parameters.append({\"params\": params,\n","                           \"weight_decay\": weight_decay,\n","                           \"lr\": lr})\n","\n","    return AdamW(parameters) # 最終的に、AdamWにパラメータを入力する。\n"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"4PLKHwvKtNBn","executionInfo":{"status":"ok","timestamp":1627870974470,"user_tz":-540,"elapsed":6,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["def train_and_save_model(train_indices, val_indices, model_path, feat_suffix):\n","    tfidf = TfidfSimpleBlock('excerpt', max_features=TFIDF_MAX_FEAT)\n","    df_tfidf = tfidf.fit(train_kf_df.loc[train_indices]) # TODO: fit_transformみたいなメソッド作って、fitではdfが返らないようにする。\n","\n","    with open(f'TFIDF_{feat_suffix}', 'wb') as f:\n","      pickle.dump(tfidf, f)\n","\n","    train_dataset = LitDataset(train_kf_df.loc[train_indices], tfidf) # train, validのDataset\n","    val_dataset = LitDataset(train_kf_df.loc[val_indices], tfidf)\n","        \n","    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n","                              drop_last=True, shuffle=True, num_workers=2) # train, validのDataLoader\n","    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n","                            drop_last=False, shuffle=False, num_workers=2)    \n","\n","    model = LitModel().to(DEVICE) # modelをDEVICEへぶち込む\n","    optimizer = create_optimizer(model) # optimizerをモデルから作成\n","    scheduler = get_cosine_schedule_with_warmup( # schedulerを作成\n","        optimizer,\n","        num_training_steps=NUM_EPOCHS * len(train_loader),\n","        num_warmup_steps=50)    \n","    rmse = train(model, model_path, train_loader, val_loader, optimizer, scheduler=scheduler)\n","\n","    del train_dataset\n","    del val_dataset\n","    del train_loader\n","    del val_loader\n","    del model\n","    del optimizer\n","    del scheduler\n","    gc.collect() \n","    torch.cuda.empty_cache()\n","    return rmse"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-04T06:26:40.755813Z","iopub.execute_input":"2021-07-04T06:26:40.758373Z","iopub.status.idle":"2021-07-04T06:27:12.493221Z","shell.execute_reply.started":"2021-07-04T06:26:40.758265Z","shell.execute_reply":"2021-07-04T06:27:12.490139Z"},"trusted":true,"id":"k2LGJD3XXecK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627879582976,"user_tz":-540,"elapsed":8608512,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"bef6b1a0-c29f-44f1-de62-dd2c3fbc3e97"},"source":["# 実行処理。 KFold & 学習\n","SEED = 1000\n","list_val_rmse = []\n","\n","for fold in sorted(train_kf_df['kfold'].unique()):\n","    print(f\"\\nFold {fold + 1}/{NUM_FOLDS}\")\n","    print(gpuinfo())\n","    model_path = f\"model_{fold + 1}.pth\" # model_fold数_.pth\n","    feat_suffix = f\"{fold + 1}.pkl\" \n","\n","    set_random_seed(SEED + fold) # SEEDはfold別に変わるようにする\n","\n","    train_indices = (train_kf_df['kfold'] != fold)\n","    val_indices = (train_kf_df['kfold'] == fold)\n","    list_val_rmse.append(train_and_save_model(train_indices, val_indices, model_path, feat_suffix))\n","    print(\"\\nPerformance estimates:\")\n","    print(list_val_rmse)\n","    print(\"Mean:\", np.array(list_val_rmse).mean())\n","    print(gpuinfo())"],"execution_count":26,"outputs":[{"output_type":"stream","text":["\n","Fold 1/5\n","{'total_MiB': 16280, 'used_MiB': 2}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","64 steps took 83.5 seconds\n","Epoch: 0 batch_num: 64\n","train_kldiv: 0.9002\n","val_rmse_mean: 0.7769 val_rmse_std: 0.9345\n","New best_val_rmse: 0.7769\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","64 steps took 82.3 seconds\n","Epoch: 0 batch_num: 128\n","train_kldiv: 0.8979\n","val_rmse_mean: 0.6843 val_rmse_std: 1.007\n","New best_val_rmse: 0.6843\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","64 steps took 82.5 seconds\n","Epoch: 1 batch_num: 4\n","train_kldiv: 0.4835\n","val_rmse_mean: 0.5491 val_rmse_std: 0.9867\n","New best_val_rmse: 0.5491\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.5 seconds\n","Epoch: 1 batch_num: 36\n","train_kldiv: 0.498\n","val_rmse_mean: 0.5233 val_rmse_std: 0.9628\n","New best_val_rmse: 0.5233\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.4 seconds\n","Epoch: 1 batch_num: 68\n","train_kldiv: 0.4889\n","val_rmse_mean: 0.5381 val_rmse_std: 0.9772\n","Still best_val_rmse: 0.5233 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.4 seconds\n","Epoch: 1 batch_num: 100\n","train_kldiv: 0.4656\n","val_rmse_mean: 0.5345 val_rmse_std: 0.9709\n","Still best_val_rmse: 0.5233 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.4 seconds\n","Epoch: 1 batch_num: 132\n","train_kldiv: 0.4295\n","val_rmse_mean: 0.542 val_rmse_std: 1.01\n","Still best_val_rmse: 0.5233 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.3 seconds\n","Epoch: 1 batch_num: 164\n","train_kldiv: 0.2844\n","val_rmse_mean: 0.5414 val_rmse_std: 0.9783\n","Still best_val_rmse: 0.5233 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.6 seconds\n","Epoch: 2 batch_num: 8\n","train_kldiv: 0.2082\n","val_rmse_mean: 0.5556 val_rmse_std: 0.9803\n","Still best_val_rmse: 0.5233 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","64 steps took 82.3 seconds\n","Epoch: 2 batch_num: 72\n","train_kldiv: 0.1834\n","val_rmse_mean: 0.5146 val_rmse_std: 1.0\n","New best_val_rmse: 0.5146\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.4 seconds\n","Epoch: 2 batch_num: 104\n","train_kldiv: 0.1668\n","val_rmse_mean: 0.5139 val_rmse_std: 0.9775\n","New best_val_rmse: 0.5139\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.4 seconds\n","Epoch: 2 batch_num: 136\n","train_kldiv: 0.1044\n","val_rmse_mean: 0.5139 val_rmse_std: 0.9807\n","Still best_val_rmse: 0.5139 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.4 seconds\n","Epoch: 2 batch_num: 168\n","train_kldiv: 0.1523\n","val_rmse_mean: 0.537 val_rmse_std: 0.9834\n","Still best_val_rmse: 0.5139 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.6 seconds\n","Epoch: 3 batch_num: 12\n","train_kldiv: 0.1248\n","val_rmse_mean: 0.52 val_rmse_std: 0.9754\n","Still best_val_rmse: 0.5139 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.4 seconds\n","Epoch: 3 batch_num: 44\n","train_kldiv: 0.09313\n","val_rmse_mean: 0.5107 val_rmse_std: 0.9862\n","New best_val_rmse: 0.5107\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.4 seconds\n","Epoch: 3 batch_num: 76\n","train_kldiv: 0.0878\n","val_rmse_mean: 0.5124 val_rmse_std: 0.9876\n","Still best_val_rmse: 0.5107 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.4 seconds\n","Epoch: 3 batch_num: 108\n","train_kldiv: 0.2005\n","val_rmse_mean: 0.5092 val_rmse_std: 0.9851\n","New best_val_rmse: 0.5092\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.4 seconds\n","Epoch: 3 batch_num: 140\n","train_kldiv: 0.1359\n","val_rmse_mean: 0.5059 val_rmse_std: 1.0\n","New best_val_rmse: 0.5059\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.4 seconds\n","Epoch: 3 batch_num: 172\n","train_kldiv: 0.1095\n","val_rmse_mean: 0.5085 val_rmse_std: 0.9854\n","Still best_val_rmse: 0.5059 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.6 seconds\n","Epoch: 4 batch_num: 16\n","train_kldiv: 0.05492\n","val_rmse_mean: 0.5097 val_rmse_std: 0.9788\n","Still best_val_rmse: 0.5059 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.4 seconds\n","Epoch: 4 batch_num: 48\n","train_kldiv: 0.04997\n","val_rmse_mean: 0.5017 val_rmse_std: 0.9887\n","New best_val_rmse: 0.5017\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.4 seconds\n","Epoch: 4 batch_num: 80\n","train_kldiv: 0.04012\n","val_rmse_mean: 0.5034 val_rmse_std: 0.9853\n","Still best_val_rmse: 0.5017 (from epoch 4)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.4 seconds\n","Epoch: 4 batch_num: 112\n","train_kldiv: 0.07851\n","val_rmse_mean: 0.5032 val_rmse_std: 0.9823\n","Still best_val_rmse: 0.5017 (from epoch 4)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.4 seconds\n","Epoch: 4 batch_num: 144\n","train_kldiv: 0.06186\n","val_rmse_mean: 0.5043 val_rmse_std: 0.9843\n","Still best_val_rmse: 0.5017 (from epoch 4)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.4 seconds\n","Epoch: 4 batch_num: 176\n","train_kldiv: 0.0858\n","val_rmse_mean: 0.5043 val_rmse_std: 0.9843\n","Still best_val_rmse: 0.5017 (from epoch 4)\n","\n","Performance estimates:\n","[0.5017269542455848]\n","Mean: 0.5017269542455848\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 2/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","64 steps took 83.3 seconds\n","Epoch: 0 batch_num: 64\n","train_kldiv: 1.227\n","val_rmse_mean: 0.7778 val_rmse_std: 0.09146\n","New best_val_rmse: 0.7778\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","64 steps took 82.3 seconds\n","Epoch: 0 batch_num: 128\n","train_kldiv: 0.6095\n","val_rmse_mean: 0.5881 val_rmse_std: 0.07601\n","New best_val_rmse: 0.5881\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","64 steps took 82.5 seconds\n","Epoch: 1 batch_num: 4\n","train_kldiv: 0.5371\n","val_rmse_mean: 0.5491 val_rmse_std: 0.07218\n","New best_val_rmse: 0.5491\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.4 seconds\n","Epoch: 1 batch_num: 36\n","train_kldiv: 0.9029\n","val_rmse_mean: 0.5764 val_rmse_std: 0.07682\n","Still best_val_rmse: 0.5491 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","64 steps took 82.3 seconds\n","Epoch: 1 batch_num: 100\n","train_kldiv: 0.6695\n","val_rmse_mean: 0.5107 val_rmse_std: 0.07036\n","New best_val_rmse: 0.5107\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.4 seconds\n","Epoch: 1 batch_num: 132\n","train_kldiv: 0.4842\n","val_rmse_mean: 0.5996 val_rmse_std: 0.06629\n","Still best_val_rmse: 0.5107 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","64 steps took 82.4 seconds\n","Epoch: 2 batch_num: 8\n","train_kldiv: 0.3923\n","val_rmse_mean: 0.5427 val_rmse_std: 0.06934\n","Still best_val_rmse: 0.5107 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.4 seconds\n","Epoch: 2 batch_num: 40\n","train_kldiv: 0.3672\n","val_rmse_mean: 0.5165 val_rmse_std: 0.0705\n","Still best_val_rmse: 0.5107 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.4 seconds\n","Epoch: 2 batch_num: 72\n","train_kldiv: 0.5676\n","val_rmse_mean: 0.5252 val_rmse_std: 0.06909\n","Still best_val_rmse: 0.5107 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.4 seconds\n","Epoch: 2 batch_num: 104\n","train_kldiv: 0.4108\n","val_rmse_mean: 0.4991 val_rmse_std: 0.07893\n","New best_val_rmse: 0.4991\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.3 seconds\n","Epoch: 2 batch_num: 136\n","train_kldiv: 0.302\n","val_rmse_mean: 0.4889 val_rmse_std: 0.06684\n","New best_val_rmse: 0.4889\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.3 seconds\n","Epoch: 2 batch_num: 168\n","train_kldiv: 0.2813\n","val_rmse_mean: 0.4941 val_rmse_std: 0.0679\n","Still best_val_rmse: 0.4889 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.5 seconds\n","Epoch: 3 batch_num: 12\n","train_kldiv: 0.1522\n","val_rmse_mean: 0.4931 val_rmse_std: 0.07461\n","Still best_val_rmse: 0.4889 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.3 seconds\n","Epoch: 3 batch_num: 44\n","train_kldiv: 0.2362\n","val_rmse_mean: 0.4814 val_rmse_std: 0.0747\n","New best_val_rmse: 0.4814\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.3 seconds\n","Epoch: 3 batch_num: 76\n","train_kldiv: 0.2501\n","val_rmse_mean: 0.4922 val_rmse_std: 0.07447\n","Still best_val_rmse: 0.4814 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.3 seconds\n","Epoch: 3 batch_num: 108\n","train_kldiv: 0.2377\n","val_rmse_mean: 0.482 val_rmse_std: 0.06765\n","Still best_val_rmse: 0.4814 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.3 seconds\n","Epoch: 3 batch_num: 140\n","train_kldiv: 0.126\n","val_rmse_mean: 0.4831 val_rmse_std: 0.06503\n","Still best_val_rmse: 0.4814 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.3 seconds\n","Epoch: 3 batch_num: 172\n","train_kldiv: 0.2288\n","val_rmse_mean: 0.4853 val_rmse_std: 0.06905\n","Still best_val_rmse: 0.4814 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.5 seconds\n","Epoch: 4 batch_num: 16\n","train_kldiv: 0.1105\n","val_rmse_mean: 0.483 val_rmse_std: 0.06332\n","Still best_val_rmse: 0.4814 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.3 seconds\n","Epoch: 4 batch_num: 48\n","train_kldiv: 0.1051\n","val_rmse_mean: 0.4867 val_rmse_std: 0.06678\n","Still best_val_rmse: 0.4814 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.3 seconds\n","Epoch: 4 batch_num: 80\n","train_kldiv: 0.2263\n","val_rmse_mean: 0.487 val_rmse_std: 0.06571\n","Still best_val_rmse: 0.4814 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.3 seconds\n","Epoch: 4 batch_num: 112\n","train_kldiv: 0.1345\n","val_rmse_mean: 0.4808 val_rmse_std: 0.06592\n","New best_val_rmse: 0.4808\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.3 seconds\n","Epoch: 4 batch_num: 144\n","train_kldiv: 0.103\n","val_rmse_mean: 0.4846 val_rmse_std: 0.06319\n","Still best_val_rmse: 0.4808 (from epoch 4)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.3 seconds\n","Epoch: 4 batch_num: 176\n","train_kldiv: 0.1703\n","val_rmse_mean: 0.4851 val_rmse_std: 0.06902\n","Still best_val_rmse: 0.4808 (from epoch 4)\n","\n","Performance estimates:\n","[0.5017269542455848, 0.48080098485479467]\n","Mean: 0.4912639695501897\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 3/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","64 steps took 83.4 seconds\n","Epoch: 0 batch_num: 64\n","train_kldiv: 1.27\n","val_rmse_mean: 0.681 val_rmse_std: 1.018\n","New best_val_rmse: 0.681\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","64 steps took 82.3 seconds\n","Epoch: 0 batch_num: 128\n","train_kldiv: 1.093\n","val_rmse_mean: 0.6806 val_rmse_std: 0.9802\n","New best_val_rmse: 0.6806\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","64 steps took 82.6 seconds\n","Epoch: 1 batch_num: 4\n","train_kldiv: 0.553\n","val_rmse_mean: 0.5646 val_rmse_std: 0.957\n","New best_val_rmse: 0.5646\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","64 steps took 82.4 seconds\n","Epoch: 1 batch_num: 68\n","train_kldiv: 0.5921\n","val_rmse_mean: 0.5074 val_rmse_std: 0.9787\n","New best_val_rmse: 0.5074\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.5 seconds\n","Epoch: 1 batch_num: 100\n","train_kldiv: 0.247\n","val_rmse_mean: 0.4829 val_rmse_std: 0.9862\n","New best_val_rmse: 0.4829\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.5 seconds\n","Epoch: 1 batch_num: 132\n","train_kldiv: 0.256\n","val_rmse_mean: 0.5257 val_rmse_std: 0.9563\n","Still best_val_rmse: 0.4829 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.5 seconds\n","Epoch: 1 batch_num: 164\n","train_kldiv: 0.5972\n","val_rmse_mean: 0.4809 val_rmse_std: 0.9516\n","New best_val_rmse: 0.4809\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.7 seconds\n","Epoch: 2 batch_num: 8\n","train_kldiv: 0.2202\n","val_rmse_mean: 0.5188 val_rmse_std: 0.9828\n","Still best_val_rmse: 0.4809 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.4 seconds\n","Epoch: 2 batch_num: 40\n","train_kldiv: 0.2215\n","val_rmse_mean: 0.5062 val_rmse_std: 0.9759\n","Still best_val_rmse: 0.4809 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.5 seconds\n","Epoch: 2 batch_num: 72\n","train_kldiv: 0.3113\n","val_rmse_mean: 0.5028 val_rmse_std: 0.9816\n","Still best_val_rmse: 0.4809 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.5 seconds\n","Epoch: 2 batch_num: 104\n","train_kldiv: 0.2781\n","val_rmse_mean: 0.5197 val_rmse_std: 0.9616\n","Still best_val_rmse: 0.4809 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.5 seconds\n","Epoch: 2 batch_num: 136\n","train_kldiv: 0.1976\n","val_rmse_mean: 0.4813 val_rmse_std: 0.9983\n","Still best_val_rmse: 0.4809 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.5 seconds\n","Epoch: 2 batch_num: 168\n","train_kldiv: 0.2225\n","val_rmse_mean: 0.5762 val_rmse_std: 0.9787\n","Still best_val_rmse: 0.4809 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","64 steps took 82.6 seconds\n","Epoch: 3 batch_num: 44\n","train_kldiv: 0.09237\n","val_rmse_mean: 0.4835 val_rmse_std: 0.9813\n","Still best_val_rmse: 0.4809 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.4 seconds\n","Epoch: 3 batch_num: 76\n","train_kldiv: 0.1465\n","val_rmse_mean: 0.4787 val_rmse_std: 0.9825\n","New best_val_rmse: 0.4787\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.5 seconds\n","Epoch: 3 batch_num: 108\n","train_kldiv: 0.1162\n","val_rmse_mean: 0.4845 val_rmse_std: 0.9492\n","Still best_val_rmse: 0.4787 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.4 seconds\n","Epoch: 3 batch_num: 140\n","train_kldiv: 0.04957\n","val_rmse_mean: 0.4859 val_rmse_std: 0.9871\n","Still best_val_rmse: 0.4787 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.5 seconds\n","Epoch: 3 batch_num: 172\n","train_kldiv: 0.0978\n","val_rmse_mean: 0.4749 val_rmse_std: 0.982\n","New best_val_rmse: 0.4749\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.6 seconds\n","Epoch: 4 batch_num: 16\n","train_kldiv: 0.07275\n","val_rmse_mean: 0.4728 val_rmse_std: 0.981\n","New best_val_rmse: 0.4728\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.4 seconds\n","Epoch: 4 batch_num: 48\n","train_kldiv: 0.04207\n","val_rmse_mean: 0.475 val_rmse_std: 0.9791\n","Still best_val_rmse: 0.4728 (from epoch 4)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.3 seconds\n","Epoch: 4 batch_num: 80\n","train_kldiv: 0.07232\n","val_rmse_mean: 0.4771 val_rmse_std: 0.9846\n","Still best_val_rmse: 0.4728 (from epoch 4)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.4 seconds\n","Epoch: 4 batch_num: 112\n","train_kldiv: 0.04295\n","val_rmse_mean: 0.4762 val_rmse_std: 0.9858\n","Still best_val_rmse: 0.4728 (from epoch 4)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.4 seconds\n","Epoch: 4 batch_num: 144\n","train_kldiv: 0.05813\n","val_rmse_mean: 0.4772 val_rmse_std: 0.9772\n","Still best_val_rmse: 0.4728 (from epoch 4)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.4 seconds\n","Epoch: 4 batch_num: 176\n","train_kldiv: 0.05262\n","val_rmse_mean: 0.4773 val_rmse_std: 0.9804\n","Still best_val_rmse: 0.4728 (from epoch 4)\n","\n","Performance estimates:\n","[0.5017269542455848, 0.48080098485479467, 0.47275398115064254]\n","Mean: 0.4850939734170073\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 4/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","64 steps took 83.6 seconds\n","Epoch: 0 batch_num: 64\n","train_kldiv: 1.24\n","val_rmse_mean: 0.6718 val_rmse_std: 0.9936\n","New best_val_rmse: 0.6718\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","64 steps took 82.3 seconds\n","Epoch: 0 batch_num: 128\n","train_kldiv: 1.126\n","val_rmse_mean: 0.6203 val_rmse_std: 0.9811\n","New best_val_rmse: 0.6203\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","64 steps took 82.5 seconds\n","Epoch: 1 batch_num: 4\n","train_kldiv: 0.5393\n","val_rmse_mean: 0.5442 val_rmse_std: 0.9913\n","New best_val_rmse: 0.5442\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.4 seconds\n","Epoch: 1 batch_num: 36\n","train_kldiv: 0.5848\n","val_rmse_mean: 0.5294 val_rmse_std: 1.001\n","New best_val_rmse: 0.5294\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.4 seconds\n","Epoch: 1 batch_num: 68\n","train_kldiv: 0.4073\n","val_rmse_mean: 0.4958 val_rmse_std: 1.01\n","New best_val_rmse: 0.4958\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.4 seconds\n","Epoch: 1 batch_num: 100\n","train_kldiv: 0.27\n","val_rmse_mean: 0.4958 val_rmse_std: 0.994\n","New best_val_rmse: 0.4958\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.4 seconds\n","Epoch: 1 batch_num: 132\n","train_kldiv: 0.2626\n","val_rmse_mean: 0.5013 val_rmse_std: 0.9738\n","Still best_val_rmse: 0.4958 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.3 seconds\n","Epoch: 1 batch_num: 164\n","train_kldiv: 0.6257\n","val_rmse_mean: 0.5007 val_rmse_std: 1.001\n","Still best_val_rmse: 0.4958 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.6 seconds\n","Epoch: 2 batch_num: 8\n","train_kldiv: 0.1935\n","val_rmse_mean: 0.5165 val_rmse_std: 1.03\n","Still best_val_rmse: 0.4958 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.4 seconds\n","Epoch: 2 batch_num: 40\n","train_kldiv: 0.5573\n","val_rmse_mean: 0.4868 val_rmse_std: 0.9768\n","New best_val_rmse: 0.4868\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.3 seconds\n","Epoch: 2 batch_num: 72\n","train_kldiv: 0.2238\n","val_rmse_mean: 0.5014 val_rmse_std: 0.9381\n","Still best_val_rmse: 0.4868 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.3 seconds\n","Epoch: 2 batch_num: 104\n","train_kldiv: 0.1015\n","val_rmse_mean: 0.4691 val_rmse_std: 0.9858\n","New best_val_rmse: 0.4691\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.4 seconds\n","Epoch: 2 batch_num: 136\n","train_kldiv: 0.3351\n","val_rmse_mean: 0.4699 val_rmse_std: 1.017\n","Still best_val_rmse: 0.4691 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.4 seconds\n","Epoch: 2 batch_num: 168\n","train_kldiv: 0.1659\n","val_rmse_mean: 0.4663 val_rmse_std: 0.9875\n","New best_val_rmse: 0.4663\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.5 seconds\n","Epoch: 3 batch_num: 12\n","train_kldiv: 0.2022\n","val_rmse_mean: 0.4753 val_rmse_std: 1.0\n","Still best_val_rmse: 0.4663 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.3 seconds\n","Epoch: 3 batch_num: 44\n","train_kldiv: 0.09801\n","val_rmse_mean: 0.4663 val_rmse_std: 0.9853\n","Still best_val_rmse: 0.4663 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.3 seconds\n","Epoch: 3 batch_num: 76\n","train_kldiv: 0.121\n","val_rmse_mean: 0.4633 val_rmse_std: 0.9853\n","New best_val_rmse: 0.4633\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.3 seconds\n","Epoch: 3 batch_num: 108\n","train_kldiv: 0.07229\n","val_rmse_mean: 0.4621 val_rmse_std: 0.982\n","New best_val_rmse: 0.4621\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.3 seconds\n","Epoch: 3 batch_num: 140\n","train_kldiv: 0.1138\n","val_rmse_mean: 0.4736 val_rmse_std: 0.9835\n","Still best_val_rmse: 0.4621 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.3 seconds\n","Epoch: 3 batch_num: 172\n","train_kldiv: 0.04732\n","val_rmse_mean: 0.4661 val_rmse_std: 0.985\n","Still best_val_rmse: 0.4621 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.5 seconds\n","Epoch: 4 batch_num: 16\n","train_kldiv: 0.08766\n","val_rmse_mean: 0.4647 val_rmse_std: 0.9966\n","Still best_val_rmse: 0.4621 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.3 seconds\n","Epoch: 4 batch_num: 48\n","train_kldiv: 0.04631\n","val_rmse_mean: 0.4649 val_rmse_std: 0.9983\n","Still best_val_rmse: 0.4621 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.3 seconds\n","Epoch: 4 batch_num: 80\n","train_kldiv: 0.07172\n","val_rmse_mean: 0.4651 val_rmse_std: 0.9913\n","Still best_val_rmse: 0.4621 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.3 seconds\n","Epoch: 4 batch_num: 112\n","train_kldiv: 0.1246\n","val_rmse_mean: 0.4638 val_rmse_std: 0.982\n","Still best_val_rmse: 0.4621 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.3 seconds\n","Epoch: 4 batch_num: 144\n","train_kldiv: 0.1441\n","val_rmse_mean: 0.4661 val_rmse_std: 0.9923\n","Still best_val_rmse: 0.4621 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.3 seconds\n","Epoch: 4 batch_num: 176\n","train_kldiv: 0.0481\n","val_rmse_mean: 0.4664 val_rmse_std: 1.007\n","Still best_val_rmse: 0.4621 (from epoch 3)\n","\n","Performance estimates:\n","[0.5017269542455848, 0.48080098485479467, 0.47275398115064254, 0.46208373938292613]\n","Mean: 0.47934141490848703\n","{'total_MiB': 16280, 'used_MiB': 927}\n","\n","Fold 5/5\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","64 steps took 83.4 seconds\n","Epoch: 0 batch_num: 64\n","train_kldiv: 0.5937\n","val_rmse_mean: 0.7412 val_rmse_std: 0.9492\n","New best_val_rmse: 0.7412\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","64 steps took 82.5 seconds\n","Epoch: 0 batch_num: 128\n","train_kldiv: 0.4565\n","val_rmse_mean: 0.5579 val_rmse_std: 0.9331\n","New best_val_rmse: 0.5579\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","64 steps took 82.7 seconds\n","Epoch: 1 batch_num: 4\n","train_kldiv: 0.3948\n","val_rmse_mean: 0.5474 val_rmse_std: 0.9785\n","New best_val_rmse: 0.5474\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.6 seconds\n","Epoch: 1 batch_num: 36\n","train_kldiv: 0.3262\n","val_rmse_mean: 0.519 val_rmse_std: 0.9972\n","New best_val_rmse: 0.519\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.6 seconds\n","Epoch: 1 batch_num: 68\n","train_kldiv: 0.5502\n","val_rmse_mean: 0.5133 val_rmse_std: 1.017\n","New best_val_rmse: 0.5133\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.6 seconds\n","Epoch: 1 batch_num: 100\n","train_kldiv: 0.8312\n","val_rmse_mean: 0.5591 val_rmse_std: 1.011\n","Still best_val_rmse: 0.5133 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","64 steps took 82.4 seconds\n","Epoch: 1 batch_num: 164\n","train_kldiv: 0.754\n","val_rmse_mean: 0.594 val_rmse_std: 0.9963\n","Still best_val_rmse: 0.5133 (from epoch 1)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","64 steps took 82.7 seconds\n","Epoch: 2 batch_num: 40\n","train_kldiv: 0.3191\n","val_rmse_mean: 0.5104 val_rmse_std: 0.9897\n","New best_val_rmse: 0.5104\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.5 seconds\n","Epoch: 2 batch_num: 72\n","train_kldiv: 0.4214\n","val_rmse_mean: 0.5027 val_rmse_std: 1.018\n","New best_val_rmse: 0.5027\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.5 seconds\n","Epoch: 2 batch_num: 104\n","train_kldiv: 0.1988\n","val_rmse_mean: 0.4826 val_rmse_std: 1.004\n","New best_val_rmse: 0.4826\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.5 seconds\n","Epoch: 2 batch_num: 136\n","train_kldiv: 0.1958\n","val_rmse_mean: 0.4873 val_rmse_std: 0.9934\n","Still best_val_rmse: 0.4826 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.4 seconds\n","Epoch: 2 batch_num: 168\n","train_kldiv: 0.1329\n","val_rmse_mean: 0.4982 val_rmse_std: 0.9909\n","Still best_val_rmse: 0.4826 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.6 seconds\n","Epoch: 3 batch_num: 12\n","train_kldiv: 0.1271\n","val_rmse_mean: 0.4984 val_rmse_std: 0.9909\n","Still best_val_rmse: 0.4826 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.4 seconds\n","Epoch: 3 batch_num: 44\n","train_kldiv: 0.1574\n","val_rmse_mean: 0.4849 val_rmse_std: 0.9689\n","Still best_val_rmse: 0.4826 (from epoch 2)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.4 seconds\n","Epoch: 3 batch_num: 76\n","train_kldiv: 0.1634\n","val_rmse_mean: 0.4794 val_rmse_std: 0.9593\n","New best_val_rmse: 0.4794\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.4 seconds\n","Epoch: 3 batch_num: 108\n","train_kldiv: 0.162\n","val_rmse_mean: 0.4792 val_rmse_std: 0.9898\n","New best_val_rmse: 0.4792\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.4 seconds\n","Epoch: 3 batch_num: 140\n","train_kldiv: 0.07201\n","val_rmse_mean: 0.4887 val_rmse_std: 0.9787\n","Still best_val_rmse: 0.4792 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.5 seconds\n","Epoch: 3 batch_num: 172\n","train_kldiv: 0.1211\n","val_rmse_mean: 0.48 val_rmse_std: 0.9735\n","Still best_val_rmse: 0.4792 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.6 seconds\n","Epoch: 4 batch_num: 16\n","train_kldiv: 0.126\n","val_rmse_mean: 0.4858 val_rmse_std: 0.9812\n","Still best_val_rmse: 0.4792 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.4 seconds\n","Epoch: 4 batch_num: 48\n","train_kldiv: 0.05689\n","val_rmse_mean: 0.4845 val_rmse_std: 0.9783\n","Still best_val_rmse: 0.4792 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.4 seconds\n","Epoch: 4 batch_num: 80\n","train_kldiv: 0.0685\n","val_rmse_mean: 0.4858 val_rmse_std: 0.9823\n","Still best_val_rmse: 0.4792 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.5 seconds\n","Epoch: 4 batch_num: 112\n","train_kldiv: 0.0422\n","val_rmse_mean: 0.4811 val_rmse_std: 0.9787\n","Still best_val_rmse: 0.4792 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.4 seconds\n","Epoch: 4 batch_num: 144\n","train_kldiv: 0.07828\n","val_rmse_mean: 0.4798 val_rmse_std: 0.9896\n","Still best_val_rmse: 0.4792 (from epoch 3)\n","{'total_MiB': 16280, 'used_MiB': 15111}\n","\n","32 steps took 41.4 seconds\n","Epoch: 4 batch_num: 176\n","train_kldiv: 0.04431\n","val_rmse_mean: 0.4819 val_rmse_std: 0.9847\n","Still best_val_rmse: 0.4792 (from epoch 3)\n","\n","Performance estimates:\n","[0.5017269542455848, 0.48080098485479467, 0.47275398115064254, 0.46208373938292613, 0.4791916165574261]\n","Mean: 0.47931145523827484\n","{'total_MiB': 16280, 'used_MiB': 927}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"YSFnleU5vZS8","executionInfo":{"status":"ok","timestamp":1627879582978,"user_tz":-540,"elapsed":39,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"8c4e74b1-e98a-46d8-fcd7-585d7468d44f"},"source":["\"\"\"desc_block = TextDescriptionBlock('excerpt')\n","desc_feats = desc_block.fit(train_kf_df.loc[train_indices])\n","desc_block_src = TextDescriptionBlock('excerpt')\n","desc_feats_src = desc_block_src.fit(train_kf_df.head(10))\"\"\""],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"desc_block = TextDescriptionBlock('excerpt')\\ndesc_feats = desc_block.fit(train_kf_df.loc[train_indices])\\ndesc_block_src = TextDescriptionBlock('excerpt')\\ndesc_feats_src = desc_block_src.fit(train_kf_df.head(10))\""]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":69},"id":"D0biwiMjq5KP","executionInfo":{"status":"ok","timestamp":1627879582979,"user_tz":-540,"elapsed":32,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"7c182ed1-07f8-41c1-deed-911ed35f70bb"},"source":["\"\"\"train_dataset = LitDataset(train_kf_df.loc[train_indices]) # train, validのDataset\n","val_dataset = LitDataset(train_kf_df.loc[val_indices])\n","    \n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n","                          drop_last=True, shuffle=True, num_workers=2) # train, validのDataLoader\n","val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n","                        drop_last=False, shuffle=False, num_workers=2)    \n","\"\"\""],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'train_dataset = LitDataset(train_kf_df.loc[train_indices]) # train, validのDataset\\nval_dataset = LitDataset(train_kf_df.loc[val_indices])\\n    \\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\\n                          drop_last=True, shuffle=True, num_workers=2) # train, validのDataLoader\\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\\n                        drop_last=False, shuffle=False, num_workers=2)    \\n'"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"m4v-cGx-Mv7S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627879582980,"user_tz":-540,"elapsed":32,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"959188eb-a301-434a-b35d-fc37d1791072"},"source":["print(list_val_rmse)"],"execution_count":29,"outputs":[{"output_type":"stream","text":["[0.5017269542455848, 0.48080098485479467, 0.47275398115064254, 0.46208373938292613, 0.4791916165574261]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XU4gRXHCBEpC","executionInfo":{"status":"ok","timestamp":1627879582981,"user_tz":-540,"elapsed":27,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"iAb99KSKBEmd","executionInfo":{"status":"ok","timestamp":1627879582981,"user_tz":-540,"elapsed":26,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"jH0aFzWxBEkG","executionInfo":{"status":"ok","timestamp":1627879582982,"user_tz":-540,"elapsed":27,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"q2CdCMuIKDMP","executionInfo":{"status":"ok","timestamp":1627879582983,"user_tz":-540,"elapsed":27,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#rep = MemReporter(model)\n","#rep.report()"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"eLl1yDOOKIe7","executionInfo":{"status":"ok","timestamp":1627879582983,"user_tz":-540,"elapsed":27,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#rep = MemReporter(model.roberta)\n","#rep.report()"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"7qkqnknA_m9D","executionInfo":{"status":"ok","timestamp":1627879582984,"user_tz":-540,"elapsed":27,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#gpuinfo()"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"PwrqSMdYA6Pu","executionInfo":{"status":"ok","timestamp":1627879582984,"user_tz":-540,"elapsed":27,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":["#del model\n","#del optimizer \n","#del train_loader\n","#del val_loader\n","#del scheduler \n","#del list_val_rmse\n","#del train_indices\n","#del val_indices\n","#del tokenizer\n","#torch.cuda.empty_cache()\n","#gpuinfo()"],"execution_count":33,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wXcHyUSJXecL"},"source":["# upload models"]},{"cell_type":"code","metadata":{"id":"YIV6UllSIGoa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627879702613,"user_tz":-540,"elapsed":119655,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"9aabc59d-3b48-4df5-ed54-1cd7c9e95b57"},"source":["%cd\n","!mkdir .kaggle\n","!mkdir /content/model\n","!cp /content/drive/MyDrive/Colab_Files/kaggle-api/kaggle.json .kaggle/\n","\n","!cp -r /content/model_1.pth /content/model/model_1.pth\n","!cp -r /content/model_2.pth /content/model/model_2.pth\n","!cp -r /content/model_3.pth /content/model/model_3.pth\n","!cp -r /content/model_4.pth /content/model/model_4.pth\n","!cp -r /content/model_5.pth /content/model/model_5.pth\n","!cp -r /content/TFIDF_1.pkl /content/model/TFIDF_1.pkl\n","!cp -r /content/TFIDF_2.pkl /content/model/TFIDF_2.pkl\n","!cp -r /content/TFIDF_3.pkl /content/model/TFIDF_3.pkl\n","!cp -r /content/TFIDF_4.pkl /content/model/TFIDF_4.pkl\n","!cp -r /content/TFIDF_5.pkl /content/model/TFIDF_5.pkl"],"execution_count":34,"outputs":[{"output_type":"stream","text":["/root\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"y9OpHdmWTPLE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627882371960,"user_tz":-540,"elapsed":76231,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"f1d48410-8a1d-48e7-d167-44a8ccc81023"},"source":["import shutil\n","model_path_out = Path('/content/model/')\n","dir_ = f'/content/drive/MyDrive/Colab_Files/kaggle/commonlit/98_model_inf/{EX_NO}'\n","!mkdir {dir_}\n","tgdir = Path(dir_)\n","\n","for file_ in list(model_path_out.iterdir()):\n","  shutil.copy(file_, tgdir)"],"execution_count":40,"outputs":[{"output_type":"stream","text":["mkdir: cannot create directory ‘/content/drive/MyDrive/Colab_Files/kaggle/commonlit/98_model_inf/060-train-01’: File exists\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"14ddOZH4IMam","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627882478307,"user_tz":-540,"elapsed":106354,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"6e963a45-35be-4e29-e598-57639e596454"},"source":["def dataset_upload():\n","    import json\n","    from kaggle.api.kaggle_api_extended import KaggleApi\n","\n","    id = f'{USERID}/{EX_NO}-02'\n","    print(id)\n","\n","    dataset_metadata = {}\n","    dataset_metadata['id'] = id\n","    dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n","    dataset_metadata['title'] = f'{EX_NO}'\n","\n","    with open(UPLOAD_DIR / 'dataset-metadata.json', 'w') as f:\n","        json.dump(dataset_metadata, f, indent=4)\n","\n","    api = KaggleApi()\n","    api.authenticate()\n","\n","    # データセットがない場合\n","    if f'{USERID}/{EX_NO}-02' not in [str(d) for d in api.dataset_list(user=USERID, search=f'\"{EX_NO}\"')]:\n","        api.dataset_create_new(folder=UPLOAD_DIR,\n","                               convert_to_csv=False,\n","                               dir_mode='skip')\n","    # データセットがある場合\n","    else:\n","        api.dataset_create_version(folder=UPLOAD_DIR,\n","                                   version_notes='update',\n","                                   convert_to_csv=False,\n","                                   delete_old_versions=True,\n","                                   dir_mode='skip')\n","dataset_upload()\n","\n"],"execution_count":41,"outputs":[{"output_type":"stream","text":["calpis10000/060-train-01-02\n"],"name":"stdout"},{"output_type":"stream","text":["  0%|          | 3.38M/1.33G [00:00<00:44, 32.0MB/s]"],"name":"stderr"},{"output_type":"stream","text":["Starting upload for file model_4.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [00:25<00:00, 55.7MB/s]\n"," 10%|▉         | 56.0k/563k [00:00<00:00, 529kB/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_4.pth (1GB)\n","Starting upload for file TFIDF_5.pkl\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 563k/563k [00:00<00:00, 1.42MB/s]\n","  0%|          | 0.00/559k [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: TFIDF_5.pkl (563KB)\n","Starting upload for file TFIDF_1.pkl\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 559k/559k [00:00<00:00, 2.05MB/s]\n","  0%|          | 0.00/561k [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: TFIDF_1.pkl (559KB)\n","Starting upload for file TFIDF_2.pkl\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 561k/561k [00:00<00:00, 2.61MB/s]\n","  0%|          | 0.00/560k [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: TFIDF_2.pkl (561KB)\n","Starting upload for file TFIDF_3.pkl\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 560k/560k [00:00<00:00, 2.78MB/s]\n","  0%|          | 0.00/1.33G [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: TFIDF_3.pkl (560KB)\n","Starting upload for file model_1.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [00:21<00:00, 65.0MB/s]\n","  0%|          | 0.00/1.33G [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_1.pth (1GB)\n","Starting upload for file model_5.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [00:21<00:00, 65.2MB/s]\n","  0%|          | 0.00/559k [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_5.pth (1GB)\n","Starting upload for file TFIDF_4.pkl\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 559k/559k [00:00<00:00, 2.45MB/s]\n","  0%|          | 0.00/1.33G [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: TFIDF_4.pkl (559KB)\n","Starting upload for file model_3.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [00:17<00:00, 81.5MB/s]\n","  1%|          | 9.62M/1.33G [00:00<00:14, 100MB/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_3.pth (1GB)\n","Starting upload for file model_2.pth\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.33G/1.33G [00:13<00:00, 109MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: model_2.pth (1GB)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"huJwVMSAPuDO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627882295742,"user_tz":-540,"elapsed":185664,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"e8d5fc02-4040-4a4d-cec1-4eb01fda94bd"},"source":["# validation再実行_予測結果取得\n","all_predictions = np.zeros(len(train_kf_df)) # 推論結果について、「fold　× 推論df」のzero行列で枠を作る\n","\n","for fold_ in sorted(train_kf_df['kfold'].unique()):\n","    model_path = UPLOAD_DIR/f\"model_{fold_ + 1}.pth\" # 対応するモデルを読む\n","    feat_path = UPLOAD_DIR/f\"TFIDF_{fold_ + 1}.pkl\" # 対応するモデルを読む\n","    print(f\"\\nUsing {model_path}\")\n","\n","    with open(feat_path, 'rb') as f:\n","      tfidf = pickle.load(f)\n","\n","    val_idx = train_kf_df['kfold'] == fold_\n","    val_df = train_kf_df[val_idx]\n","    val_dataset = LitDataset(val_df, tfidf, inference_only=True) # TestのDataset(何で、もう一回作るのだろう？)\n","    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n","                          drop_last=False, shuffle=False, num_workers=2) # TestのDataLoader\n","\n","    model = LitModel()\n","    model.load_state_dict(torch.load(model_path))    # 対応するモデルから、重みを読み込む\n","    model.to(DEVICE) # モデルをDEVICEへぶち込む\n","\n","    all_predictions[val_idx] = predict(model, val_loader) # 推論結果行列の対象列に、推論結果を入力(以後、繰り返し)\n","\n","    del model\n","    gc.collect()\n"],"execution_count":39,"outputs":[{"output_type":"stream","text":["\n","Using /content/model/model_1.pth\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Using /content/model/model_2.pth\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Using /content/model/model_3.pth\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Using /content/model/model_4.pth\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Using /content/model/model_5.pth\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/clrp-pre-trained/clrp_roberta_large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"0zzuBPobmLFu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627882478310,"user_tz":-540,"elapsed":27,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"6e065d76-61d5-477d-e089-9cc40c889350"},"source":["from sklearn.metrics import mean_squared_error\n","import math\n","np.sqrt(mean_squared_error(train_kf_df.target.values, all_predictions))"],"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.47949374637911873"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"id":"Wpc8ro9hmNci","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627882478311,"user_tz":-540,"elapsed":15,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"c7f63f9d-d400-466d-a3c5-a6b6a86555a2"},"source":["train_kf_df['pred'] = all_predictions\n","fold = 1\n","tg_true = train_kf_df[train_kf_df['kfold']==fold]['target'].values\n","tg_pred = train_kf_df[train_kf_df['kfold']==fold]['pred'].values\n","np.sqrt(mean_squared_error(tg_true, tg_pred))"],"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.4808009859431738"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"code","metadata":{"id":"ceDI72NumT5-","colab":{"base_uri":"https://localhost:8080/","height":298},"executionInfo":{"status":"ok","timestamp":1627882478898,"user_tz":-540,"elapsed":597,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"70a2f19e-10ec-42f5-f605-cb9d196bcfec"},"source":["train_kf_df['pred'] = all_predictions\n","train_kf_df['diff_sq'] = (train_kf_df['target'] - train_kf_df['pred'])**2\n","train_kf_df.plot(kind='scatter', x='target', y='diff_sq')"],"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7fad6f6b5990>"]},"metadata":{"tags":[]},"execution_count":44},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"PvRi_JQgwcKI","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1627882478899,"user_tz":-540,"elapsed":22,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"f60b7b83-af6c-417b-b159-c54fbc95667b"},"source":["# 二乗誤差が2.0を超える列\n","thr_ = 2.0 \n","train_kf_df[train_kf_df['diff_sq'] > thr_]"],"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>url_legal</th>\n","      <th>license</th>\n","      <th>excerpt</th>\n","      <th>target</th>\n","      <th>standard_error</th>\n","      <th>kfold</th>\n","      <th>bins_tg</th>\n","      <th>bins_std</th>\n","      <th>bins</th>\n","      <th>pred</th>\n","      <th>diff_sq</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>59</th>\n","      <td>9ea0d2788</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>The most important bee in the hive is naturall...</td>\n","      <td>0.987862</td>\n","      <td>0.594408</td>\n","      <td>2</td>\n","      <td>10</td>\n","      <td>9</td>\n","      <td>109</td>\n","      <td>-0.439808</td>\n","      <td>2.038241</td>\n","    </tr>\n","    <tr>\n","      <th>141</th>\n","      <td>bcd734621</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Midas was enjoying himself in his treasure-roo...</td>\n","      <td>0.943021</td>\n","      <td>0.537713</td>\n","      <td>0</td>\n","      <td>10</td>\n","      <td>5</td>\n","      <td>105</td>\n","      <td>-0.893063</td>\n","      <td>3.371203</td>\n","    </tr>\n","    <tr>\n","      <th>162</th>\n","      <td>060fc57c6</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>The owner of the island and sheep, A.P. Moore,...</td>\n","      <td>-2.099605</td>\n","      <td>0.472377</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>32</td>\n","      <td>-0.607523</td>\n","      <td>2.226308</td>\n","    </tr>\n","    <tr>\n","      <th>304</th>\n","      <td>f04e03fd8</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Jupiter, two hours high, was the herald of the...</td>\n","      <td>-3.229761</td>\n","      <td>0.551435</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>-1.791918</td>\n","      <td>2.067395</td>\n","    </tr>\n","    <tr>\n","      <th>583</th>\n","      <td>7aad61e03</td>\n","      <td>https://www.commonlit.org/texts/freud-s-theory...</td>\n","      <td>CC BY-NC-SA 2.0</td>\n","      <td>The most primitive part of the human mind, the...</td>\n","      <td>-2.051978</td>\n","      <td>0.508171</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>34</td>\n","      <td>-0.597585</td>\n","      <td>2.115261</td>\n","    </tr>\n","    <tr>\n","      <th>990</th>\n","      <td>afeb324bd</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>On the morning of the 20th of March, a long se...</td>\n","      <td>0.401053</td>\n","      <td>0.481889</td>\n","      <td>0</td>\n","      <td>9</td>\n","      <td>2</td>\n","      <td>92</td>\n","      <td>-1.388508</td>\n","      <td>3.202526</td>\n","    </tr>\n","    <tr>\n","      <th>1008</th>\n","      <td>4ba8e0311</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Bull, John, a fine, fat, American-beef fed ind...</td>\n","      <td>-3.403930</td>\n","      <td>0.599598</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>-1.945527</td>\n","      <td>2.126940</td>\n","    </tr>\n","    <tr>\n","      <th>1152</th>\n","      <td>03b761fd9</td>\n","      <td>https://simple.wikipedia.org/wiki/Larva</td>\n","      <td>CC BY-SA 3.0 and GFDL</td>\n","      <td>Probably the most widely accepted theory expla...</td>\n","      <td>-2.778515</td>\n","      <td>0.533111</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>15</td>\n","      <td>-1.198107</td>\n","      <td>2.497688</td>\n","    </tr>\n","    <tr>\n","      <th>1314</th>\n","      <td>85b41606e</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>As soon as the plate is dry, a positive cliché...</td>\n","      <td>-3.543987</td>\n","      <td>0.609348</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>-2.086170</td>\n","      <td>2.125230</td>\n","    </tr>\n","    <tr>\n","      <th>1347</th>\n","      <td>bae209b89</td>\n","      <td>https://www.africanstorybook.org/</td>\n","      <td>CC BY 4.0</td>\n","      <td>After a night of heavy rain, a group of friend...</td>\n","      <td>1.432604</td>\n","      <td>0.615058</td>\n","      <td>4</td>\n","      <td>11</td>\n","      <td>10</td>\n","      <td>1110</td>\n","      <td>-0.056088</td>\n","      <td>2.216202</td>\n","    </tr>\n","    <tr>\n","      <th>1412</th>\n","      <td>8f35441e3</td>\n","      <td>https://www.africanstorybook.org/#</td>\n","      <td>CC BY 4.0</td>\n","      <td>Every day, Emeka's father took him to school i...</td>\n","      <td>1.583847</td>\n","      <td>0.624776</td>\n","      <td>1</td>\n","      <td>11</td>\n","      <td>10</td>\n","      <td>1110</td>\n","      <td>-0.005833</td>\n","      <td>2.527083</td>\n","    </tr>\n","    <tr>\n","      <th>1821</th>\n","      <td>0c101f2db</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>The \"Legend of Sleepy Hollow\" is a genuine gho...</td>\n","      <td>0.356843</td>\n","      <td>0.481520</td>\n","      <td>3</td>\n","      <td>8</td>\n","      <td>2</td>\n","      <td>82</td>\n","      <td>-1.142581</td>\n","      <td>2.248272</td>\n","    </tr>\n","    <tr>\n","      <th>1944</th>\n","      <td>04ade0eb2</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>While I was hailing the brig, I spied a tract ...</td>\n","      <td>-3.315282</td>\n","      <td>0.544735</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>-1.610090</td>\n","      <td>2.907681</td>\n","    </tr>\n","    <tr>\n","      <th>2124</th>\n","      <td>76f92b721</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>The biggest desert in the world is in Africa, ...</td>\n","      <td>1.103341</td>\n","      <td>0.553751</td>\n","      <td>2</td>\n","      <td>10</td>\n","      <td>6</td>\n","      <td>106</td>\n","      <td>-0.493368</td>\n","      <td>2.549481</td>\n","    </tr>\n","    <tr>\n","      <th>2277</th>\n","      <td>7c732b8bb</td>\n","      <td>https://en.wikipedia.org/wiki/Environmental_sc...</td>\n","      <td>CC BY-SA 3.0</td>\n","      <td>Environmental science is an interdisciplinary ...</td>\n","      <td>-3.137143</td>\n","      <td>0.555843</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>16</td>\n","      <td>-1.431504</td>\n","      <td>2.909204</td>\n","    </tr>\n","    <tr>\n","      <th>2611</th>\n","      <td>034bfda3f</td>\n","      <td>https://www.commonlit.org/texts/everyday-life-...</td>\n","      <td>CC BY-NC-SA 2.0</td>\n","      <td>Even the clothes we wear every day are scrupul...</td>\n","      <td>-1.624428</td>\n","      <td>0.484176</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>43</td>\n","      <td>-0.136803</td>\n","      <td>2.213030</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             id  ...   diff_sq\n","59    9ea0d2788  ...  2.038241\n","141   bcd734621  ...  3.371203\n","162   060fc57c6  ...  2.226308\n","304   f04e03fd8  ...  2.067395\n","583   7aad61e03  ...  2.115261\n","990   afeb324bd  ...  3.202526\n","1008  4ba8e0311  ...  2.126940\n","1152  03b761fd9  ...  2.497688\n","1314  85b41606e  ...  2.125230\n","1347  bae209b89  ...  2.216202\n","1412  8f35441e3  ...  2.527083\n","1821  0c101f2db  ...  2.248272\n","1944  04ade0eb2  ...  2.907681\n","2124  76f92b721  ...  2.549481\n","2277  7c732b8bb  ...  2.909204\n","2611  034bfda3f  ...  2.213030\n","\n","[16 rows x 12 columns]"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cL4lTGKjSAA5","executionInfo":{"status":"ok","timestamp":1627882478900,"user_tz":-540,"elapsed":16,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}},"outputId":"e83d04aa-c056-4b7c-db61-6058870fff67"},"source":["# 二乗誤差が2.0を超える文章\n","thr_ = 2.0 \n","tmp_df = train_kf_df[train_kf_df['diff_sq'] > thr_].copy()\n","for i in tmp_df.index:\n","  print(tmp_df.loc[i].target)\n","  #print(tmp_df.loc[i].standard_error)\n","  print(tmp_df.loc[i].pred)\n","  print(tmp_df.loc[i].excerpt)\n","  print('--------------------------')"],"execution_count":46,"outputs":[{"output_type":"stream","text":["0.987861812\n","-0.4398081302642822\n","The most important bee in the hive is naturally the queen. She is longer and sleeker than the others, and has a crooked sting, of which, however, she seldom makes use. Similar in form, but smaller, are the working-bees, whose sting is straight. The male bee, or drone, is thicker than the others, and stingless.\n","\"What has the queen to do in the hive?\" I asked. The old gentleman replied, \"She is the mother-bee, lays all the eggs, and is so diligent that she often lays twelve hundred in a day, having a separate cell for each egg. That is her only work; for she leaves the whole care of her children to the industrious working-bees, who have various labors to perform. Some of them build cells of wax; others bring in honey on the dust of flowers, called pollen; yet others feed and take care of the young; and a small number act as body-guard to the queen.\"\n","--------------------------\n","0.943020903\n","-0.8930626511573792\n","Midas was enjoying himself in his treasure-room, one day, as usual, when he perceived a shadow fall over the heaps of gold; and, looking suddenly up, what should he behold but the figure of a stranger, standing in the bright and narrow sunbeam! It was a young man, with a cheerful and ruddy face. Whether it was that the imagination of King Midas threw a yellow tinge over everything, or whatever the cause might be, he could not help fancying that the smile with which the stranger regarded him had a kind of golden radiance in it. Certainly, although his figure intercepted the sunshine, there was now a brighter gleam upon all the piled-up treasures than before. Even the remotest corners had their share of it, and were lighted up, when the stranger smiled, as with tips of flame and sparkles of fire.\n","--------------------------\n","-2.099604652\n","-0.6075228452682495\n","The owner of the island and sheep, A.P. Moore, a few years ago purchased the property from the widow of his deceased brother Henry, for $600,000. Owing to ill health, he has rented it to his brother Lawrence for $140,000 a year, and soon starts for Boston, where he will settle down for the rest of his life. He still retains an interest in the Santa Cruz Island ranch, which is about 25 miles southeast of Santa Barbara. This island contains about 64,000 acres, and on it are 25,000 sheep. On Catalina Island, 60 miles east of Santa Barbara, are 15,000 sheep, and on Clementa Island, 80 miles east of that city, are 10,000 sheep. Forty miles west of the same city is San Miguel, on which are 2,000 sheep. Each one of these ranches has a sailing vessel to carry freight, etc., to and fro between the islands and the mainland, and they are kept busy the greater part of the time.\n","--------------------------\n","-3.229761439\n","-1.7919175624847412\n","Jupiter, two hours high, was the herald of the day; the Pleiades, just above the horizon, shed their sweet influence in the east; Lyra sparkled near the zenith; Andromeda veiled her newly discovered glories from the naked eye in the south; the steady Pointers, far beneath the pole, looked meekly up from the depths of the north to their sovereign.\n","Such was the glorious spectacle as I entered the train. As we proceeded, the timid approach of twilight became more perceptible; the intense blue of the sky began to soften; the smaller stars, like little children, went first to rest; the sister-beams of the Pleiades soon melted together; but the bright constellations of the west and north remained unchanged. Steadily the wondrous transfiguration went on. Hands of angels, hidden from mortal eyes, shifted the scenery of the heavens; the glories of night dissolved into the glories of the dawn.\n","--------------------------\n","-2.05197829\n","-0.5975847244262695\n","The most primitive part of the human mind, the id is the source of our bodily needs, wants, desires, and impulses. Freud believed that the id acts according to the \"pleasure principle\" – the psychic force that motivates the tendency to seek immediate gratification of any impulse. The id is the only component of personality that is present from birth, and for good reason. Infants depend on others to provide them with food, to change their diaper, and to avoid pain or discomfort. The id is the part of the mind that compels a baby to cry when he or she is in need of something, ensuring a healthy and happy upbringing.\n","The id, according to Freud, is the most selfish part of our mind. It is only concerned with the immediate satisfaction of whatever want or need the body is experiencing at the moment. Freud stated that the id \"knows no judgements of value: no good and evil, no morality\" – only the fulfillment of immediate desires. Infants, for example, do not consider the needs of their parents when they cry.\n","--------------------------\n","0.401052549\n","-1.388507604598999\n","On the morning of the 20th of March, a long series of earthquakes spread alarm throughout all the cities and numerous villages that are scattered over the sides of Mt. Etna. The shocks followed each other at intervals of a few minutes; dull subterranean rumblings were heard; and a catastrophe was seen to be impending. Toward evening the ground cracked at the lower part of the south side of the mountain, at the limit of the cultivated zone, and at four kilometers to the north of the village of Nicolosi. There formed on the earth a large number of very wide fissures, through which escaped great volumes of steam and gases which enveloped the mountain in a thick haze; and toward night, a very bright red light, which, seen from Catania, seemed to come out in great waves from the foot of the mountain, announced the coming of the lava.\n","--------------------------\n","-3.403929754\n","-1.9455265998840332\n","Bull, John, a fine, fat, American-beef fed individual who inhabits a suffragette-infested island somewhere in the North Atlantic. Born several hundred years ago and is beginning to show his age. Is fond of the sea and is said to have a fine fleet. This has had off years, notably 1812. B. has had trouble with a son who wishes to leave the paternal protection. Is fearless except when faced by a hunger strike, the Pankhurst family, and thoughts of Germany. Patronizes a costly social organization known as the Royal Family, or a reception committee for American heiresstocracy, which also dedicates buildings, poses for stamps, post-cards, motion pictures and raises princesses of Wales for magazine articles and crowning purposes. B. is a monitor of English style; wears a monocle, spats, 'i 'at, cane, pipe, awful accent, and never makes his appearance without a cawld bawth. He detests the word \"egotism.\" Is a celebrated humorist, seeing through all jokes but himself. Ambition: 'Ome sweet 'Ome. Recreation: Tea, Week Ends. Address: Hingland. Clubs: Policemen's, Golf, Jockey, and Suffrage. Epitaph: See Emperor William Again.\n","--------------------------\n","-2.778515087\n","-1.1981074810028076\n","Probably the most widely accepted theory explaining the evolution of larval stages is the need for dispersal. Sessile organisms such as barnacles and tunicates, and sea-floor groups like mussels and crabs, need some way to move their young into new territory, since they cannot move long distances as adults. Many species have relatively long pelagic larval stages (how long a larva is in the water column). During this time, larvae feed and grow, and many species move through several stages of development. For example, most barnacles molt through six nauplius larva stages before molting to a cipris, when they look to settle. The larvae eat different food from the adults, and disperse.\n","The other consideration is the small size of the eggs. If animals lay many small eggs (and most do), then the young stages cannot live the life the adults lead. They must live a separate life until they have the size and capability to live as an adult. This is what the larvae do.\n","--------------------------\n","-3.5439874060000003\n","-2.0861704349517822\n","As soon as the plate is dry, a positive cliché of the drawing to be reproduced is laid upon it, and the whole exposed to the sun for a minute, or to the electric light for three minutes. The reaction produced is the same as with the citrate of iron, but much quicker; the exposed parts are no longer hygroscopic, but in the parts protected by the lines of the drawing the sensitive coating has retained its stickiness, and will hold any powder that may be passed over it, thus producing a very clear image of the drawing. The coating being excessively thin, the little moisture it holds and the powder applied suffice to break its continuity, especially if the powder be slightly alkaline. If the rest of the surface were sufficiently resisting, the plate might be bitten at once; but light alone is not enough to produce complete impermeability: the action of heat must be combined with it. The plate is, therefore, placed on a grating, with wide openings, a large flame is applied underneath, and it is heated till the borders where the copper is bare show iridescent colors.\n","--------------------------\n","1.432603719\n","-0.056087519973516464\n","After a night of heavy rain, a group of friends were on their way to school. \n","They came to the river they had to cross every day. \"Yoh! It's stopped raining, but look how full and fast the river is,\" said Siya. \n","\"Oh no,\" groaned Linda. \"Do you think teacher will be angry if we miss our classes today?\" \n","Linda remembered what the Sea Rescue instructor had taught them in water safety lessons. \n","\"Never cross a flooded river. Even if you can't get to school,\" the instructor had said. \n","Meanwhile, Lungi stepped straight into the river! \"I know where the stepping stones are!\" he yelled. \n","But he soon fell into the water and the strong river began pulling him away. \n","\"Run and get help!\" shouted Linda. \"Tell them to call the free emergency number, like the Sea Rescue lady told us.\" \n","\"Help, help!\" shouted Lungi as he struggled to keep his head above the water. \n","\"Hold on, Lungi!\" shouted Phelelani, as he grabbed a branch that he could use to help his friend. \n","Phelelani's class had been taught that they should never go into the water to help someone as they might also be washed away.\n","--------------------------\n","1.583846826\n","-0.005833478644490242\n","Every day, Emeka's father took him to school in his car. He also brought Emeka home after school. One afternoon on their way home, Emeka's father stopped to buy something at a big shop. From the car, Emeka looked across the road and saw an old man. He was carrying a big load on his head. He was tired and walked slowly. Emeka kept looking at him. The old man sat under the shade of a tree on the walkway and opened his bag. He had two flat plastic water bottles, which he was making into shoes. Emeka thought about that old man for a long time. He felt sad. When he got home, he could not eat. He thought about what he could do. He got up and took some money from his money bag. He called Chita and jumped on his bicycle. Emeka rode to the shop where his father had shopped. The boy ran into the shop and came out with a bag. He went to where the old man was resting against a tree. Emeka called out, \"Good afternoon, sir.\" The man answered, \"Peace to you, my child.\"\n","--------------------------\n","0.356843257\n","-1.1425806283950806\n","The \"Legend of Sleepy Hollow\" is a genuine ghost story. It is not very startling, but very, very funny, when you know what scared poor Ichabod Crane on his midnight ride that last time he went courting Governor Wouter Van Twiller's only daughter.\n","You must read for yourselves the famous story of Rip Van Winkle and the nap he took. It is too long for me to give in Irving's words, and \"Rip Van Winkle\" is just such a story as no one but Irving knows how to tell.\n","In another of his interesting stories in the \"Sketch Book,\" told, he says, by a strange old traveler to as strange a company gathered in a great inn-kitchen, Irving describes the busy making-ready for a wedding. The bride's father, he says, \"had in truth nothing exactly to do.\"\n","Do you suppose he was content to do nothing \"when all the world was in a hurry?\"\n","--------------------------\n","-3.31528229\n","-1.6100900173187256\n","While I was hailing the brig, I spied a tract of water lying between us, where no great waves came, but which yet boiled white all over and bristled in the moon with rings and bubbles. Sometimes the whole tract swung to one side, like the tail of a live serpent; sometimes, for a glimpse, it would all disappear and then boil up again. What it was I had no guess, which for the time increased my fear of it; but I now know it must have been the roost or tide-race, which had carried me away so fast and tumbled me about so cruelly, and at last, as if tired of that play, had flung out me and the spare yard upon its landward margin.\n","I now lay quite becalmed, and began to feel that a man can die of cold as well as of drowning. The shores of Earraid were close in; I could see in the moonlight the dots of heather and the sparkling of the mica in the rocks.\n","--------------------------\n","1.103341259\n","-0.4933680593967438\n","The biggest desert in the world is in Africa, and is called the Sahara. It is almost as large as the Atlantic Ocean, but instead of water it is all sands and rocks. Like the ocean, it is visited with storms; dreadful gales, when the wind scoops up thousands of tons of sand and drives them forward, burying and crushing all they meet. And it has islands, too—small green patches, where springs bubble through the ground, and ferns and acacias and palm-trees grow. When a traveler sees one of these fertile spots afar off, he feels as a tempest-tossed sailor does at sight of land. It is delightful to quit the hot, baking sun, sit in shadow under the trees, and rest the eyes, long wearied with dazzling sands, on the sweet green and the clear spring. Oases, these islands are called. Long distances divide them. It is often a race for life to get across from one to the other.\n","--------------------------\n","-3.1371432610000003\n","-1.431504249572754\n","Environmental science is an interdisciplinary academic field that integrates physical, biological and information sciences (including ecology, biology, physics, chemistry, zoology, mineralogy, oceanology, limnology, soil science, geology, atmospheric science, and geodesy) to the study of the environment, and the solution of environmental problems. Environmental science emerged from the fields of natural history and medicine during the Enlightenment. Today it provides an integrated, quantitative, and interdisciplinary approach to the study of environmental systems.\n","Related areas of study include environmental studies and environmental engineering. Environmental studies incorporate more of the social sciences for understanding human relationships, perceptions and policies towards the environment. Environmental engineering focuses on design and technology for improving environmental quality in every aspect. Environmental scientists work on subjects like the understanding of earth processes, evaluating alternative energy systems, pollution control and mitigation, natural resource management, and the effects of global climate change. Environmental issues almost always include an interaction of physical, chemical, and biological processes.\n","--------------------------\n","-1.624428478\n","-0.13680268824100494\n","Even the clothes we wear every day are scrupulously patterned after Victorian antiques and nineteenth-century fashion plates. Clothes are incredibly intimate. They influence how we move, and at the same time record tiny details about us that seem too mundane to write down — things like whether the items in our pockets are light or heavy, or what we do with our hands when we don't have pockets at all. I sew all my own clothes by hand, and Gabriel's are made for him by a seamstress in Seattle.\n","I'm an author; as with any true writer it's not just my profession but how I experience the world. I keep a diary every day, using an antique mother-of-pearl fountain pen I bought with part of my first book advance. I draft a lot of my manuscripts the same way: I enjoy this tangible connection to my words. (There have been some really interesting studies done showing the human brain processes information more thoroughly when it's written by hand as opposed to typed.) When I take notes from antique books and magazines I use a pencil to avoid dribbling ink on irreplaceable antique volumes.\n","--------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"d89ElwoOUPDx","executionInfo":{"status":"aborted","timestamp":1627879893622,"user_tz":-540,"elapsed":287,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"}}},"source":[""],"execution_count":null,"outputs":[]}]}